  Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more Page semi-protected Artificial intelligence From Wikipedia, the free encyclopedia Jump to navigationJump to search Part of a series on Artificial intelligence Anatomy-1751201 1280.png Major goals Artificial general intelligencePlanningComputer visionGeneral game playingKnowledge reasoningMachine learningNatural language processingRobotics Approaches SymbolicDeep learningBayesian networksEvolutionary algorithms Philosophy Chinese roomFriendly AIControl problem/TakeoverEthicsExistential riskTuring test History TimelineProgressAI winter Technology ApplicationsProjectsProgramming languages Glossary Glossary vte "AI" redirects here. For other uses, see AI (disambiguation) and Artificial intelligence (disambiguation). Artificial intelligence (AI) is intelligence demonstrated by machines, as opposed to the natural intelligence displayed by animals including humans. Leading AI textbooks define the field as the study of "intelligent agents": any system that perceives its environment and takes actions that maximize its chance of achieving its goals.[a] Some popular accounts use the term "artificial intelligence" to describe machines that mimic "cognitive" functions that humans associate with the human mind, such as "learning" and "problem solving", however this definition is rejected by major AI researchers.[b]  AI applications include advanced web search engines (i.e. Google), recommendation systems (used by YouTube, Amazon and Netflix), understanding human speech (such as Siri or Alexa), self-driving cars (e.g. Tesla), automated decision-making and competing at the highest level in strategic game systems (such as chess and Go).[2] As machines become increasingly capable, tasks considered to require "intelligence" are often removed from the definition of AI, a phenomenon known as the AI effect.[3] For instance, optical character recognition is frequently excluded from things considered to be AI,[4] having become a routine technology.[5]  Artificial intelligence was founded as an academic discipline in 1956, and in the years since has experienced several waves of optimism,[6][7] followed by disappointment and the loss of funding (known as an "AI winter"),[8][9] followed by new approaches, success and renewed funding.[7][10] AI research has tried and discarded many different approaches during its lifetime, including simulating the brain, modeling human problem solving, formal logic, large databases of knowledge and imitating animal behavior. In the first decades of the 21st century, highly mathematical statistical machine learning has dominated the field, and this technique has proved highly successful, helping to solve many challenging problems throughout industry and academia.[11][10]  The various sub-fields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception and the ability to move and manipulate objects.[c] General intelligence (the ability to solve an arbitrary problem) is among the field's long-term goals.[12] To solve these problems, AI researchers use versions of search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, probability and economics. AI also draws upon computer science, psychology, linguistics, philosophy, and many other fields.  The field was founded on the assumption that human intelligence "can be so precisely described that a machine can be made to simulate it".[d] This raises philosophical arguments about the mind and the ethics of creating artificial beings endowed with human-like intelligence. These issues have been explored by myth, fiction and philosophy since antiquity.[14] Science fiction and futurology have also suggested that, with its enormous potential and power, AI may become an existential risk to humanity.[15][16]   Contents 1	History 1.1	Precursors 1.2	Symbolic AI 1.3	Early subsymbolic 1.4	Statistical AI 1.5	Artificial general intelligence research 2	Goals 2.1	Reasoning, problem solving 2.2	Knowledge representation 2.3	Planning 2.4	Learning 2.5	Natural language processing 2.6	Perception 2.7	Motion and manipulation 2.8	Social intelligence 2.9	General intelligence 3	Tools 3.1	Search and optimization 3.2	Logic 3.3	Probabilistic methods for uncertain reasoning 3.4	Classifiers and statistical learning methods 3.5	Artificial neural networks 4	Applications 4.1	High profile applications 4.2	Uses throughout industry and academia 4.3	Notable experimental applications 5	Philosophy 5.1	Defining artificial intelligence 5.2	Evaluating approaches to AI 5.3	Machine consciousness, sentience and mind 6	Future of AI 6.1	Superintelligence 6.2	Risks 6.3	Ethical machines 6.4	Regulation 7	In fiction 8	See also 9	Explanatory notes 10	Citations 11	References 11.1	AI textbooks 11.2	History of AI 11.3	Other sources 12	Further reading 13	External links 14	Sources History Main articles: History of artificial intelligence and Timeline of artificial intelligence  Silver didrachma from Crete depicting Talos, an ancient mythical automaton with artificial intelligence Precursors Artificial beings with intelligence appeared as storytelling devices in antiquity,[17] and have been common in fiction, as in Mary Shelley's Frankenstein or Karel Čapek's R.U.R.[18] These characters and their fates raised many of the same issues now discussed in the ethics of artificial intelligence.[19]  The study of mechanical or "formal" reasoning began with philosophers and mathematicians in antiquity. The study of mathematical logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as "0" and "1", could simulate any conceivable act of mathematical deduction. This insight, that digital computers can simulate any process of formal reasoning, is known as the Church–Turing thesis.[20]  The Church-Turing thesis, along with concurrent discoveries in neurobiology, information theory and cybernetics, led researchers to consider the possibility of building an electronic brain.[21] The first work that is now generally recognized as AI was McCullouch and Pitts' 1943 formal design for Turing-complete "artificial neurons".[22]  Symbolic AI Main article: Symbolic AI When access to digital computers became possible in the mid-1950s, AI research began to explore the possibility that human intelligence could be reduced to symbol manipulation. Approaches based on cybernetics or artificial neural networks were abandoned or pushed into the background.  The field of AI research was born at a workshop at Dartmouth College in 1956.[e][25] The attendees became the founders and leaders of AI research.[f] They and their students produced programs that the press described as "astonishing":[g] computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English.[h][27] By the middle of the 1960s, research in the U.S. was heavily funded by the Department of Defense[28] and laboratories had been established around the world.[29]  Researchers in the 1960s and the 1970s were convinced that symbolic approaches would eventually succeed in creating a machine with artificial general intelligence and considered this the goal of their field.[30] Herbert Simon predicted, "machines will be capable, within twenty years, of doing any work a man can do".[31] Marvin Minsky agreed, writing, "within a generation ... the problem of creating 'artificial intelligence' will substantially be solved".[32]  They failed to recognize the difficulty of some of the remaining tasks. Progress slowed and in 1974, in response to the criticism of Sir James Lighthill[33] and ongoing pressure from the US Congress to fund more productive projects, both the U.S. and British governments cut off exploratory research in AI. The next few years would later be called an "AI winter", a period when obtaining funding for AI projects was difficult. [8]  In the early 1980s, AI research was revived by the commercial success of expert systems,[34] a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S and British governments to restore funding for academic research.[7] However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.[9]  Early subsymbolic Many researchers began to doubt that the symbolic approach would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition. A number of researchers began to look into "sub-symbolic" approaches to specific AI problems.[35] Robotics researchers, such as Rodney Brooks, rejected symbolic AI and focused on the basic engineering problems that would allow robots to move, survive, and learn their environment.[i] Interest in neural networks and "connectionism" was revived by Geoffrey Hinton, David Rumelhart and others in the middle of the 1980s.[40] Soft computing tools were developed in the 80s, such as neural networks, fuzzy systems, Grey system theory, evolutionary computation and many tools drawn from statistics or mathematical optimization.  Statistical AI AI gradually restored its reputation in the late 1990s and early 21st century by finding specific solutions to specific problems. The narrow focus allowed researchers to produce verifiable results, exploit more mathematical methods, and collaborate with other fields (such as statistics, economics and mathematics).[41] By 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as "artificial intelligence".[11]  Faster computers, algorithmic improvements, and access to large amounts of data enabled advances in machine learning and perception; data-hungry deep learning methods started to dominate accuracy benchmarks around 2012.[42] According to Bloomberg's Jack Clark, 2015 was a landmark year for artificial intelligence, with the number of software projects that use AI within Google increased from a "sporadic usage" in 2012 to more than 2,700 projects.[j] He attributes this to an increase in affordable neural networks, due to a rise in cloud computing infrastructure and to an increase in research tools and datasets.[10] In a 2017 survey, one in five companies reported they had "incorporated AI in some offerings or processes".[43] The amount of research into AI (measured by total publications) increased by 50% in the years 2015–2019.[44]  Artificial general intelligence research Main article: Artificial general intelligence Numerous academic researchers became concerned that AI was no longer pursuing the original goal of creating versatile, fully intelligent machines. Much of current research involves statistical AI, which is overwhelmingly used to solve specific problems, even highly successful techniques such as deep learning. This concern has led to the subfield artificial general intelligence (or "AGI"), which had several well-funded institutions by the 2010s.[12]  Goals The general problem of simulating (or creating) intelligence has been broken down into sub-problems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention.[c]  Reasoning, problem solving Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions.[45] By the late 1980s and 1990s, AI research had developed methods for dealing with uncertain or incomplete information, employing concepts from probability and economics.[46]  Many of these algorithms proved to be insufficient for solving large reasoning problems because they experienced a "combinatorial explosion": they became exponentially slower as the problems grew larger.[47] Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.[48]   An ontology represents knowledge as a set of concepts within a domain and the relationships between those concepts. Knowledge representation Main articles: Knowledge representation, Commonsense knowledge, Description logic, and ontology Knowledge representation and knowledge engineering[49] allow AI programs to answer questions intelligently and make deductions about real world facts.  A representation of "what exists" is an ontology: the set of objects, relations, concepts, and properties formally described so that software agents can interpret them.[50] The most general ontologies are called upper ontologies, which attempt to provide a foundation for all other knowledge and act as mediators between domain ontologies that cover specific knowledge about a particular knowledge domain (field of interest or area of concern). A truly intelligent program would also need access to commonsense knowledge; the set of facts that an average person knows. The semantics of an ontology is typically represented in a description logic, such as the Web Ontology Language.[51]  AI research has developed tools to represent specific domains, such as: objects, properties, categories and relations between objects;[51] situations, events, states and time;[52] causes and effects;[53] knowledge about knowledge (what we know about what other people know);.[54] default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing); [55] as well as other domains. Among the most difficult problems in AI are: the breadth of commonsense knowledge (the number of atomic facts that the average person knows is enormous);[56] and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as "facts" or "statements" that they could express verbally).[48]  Formal knowledge representations are used in content-based indexing and retrieval,[57] scene interpretation,[58] clinical decision support,[59] knowledge discovery (mining "interesting" and actionable inferences from large databases),[60] and other areas.[61]  Planning Main article: Automated planning and scheduling An intelligent agent that can plan makes a representation of the state of the world, makes predictions about how their actions will change it and makes choices that maximize the utility (or "value") of the available choices.[62] In classical planning problems, the agent can assume that it is the only system acting in the world, allowing the agent to be certain of the consequences of its actions.[63] However, if the agent is not the only actor, then it requires that the agent reason under uncertainty, and continuously re-assess its environment and adapt.[64] Multi-agent planning uses the cooperation and competition of many agents to achieve a given goal. Emergent behavior such as this is used by evolutionary algorithms and swarm intelligence.[65]  Learning Main article: Machine learning Machine learning (ML), a fundamental concept of AI research since the field's inception,[k] is the study of computer algorithms that improve automatically through experience.[l]  Unsupervised learning finds patterns in a stream of input. Supervised learning requires a human to label the input data first, and comes in two main varieties: classification and numerical regression. Classification is used to determine what category something belongs in -- the program sees a number of examples of things from several categories and will learn to classify new inputs. Regression is the attempt to produce a function that describes the relationship between inputs and outputs and predicts how the outputs should change as the inputs change. Both classifiers and regression learners can be viewed as "function approximators" trying to learn an unknown (possibly implicit) function; for example, a spam classifier can be viewed as learning a function that maps from the text of an email to one of two categories, "spam" or "not spam".[69] In reinforcement learning the agent is rewarded for good responses and punished for bad ones. The agent classifies its responses to form a strategy for operating in its problem space.[70] Transfer learning is when knowledge gained from one problem is applied to a new problem.[71]  Computational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.[72]   A parse tree represents the syntactic structure of a sentence according to some formal grammar. Natural language processing Main article: Natural language processing Natural language processing (NLP)[73] allows machines to read and understand human language. A sufficiently powerful natural language processing system would enable natural-language user interfaces and the acquisition of knowledge directly from human-written sources, such as newswire texts. Some straightforward applications of NLP include information retrieval, question answering and machine translation.[74]  Symbolic AI used formal syntax to translate the deep structure of sentences into logic. This failed to produce useful applications, due to the intractability of logic[47] and the breadth of commonsense knowledge.[56] Modern statistical techniques include co-occurrence frequencies (how often one word appears near another), "Keyword spotting" (searching for a particular word to retrieve information), transformer-based deep learning (which finds patterns in text), and others.[75] They have achieved acceptable accuracy at the page or paragraph level, and, by 2019, could generate coherent text.[76]   Feature detection (pictured: edge detection) helps AI compose informative abstract structures out of raw data. Perception Main articles: Machine perception, Computer vision, and Speech recognition Machine perception[77] is the ability to use input from sensors (such as cameras, microphones, wireless signals, and active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Applications include speech recognition,[78] facial recognition, and object recognition.[79]  Computer vision is the ability to analyze visual input.[80]  Motion and manipulation Main article: Robotics AI is heavily used in robotics.[81] Localization is how a robot knows its location and map its environment. When given a small, static, and visible environment, this is easy; however, dynamic environments, such as (in endoscopy) the interior of a patient's breathing body, pose a greater challenge.[82]  Motion planning is the process of breaking down a movement task into "primitives" such as individual joint movements. Such movement often involves compliant motion, a process where movement requires maintaining physical contact with an object. Robots can learn from experience how to move efficiently despite the presence of friction and gear slippage.[83]   Kismet, a robot with rudimentary social skills[84] Social intelligence Main article: Affective computing Affective computing is an interdisciplinary umbrella that comprises systems which recognize, interpret, process, or simulate human feeling, emotion and mood.[85] For example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human–computer interaction. However, this tends to give naïve users an unrealistic conception of how intelligent existing computer agents actually are.[86]  Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis), wherein AI classifies the affects displayed by a videotaped subject.[87]  General intelligence Main article: Artificial general intelligence A machine with general intelligence can solve a wide variety of problems with a breadth and versatility similar to human intelligence. There are several competing ideas about how to develop artificial general intelligence. Hans Moravec and Marvin Minsky argue that work in different individual domains can be incorporated into an advanced multi-agent system or cognitive architecture with general intelligence.[88] Pedro Domingos hopes that there is a conceptually straightforward, but mathematically difficult, "master algorithm" that could lead to AGI.[89] Others believe that anthropomorphic features like an artificial brain[90] or simulated child development[m] will someday reach a critical point where general intelligence emerges.  Tools Search and optimization Main articles: Search algorithm, Mathematical optimization, and Evolutionary computation Many problems in AI can be solved theoretically by intelligently searching through many possible solutions:[91] Reasoning can be reduced to performing a search. For example, logical proof can be viewed as searching for a path that leads from premises to conclusions, where each step is the application of an inference rule.[92] Planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis.[93] Robotics algorithms for moving limbs and grasping objects use local searches in configuration space.[94]  Simple exhaustive searches[95] are rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes. The solution, for many problems, is to use "heuristics" or "rules of thumb" that prioritize choices in favor of those more likely to reach a goal and to do so in a shorter number of steps. In some search methodologies heuristics can also serve to eliminate some choices unlikely to lead to a goal (called "pruning the search tree"). Heuristics supply the program with a "best guess" for the path on which the solution lies.[96] Heuristics limit the search for solutions into a smaller sample size.[97]   A particle swarm seeking the global minimum A very different kind of search came to prominence in the 1990s, based on the mathematical theory of optimization. For many problems, it is possible to begin the search with some form of a guess and then refine the guess incrementally until no more refinements can be made. These algorithms can be visualized as blind hill climbing: we begin the search at a random point on the landscape, and then, by jumps or steps, we keep moving our guess uphill, until we reach the top. Other optimization algorithms are simulated annealing, beam search and random optimization.[98] Evolutionary computation uses a form of optimization search. For example, they may begin with a population of organisms (the guesses) and then allow them to mutate and recombine, selecting only the fittest to survive each generation (refining the guesses). Classic evolutionary algorithms include genetic algorithms, gene expression programming, and genetic programming.[99] Alternatively, distributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking) and ant colony optimization (inspired by ant trails).[100]  Logic Main articles: Logic programming and Automated reasoning Logic[101] is used for knowledge representation and problem solving, but it can be applied to other problems as well. For example, the satplan algorithm uses logic for planning[102] and inductive logic programming is a method for learning.[103]  Several different forms of logic are used in AI research. Propositional logic[104] involves truth functions such as "or" and "not". First-order logic[105] adds quantifiers and predicates, and can express facts about objects, their properties, and their relations with each other. Fuzzy logic assigns a "degree of truth" (between 0 and 1) to vague statements such as "Alice is old" (or rich, or tall, or hungry), that are too linguistically imprecise to be completely true or false.[106] Default logics, non-monotonic logics and circumscription are forms of logic designed to help with default reasoning and the qualification problem. [55] Several extensions of logic have been designed to handle specific domains of knowledge, such as: description logics;[51] situation calculus, event calculus and fluent calculus (for representing events and time);[52] causal calculus;[53] belief calculus (belief revision); and modal logics.[54] Logics to model contradictory or inconsistent statements arising in multi-agent systems have also been designed, such as paraconsistent logics.[citation needed]  Probabilistic methods for uncertain reasoning Main articles: Bayesian network, Hidden Markov model, Kalman filter, Particle filter, Decision theory, and Utility theory  Expectation-maximization clustering of Old Faithful eruption data starts from a random guess but then successfully converges on an accurate clustering of the two physically distinct modes of eruption. Many problems in AI (in reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of powerful tools to solve these problems using methods from probability theory and economics.[107] Bayesian networks[108] are a very general tool that can be used for various problems: reasoning (using the Bayesian inference algorithm),[n][110] learning (using the expectation-maximization algorithm),[o][112] planning (using decision networks)[113] and perception (using dynamic Bayesian networks).[114] Probabilistic algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping perception systems to analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).[114]  A key concept from the science of economics is "utility": a measure of how valuable something is to an intelligent agent. Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis,[115] and information value theory.[116] These tools include models such as Markov decision processes,[117] dynamic decision networks,[114] game theory and mechanism design.[118]  Classifiers and statistical learning methods Main articles: Classifier (mathematics), Statistical classification, and Machine learning The simplest AI applications can be divided into two types: classifiers ("if shiny then diamond") and controllers ("if diamond then pick up"). Controllers do, however, also classify conditions before inferring actions, and therefore classification forms a central part of many AI systems. Classifiers are functions that use pattern matching to determine a closest match. They can be tuned according to examples, making them very attractive for use in AI. These examples are known as observations or patterns. In supervised learning, each pattern belongs to a certain predefined class. A class is a decision that has to be made. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.[119]  A classifier can be trained in various ways; there are many statistical and machine learning approaches. The decision tree is the simplest and most widely used symbolic machine learning algorithm.[120] K-nearest neighbor algorithm was the most widely used analogical AI until the mid-1990s.[121] Kernel methods such as the support vector machine (SVM) displaced k-nearest neighbor in the 1990s.[122] The naive Bayes classifier is reportedly the "most widely used learner"[123] at Google, due in part to its scalability.[124] Neural networks are also used for classification.[125]  Classifier performance depends greatly on the characteristics of the data to be classified, such as the dataset size, distribution of samples across classes, the dimensionality, and the level of noise. Model-based classifiers perform well if the assumed model is an extremely good fit for the actual data. Otherwise, if no matching model is available, and if accuracy (rather than speed or scalability) is the sole concern, conventional wisdom is that discriminative classifiers (especially SVM) tend to be more accurate than model-based classifiers such as "naive Bayes" on most practical data sets.[126]  Artificial neural networks Main articles: Artificial neural network and Connectionism  A neural network is an interconnected group of nodes, akin to the vast network of neurons in the human brain. Neural networks[125] were inspired by the architecture of neurons in the human brain. A simple "neuron" N accepts input from other neurons, each of which, when activated (or "fired"), casts a weighted "vote" for or against whether neuron N should itself activate. Learning requires an algorithm to adjust these weights based on the training data; one simple algorithm (dubbed "fire together, wire together") is to increase the weight between two connected neurons when the activation of one triggers the successful activation of another. Neurons have a continuous spectrum of activation; in addition, neurons can process inputs in a nonlinear way rather than weighing straightforward votes.  Modern neural networks model complex relationships between inputs and outputs or and find patterns in data. They can learn continuous functions and even digital logical operations. Neural networks can be viewed a type of mathematical optimization — they perform a gradient descent on a multi-dimensional topology that was created by training the network. The most common training technique is the backpropagation algorithm.[127] Other learning techniques for neural networks are Hebbian learning ("fire together, wire together"), GMDH or competitive learning.[128]  The main categories of networks are acyclic or feedforward neural networks (where the signal passes in only one direction) and recurrent neural networks (which allow feedback and short-term memories of previous input events). Among the most popular feedforward networks are perceptrons, multi-layer perceptrons and radial basis networks.[129]  Deep feedforward neural networks Main article: Deep learning Deep learning is the use of artificial neural networks which have several layers of neurons between the network's inputs and outputs. Deep learning has drastically improved the performance of programs in many important subfields of artificial intelligence, including computer vision, speech recognition, natural language processing and others.[130] According to one overview,[131] the expression "Deep Learning" was introduced to the machine learning community by Rina Dechter in 1986[132] and gained traction after Igor Aizenberg and colleagues introduced it to artificial neural networks in 2000.[133] The first functional deep Learning networks were published by Alexey Grigorevich Ivakhnenko and V. G. Lapa in 1965.[134] These networks are trained one layer at a time. Ivakhnenko's 1971 paper[135] describes the learning of a deep feedforward multilayer perceptron with eight layers, already much deeper than many later networks. In 2006, a publication by Geoffrey Hinton and Ruslan Salakhutdinov introduced another way of pre-training many-layered feedforward neural networks (FNNs) one layer at a time, treating each layer in turn as an unsupervised restricted Boltzmann machine, then using supervised backpropagation for fine-tuning.[136] Similar to shallow artificial neural networks, deep neural networks can model complex non-linear relationships.  Deep learning often uses convolutional neural networks (CNNs), whose origins can be traced back to the Neocognitron introduced by Kunihiko Fukushima in 1980.[137] In 1989, Yann LeCun and colleagues applied backpropagation to such an architecture. In the early 2000s, in an industrial application, CNNs already processed an estimated 10% to 20% of all the checks written in the US.[138] Since 2011, fast implementations of CNNs on GPUs have won many visual pattern recognition competitions.  CNNs with 12 convolutional layers were used with reinforcement learning by Deepmind's "AlphaGo Lee", the program that beat a top Go champion in 2016.[139]  Deep recurrent neural networks Main article: Recurrent neural networks Early on, deep learning was also applied to sequence learning with recurrent neural networks (RNNs)[140] which are theoretically Turing complete[141] and can run arbitrary programs to process arbitrary sequences of inputs. The depth of an RNN is unlimited and depends on the length of its input sequence; thus, an RNN is an example of deep learning.[142] RNNs can be trained by gradient descent[143] but suffer from the vanishing gradient problem.[144] In 1992, it was shown that unsupervised pre-training of a stack of recurrent neural networks can speed up subsequent supervised learning of deep sequential problems.[145]  Numerous researchers now use variants of a deep learning recurrent NN called the long short-term memory (LSTM) network published by Hochreiter & Schmidhuber in 1997.[146] LSTM is often trained by Connectionist Temporal Classification (CTC).[147] At Google, Microsoft and Baidu this approach has revolutionized speech recognition.[148]  For example, in 2015, Google's speech recognition experienced a dramatic performance jump of 49% through CTC-trained LSTM. Google also used LSTM to improve machine translation,[149] Language Modeling,[150] and Multilingual Language Processing.[151] LSTM combined with CNNs also improved automatic image captioning[152] and a plethora of other applications.  Applications  For this project the AI had to learn the typical patterns in the colors and brushstrokes of Renaissance painter Raphael. The portrait shows the face of the actress Ornella Muti, "painted" by AI in the style of Raphael. Main article: Applications of artificial intelligence AI is relevant to any intellectual task.[153] Modern artificial intelligence techniques are pervasive and are too numerous to list here.[154] Frequently, when a technique reaches mainstream use, it is no longer considered artificial intelligence; this phenomenon is described as the AI effect.[155]  High profile applications In the 2010s, AI applications were at the heart of the most commercially successful areas of computing, and have become a ubiquitous feature of daily life. AI is used in search engines (such as Google Search), targeting online advertisements,[156] recommendation systems (offered by Netflix, YouTube or Amazon), driving internet traffic,[157][158] targeted advertising (AdSense, Facebook), virtual assistants (such as Siri or Alexa),[159] autonomous vehicles (including drones and self-driving cars), automatic language translation (Microsoft Translator, Google Translate), facial recognition (Apple's Face ID or Microsoft's DeepFace), image labeling (used by Facebook, Apple's iPhoto and TikTok) and spam filtering.  Uses throughout industry and academia There are also thousands of successful AI applications used to solve problems for specific industries or institutions. A few examples are: energy storage,[160] deepfakes,[161] medical diagnosis, military logistics, or supply chain management, solving Wicked problem through harnessing Wisdom of the crowd.  Notable experimental applications Game playing has been a test of AI's strength since the 1950s. Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997.[162] In 2011, in a Jeopardy! quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin.[163] In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps.[164] Other programs handle imperfect-information games; such as for poker at a superhuman level, Pluribus[p] and Cepheus.[166] DeepMind in the 2010s developed a "generalized artificial intelligence" that could learn many diverse Atari games on its own.[167]  By 2020, Natural Language Processing systems such as the enormous GPT-3 (then by far the largest artificial neural network) were matching human performance on pre-existing benchmarks, albeit without the system attaining commonsense understanding of the contents of the benchmarks.[168] DeepMind's AlphaFold 2 (2020) demonstrated the ability to determine, in hours rather than months, the 3D structure of a protein.[169] Other applications predict the result of judicial decisions,[170] create art (such as poetry or painting) and prove mathematical theorems.  Philosophy Main article: Philosophy of artificial intelligence Defining artificial intelligence Thinking vs. acting: the Turing test Main articles: Turing test, Dartmouth Workshop, and Synthetic intelligence Alan Turing wrote in 1950 "I propose to consider the question 'can machines think'?"[171] He advised changing the question from whether a machine "thinks", to "whether or not it is possible for machinery to show intelligent behaviour".[172] The only thing visible is the behavior of the machine, so it does not matter if the machine is conscious, or has a mind, or whether the intelligence is merely a "simulation" and not "the real thing". He noted that we also don't know these things about other people, but that we extend a "polite convention" that they are actually "thinking". This idea forms the basis of the Turing test.[173][q]  Acting humanly vs. acting intelligently: intelligent agents Main article: Intelligent agents AI founder John McCarthy said: "Artificial intelligence is not, by definition, simulation of human intelligence".[175] Russell and Norvig agree and criticize the Turing test. They wrote: "Aeronautical engineering texts do not define the goal of their field as 'making machines that fly so exactly like pigeons that they can fool other pigeons.'"[174] Other researchers and analysts disagree and have argued that AI should simulate natural intelligence by studying psychology or neurobiology.[r]  The intelligent agent paradigm[177] defines intelligent behavior in general, without reference to human beings. An intelligent agent is a system that perceives its environment and takes actions that maximize its chances of success. Any system that has goal-directed behavior can be analyzed as an intelligent agent: something as simple as a thermostat, as complex as a human being, as well as large systems such as firms, biomes or nations. The intelligent agent paradigm became widely accepted during the 1990s, and currently serves as the definition of the field.[a]  The paradigm has other advantages for AI. It provides a reliable and scientific way to test programs; researchers can directly compare or even combine different approaches to isolated problems, by asking which agent is best at maximizing a given "goal function". It also gives them a common language to communicate with other fields — such as mathematical optimization (which is defined in terms of "goals") or economics (which uses the same definition of a "rational agent").[178]  Evaluating approaches to AI No established unifying theory or paradigm has guided AI research for most of its history.[s] The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term "artificial intelligence" to mean "machine learning with neural networks"). This approach is mostly sub-symbolic, neat, soft and narrow (see below). Critics argue that these questions may have to be revisited by future generations of AI researchers.  Symbolic AI and its limits Main articles: Symbolic AI, Physical symbol systems hypothesis, Moravec's paradox, and Dreyfus' critique of artificial intelligence Symbolic AI (or "GOFAI")[180] simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at "intelligent" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis: "A physical symbol system has the necessary and sufficient means of general intelligent action."[181]  However, the symbolic approach failed dismally on many tasks that humans solve easily, such as learning, recognizing an object or commonsense reasoning. Moravec's paradox is the discovery that high-level "intelligent" tasks were easy for AI, but low level "instinctive" tasks were extremely difficult.[182] Philosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a "feel" for the situation, rather than explicit symbolic knowledge.[183] Although his arguments had been ridiculed and ignored when they were first presented, eventually AI research came to agree.[t][48]  The issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes that human intuition does, such as algorithmic bias. Critics such Noam Chomsky argue continuing research into symbolic AI will still be necessary to attain general intelligence,[185][186] in part because sub-symbolic AI is a move away from explainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision.  Neat vs. scruffy Main article: Neats and scruffies "Neats" hope that intelligent behavior be described using simple, elegant principles (such as logic, optimization, or neural networks). "Scruffies" expect that it necessarily requires solving a large number of unrelated problems. This issue was actively discussed in the 70s and 80s,[187] but in the 1990s mathematical methods and solid scientific standards became the norm, a transition that Russell and Norvig termed "the victory of the neats".[188]  Soft vs. hard computing Main article: Soft computing Finding a provably correct or optimal solution is intractable for many important problems. [47] Soft computing is a set of techniques, including genetic algorithms, fuzzy logic and neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 80s and most successful AI programs in the 21st century are examples of soft computing with neural networks.  Narrow vs. general AI Main article: Artificial general intelligence Ai researchers are divided as to whether to pursue the goals of artificial general intelligence and superintelligence (general AI) directly, or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field's long-term goals[189][190] General intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focussing on specific problems with specific solutions. The experimental sub-field of artificial general intelligence studies this area exclusively.  Machine consciousness, sentience and mind Main articles: Philosophy of artificial intelligence and Artificial Consciousness The philosophy of mind does not know whether a machine can have a mind, consciousness and mental states, in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant, because it does not effect the goals of the field. Stuart Russell and Peter Norvig observe that most AI researchers "don't care about the [philosophy of AI] — as long as the program works, they don't care whether you call it a simulation of intelligence or real intelligence."[191] However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction.  Consciousness Main articles: Hard problem of consciousness and Theory of mind David Chalmers identified two problems in understanding the mind, which he named the "hard" and "easy" problems of consciousness.[192] The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all. Human information processing is easy to explain, however human subjective experience is difficult to explain. For example, it is easy to imagine a color blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to know what red looks like.[193]  Computationalism and functionalism Main articles: Computationalism, Functionalism (philosophy of mind), and Chinese room Computationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind-body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.[194]  Philosopher John Searle characterized this position as "strong AI": "The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds."[u] Searle counters this assertion with his Chinese room argument, which attempts to show that, even if a machine perfectly simulates human behavior, there is still no reason to suppose it also has a mind.[197]  Robot rights Main article: Robot rights If a machine has a mind and subjective experience, then it may also have sentience (the ability to feel), and if so, then it could also suffer, and thus it would be entitled to certain rights.[198] Any hypothetical robot rights would lie on a spectrum with animal rights and human rights.[199] This issue has been considered in fiction for centuries,[200] and is now being considered by, for example, California's Institute for the Future, however critics argue that the discussion is premature.[201]  Future of AI Superintelligence Main articles: Superintelligence, Technological singularity, and Transhumanism A superintelligence, hyperintelligence, or superhuman intelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind. Superintelligence may also refer to the form or degree of intelligence possessed by such an agent.[190]  If research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to recursive self-improvement.[202] Its intelligence would increase exponentially in an intelligence explosion and could dramatically surpass humans. Science fiction writer Vernor Vinge named this scenario the "singularity".[203] Because it is difficult or impossible to know the limits of intelligence or the capabilities of superintelligent machines, the technological singularity is an occurrence beyond which events are unpredictable or even unfathomable.[204]  Robot designer Hans Moravec, cyberneticist Kevin Warwick, and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, has roots in Aldous Huxley and Robert Ettinger.[205]  Edward Fredkin argues that "artificial intelligence is the next stage in evolution", an idea first proposed by Samuel Butler's "Darwin among the Machines" as far back as 1863, and expanded upon by George Dyson in his book of the same name in 1998.[206]  Risks Technological unemployment Main articles: Workplace impact of artificial intelligence and Technological unemployment In the past technology has tended to increase rather than reduce total employment, but economists acknowledge that "we're in uncharted territory" with AI.[207] A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit, if productivity gains are redistributed.[208] Subjective estimates of the risk vary widely; for example, Michael Osborne and Carl Benedikt Frey estimate 47% of U.S. jobs are at "high risk" of potential automation, while an OECD report classifies only 9% of U.S. jobs as "high risk".[v][210]  Unlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist states that "the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution" is "worth taking seriously".[211] Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.[212]  Bad actors and weaponized AI Main articles: lethal autonomous weapon and artificial intelligence arms race AI provides a number of tools that are particularly useful for authoritarian governments: smart spyware, face recognition and voice recognition allow widespread surveillance; such surveillance allows machine learning to classify potential enemies of the state and can prevent them from hiding; recommendation systems can precisely target propaganda and misinformation for maximum effect; deepfakes aid in producing misinformation; advanced AI can make centralized decision making more competitive with liberal and decentralized systems such as markets.[213]  Terrorists, criminals and rogue states may use other forms of weaponized AI such as advanced digital warfare and lethal autonomous weapons. By 2015, over fifty countries were reported to be researching battlefield robots.[214]  Algorithmic bias Main article: algorithmic bias AI programs can become biased after learning from real world data. It is not typically introduced by the system designers, but is learned by the program, and thus the programmers are often unaware that the bias exists.[215] Bias can be inadvertently introduced by the way training data is selected.[216] It can also emerge from correlations: AI is used to classify individuals into groups and then make predictions assuming that the individual will resemble other members of the group. In some cases, this assumption may be unfair.[217] An example of this is COMPAS, a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist. ProPublica claims that the COMPAS-assigned recidivism risk level of black defendants is far more likely to be an overestimate than that of white defendants, despite the fact that the program was not told the races of the defendants.[218] Other examples where algorithmic bias can lead to unfair outcomes are when AI is used for credit rating or hiring.  Existential risk Main articles: Existential risk from artificial general intelligence and Superintelligence Superintelligent AI may be able to improve itself to the point that humans could not control it. This could, as physicist Stephen Hawking puts it, "spell the end of the human race".[219] Philosopher Nick Bostrom argues that sufficiently intelligent AI, if it chooses actions based on achieving some goal, will exhibit convergent behavior such as acquiring resources or protecting itself from being shut down. If this AI's goals do not fully reflect humanity's, it might need to harm humanity in order to acquire more resources or prevent itself from being shut down, ultimately to better achieve its goal. He concludes that AI poses a risk to mankind, however humble or "friendly" its stated goals might be.[220] Political scientist Charles T. Rubin argues that "any sufficiently advanced benevolence may be indistinguishable from malevolence." Humans should not assume machines or robots would treat us favorably because there is no a priori reason to believe that they would share our system of morality.[221]  The opinion of experts and industry insiders is mixed, with sizable fractions both concerned and unconcerned by risk from eventual superhumanly-capable AI.[222] Stephen Hawking, Microsoft founder Bill Gates, history professor Yuval Noah Harari, and SpaceX founder Elon Musk have all expressed serious misgivings about the future of AI.[223] Prominent tech titans including Peter Thiel (Amazon Web Services) and Musk have committed more than $1 billion to nonprofit companies that champion responsible AI development, such as OpenAI and the Future of Life Institute.[224] Mark Zuckerberg (CEO, Facebook) has said that artificial intelligence is helpful in its current form and will continue to assist humans.[225] Other experts argue is that the risks are far enough in the future to not be worth researching, or that humans will be valuable from the perspective of a superintelligent machine.[226] Rodney Brooks, in particular, has said that "malevolent" AI is still centuries away.[w]  Ethical machines Main articles: Machine ethics, Friendly AI, Artificial moral agents, and Human Compatible Friendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.[228]  Machines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.[229] Machine ethics is also called machine morality, computational ethics or computational morality,[229] and was founded at an AAAI symposium in 2005.[230]  Others approaches include Wendell Wallach's "artificial moral agents"[231] and Stuart J. Russell's three principles for developing provably beneficial machines.[232]  Regulation Main articles: Regulation of artificial intelligence, Regulation of algorithms, and AI control problem The regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI); it is therefore related to the broader regulation of algorithms.[233] The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally.[234] Between 2016 and 2020, more than 30 countries adopted dedicated strategies for AI.[44] Most EU member states had released national AI strategies, as had Canada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, USA and Viet Nam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia.[44] The Global Partnership on Artificial Intelligence was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology.[44]  In fiction Main article: Artificial intelligence in fiction  The word "robot" itself was coined by Karel Čapek in his 1921 play R.U.R., the title standing for "Rossum's Universal Robots" Thought-capable artificial beings have appeared as storytelling devices since antiquity,[17] and have been a persistent theme in science fiction.[19]  A common trope in these works began with Mary Shelley's Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke's and Stanley Kubrick's 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.[235]  Isaac Asimov introduced the Three Laws of Robotics in many books and stories, most notably the "Multivac" series about a super-intelligent computer of the same name. Asimov's laws are often brought up during lay discussions of machine ethics;[236] while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.[237]  Transhumanism (the merging of humans and machines) is explored in the manga Ghost in the Shell and the science-fiction series Dune.  Several works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel Čapek's R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.[238]  See also icon	Computer programming portal A.I. Rising AI control problem Artificial intelligence arms race Artificial general intelligence Behavior selection algorithm Business process automation Case-based reasoning Citizen Science Emergent algorithm Female gendering of AI technologies Glossary of artificial intelligence Robotic process automation Synthetic intelligence Universal basic income Weak AI Explanatory notes  Definition of AI as the study of intelligent agents, drawn from the leading AI textbooks. Poole, Mackworth & Goebel (1998, p. 1), which provides the version that is used in this article. These authors use the term "computational intelligence" as a synonym for artificial intelligence. Russell & Norvig (2003, p. 55) (who prefer the term "rational agent") and write "The whole-agent view is now widely accepted in the field". Nilsson (1998) Legg & Hutter (2007)  Stuart Russell and Peter Norvig characterize this definition as "thinking humanly" and reject it in favor of "acting rationally".[1]  This list of intelligent traits is based on the topics covered by the major AI textbooks, including: Russell & Norvig (2003), Luger & Stubblefield (2004), Poole, Mackworth & Goebel (1998) and Nilsson (1998)  This statement comes from the proposal for the Dartmouth workshop of 1956, which reads: "Every aspect of learning or any other feature of intelligence can be so precisely described that a machine can be made to simulate it."[13]  Daniel Crevier wrote "the conference is generally recognized as the official birthdate of the new science."[23] Russell and Norvifg call the conference "the birth of artificial intelligence."[24]  Russell and Norvig wrote "for the next 20 years the field would be dominated by these people and their students."[24]  Russell and Norvig wrote "it was astonishing whenever a computer did anything kind of smartish".[26]  The programs described are Arthur Samuel's checkers program for the IBM 701, Daniel Bobrow's STUDENT, Newell and Simon's Logic Theorist and Terry Winograd's SHRDLU.  Embodied approaches to AI[36] were championed by Hans Moravec[37] and Rodney Brooks[38] and went by many names: Nouvelle AI,[38] Developmental robotics,[39] situated AI, behavior-based AI as well as others. A similar movement in cognitive science was the embodied mind thesis.  Clark wrote: "After a half-decade of quiet breakthroughs in artificial intelligence, 2015 has been a landmark year. Computers are smarter and learning faster than ever."[10]  Alan Turing discussed the centrality of learning as early as 1950, in his classic paper "Computing Machinery and Intelligence".[66] In 1956, at the original Dartmouth AI summer conference, Ray Solomonoff wrote a report on unsupervised probabilistic machine learning: "An Inductive Inference Machine".[67]  This is a form of Tom Mitchell's widely quoted definition of machine learning: "A computer program is set to learn from an experience E with respect to some task T and some performance measure P if its performance on T as measured by P improves with experience E."[68]  Alan Turing suggested in "Computing Machinery and Intelligence" that a "thinking machine" would need to be educated like a child.[66] Developmental robotics is a modern version of the idea.[39]  Compared with symbolic logic, formal Bayesian inference is computationally expensive. For inference to be tractable, most observations must be conditionally independent of one another. AdSense uses a Bayesian network with over 300 million edges to learn which ads to serve.[109]  Expectation-maximization, one of the most popular algorithms in machine learning, allows clustering in the presence of unknown latent variables[111]  The Smithsonian reports: "Pluribus has bested poker pros in a series of six-player no-limit Texas Hold'em games, reaching a milestone in artificial intelligence research. It is the first bot to beat humans in a complex multiplayer competition."[165]  The distinction between "acting" and "thinking" is due to Russell and Norvig.[174]  The distinction between "acting humanly" and "acting rationally" is due to Russell and Norvig.[174] Pamela McCorduck wrote in 2004 that there are "two major branches of artificial intelligence: one aimed at producing intelligent behavior regardless of how it was accomplished, and the other aimed at modeling intelligent processes found in nature, particularly human ones."[176]  Nils Nilsson wrote in 1983: "Simply put, there is wide disagreement in the field about what AI is all about."[179]  Daniel Crevier wrote that "time has proven the accuracy and perceptiveness of some of Dreyfus's comments. Had he formulated them less aggressively, constructive actions they suggested might have been taken much earlier."[184]  Searle presented this definition of "Strong AI" in 1999.[195] Searle's original formulation was "The appropriately programmed computer really is a mind, in the sense that computers given the right programs can be literally said to understand and have other cognitive states."[196] Strong AI is defined similarly by Russell and Norvig: "The assertion that machines could possibly act intelligently (or, perhaps better, act as if they were intelligent) is called the 'weak AI' hypothesis by philosophers, and the assertion that machines that do so are actually thinking (as opposed to simulating thinking) is called the 'strong AI' hypothesis."[191]  See table 4; 9% is both the OECD average and the US average.[209]  Rodney Brooks writes, "I think it is a mistake to be worrying about us developing malevolent AI anytime in the next few hundred years. I think the worry stems from a fundamental error in not distinguishing the difference between the very real recent advances in a particular aspect of AI and the enormity and complexity of building sentient volitional intelligence."[227] Citations  Russell & Norvig (2009), p. 2.  Google (2016).  McCorduck (2004), p. 204.  Ashok83 (2019).  Schank (1991), p. 38.  Crevier (1993), p. 109.  Funding initiatives in the early 80s: Fifth Generation Project (Japan}, Alvey (UK), Microelectronics and Computer Technology Corporation (US), Strategic Computing Initiative (US): McCorduck (2004, pp. 426–441) Crevier (1993, pp. 161–162, 197–203, 211, 240) Russell & Norvig (2003, p. 24) NRC (1999, pp. 210–211) Newquist (1994, pp. 235–248)  First AI Winter, Lighthill report, Mansfield Amendment Crevier (1993, pp. 115–117) Russell & Norvig (2003, p. 22) NRC (1999, pp. 212–213) Howe (1994) Newquist (1994, pp. 189–201)  Second AI Winter: McCorduck (2004, pp. 430–435) Crevier (1993, pp. 209–210) NRC (1999, pp. 214–216) Newquist (1994, pp. 301–318)  Clark (2015b).  AI widely used in late 1990s: Russell & Norvig (2003, p. 28) Kurzweil (2005, p. 265) NRC (1999, pp. 216–222) Newquist (1994, pp. 189–201)  Pennachin & Goertzel (2007); Roberts (2016)  McCarthy et al. (1955).  Newquist (1994), pp. 45–53.  Spadafora (2016).  Lombardo, Boehm & Nairz (2020).  AI in myth: McCorduck (2004, pp. 4–5) Russell & Norvig (2003, p. 939)  McCorduck (2004), pp. 17–25.  McCorduck (2004), pp. 340–400.  Berlinski (2000).  AI's immediate precursors: McCorduck (2004, pp. 51–107) Crevier (1993, pp. 27–32) Russell & Norvig (2003, pp. 15, 940) Moravec (1988, p. 3)  Russell & Norvig (2009), p. 16.  Crevier (1993), pp. 47–49.  Russell & Norvig (2003), p. 17.  Dartmouth workshop: Russell & Norvig (2003, p. 17) McCorduck (2004, pp. 111–136) NRC & (1999, pp. 200–201) The proposal: McCarthy et al. (1955)  Russell & Norvig (2003), p. 18.  Successful Symbolic AI programs: McCorduck (2004, pp. 243–252) Crevier (1993, pp. 52–107) Moravec (1988, p. 9) Russell & Norvig (2003, pp. 18–21)  AI heavily funded in 1960s: McCorduck (2004, p. 131) Crevier (1993, pp. 51, 64–65) NRC (1999, pp. 204–205)  Howe (1994).  Newquist (1994), pp. 86–86.  Simon (1965, p. 96) quoted in Crevier (1993, p. 109)  Minsky (1967, p. 2) quoted in Crevier (1993, p. 109)  Lighthill (1973).  Expert systems: Russell & Norvig (2003, pp. 22–24) Luger & Stubblefield (2004, pp. 227–331) Nilsson (1998, chpt. 17.4) McCorduck (2004, pp. 327–335, 434–435) Crevier (1993, pp. 145–62, 197–203) Newquist (1994, pp. 155–183)  Nilsson (1998), p. 7.  McCorduck (2004), pp. 454–462.  Moravec (1988).  Brooks (1990).  Developmental robotics: Weng et al. (2001) Lungarella et al. (2003) Asada et al. (2009) Oudeyer (2010)  Revival of connectionism: Crevier (1993, pp. 214–215) Russell & Norvig (2003, p. 25)  Formal and narrow methods adopted in the 1990s: Russell & Norvig (2003, pp. 25–26) McCorduck (2004, pp. 486–487)  McKinsey (2018).  MIT Sloan Management Review (2018); Lorica (2017)  UNESCO (2021).  Problem solving, puzzle solving, game playing and deduction: Russell & Norvig (2003, chpt. 3–9) Poole, Mackworth & Goebel (1998, chpt. 2,3,7,9) Luger & Stubblefield (2004, chpt. 3,4,6,8) Nilsson (1998, chpt. 7–12)  Uncertain reasoning: Russell & Norvig (2003, pp. 452–644) Poole, Mackworth & Goebel (1998, pp. 345–395) Luger & Stubblefield (2004, pp. 333–381) Nilsson (1998, chpt. 19)  Intractability and efficiency and the combinatorial explosion: Russell & Norvig (2003, pp. 9, 21–22)  Psychological evidence of the prevalence sub-symbolic reasoning and knowledge: Kahneman (2011) Wason & Shapiro (1966) Kahneman, Slovic & Tversky (1982) Dreyfus & Dreyfus (1986)  Knowledge representation and knowledge engineering: Russell & Norvig (2003, pp. 260–266, 320–363) Poole, Mackworth & Goebel (1998, pp. 23–46, 69–81, 169–233, 235–277, 281–298, 319–345) Luger & Stubblefield (2004, pp. 227–243), Nilsson (1998, chpt. 17.1–17.4, 18)  Russell & Norvig (2003), pp. 320–328.  Representing categories and relations: Semantic networks, description logics, inheritance (including frames and scripts): Russell & Norvig (2003, pp. 349–354), Poole, Mackworth & Goebel (1998, pp. 174–177), Luger & Stubblefield (2004, pp. 248–258), Nilsson (1998, chpt. 18.3)  Representing events and time:Situation calculus, event calculus, fluent calculus (including solving the frame problem): Russell & Norvig (2003, pp. 328–341), Poole, Mackworth & Goebel (1998, pp. 281–298), Nilsson (1998, chpt. 18.2)  Causal calculus: Poole, Mackworth & Goebel (1998, pp. 335–337)  Representing knowledge about knowledge: Belief calculus, modal logics: Russell & Norvig (2003, pp. 341–344), Poole, Mackworth & Goebel (1998, pp. 275–277)  Default reasoning, Frame problem, default logic, non-monotonic logics, circumscription, closed world assumption, abduction: Russell & Norvig (2003, pp. 354–360) Poole, Mackworth & Goebel (1998, pp. 248–256, 323–335) Luger & Stubblefield (2004, pp. 335–363) Nilsson (1998, ~18.3.3) (Poole et al. places abduction under "default reasoning". Luger et al. places this under "uncertain reasoning").  Breadth of commonsense knowledge: Russell & Norvig (2003, p. 21), Crevier (1993, pp. 113–114), Moravec (1988, p. 13), Lenat & Guha (1989, Introduction)  Smoliar & Zhang (1994).  Neumann & Möller (2008).  Kuperman, Reichley & Bailey (2006).  McGarry (2005).  Bertini, Del Bimbo & Torniai (2006).  Planning: Russell & Norvig (2003, pp. 375–459) Poole, Mackworth & Goebel (1998, pp. 281–316) Luger & Stubblefield (2004, pp. 314–329) Nilsson (1998, chpt. 10.1–2, 22) Information value theory: Russell & Norvig (2003, pp. 600–604)  Classical planning: Russell & Norvig (2003, pp. 375–430) Poole, Mackworth & Goebel (1998, pp. 281–315) Luger & Stubblefield (2004, pp. 314–329) Nilsson (1998, chpt. 10.1–2, 22)  Planning and acting in non-deterministic domains: conditional planning, execution monitoring, replanning and continuous planning: Russell & Norvig (2003, pp. 430–449)  Multi-agent planning and emergent behavior: Russell & Norvig (2003, pp. 449–455)  Turing (1950).  Solomonoff (1956).  Russell & Norvig (2003), pp. 649–788.  Learning: Russell & Norvig (2003, pp. 649–788) Poole, Mackworth & Goebel (1998, pp. 397–438) Luger & Stubblefield (2004, pp. 385–542) Nilsson (1998, chpt. 3.3, 10.3, 17.5, 20)  Reinforcement learning: Russell & Norvig (2003, pp. 763–788) Luger & Stubblefield (2004, pp. 442–449)  The Economist (2016).  Jordan & Mitchell (2015).  Natural language processing (NLP): Russell & Norvig (2003, pp. 790–831) Poole, Mackworth & Goebel (1998, pp. 91–104) Luger & Stubblefield (2004, pp. 591–632)  Applications of NLP: Russell & Norvig (2003, pp. 840–857) Luger & Stubblefield (2004, pp. 623–630)  Modern statistical approaches to NLP: Cambria & White (2014)  Vincent (2019).  Machine perception: Russell & Norvig (2003, pp. 537–581, 863–898) Nilsson (1998, ~chpt. 6)  Speech recognition: Russell & Norvig (2003, pp. 568–578)  Object recognition: Russell & Norvig (2003, pp. 885–892)  Computer vision: Russell & Norvig (2003, pp. 863–898) Nilsson (1998, chpt. 6)  Robotics: Russell & Norvig (2003, pp. 901–942) Poole, Mackworth & Goebel (1998, pp. 443–460)  Robotic mapping and Localization: Russell & Norvig (2003, pp. 908–915) Cadena et al. (2016)  Motion planning and configuration space: Russell & Norvig (2003, pp. 916–932) Tecuci (2012)  MIT AIL (2014).  Affective computing: Thro (1993) Edelson (1991) Tao & Tan (2005) Scassellati (2002)  Waddell (2018).  Poria et al. (2017).  The Society of Mind: Minsky (1986) Moravec's "golden spike": Moravec (1988, p. 20) Multi-agent systems, hybrid intelligent systems, agent architectures, cognitive architecture: Russell & Norvig (2003, pp. 27, 932, 970–972) Nilsson (1998, chpt. 25)  Domingos (2015), Chpt. 9.  Artificial brain as an approach to AGI: Russell & Norvig (2003, p. 957) Crevier (1993, pp. 271 & 279) Goertzel et. al. (2010) A few of the people who make some form of the argument: Moravec (1988, p. 20) Kurzweil (2005, p. 262) Hawkins & Blakeslee (2005)  Search algorithms: Russell & Norvig (2003, pp. 59–189) Poole, Mackworth & Goebel (1998, pp. 113–163) Luger & Stubblefield (2004, pp. 79–164, 193–219) Nilsson (1998, chpt. 7–12)  Forward chaining, backward chaining, Horn clauses, and logical deduction as search: Russell & Norvig (2003, pp. 217–225, 280–294) Poole, Mackworth & Goebel (1998, pp. ~46–52) Luger & Stubblefield (2004, pp. 62–73) Nilsson (1998, chpt. 4.2, 7.2)  State space search and planning: Russell & Norvig (2003, pp. 382–387) Poole, Mackworth & Goebel (1998, pp. 298–305) Nilsson (1998, chpt. 10.1–2)  Moving and configuration space: Russell & Norvig (2003, pp. 916–932)  Uninformed searches (breadth first search, depth first search and general state space search): Russell & Norvig (2003, pp. 59–93) Poole, Mackworth & Goebel (1998, pp. 113–132) Luger & Stubblefield (2004, pp. 79–121) Nilsson (1998, chpt. 8)  Heuristic or informed searches (e.g., greedy best first and A*): Russell & Norvig (2003, pp. 94–109) Poole, Mackworth & Goebel (1998, pp. pp. 132–147) Poole & Mackworth (2017, Section 3.6) Luger & Stubblefield (2004, pp. 133–150)  Tecuci (2012).  Optimization searches: Russell & Norvig (2003, pp. 110–116, 120–129) Poole, Mackworth & Goebel (1998, pp. 56–163) Luger & Stubblefield (2004, pp. 127–133)  Genetic programming and genetic algorithms: Luger & Stubblefield (2004, pp. 509–530) Nilsson (1998, chpt. 4.2)  Artificial life and society based learning: Luger & Stubblefield (2004, pp. 530–541) Merkle & Middendorf (2013)  Logic: Russell & Norvig (2003, pp. 194–310), Luger & Stubblefield (2004, pp. 35–77), Nilsson (1998, chpt. 13–16)  Satplan: Russell & Norvig (2003, pp. 402–407), Poole, Mackworth & Goebel (1998, pp. 300–301), Nilsson (1998, chpt. 21)  Explanation based learning, relevance based learning, inductive logic programming, case based reasoning: Russell & Norvig (2003, pp. 678–710), Poole, Mackworth & Goebel (1998, pp. 414–416), Luger & Stubblefield (2004, pp. ~422–442), Nilsson (1998, chpt. 10.3, 17.5)  Propositional logic: Russell & Norvig (2003, pp. 204–233), Luger & Stubblefield (2004, pp. 45–50) Nilsson (1998, chpt. 13)  First-order logic and features such as equality: Russell & Norvig (2003, pp. 240–310), Poole, Mackworth & Goebel (1998, pp. 268–275), Luger & Stubblefield (2004, pp. 50–62), Nilsson (1998, chpt. 15)  Fuzzy logic: Russell & Norvig (2003, pp. 526–527) Scientific American (1999)  Stochastic methods for uncertain reasoning: Russell & Norvig (2003, pp. 462–644), Poole, Mackworth & Goebel (1998, pp. 345–395), Luger & Stubblefield (2004, pp. 165–191, 333–381), Nilsson (1998, chpt. 19)  Bayesian networks: Russell & Norvig (2003, pp. 492–523), Poole, Mackworth & Goebel (1998, pp. 361–381), Luger & Stubblefield (2004, pp. ~182–190, ≈363–379), Nilsson (1998, chpt. 19.3–4)  Domingos (2015), chapter 6.  Bayesian inference algorithm: Russell & Norvig (2003, pp. 504–519), Poole, Mackworth & Goebel (1998, pp. 361–381), Luger & Stubblefield (2004, pp. ~363–379), Nilsson (1998, chpt. 19.4 & 7)  Domingos (2015), p. 210.  Bayesian learning and the expectation-maximization algorithm: Russell & Norvig (2003, pp. 712–724), Poole, Mackworth & Goebel (1998, pp. 424–433), Nilsson (1998, chpt. 20) Domingos (2015, p. 210)  Bayesian decision theory and Bayesian decision networks: Russell & Norvig (2003, pp. 597–600)  Stochastic temporal models: Russell & Norvig (2003, pp. 537–581) Dynamic Bayesian networks: Russell & Norvig (2003, pp. 551–557) Hidden Markov model: (Russell & Norvig 2003, pp. 549–551) Kalman filters: Russell & Norvig (2003, pp. 551–557)  decision theory and decision analysis: Russell & Norvig (2003, pp. 584–597), Poole, Mackworth & Goebel (1998, pp. 381–394)  Information value theory: Russell & Norvig (2003, pp. 600–604)  Markov decision processes and dynamic decision networks: Russell & Norvig (2003, pp. 613–631)  Game theory and mechanism design: Russell & Norvig (2003, pp. 631–643)  Statistical learning methods and classifiers: Russell & Norvig (2003, pp. 712–754), Luger & Stubblefield (2004, pp. 453–541)  Decision tree: Domingos (2015, p. 88) Russell & Norvig (2003, pp. 653–664), Poole, Mackworth & Goebel (1998, pp. 403–408), Luger & Stubblefield (2004, pp. 408–417)  K-nearest neighbor algorithm: Domingos (2015, p. 187) Russell & Norvig (2003, pp. 733–736)  kernel methods such as the support vector machine: Domingos (2015, p. 88) Russell & Norvig (2003, pp. 749–752) Gaussian mixture model: Russell & Norvig (2003, pp. 725–727)  Domingos (2015), p. 152.  Naive Bayes classifier: Domingos (2015, p. 152) Russell & Norvig (2003, p. 718)  Neural networks: Russell & Norvig (2003, pp. 736–748), Poole, Mackworth & Goebel (1998, pp. 408–414), Luger & Stubblefield (2004, pp. 453–505), Nilsson (1998, chpt. 3) Domingos (2015, Chapter 4)  Classifier performance: van der Walt & Bernard (2006) Russell & Norvig (2009, 18.12: Learning from Examples: Summary)  Backpropagation: Russell & Norvig (2003, pp. 744–748), Luger & Stubblefield (2004, pp. 467–474), Nilsson (1998, chpt. 3.3) Paul Werbos' introduction of backpropagation to AI: Werbos (1974); Werbos (1982) Automatic differentiation, an essential precursor: Linnainmaa (1970); Griewank (2012)  Competitive learning, Hebbian coincidence learning, Hopfield networks and attractor networks: Luger & Stubblefield (2004, pp. 474–505)  Feedforward neural networks, perceptrons and radial basis networks: Russell & Norvig (2003, pp. 739–748, 758) Luger & Stubblefield (2004, pp. 458–467)  Deep learning: Goodfellow, Bengio & Courville (2016) Hinton et. al. (2016) Schmidhuber (2015a)  Schmidhuber (2015b).  Dechter (1986).  Aizenberg, Aizenberg & Vandewalle (2000).  Ivakhnenko (1965).  Ivakhnenko (1971).  Hinton (2007).  Fukushima (1980).  LeCun (2016).  Silver et. al. (2017).  Recurrent neural networks, Hopfield nets: Russell & Norvig (2003, p. 758) Luger & Stubblefield (2004, pp. 474–505)  Hyötyniemi (1996).  Schmidhuber (2015a).  Werbos (1988); Robinson & Fallside (1987); Williams & Zipser (1994)  Goodfellow, Bengio & Courville (2016); Hochreiter (1991)  Schmidhuber (1992).  Hochreiter & Schmidhuber (1997).  Graves et al. 2006.  Hannun et. al. (2014); Sak, Senior & Beaufays (2014); Li & Wu (2015)  Sutskever, Vinyals & Le (2014).  Jozefowicz et. al. (2016).  Gillick et al. (2015).  Vinyals et al. (2015).  Russell & Norvig (2009), p. 1.  European Commission (2020), p. 1.  CNN (2006).  Targeted advertising: Russell & Norvig (2009, p. 1) Economist (2016) Lohr (2016)  Lohr (2016).  Smith (2016).  Rowinski (2013).  Frangoul (2019).  Brown (2019).  McCorduck (2004), pp. 480–483.  Markoff (2011).  Google (2016); BBC (2016)  Solly (2019).  Bowling et al. (2015).  Sample (2017).  Anadiotis (2020).  Heath (2020).  Aletras et. al. (2016).  Turing (1950), p. 1.  Turing (1948).  Turing's original publication of the Turing test in "Computing machinery and intelligence": Turing (1950) Historical influence and philosophical implications: Haugeland (1985, pp. 6–9) Crevier (1993, p. 24) McCorduck (2004, pp. 70–71) Russell & Norvig (2003, pp. 2–3 and 948)  Russell & Norvig (2003), p. 3.  Maker (2006).  McCorduck (2004), pp. 100–101.  The intelligent agent paradigm: Russell & Norvig (2003, pp. 27, 32–58, 968–972) Poole, Mackworth & Goebel (1998, pp. 7–21) Luger & Stubblefield (2004, pp. 235–240) Hutter (2005, pp. 125–126) The definition used in this article, in terms of goals, actions, perception and environment, is due to Russell & Norvig (2003). Other definitions also include knowledge, learning and autonomy as additional criteria.  Russell & Norvig (2003), p. 27.  Nilsson (1983), p. 10.  Haugeland (1985), pp. 112–117.  Physical symbol system hypothesis: Newell & Simon (1976, p. 116) Historical significance: McCorduck (2004, p. 153) Russell & Norvig (2003, p. 18)  Moravec's paradox: Moravec (1988, pp. 15–16) Minsky (1986, p. 29) Pinker (2007, pp. 190–91)  Dreyfus' critique of AI: Dreyfus (1972) Dreyfus & Dreyfus (1986) Historical significance and philosophical implications: Crevier (1993, pp. 120–132) McCorduck (2004, pp. 211–239) Russell & Norvig (2003, pp. 950–952) Fearn (2007, Chpt. 3)  Crevier (1993), p. 125.  Langley (2011).  Katz (2012).  Neats vs. scruffies, the historic debate: McCorduck (2004, pp. 421–424, 486–489) Crevier (1993, p. 168) Nilsson (1983, pp. 10–11) A classic example of the "scruffy" approach to intelligence: Minsky (1986) A modern example of neat AI and its aspirations: Domingos (2015)  Russell & Norvig (2003), p. 25-26.  Pennachin & Goertzel (2007).  Roberts (2016).  Russell & Norvig (2003), p. 947.  Chalmers (1995).  Dennett (1991).  Horst (2005).  Searle (1999).  Searle (1980), p. 1.  Searle's Chinese room argument: Searle (1980). Searle's original presentation of the thought experiment. Searle (1999). Discussion: Russell & Norvig (2003, pp. 958–960) McCorduck (2004, pp. 443–445) Crevier (1993, pp. 269–271)  Robot rights: Russell & Norvig (2003, p. 964) BBC (2006) Maschafilm (2010) (the film Plug & Pray)  Evans (2015).  McCorduck (2004), pp. 19–25.  Henderson (2007).  Omohundro (2008).  Vinge (1993).  Russell & Norvig (2003), p. 963.  Transhumanism: Moravec (1988) Kurzweil (2005) Russell & Norvig (2003, p. 963)  AI as evolution: Edward Fredkin is quoted in McCorduck (2004, p. 401) Butler (1863) Dyson (1998)  Ford & Colvin (2015); McGaughey (2018)  IGM Chicago (2017).  Arntz, Gregory & Zierahn (2016), p. 33.  Lohr (2017); Frey & Osborne (2017); Arntz, Gregory & Zierahn (2016, p. 33)  Morgenstern (2015).  Mahdawi (2017); Thompson (2014)  Harari (2018).  Weaponized AI: Robitzski (2018) Sainato (2015)  CNA (2019).  Goffrey (2008), p. 17.  Lipartito (2011, p. 36); Goodman & Flaxman (2017, p. 6)  Larson & Angwin (2016).  Cellan-Jones (2014).  Bostrom (2014); Müller & Bostrom (2014); Bostrom (2015)  Rubin (2003).  Müller & Bostrom (2014).  Leaders' concerns about the existential risks of AI: Rawlinson (2015) Holley (2015) Gibbs (2014) Churm (2019) Sainato (2015)  Funding to mitigate risks of AI: Post (2015) Del Prado (2015) Clark (2015a) FastCompany (2015)  Leaders who argue the benefits of AI outweigh the risks: Thibodeau (2019) Bhardwaj (2018)  Arguments that AI is not an imminent risk: Brooks (2014) Geist (2015) Madrigal (2015) Lee (2014)  Brooks (2014).  Yudkowsky (2008).  Anderson & Anderson (2011).  AAAI (2014).  Wallach (2010).  Russell (2019), p. 173.  Regulation of AI to mitigate risks: Berryhill et al. (2019) Barfield & Pagallo (2018) Iphofen & Kritikos (2019) Wirtz, Weyerer & Geyer (2018) Buiten (2019)  Law Library of Congress (U.S.). Global Legal Research Directorate (2019).  Buttazzo (2001).  Anderson (2008).  McCauley (2007).  Galvan (1997). References AI textbooks These were the four the most widely used AI textbooks in 2009.  Luger, George; Stubblefield, William (2004). Artificial Intelligence: Structures and Strategies for Complex Problem Solving (5th ed.). Benjamin/Cummings. ISBN 978-0-8053-4780-7. Archived from the original on 26 July 2020. Retrieved 17 December 2019. Nilsson, Nils (1998). Artificial Intelligence: A New Synthesis. Morgan Kaufmann. ISBN 978-1-55860-467-4. Archived from the original on 26 July 2020. Retrieved 18 November 2019. Russell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN 0-13-790395-2. Russell, Stuart J.; Norvig, Peter (2009). Artificial Intelligence: A Modern Approach (3rd ed.). Upper Saddle River, New Jersey: Prentice Hall. ISBN 978-0-13-604259-4.. Poole, David; Mackworth, Alan; Goebel, Randy (1998). Computational Intelligence: A Logical Approach. New York: Oxford University Press. ISBN 978-0-19-510270-3. Archived from the original on 26 July 2020. Retrieved 22 August 2020. Poole, David; Mackworth, Alan (2017). Artificial Intelligence: Foundations of Computational Agents (2nd ed.). Cambridge University Press. ISBN 978-1-107-19539-4. History of AI Crevier, Daniel (1993), AI: The Tumultuous Search for Artificial Intelligence, New York, NY: BasicBooks, ISBN 0-465-02997-3. McCorduck, Pamela (2004), Machines Who Think (2nd ed.), Natick, MA: A. K. Peters, Ltd., ISBN 1-56881-205-1. Newquist, HP (1994). The Brain Makers: Genius, Ego, And Greed In The Quest For Machines That Think. New York: Macmillan/SAMS. ISBN 978-0-672-30412-5. Nilsson, Nils (2009). The Quest for Artificial Intelligence: A History of Ideas and Achievements. New York: Cambridge University Press. ISBN 978-0-521-12293-1. Other sources "From not working to neural networking". The Economist. 2016. Archived from the original on 31 December 2016. Retrieved 26 April 2018. Thompson, Derek (23 January 2014). "What Jobs Will the Robots Take?". The Atlantic. Archived from the original on 24 April 2018. Retrieved 24 April 2018. Scassellati, Brian (2002). "Theory of mind for a humanoid robot". Autonomous Robots. 12 (1): 13–24. doi:10.1023/A:1013298507114. S2CID 1979315. Sample, Ian (14 March 2017). "Google's DeepMind makes AI program that can learn like a human". The Guardian. Archived from the original on 26 April 2018. Retrieved 26 April 2018. Heath, Nick (11 December 2020). "What is AI? Everything you need to know about Artificial Intelligence". ZDNet. Retrieved 1 March 2021. Bowling, Michael; Burch, Neil; Johanson, Michael; Tammelin, Oskari (9 January 2015). "Heads-up limit hold'em poker is solved". Science. 347 (6218): 145–149. Bibcode:2015Sci...347..145B. doi:10.1126/science.1259433. ISSN 0036-8075. PMID 25574016. S2CID 3796371. Solly, Meilan (15 July 2019). "This Poker-Playing A.I. Knows When to Hold 'Em and When to Fold 'Em". Smithsonian. "Artificial intelligence: Google's AlphaGo beats Go master Lee Se-dol". BBC News. 12 March 2016. Archived from the original on 26 August 2016. Retrieved 1 October 2016.</ref> Rowinski, Dan (15 January 2013). "Virtual Personal Assistants & The Future Of Your Smartphone [Infographic]". ReadWrite. Archived from the original on 22 December 2015. Markoff, John (16 February 2011). "Computer Wins on 'Jeopardy!': Trivial, It's Not". The New York Times. Archived from the original on 22 October 2014. Retrieved 25 October 2014. Anadiotis, George (1 October 2020). "The state of AI in 2020: Democratization, industrialization, and the way to artificial general intelligence". ZDNet. Retrieved 1 March 2021. Goertzel, Ben; Lian, Ruiting; Arel, Itamar; de Garis, Hugo; Chen, Shuo (December 2010). "A world survey of artificial brain projects, Part II: Biologically inspired cognitive architectures". Neurocomputing. 74 (1–3): 30–49. doi:10.1016/j.neucom.2010.08.012. Hyötyniemi, Heikki (1996). "Turing machines are recurrent neural networks". Proceedings of STeP '96/Publications of the Finnish Artificial Intelligence Society: 13–24. Werbos, P. J. (1988), "Generalization of backpropagation with application to a recurrent gas market model", Neural Networks, 1 (4): 339–356, doi:10.1016/0893-6080(88)90007-X Robinson, A. J.; Fallside, F. (1987), "The utility driven dynamic error propagation network.", Technical Report CUED/F-INFENG/TR.1, Cambridge University Engineering Department Hochreiter, Sepp (1991). Untersuchungen zu dynamischen neuronalen Netzen (PDF) (diploma thesis). Munich: Institut f. Informatik, Technische Univ. Archived 6 March 2015 at the Wayback Machine Williams, R. J.; Zipser, D. (1994), "Gradient-based learning algorithms for recurrent networks and their computational complexity", Back-propagation: Theory, Architectures and Applications, Hillsdale, NJ: Erlbaum Schmidhuber, J. (1992). "Learning complex, extended sequences using the principle of history compression". Neural Computation. 4 (2): 234–242. CiteSeerX 10.1.1.49.3934. doi:10.1162/neco.1992.4.2.234. S2CID 18271205. Hochreiter, Sepp; Schmidhuber, Jürgen (1997), "Long Short-Term Memory", Neural Computation, 9 (8): 1735–1780, doi:10.1162/neco.1997.9.8.1735, PMID 9377276, S2CID 1915014 Graves, Alex; Fernandez, Santiago; Gomez, Faustino; Schmidhuber, Jürgen (2006), "Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural nets", Proceedings of ICML'06: 369–376, doi:10.1145/1143844.1143891, S2CID 9901844 Hannun, Awni; Case, Carl; Casper, Jared; Catanzaro, Bryan; Diamos, Greg; Elsen, Erich; Prenger, Ryan; Satheesh, Sanjeev; Sengupta, Shubho; Coates, Adam; Ng, Andrew Y. (2014). "Deep Speech: Scaling up end-to-end speech recognition". arXiv:1412.5567 [cs.CL]. Sak, Hasim; Senior, Andrew; Beaufays, Francoise (2014), "Long Short-Term Memory recurrent neural network architectures for large scale acoustic modeling", Proceedings of Interspeech 2014 Li, Xiangang; Wu, Xihong (2015). "Constructing Long Short-Term Memory based Deep Recurrent Neural Networks for Large Vocabulary Speech Recognition". arXiv:1410.4281 [cs.CL]. Sutskever, Ilya; Vinyals, Oriol; Le, Quoc V. (2014). "Sequence to Sequence Learning with Neural Networks". arXiv:1409.3215 [cs.CL]. Jozefowicz, Rafal; Vinyals, Oriol; Schuster, Mike; Shazeer, Noam; Wu, Yonghui (2016). "Exploring the Limits of Language Modeling". arXiv:1602.02410 [cs.CL]. Gillick, Dan; Brunk, Cliff; Vinyals, Oriol; Subramanya, Amarnag (2015). "Multilingual Language Processing From Bytes". arXiv:1512.00103 [cs.CL]. Vinyals, Oriol; Toshev, Alexander; Bengio, Samy; Erhan, Dumitru (2015). "Show and Tell: A Neural Image Caption Generator". arXiv:1411.4555 [cs.CV]. Goodfellow, Ian; Bengio, Yoshua; Courville, Aaron (2016), Deep Learning, MIT Press. Archived 16 April 2016 at the Wayback Machine Hinton, G.; Deng, L.; Yu, D.; Dahl, G.; Mohamed, A.; Jaitly, N.; Senior, A.; Vanhoucke, V.; Nguyen, P.; Sainath, T.; Kingsbury, B. (2012). "Deep Neural Networks for Acoustic Modeling in Speech Recognition – The shared views of four research groups". IEEE Signal Processing Magazine. 29 (6): 82–97. Bibcode:2012ISPM...29...82H. doi:10.1109/msp.2012.2205597. S2CID 206485943. Schmidhuber, J. (2015a). "Deep Learning in Neural Networks: An Overview". Neural Networks. 61: 85–117. arXiv:1404.7828. doi:10.1016/j.neunet.2014.09.003. PMID 25462637. S2CID 11715509. Schmidhuber, Jürgen (2015b). "Deep Learning". Scholarpedia. 10 (11): 32832. Bibcode:2015SchpJ..1032832S. doi:10.4249/scholarpedia.32832. Dechter, Rina (1986), Learning while searching in constraint-satisfaction problems, University of California, Computer Science Department, Cognitive Systems Laboratory Archived 19 April 2016 at the Wayback Machine Aizenberg, Igor; Aizenberg, Naum N.; Vandewalle, Joos P.L. (2000), Multi-Valued and Universal Binary Neurons: Theory, Learning and Applications., Springer Science & Business Media Ivakhnenko, Alexey (1965). Cybernetic Predicting Devices. Kiev: Naukova Dumka.</ref>[page needed] Ivakhnenko, A. G. (1971). "Polynomial Theory of Complex Systems". IEEE Transactions on Systems, Man, and Cybernetics (4): 364–378. doi:10.1109/TSMC.1971.4308320. S2CID 17606980. Hinton, G. E. (2007). "Learning multiple layers of representation". Trends in Cognitive Sciences. 11 (10): 428–434. doi:10.1016/j.tics.2007.09.004. PMID 17921042. S2CID 15066318.</ref> Similar to shallow artificial neural networks, deep neural networks can model complex non-linear relationships. Fukushima, K. (1980). "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position". Biological Cybernetics. 36 (4): 193–202. doi:10.1007/bf00344251. PMID 7370364. S2CID 206775608. LeCun, Yann (2016), Slides on Deep LearningArchived 23 April 2016 at the Wayback Machine Silver, David; Schrittwieser, Julian; Simonyan, Karen; Antonoglou, Ioannis; Huang, Aja; Guez, Arthur; Hubert, Thomas; Baker, Lucas; Lai, Matthew; Bolton, Adrian; Chen, Yutian; Lillicrap, Timothy; Fan, Hui; Sifre, Laurent; Driessche, George van den; Graepel, Thore; Hassabis, Demis (19 October 2017). "Mastering the game of Go without human knowledge" (PDF). Nature. 550 (7676): 354–359. Bibcode:2017Natur.550..354S. doi:10.1038/nature24270. ISSN 0028-0836. PMID 29052630. S2CID 205261034. AlphaGo Lee... 12 convolutional layers Linnainmaa, Seppo (1970). The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors (Thesis) (in Finnish). Univ. Helsinki, 6–7.| Griewank, Andreas (2012). "Who Invented the Reverse Mode of Differentiation? Optimization Stories". Documenta Matematica, Extra Volume ISMP: 389–400. Werbos, Paul (1974). Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences (Ph.D. thesis). Harvard University. Werbos, Paul (1982). "Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences" (PDF). System Modeling and Optimization. Applications of advances in nonlinear sensitivity analysis. Berlin, Heidelberg: Springer. Archived 14 April 2016 at the Wayback Machine "What is 'fuzzy logic'? Are there computers that are inherently fuzzy and do not apply the usual binary logic?". Scientific American. 21 October 1999. Retrieved 5 May 2018. Merkle, Daniel; Middendorf, Martin (2013). "Swarm Intelligence". In Burke, Edmund K.; Kendall, Graham (eds.). Search Methodologies: Introductory Tutorials in Optimization and Decision Support Techniques. Springer Science & Business Media. ISBN 978-1-4614-6940-7. van der Walt, Christiaan; Bernard, Etienne (2006). "Data characteristics that determine classifier performance" (PDF). Archived from the original (PDF) on 25 March 2009. Retrieved 5 August 2009. Hutter, Marcus (2005). Universal Artificial Intelligence. Berlin: Springer. ISBN 978-3-540-22139-5. Howe, J. (November 1994). "Artificial Intelligence at Edinburgh University: a Perspective". Archived from the original on 15 May 2007. Retrieved 30 August 2007. Galvan, Jill (1 January 1997). "Entering the Posthuman Collective in Philip K. Dick's "Do Androids Dream of Electric Sheep?"". Science Fiction Studies. 24 (3): 413–429. JSTOR 4240644. McCauley, Lee (2007). "AI armageddon and the three laws of robotics". Ethics and Information Technology. 9 (2): 153–164. CiteSeerX 10.1.1.85.8904. doi:10.1007/s10676-007-9138-2. S2CID 37272949. Buttazzo, G. (July 2001). "Artificial consciousness: Utopia or real possibility?". Computer. 34 (7): 24–30. doi:10.1109/2.933500. Anderson, Susan Leigh (2008). "Asimov's "three laws of robotics" and machine metaethics". AI & Society. 22 (4): 477–493. doi:10.1007/s00146-007-0094-5. S2CID 1809459. Yudkowsky, E (2008), "Artificial Intelligence as a Positive and Negative Factor in Global Risk" (PDF), Global Catastrophic Risks, Oxford University Press, 2008, Bibcode:2008gcr..book..303Y McGaughey, E (2018), Will Robots Automate Your Job Away? Full Employment, Basic Income, and Economic Democracy, p. SSRN part 2(3), SSRN 3044448 Archived 24 May 2018 at the Wayback Machine IGM Chicago (30 June 2017). "Robots and Artificial Intelligence". www.igmchicago.org. Archived from the original on 1 May 2019. Retrieved 3 July 2019. Lohr, Steve (2017). "Robots Will Take Jobs, but Not as Fast as Some Fear, New Report Says". The New York Times. Archived from the original on 14 January 2018. Retrieved 13 January 2018. Frey, Carl Benedikt; Osborne, Michael A (1 January 2017). "The future of employment: How susceptible are jobs to computerisation?". Technological Forecasting and Social Change. 114: 254–280. CiteSeerX 10.1.1.395.416. doi:10.1016/j.techfore.2016.08.019. ISSN 0040-1625. Arntz, Melanie; Gregory, Terry; Zierahn, Ulrich (2016), "The risk of automation for jobs in OECD countries: A comparative analysis", OECD Social, Employment, and Migration Working Papers 189 Morgenstern, Michael (9 May 2015). "Automation and anxiety". The Economist. Archived from the original on 12 January 2018. Retrieved 13 January 2018. Mahdawi, Arwa (26 June 2017). "What jobs will still be around in 20 years? Read this to prepare your future". The Guardian. Archived from the original on 14 January 2018. Retrieved 13 January 2018. Rubin, Charles (Spring 2003). "Artificial Intelligence and Human Nature". The New Atlantis. 1: 88–100. Archived from the original on 11 June 2012. Bostrom, Nick (2014). Superintelligence: Paths, Dangers, Strategies. Oxford University Press. Brooks, Rodney (10 November 2014). "artificial intelligence is a tool, not a threat". Archived from the original on 12 November 2014. Sainato, Michael (19 August 2015). "Stephen Hawking, Elon Musk, and Bill Gates Warn About Artificial Intelligence". Observer. Archived from the original on 30 October 2015. Retrieved 30 October 2015. Harari, Yuval Noah (October 2018). "Why Technology Favors Tyranny". The Atlantic. Robitzski, Dan (5 September 2018). "Five experts share what scares them the most about AI". Archived from the original on 8 December 2019. Retrieved 8 December 2019. Goffrey, Andrew (2008). "Algorithm". In Fuller, Matthew (ed.). Software studies: a lexicon. Cambridge, Mass.: MIT Press. pp. 15–20. ISBN 978-1-4356-4787-9. Lipartito, Kenneth (6 January 2011). "The Narrative and the Algorithm: Genres of Credit Reporting from the Nineteenth Century to Today" (PDF) (Submitted manuscript). doi:10.2139/ssrn.1736283. S2CID 166742927. Goodman, Bryce; Flaxman, Seth (2017). "EU regulations on algorithmic decision-making and a "right to explanation"". AI Magazine. 38 (3): 50. arXiv:1606.08813. doi:10.1609/aimag.v38i3.2741. S2CID 7373959. CNA (12 January 2019). "Commentary: Bad news. Artificial intelligence is biased". CNA. Archived from the original on 12 January 2019. Retrieved 19 June 2020. Larson, Jeff; Angwin, Julia (23 May 2016). "How We Analyzed the COMPAS Recidivism Algorithm". ProPublica. Archived from the original on 29 April 2019. Retrieved 19 June 2020. Müller, Vincent C.; Bostrom, Nick (2014). "Future Progress in Artificial Intelligence: A Poll Among Experts" (PDF). AI Matters. 1 (1): 9–11. doi:10.1145/2639475.2639478. S2CID 8510016. Archived (PDF) from the original on 15 January 2016. Cellan-Jones, Rory (2 December 2014). "Stephen Hawking warns artificial intelligence could end mankind". BBC News. Archived from the original on 30 October 2015. Retrieved 30 October 2015. Rawlinson, Kevin (29 January 2015). "Microsoft's Bill Gates insists AI is a threat". BBC News. Archived from the original on 29 January 2015. Retrieved 30 January 2015. Holley, Peter (28 January 2015). "Bill Gates on dangers of artificial intelligence: 'I don't understand why some people are not concerned'". The Washington Post. ISSN 0190-8286. Archived from the original on 30 October 2015. Retrieved 30 October 2015. Gibbs, Samuel (27 October 2014). "Elon Musk: artificial intelligence is our biggest existential threat". The Guardian. Archived from the original on 30 October 2015. Retrieved 30 October 2015. Churm, Philip Andrew (14 May 2019). "Yuval Noah Harari talks politics, technology and migration". euronews. Archived from the original on 14 May 2019. Retrieved 15 November 2020. Bostrom, Nick (2015). "What happens when our computers get smarter than we are?". TED (conference). Archived from the original on 25 July 2020. Retrieved 30 January 2020. Post, Washington (2015). "Tech titans like Elon Musk are spending $1 billion to save you from terminators". Archived from the original on 7 June 2016. Del Prado, Guia Marie (9 October 2015). "The mysterious artificial intelligence company Elon Musk invested in is developing game-changing smart computers". Tech Insider. Archived from the original on 30 October 2015. Retrieved 30 October 2015. FastCompany (15 January 2015). "Elon Musk Is Donating $10M Of His Own Money To Artificial Intelligence Research". Fast Company. Archived from the original on 30 October 2015. Retrieved 30 October 2015. Thibodeau, Patrick (25 March 2019). "Oracle CEO Mark Hurd sees no reason to fear ERP AI". SearchERP. Archived from the original on 6 May 2019. Retrieved 6 May 2019. Bhardwaj, Prachi (24 May 2018). "Mark Zuckerberg responds to Elon Musk's paranoia about AI: 'AI is going to... help keep our communities safe.'". Business Insider. Archived from the original on 6 May 2019. Retrieved 6 May 2019. Geist, Edward Moore (9 August 2015). "Is artificial intelligence really an existential threat to humanity?". Bulletin of the Atomic Scientists. Archived from the original on 30 October 2015. Retrieved 30 October 2015. Madrigal, Alexis C. (27 February 2015). "The case against killer robots, from a guy actually working on artificial intelligence". Fusion.net. Archived from the original on 4 February 2016. Retrieved 31 January 2016. Lee, Timothy B. (22 August 2014). "Will artificial intelligence destroy humanity? Here are 5 reasons not to worry". Vox. Archived from the original on 30 October 2015. Retrieved 30 October 2015. Law Library of Congress (U.S.). Global Legal Research Directorate, issuing body. (2019). Regulation of artificial intelligence in selected jurisdictions. LCCN 2019668143. OCLC 1110727808. UNESCO Science Report: the Race Against Time for Smarter Development. Paris: UNESCO. 11 June 2021. ISBN 978-92-3-100450-6. Berryhill, Jamie; Heang, Kévin Kok; Clogher, Rob; McBride, Keegan (2019). Hello, World: Artificial Intelligence and its Use in the Public Sector (PDF). Paris: OECD Observatory of Public Sector Innovation. Archived (PDF) from the original on 20 December 2019. Retrieved 9 August 2020. Barfield, Woodrow; Pagallo, Ugo (2018). Research handbook on the law of artificial intelligence. Cheltenham, UK. ISBN 978-1-78643-904-8. OCLC 1039480085. Iphofen, Ron; Kritikos, Mihalis (3 January 2019). "Regulating artificial intelligence and robotics: ethics by design in a digital society". Contemporary Social Science. 16 (2): 170–184. doi:10.1080/21582041.2018.1563803. ISSN 2158-2041. S2CID 59298502. Wirtz, Bernd W.; Weyerer, Jan C.; Geyer, Carolin (24 July 2018). "Artificial Intelligence and the Public Sector – Applications and Challenges". International Journal of Public Administration. 42 (7): 596–615. doi:10.1080/01900692.2018.1498103. ISSN 0190-0692. S2CID 158829602. Archived from the original on 18 August 2020. Retrieved 22 August 2020. Buiten, Miriam C (2019). "Towards Intelligent Regulation of Artificial Intelligence". European Journal of Risk Regulation. 10 (1): 41–59. doi:10.1017/err.2019.8. ISSN 1867-299X. Wallach, Wendell (2010). Moral Machines. Oxford University Press. Brown, Eileen (5 November 2019). "Half of Americans do not believe deepfake news could target them online". ZDNet. Archived from the original on 6 November 2019. Retrieved 3 December 2019. Frangoul, Anmar (14 June 2019). "A Californian business is using A.I. to change the way we think about energy storage". CNBC. Archived from the original on 25 July 2020. Retrieved 5 November 2019. "The Economist Explains: Why firms are piling into artificial intelligence". The Economist. 31 March 2016. Archived from the original on 8 May 2016. Retrieved 19 May 2016. Lohr, Steve (28 February 2016). "The Promise of Artificial Intelligence Unfolds in Small Steps". The New York Times. Archived from the original on 29 February 2016. Retrieved 29 February 2016. Smith, Mark (22 July 2016). "So you think you chose to read this article?". BBC News. Archived from the original on 25 July 2016. Aletras, N.; Tsarapatsanis, D.; Preotiuc-Pietro, D.; Lampos, V. (2016). "Predicting judicial decisions of the European Court of Human Rights: a Natural Language Processing perspective". PeerJ Computer Science. 2: e93. doi:10.7717/peerj-cs.93. Cadena, Cesar; Carlone, Luca; Carrillo, Henry; Latif, Yasir; Scaramuzza, Davide; Neira, Jose; Reid, Ian; Leonard, John J. (December 2016). "Past, Present, and Future of Simultaneous Localization and Mapping: Toward the Robust-Perception Age". IEEE Transactions on Robotics. 32 (6): 1309–1332. arXiv:1606.05830. Bibcode:2016arXiv160605830C. doi:10.1109/TRO.2016.2624754. S2CID 2596787. Cambria, Erik; White, Bebo (May 2014). "Jumping NLP Curves: A Review of Natural Language Processing Research [Review Article]". IEEE Computational Intelligence Magazine. 9 (2): 48–57. doi:10.1109/MCI.2014.2307227. S2CID 206451986. Vincent, James (7 November 2019). "OpenAI has published the text-generating AI it said was too dangerous to share". The Verge. Archived from the original on 11 June 2020. Retrieved 11 June 2020. Jordan, M. I.; Mitchell, T. M. (16 July 2015). "Machine learning: Trends, perspectives, and prospects". Science. 349 (6245): 255–260. Bibcode:2015Sci...349..255J. doi:10.1126/science.aaa8415. PMID 26185243. S2CID 677218. Maschafilm (2010). "Content: Plug & Pray Film – Artificial Intelligence – Robots -". plugandpray-film.de. Archived from the original on 12 February 2016. Evans, Woody (2015). "Posthuman Rights: Dimensions of Transhuman Worlds". Teknokultura. 12 (2). doi:10.5209/rev_TK.2015.v12.n2.49072. Waddell, Kaveh (2018). "Chatbots Have Entered the Uncanny Valley". The Atlantic. Archived from the original on 24 April 2018. Retrieved 24 April 2018. Poria, Soujanya; Cambria, Erik; Bajpai, Rajiv; Hussain, Amir (September 2017). "A review of affective computing: From unimodal analysis to multimodal fusion". Information Fusion. 37: 98–125. doi:10.1016/j.inffus.2017.02.003. hdl:1893/25490. "Robots could demand legal rights". BBC News. 21 December 2006. Archived from the original on 15 October 2019. Retrieved 3 February 2011. Horst, Steven (2005). "The Computational Theory of Mind". The Stanford Encyclopedia of Philosophy. Omohundro, Steve (2008). The Nature of Self-Improving Artificial Intelligence. presented and distributed at the 2007 Singularity Summit, San Francisco, CA. Ford, Martin; Colvin, Geoff (6 September 2015). "Will robots create more jobs than they destroy?". The Guardian. Archived from the original on 16 June 2018. Retrieved 13 January 2018. White Paper: On Artificial Intelligence – A European approach to excellence and trust (PDF). Brussels: European Commission. 2020. Archived (PDF) from the original on 20 February 2020. Retrieved 20 February 2020. Anderson, Michael; Anderson, Susan Leigh (2011). Machine Ethics. Cambridge University Press. "Machine Ethics". aaai.org. Archived from the original on 29 November 2014. Russell, Stuart (8 October 2019). Human Compatible: Artificial Intelligence and the Problem of Control. United States: Viking. ISBN 978-0-525-55861-3. OCLC 1083694322. "AI set to exceed human brain power". CNN. 9 August 2006. Archived from the original on 19 February 2008. "Robots could demand legal rights". BBC News. 21 December 2006. Archived from the original on 15 October 2019. Retrieved 3 February 2011. "Kismet". MIT Artificial Intelligence Laboratory, Humanoid Robotics Group. Archived from the original on 17 October 2014. Retrieved 25 October 2014. Sikos, Leslie F. (June 2017). Description Logics in Multimedia Reasoning. Cham: Springer. doi:10.1007/978-3-319-54066-5. ISBN 978-3-319-54066-5. S2CID 3180114. Archived from the original on 29 August 2017. Smoliar, Stephen W.; Zhang, HongJiang (1994). "Content based video indexing and retrieval". IEEE Multimedia. 1 (2): 62–72. doi:10.1109/93.311653. S2CID 32710913. Neumann, Bernd; Möller, Ralf (January 2008). "On scene interpretation with description logics". Image and Vision Computing. 26 (1): 82–101. doi:10.1016/j.imavis.2007.08.013. Kuperman, G. J.; Reichley, R. M.; Bailey, T. C. (1 July 2006). "Using Commercial Knowledge Bases for Clinical Decision Support: Opportunities, Hurdles, and Recommendations". Journal of the American Medical Informatics Association. 13 (4): 369–371. doi:10.1197/jamia.M2055. PMC 1513681. PMID 16622160. McGarry, Ken (1 December 2005). "A survey of interestingness measures for knowledge discovery". The Knowledge Engineering Review. 20 (1): 39–61. doi:10.1017/S0269888905000408. S2CID 14987656. Bertini, M; Del Bimbo, A; Torniai, C (2006). "Automatic annotation and semantic retrieval of video sequences using multimedia ontologies". MM '06 Proceedings of the 14th ACM international conference on Multimedia. 14th ACM international conference on Multimedia. Santa Barbara: ACM. pp. 679–682. Kahneman, Daniel (25 October 2011). Thinking, Fast and Slow. Macmillan. ISBN 978-1-4299-6935-2. Retrieved 8 April 2012. Turing, Alan (1948), "Machine Intelligence", in Copeland, B. Jack (ed.), The Essential Turing: The ideas that gave birth to the computer age, Oxford: Oxford University Press, p. 412, ISBN 978-0-19-825080-7 Domingos, Pedro (22 September 2015). The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World. Basic Books. ISBN 978-0465065707. Minsky, Marvin (1986), The Society of Mind, Simon and Schuster Pinker, Steven (4 September 2007) [1994], The Language Instinct, Perennial Modern Classics, Harper, ISBN 978-0-06-133646-1 Chalmers, David (1995). "Facing up to the problem of consciousness". Journal of Consciousness Studies. 2 (3): 200–219. Archived from the original on 8 March 2005. Retrieved 11 October 2018. Roberts, Jacob (2016). "Thinking Machines: The Search for Artificial Intelligence". Distillations. Vol. 2 no. 2. pp. 14–23. Archived from the original on 19 August 2018. Retrieved 20 March 2018. Pennachin, C.; Goertzel, B. (2007). "Contemporary Approaches to Artificial General Intelligence". Artificial General Intelligence. Cognitive Technologies. Berlin, Heidelberg: Springer. doi:10.1007/978-3-540-68677-4_1. ISBN 978-3-540-23733-4. "Ask the AI experts: What's driving today's progress in AI?". McKinsey & Company. Archived from the original on 13 April 2018. Retrieved 13 April 2018. "Reshaping Business With Artificial Intelligence". MIT Sloan Management Review. Archived from the original on 19 May 2018. Retrieved 2 May 2018. Lorica, Ben (18 December 2017). "The state of AI adoption". O'Reilly Media. Archived from the original on 2 May 2018. Retrieved 2 May 2018. "AlphaGo – Google DeepMind". Archived from the original on 10 March 2016. Asada, M.; Hosoda, K.; Kuniyoshi, Y.; Ishiguro, H.; Inui, T.; Yoshikawa, Y.; Ogino, M.; Yoshida, C. (2009). "Cognitive developmental robotics: a survey". IEEE Transactions on Autonomous Mental Development. 1 (1): 12–34. doi:10.1109/tamd.2009.2021702. S2CID 10168773. Ashok83 (10 September 2019). "How AI Is Getting Groundbreaking Changes In Talent Management And HR Tech". Hackernoon. Archived from the original on 11 September 2019. Retrieved 14 February 2020. Berlinski, David (2000). The Advent of the Algorithm. Harcourt Books. ISBN 978-0-15-601391-8. OCLC 46890682. Archived from the original on 26 July 2020. Retrieved 22 August 2020. Brooks, Rodney (1990). "Elephants Don't Play Chess" (PDF). Robotics and Autonomous Systems. 6 (1–2): 3–15. CiteSeerX 10.1.1.588.7539. doi:10.1016/S0921-8890(05)80025-9. Archived (PDF) from the original on 9 August 2007. Butler, Samuel (13 June 1863). "Darwin among the Machines". Letters to the Editor. The Press. Christchurch, New Zealand. Archived from the original on 19 September 2008. Retrieved 16 October 2014 – via Victoria University of Wellington. Clark, Jack (1 July 2015a). "Musk-Backed Group Probes Risks Behind Artificial Intelligence". Bloomberg.com. Archived from the original on 30 October 2015. Retrieved 30 October 2015. Clark, Jack (8 December 2015b). "Why 2015 Was a Breakthrough Year in Artificial Intelligence". Bloomberg.com. Archived from the original on 23 November 2016. Retrieved 23 November 2016. Dennett, Daniel (1991). Consciousness Explained. The Penguin Press. ISBN 978-0-7139-9037-9. Dreyfus, Hubert (1972). What Computers Can't Do. New York: MIT Press. ISBN 978-0-06-011082-6. Dreyfus, Hubert; Dreyfus, Stuart (1986). Mind over Machine: The Power of Human Intuition and Expertise in the Era of the Computer. Oxford, UK: Blackwell. ISBN 978-0-02-908060-3. Archived from the original on 26 July 2020. Retrieved 22 August 2020. Dyson, George (1998). Darwin among the Machines. Allan Lane Science. ISBN 978-0-7382-0030-9. Archived from the original on 26 July 2020. Retrieved 22 August 2020. Edelson, Edward (1991). The Nervous System. New York: Chelsea House. ISBN 978-0-7910-0464-7. Archived from the original on 26 July 2020. Retrieved 18 November 2019. Fearn, Nicholas (2007). The Latest Answers to the Oldest Questions: A Philosophical Adventure with the World's Greatest Thinkers. New York: Grove Press. ISBN 978-0-8021-1839-4. Haugeland, John (1985). Artificial Intelligence: The Very Idea. Cambridge, Mass.: MIT Press. ISBN 978-0-262-08153-5. Hawkins, Jeff; Blakeslee, Sandra (2005). On Intelligence. New York: Owl Books. ISBN 978-0-8050-7853-4. Henderson, Mark (24 April 2007). "Human rights for robots? We're getting carried away". The Times Online. London. Archived from the original on 31 May 2014. Retrieved 31 May 2014. Kahneman, Daniel; Slovic, D.; Tversky, Amos (1982). Judgment under uncertainty: Heuristics and biases. Science. 185. New York: Cambridge University Press. pp. 1124–1131. doi:10.1126/science.185.4157.1124. ISBN 978-0-521-28414-1. PMID 17835457. S2CID 143452957. Katz, Yarden (1 November 2012). "Noam Chomsky on Where Artificial Intelligence Went Wrong". The Atlantic. Archived from the original on 28 February 2019. Retrieved 26 October 2014. Kurzweil, Ray (2005). The Singularity is Near. Penguin Books. ISBN 978-0-670-03384-3. Langley, Pat (2011). "The changing science of machine learning". Machine Learning. 82 (3): 275–279. doi:10.1007/s10994-011-5242-y. Legg, Shane; Hutter, Marcus (15 June 2007). A Collection of Definitions of Intelligence (Technical report). IDSIA. arXiv:0706.3639. Bibcode:2007arXiv0706.3639L. 07-07. Lenat, Douglas; Guha, R. V. (1989). Building Large Knowledge-Based Systems. Addison-Wesley. ISBN 978-0-201-51752-1. Lighthill, James (1973). "Artificial Intelligence: A General Survey". Artificial Intelligence: a paper symposium. Science Research Council. Lombardo, P; Boehm, I; Nairz, K (2020). "RadioComics – Santa Claus and the future of radiology". Eur J Radiol. 122 (1): 108771. doi:10.1016/j.ejrad.2019.108771. PMID 31835078. Lungarella, M.; Metta, G.; Pfeifer, R.; Sandini, G. (2003). "Developmental robotics: a survey". Connection Science. 15 (4): 151–190. CiteSeerX 10.1.1.83.7615. doi:10.1080/09540090310001655110. S2CID 1452734. Maker, Meg Houston (2006). "AI@50: AI Past, Present, Future". Dartmouth College. Archived from the original on 3 January 2007. Retrieved 16 October 2008. McCarthy, John; Minsky, Marvin; Rochester, Nathan; Shannon, Claude (1955). "A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence". Archived from the original on 26 August 2007. Retrieved 30 August 2007. Minsky, Marvin (1967). Computation: Finite and Infinite Machines. Englewood Cliffs, N.J.: Prentice-Hall. ISBN 978-0-13-165449-5. Archived from the original on 26 July 2020. Retrieved 18 November 2019. Moravec, Hans (1988). Mind Children. Harvard University Press. ISBN 978-0-674-57616-2. Archived from the original on 26 July 2020. Retrieved 18 November 2019. NRC (United States National Research Council) (1999). "Developments in Artificial Intelligence". Funding a Revolution: Government Support for Computing Research. National Academy Press. Newell, Allen; Simon, H. A. (1976). "Computer Science as Empirical Inquiry: Symbols and Search". Communications of the ACM. 19 (3): 113–126. doi:10.1145/360018.360022.. Nilsson, Nils (1983). "Artificial Intelligence Prepares for 2001" (PDF). AI Magazine. 1 (1). Archived (PDF) from the original on 17 August 2020. Retrieved 22 August 2020. Presidential Address to the Association for the Advancement of Artificial Intelligence. Oudeyer, P-Y. (2010). "On the impact of robotics in behavioral and cognitive sciences: from insect navigation to human cognitive development" (PDF). IEEE Transactions on Autonomous Mental Development. 2 (1): 2–16. doi:10.1109/tamd.2009.2039057. S2CID 6362217. Archived (PDF) from the original on 3 October 2018. Retrieved 4 June 2013. Schank, Roger C. (1991). "Where's the AI". AI magazine. Vol. 12 no. 4. Searle, John (1980). "Minds, Brains and Programs" (PDF). Behavioral and Brain Sciences. 3 (3): 417–457. doi:10.1017/S0140525X00005756. Archived (PDF) from the original on 17 March 2019. Retrieved 22 August 2020. Searle, John (1999). Mind, language and society. New York: Basic Books. ISBN 978-0-465-04521-1. OCLC 231867665. Archived from the original on 26 July 2020. Retrieved 22 August 2020. Simon, H. A. (1965). The Shape of Automation for Men and Management. New York: Harper & Row. Archived from the original on 26 July 2020. Retrieved 18 November 2019. Solomonoff, Ray (1956). An Inductive Inference Machine (PDF). Dartmouth Summer Research Conference on Artificial Intelligence. Archived (PDF) from the original on 26 April 2011. Retrieved 22 March 2011 – via std.com, pdf scanned copy of the original. Later published as Solomonoff, Ray (1957). "An Inductive Inference Machine". IRE Convention Record. Section on Information Theory, part 2. pp. 56–62. Spadafora, Anthony (21 October 2016). "Stephen Hawking believes AI could be mankind's last accomplishment". BetaNews. Archived from the original on 28 August 2017. Tao, Jianhua; Tan, Tieniu (2005). Affective Computing and Intelligent Interaction. Affective Computing: A Review. LNCS 3784. Springer. pp. 981–995. doi:10.1007/11573548. Tecuci, Gheorghe (March–April 2012). "Artificial Intelligence". Wiley Interdisciplinary Reviews: Computational Statistics. 4 (2): 168–180. doi:10.1002/wics.200. Thro, Ellen (1993). Robotics: The Marriage of Computers and Machines. New York: Facts on File. ISBN 978-0-8160-2628-9. Archived from the original on 26 July 2020. Retrieved 22 August 2020. Turing, Alan (October 1950), "Computing Machinery and Intelligence", Mind, LIX (236): 433–460, doi:10.1093/mind/LIX.236.433, ISSN 0026-4423. Vinge, Vernor (1993). "The Coming Technological Singularity: How to Survive in the Post-Human Era". Vision 21: Interdisciplinary Science and Engineering in the Era of Cyberspace: 11. Bibcode:1993vise.nasa...11V. Archived from the original on 1 January 2007. Retrieved 14 November 2011. Wason, P. C.; Shapiro, D. (1966). "Reasoning". In Foss, B. M. (ed.). New horizons in psychology. Harmondsworth: Penguin. Archived from the original on 26 July 2020. Retrieved 18 November 2019. Weng, J.; McClelland; Pentland, A.; Sporns, O.; Stockman, I.; Sur, M.; Thelen, E. (2001). "Autonomous mental development by robots and animals" (PDF). Science. 291 (5504): 599–600. doi:10.1126/science.291.5504.599. PMID 11229402. S2CID 54131797. Archived (PDF) from the original on 4 September 2013. Retrieved 4 June 2013 – via msu.edu. Further reading DH Author, "Why Are There Still So Many Jobs? The History and Future of Workplace Automation" (2015) 29(3) Journal of Economic Perspectives 3. Boden, Margaret, Mind As Machine, Oxford University Press, 2006. Cukier, Kenneth, "Ready for Robots? How to Think about the Future of AI", Foreign Affairs, vol. 98, no. 4 (July/August 2019), pp. 192–98. George Dyson, historian of computing, writes (in what might be called "Dyson's Law") that "Any system simple enough to be understandable will not be complicated enough to behave intelligently, while any system complicated enough to behave intelligently will be too complicated to understand." (p. 197.) Computer scientist Alex Pentland writes: "Current AI machine-learning algorithms are, at their core, dead simple stupid. They work, but they work by brute force." (p. 198.) Domingos, Pedro, "Our Digital Doubles: AI will serve our species, not control it", Scientific American, vol. 319, no. 3 (September 2018), pp. 88–93. Gopnik, Alison, "Making AI More Human: Artificial intelligence has staged a revival by starting to incorporate what we know about how children learn", Scientific American, vol. 316, no. 6 (June 2017), pp. 60–65. Johnston, John (2008) The Allure of Machinic Life: Cybernetics, Artificial Life, and the New AI, MIT Press. Koch, Christof, "Proust among the Machines", Scientific American, vol. 321, no. 6 (December 2019), pp. 46–49. Christof Koch doubts the possibility of "intelligent" machines attaining consciousness, because "[e]ven the most sophisticated brain simulations are unlikely to produce conscious feelings." (p. 48.) According to Koch, "Whether machines can become sentient [is important] for ethical reasons. If computers experience life through their own senses, they cease to be purely a means to an end determined by their usefulness to... humans. Per GNW [the Global Neuronal Workspace theory], they turn from mere objects into subjects... with a point of view.... Once computers' cognitive abilities rival those of humanity, their impulse to push for legal and political rights will become irresistible—the right not to be deleted, not to have their memories wiped clean, not to suffer pain and degradation. The alternative, embodied by IIT [Integrated Information Theory], is that computers will remain only supersophisticated machinery, ghostlike empty shells, devoid of what we value most: the feeling of life itself." (p. 49.) Marcus, Gary, "Am I Human?: Researchers need new ways to distinguish artificial intelligence from the natural kind", Scientific American, vol. 316, no. 3 (March 2017), pp. 58–63. A stumbling block to AI has been an incapacity for reliable disambiguation. An example is the "pronoun disambiguation problem": a machine has no way of determining to whom or what a pronoun in a sentence refers. (p. 61.) E McGaughey, 'Will Robots Automate Your Job Away? Full Employment, Basic Income, and Economic Democracy' (2018) SSRN, part 2(3) Archived 24 May 2018 at the Wayback Machine. George Musser, "Artificial Imagination: How machines could learn creativity and common sense, among other human qualities", Scientific American, vol. 320, no. 5 (May 2019), pp. 58–63. Myers, Courtney Boyd ed. (2009). "The AI Report" Archived 29 July 2017 at the Wayback Machine. Forbes June 2009 Raphael, Bertram (1976). The Thinking Computer. W.H. Freeman and Co. ISBN 978-0716707233. Archived from the original on 26 July 2020. Retrieved 22 August 2020. Scharre, Paul, "Killer Apps: The Real Dangers of an AI Arms Race", Foreign Affairs, vol. 98, no. 3 (May/June 2019), pp. 135–44. "Today's AI technologies are powerful but unreliable. Rules-based systems cannot deal with circumstances their programmers did not anticipate. Learning systems are limited by the data on which they were trained. AI failures have already led to tragedy. Advanced autopilot features in cars, although they perform well in some circumstances, have driven cars without warning into trucks, concrete barriers, and parked cars. In the wrong situation, AI systems go from supersmart to superdumb in an instant. When an enemy is trying to manipulate and hack an AI system, the risks are even greater." (p. 140.) Serenko, Alexander (2010). "The development of an AI journal ranking based on the revealed preference approach" (PDF). Journal of Informetrics. 4 (4): 447–59. doi:10.1016/j.joi.2010.04.001. Archived (PDF) from the original on 4 October 2013. Retrieved 24 August 2013. Serenko, Alexander; Michael Dohan (2011). "Comparing the expert survey and citation impact journal ranking methods: Example from the field of Artificial Intelligence" (PDF). Journal of Informetrics. 5 (4): 629–49. doi:10.1016/j.joi.2011.06.002. Archived (PDF) from the original on 4 October 2013. Retrieved 12 September 2013. Tom Simonite (29 December 2014). "2014 in Computing: Breakthroughs in Artificial Intelligence". MIT Technology Review. Sun, R. & Bookman, L. (eds.), Computational Architectures: Integrating Neural and Symbolic Processes. Kluwer Academic Publishers, Needham, MA. 1994. Taylor, Paul, "Insanely Complicated, Hopelessly Inadequate" (review of Brian Cantwell Smith, The Promise of Artificial Intelligence: Reckoning and Judgment, MIT, 2019, ISBN 978-0262043045, 157 pp.; Gary Marcus and Ernest Davis, Rebooting AI: Building Artificial Intelligence We Can Trust, Ballantine, 2019, ISBN 978-1524748258, 304 pp.; Judea Pearl and Dana Mackenzie, The Book of Why: The New Science of Cause and Effect, Penguin, 2019, ISBN 978-0141982410, 418 pp.), London Review of Books, vol. 43, no. 2 (21 January 2021), pp. 37–39. Paul Taylor writes (p. 39): "Perhaps there is a limit to what a computer can do without knowing that it is manipulating imperfect representations of an external reality." Tooze, Adam, "Democracy and Its Discontents", The New York Review of Books, vol. LXVI, no. 10 (6 June 2019), pp. 52–53, 56–57. "Democracy has no clear answer for the mindless operation of bureaucratic and technological power. We may indeed be witnessing its extension in the form of artificial intelligence and robotics. Likewise, after decades of dire warning, the environmental problem remains fundamentally unaddressed.... Bureaucratic overreach and environmental catastrophe are precisely the kinds of slow-moving existential challenges that democracies deal with very badly.... Finally, there is the threat du jour: corporations and the technologies they promote." (pp. 56–57.) External links Artificial intelligence at Wikipedia's sister projects Definitions from Wiktionary Media from Wikimedia Commons Quotations from Wikiquote Textbooks from Wikibooks Resources from Wikiversity Data from Wikidata "Artificial Intelligence". Internet Encyclopedia of Philosophy. Thomason, Richmond. "Logic and Artificial Intelligence". In Zalta, Edward N. (ed.). Stanford Encyclopedia of Philosophy. Artificial Intelligence, BBC Radio 4 discussion with John Agar, Alison Adam & Igor Aleksander (In Our Time, Dec. 8, 2005) Articles related to Artificial intelligence Authority control Edit this at Wikidata Sources Definition of Free Cultural Works logo notext.svg This article incorporates text from a free content work. Licensed under C-BY-SA 3.0 IGO Text taken from UNESCO Science Report: the Race Against Time for Smarter Development., Schneegans, S., T. Straza and J. Lewis (eds), UNESCO. To learn how to add open license text to Wikipedia articles, please see this how-to page. For information on reusing text from Wikipedia, please see the terms of use. Categories: Artificial intelligenceCyberneticsFormal sciencesComputational neuroscienceEmerging technologiesUnsolved problems in computer scienceComputational fields of study Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadView sourceView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikibooks Wikinews Wikiquote Wikiversity  Languages Български Deutsch Ελληνικά Français Македонски Shqip Татарча/tatarça Türkçe 中文 113 more Edit links This page was last edited on 6 October 2021, at 23:38 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki.   Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more Animal cognition From Wikipedia, the free encyclopedia Jump to navigationJump to search For the scientific journal, see Animal Cognition.  A crab-eating macaque using a stone tool to crack open a nut File:Bajan-Birds-Pull-Strings-Two-Wild-Antillean-Species-Enter-the-Select-Club-of-String-Pullers-pone.0156112.s005.ogv Experiments like the string-pulling task performed here by a Carib grackle provide insights into animal cognition. Animal cognition encompasses the mental capacities of non-human animals including insect cognition. The study of animal conditioning and learning used in this field was developed from comparative psychology. It has also been strongly influenced by research in ethology, behavioral ecology, and evolutionary psychology; the alternative name cognitive ethology is sometimes used. Many behaviors associated with the term animal intelligence are also subsumed within animal cognition.[1]  Researchers have examined animals that placed in the cognition, in mammals instead of humans; (included primates, cetaceans, elephants, bears, dogs, cats, pigs, horses, cows, rabbits, raccoons, and rodents), birds (including parrots, fowl, corvids, and pigeons), reptiles (lizards, snakes, and turtles), fish and invertebrates (including cephalopods, spiders, and insects).   Contents 1	Historical background 1.1	Earliest inferences 1.2	Morgan's Canon 1.3	From anecdote to laboratory 1.4	The behavioristic half-century 1.5	The cognitive revolution 2	Methods 3	Research questions 3.1	Perception 3.2	Attention 3.2.1	Selective learning 3.2.2	Divided attention 3.2.3	Visual search and attentional priming 3.3	Concepts and categories 3.3.1	Methods 3.3.2	Perceptual categories 3.3.2.1	Natural categories 3.3.3	Functional or associative categories 3.3.4	Relational or abstract categories 3.3.5	Rule learning 3.4	Memory 3.4.1	Methods 3.4.1.1	Habituation 3.4.1.2	Delayed response 3.4.1.3	Radial arm maze 3.4.1.4	Water maze 3.4.1.5	Novel object recognition test 3.5	Spatial cognition 3.5.1	Long-distance navigation; homing 3.6	Timing 3.6.1	Time of day: circadian rhythms 3.6.2	Interval timing 3.7	Tool and weapon use 3.7.1	Mammals 3.7.2	Birds 3.7.3	Fish 3.7.4	Invertebrates 3.8	Reasoning and problem solving 3.9	Cognitive bias 3.10	Language 3.11	Insight 3.12	Numeracy 3.13	Sapience 3.14	Theory of mind 3.15	Consciousness 4	Biological constraints 5	Experimental evidence against animal cognition 6	Cognitive faculty by species 7	See also 8	References 9	Further reading 10	External links Historical background Earliest inferences The mind and behavior of non-human animals has captivated the human imagination for centuries. Many writers, such as Descartes, have speculated about the presence or absence of the animal mind.[2] These speculations led to many observations of animal behavior before modern science and testing were available. This ultimately resulted in the creation of multiple hypotheses about animal intelligence.  One of Aesop's Fables was The Crow and the Pitcher, in which a crow drops pebbles into a vessel of water until he is able to drink. This was a relatively accurate reflection of the capability of corvids to understand water displacement.[3] The Roman naturalist Pliny the Elder was the earliest to attest that said story reflects the behavior of real-life corvids.[4]  Aristotle, in his biology, hypothesized a causal chain where an animal's sense organs transmitted information to an organ capable of making decisions, and then to a motor organ. Despite Aristotle's cardiocentrism (mistaken belief that cognition occurred in the heart), this approached some modern understandings of information processing.[5]  Early inferences were not necessarily precise or accurate. Nonetheless, interest in animal mental abilities, and comparisons to humans, increased with early myrmecology, the study of ant behavior, as well as the classification of humans as primates beginning with Linnaeus.  Morgan's Canon Main article: Morgan's Canon Coined by 19th-century British psychologist C. Lloyd Morgan, Morgan's Canon remains a fundamental precept of comparative (animal) psychology. In its developed form, it states that:[6]  In no case is an animal activity to be interpreted in terms of higher psychological processes if it can be fairly interpreted in terms of processes which stand lower in the scale of psychological evolution and development.  In other words, Morgan believed that anthropomorphic approaches to animal behavior were fallacious, and that people should only consider behaviour as, for example, rational, purposive or affectionate, if there is no other explanation in terms of the behaviours of more primitive life-forms to which we do not attribute those faculties.  From anecdote to laboratory See also: Comparative psychology Speculation about animal intelligence gradually yielded to scientific study after Darwin placed humans and animals on a continuum, although Darwin's largely anecdotal approach to the topic would not pass scientific muster later on.[7] This method would be expanded by his protégé George J. Romanes,[8] who played a key role in the defense of Darwinism and its refinement over the years. Still, Romanes is most famous for two major flaws in his work: his focus on anecdotal observations and entrenched anthropomorphism.[9] Unsatisfied with the previous approach, E. L. Thorndike brought animal behavior into the laboratory for objective scrutiny. Thorndike's careful observations of the escape of cats, dogs, and chicks from puzzle boxes led him to conclude that what appears to the naive human observer to be intelligent behavior may be strictly attributable to simple associations. According to Thorndike, using Morgan's Canon, the inference of animal reason, insight, or consciousness is unnecessary and misleading.[10] At about the same time, I. P. Pavlov began his seminal studies of conditioned reflexes in dogs. Pavlov quickly abandoned attempts to infer canine mental processes; such attempts, he said, led only to disagreement and confusion. He was, however, willing to propose unseen physiological processes that might explain his observations.[11]  The behavioristic half-century The work of Thorndike, Pavlov and a little later of the outspoken behaviorist John B. Watson[12] set the direction of much research on animal behavior for more than half a century. During this time there was considerable progress in understanding simple associations; notably, around 1930 the differences between Thorndike's instrumental (or operant) conditioning and Pavlov's classical (or Pavlovian) conditioning were clarified, first by Miller and Kanorski, and then by B. F. Skinner.[13][14] Many experiments on conditioning followed; they generated some complex theories,[15] but they made little or no reference to intervening mental processes. Probably the most explicit dismissal of the idea that mental processes control behavior was the radical behaviorism of Skinner. This view seeks to explain behavior, including "private events" like mental images, solely by reference to the environmental contingencies impinging on the human or animal.[16]  Despite the predominantly behaviorist orientation of research before 1960, the rejection of mental processes in animals was not universal during those years. Influential exceptions included, for example, Wolfgang Köhler and his insightful chimpanzees[17] and Edward Tolman whose proposed cognitive map was a significant contribution to subsequent cognitive research in both humans and animals.[18]  The cognitive revolution Beginning around 1960, a "cognitive revolution" in research on humans[19] gradually spurred a similar transformation of research with animals. Inference to processes not directly observable became acceptable and then commonplace. An important proponent of this shift in thinking was Donald O. Hebb, who argued that "mind" is simply a name for processes in the head that control complex behavior, and that it is both necessary and possible to infer those processes from behavior.[20] Animals came to be seen as "goal seeking agents that acquire, store, retrieve, and internally process information at many levels of cognitive complexity".[21]  Methods The acceleration of research on animal cognition in the last 50 years or so has led to a rapid expansion in the variety of species studied and methods employed. The remarkable behavior of large-brained animals such as primates and cetacea have claimed special attention, but all sorts of animals large and small (birds, fish, ants, bees, and others) have been brought into the laboratory or observed in carefully controlled field studies. In the laboratory, animals push levers, pull strings, dig for food, swim in water mazes, or respond to images on computer screens to get information for discrimination, attention, memory, and categorization experiments.[22] Careful field studies explore memory for food caches, navigation by stars,[23] communication, tool use, identification of conspecifics, and many other matters. Studies often focus on the behavior of animals in their natural environments and discuss the putative function of the behavior for the propagation and survival of the species. These developments reflect an increased cross-fertilization from related fields such as ethology and behavioral ecology. Contributions from behavioral neuroscience are beginning to clarify the physiological substrate of some inferred mental process.  Some researchers have made effective use of a Piagetian methodology, taking tasks which human children are known to master at different stages of development and investigating which of them can be performed by particular species. Others have been inspired by concerns for animal welfare and the management of domestic species; for example, Temple Grandin has harnessed her unique expertise in animal welfare and the ethical treatment of farm livestock to highlight underlying similarities between humans and other animals.[24] From a methodological point of view, one of the main risks in this sort of work is anthropomorphism, the tendency to interpret an animal's behavior in terms of human feelings, thoughts, and motivations.[1]  Research questions  The common chimpanzee can use tools. This individual is using a stick to get food. Human and non-human animal cognition have much in common, and this is reflected in the research summarized below; most of the headings found here might also appear in an article on human cognition. Of course, research in the two also differs in important respects. Notably, much research with humans either studies or involves language, and much research with animals is related directly or indirectly to behaviors important to survival in natural settings. Following are summaries of some of the major areas of research in animal cognition.  Perception Animals process information from eyes, ears, and other sensory organs to perceive the environment. Perceptual processes have been studied in many species, with results that are often similar to those in humans. Equally interesting are those perceptual processes that differ from, or go beyond those found in humans, such as echolocation in bats and dolphins, motion detection by skin receptors in fish, and extraordinary visual acuity, motion sensitivity and ability to see ultraviolet light in some birds.[25]  Attention Much of what is happening in the world at any moment is irrelevant to current behavior. Attention refers to mental processes that select relevant information, inhibit irrelevant information, and switch among these as the situation demands.[26] Often the selective process is tuned before relevant information appears; such expectation makes for rapid selection of key stimuli when they become available. A large body of research has explored the way attention and expectation affect the behavior of non-human animals, and much of this work suggests that attention operates in birds, mammals and reptiles in much the same way that it does in humans.[27]  Selective learning Animals trained to discriminate between two stimuli, say black versus white, can be said to attend to the "brightness dimension," but this says little about whether this dimension is selected in preference to others. More enlightenment comes from experiments that allow the animal to choose from several alternatives. For example, several studies have shown that performance is better on, for example, a color discrimination (e.g. blue vs green) after the animal has learned another color discrimination (e.g. red vs orange) than it is after training on a different dimension such as an X shape versus an O shape. The reverse effect happens after training on forms. Thus, the earlier learning appears to affect which dimension, color or form, the animal will attend to.[28]  Other experiments have shown that after animals have learned to respond to one aspect of the environment responsiveness to other aspects is suppressed. In "blocking", for example, an animal is conditioned to respond to one stimulus ("A") by pairing that stimulus with reward or punishment. After the animal responds consistently to A, a second stimulus ("B") accompanies A on additional training trials. Later tests with the B stimulus alone elicit little response, suggesting that learning about B has been blocked by prior learning about A.[29] This result supports the hypothesis that stimuli are neglected if they fail to provide new information. Thus, in the experiment just cited, the animal failed to attend to B because B added no information to that supplied by A. If true, this interpretation is an important insight into attentional processing, but this conclusion remains uncertain because blocking and several related phenomena can be explained by models of conditioning that do not invoke attention.[30]  Divided attention Attention is a limited resource and is not a none-or-all response: the more attention devoted to one aspect of the environment, the less is available for others.[31] A number of experiments have studied this in animals. In one experiment, a tone and a light are presented simultaneously to pigeons. The pigeons gain a reward only by choosing the correct combination of the two stimuli (e.g. a high frequency tone together with a yellow light). The birds perform well at this task, presumably by dividing attention between the two stimuli. When only one of the stimuli varies and the other is presented at its rewarded value, discrimination improves on the variable stimulus but discrimination on the alternative stimulus worsens.[32] These outcomes are consistent with the notion that attention is a limited resource that can be more or less focused among incoming stimuli.  Visual search and attentional priming As noted above, the function of attention is to select information that is of special use to the animal. Visual search typically calls for this sort of selection, and search tasks have been used extensively in both humans and animals to determine the characteristics of attentional selection and the factors that control it.  Experimental research on visual search in animals was initially prompted by field observations published by Luc Tinbergen (1960).[33] Tinbergen observed that birds are selective when foraging for insects. For example, he found that birds tended to catch the same type of insect repeatedly even though several types were available. Tinbergen suggested that this prey selection was caused by an attentional bias that improved detection of one type of insect while suppressing detection of others. This "attentional priming" is commonly said to result from a pretrial activation of a mental representation of the attended object, which Tinbergen called a "searching image".  Tinbergen's field observations on priming have been supported by a number of experiments. For example, Pietrewicz and Kamil (1977, 1979)[34][35] presented blue jays with pictures of tree trunks upon which rested either a moth of species A, a moth of species B, or no moth at all. The birds were rewarded for pecks at a picture showing a moth. Crucially, the probability with which a particular species of moth was detected was higher after repeated trials with that species (e.g. A, A, A,...) than it was after a mixture of trials (e.g. A, B, B, A, B, A, A...). These results suggest again that sequential encounters with an object can establish an attentional predisposition to see the object.  Another way to produce attentional priming in search is to provide an advance signal that is associated with the target. For example, if a person hears a song sparrow he or she may be predisposed to detect a song sparrow in a shrub, or among other birds. A number of experiments have reproduced this effect in animal subjects.[36][37]  Still other experiments have explored nature of stimulus factors that affect the speed and accuracy of visual search. For example, the time taken to find a single target increases as the number of items in the visual field increases. This rise in RT is steep if the distracters are similar to the target, less steep if they are dissimilar, and may not occur if the distracters are very different from the target in form or color.[38]  Concepts and categories Fundamental but difficult to define, the concept of "concept" was discussed for hundreds of years by philosophers before it became a focus of psychological study. Concepts enable humans and animals to organize the world into functional groups; the groups may be composed of perceptually similar objects or events, diverse things that have a common function, relationships such as same versus different, or relations among relations such as analogies.[39] Extensive discussions on these matters together with many references may be found in Shettleworth (2010)[1] Wasserman and Zentall (2006)[22] and in Zentall et al. (2008). The latter is freely available online.[40]  Methods Most work on animal concepts has been done with visual stimuli, which can easily be constructed and presented in great variety, but auditory and other stimuli have been used as well.[41] Pigeons have been widely used, for they have excellent vision and are readily conditioned to respond to visual targets; other birds and a number of other animals have been studied as well.[1] In a typical experiment, a bird or other animal confronts a computer monitor on which a large number of pictures appear one by one, and the subject gets a reward for pecking or touching a picture of a category item and no reward for non-category items. Alternatively, a subject may be offered a choice between two or more pictures. Many experiments end with the presentation of items never seen before; successful sorting of these items shows that the animal has not simply learned many specific stimulus-response associations. A related method, sometimes used to study relational concepts, is matching-to-sample. In this task an animal sees one stimulus and then chooses between two or more alternatives, one of which is the same as the first; the animal is then rewarded for choosing the matching stimulus.[1][22][40]  Perceptual categories Perceptual categorization is said to occur when a person or animal responds in a similar way to a range of stimuli that share common features. For example, a squirrel climbs a tree when it sees Rex, Shep, or Trixie, which suggests that it categorizes all three as something to avoid. This sorting of instances into groups is crucial to survival. Among other things, an animal must categorize if it is to apply learning about one object (e.g. Rex bit me) to new instances of that category (dogs may bite).[1][22][40]  Natural categories Many animals readily classify objects by perceived differences in form or color. For example, bees or pigeons quickly learn to choose any red object and reject any green object if red leads to reward and green does not. Seemingly much more difficult is an animal's ability to categorize natural objects that vary a great deal in color and form even while belonging to the same group. In a classic study, Richard J. Herrnstein trained pigeons to respond to the presence or absence of human beings in photographs.[42] The birds readily learned to peck photos that contained partial or full views of humans and to avoid pecking photos with no human, despite great differences in the form, size, and color of both the humans displayed and in the non-human pictures. In follow-up studies, pigeons categorized other natural objects (e.g. trees) and after training they were able without reward to sort photos they had not seen before .[43][44] Similar work has been done with natural auditory categories, for example, bird songs.[45] Honeybees (Apis mellifera) are able to form concepts of "up" and "down".[46]  Functional or associative categories Perceptually unrelated stimuli may come to be responded to as members of a class if they have a common use or lead to common consequences. An oft-cited study by Vaughan (1988) provides an example.[47] Vaughan divided a large set of unrelated pictures into two arbitrary sets, A and B. Pigeons got food for pecking at pictures in set A but not for pecks at pictures in set B. After they had learned this task fairly well, the outcome was reversed: items in set B led to food and items in set A did not. Then the outcome was reversed again, and then again, and so on. Vaughan found that after 20 or more reversals, associating a reward with a few pictures in one set caused the birds to respond to the other pictures in that set without further reward as if they were thinking "if these pictures in set A bring food, the others in set A must also bring food." That is, the birds now categorized the pictures in each set as functionally equivalent. Several other procedures have yielded similar results.[1][40]  Relational or abstract categories When tested in a simple stimulus matching-to-sample task (described above) many animals readily learn specific item combinations, such as "touch red if the sample is red, touch green if the sample is green." But this does not demonstrate that they distinguish between "same" and "different" as general concepts. Better evidence is provided if, after training, an animal successfully makes a choice that matches a novel sample that it has never seen before. Monkeys and chimpanzees do learn to do this, as do pigeons if they are given a great deal of practice with many different stimuli. However, because the sample is presented first, successful matching might mean that the animal is simply choosing the most recently seen "familiar" item rather than the conceptually "same" item. A number of studies have attempted to distinguish these possibilities, with mixed results.[1][40]  Rule learning The use of rules has sometimes been considered an ability restricted to humans, but a number of experiments have shown evidence of simple rule learning in primates[48] and also in other animals. Much of the evidence has come from studies of sequence learning in which the "rule" consists of the order in which a series of events occurs. Rule use is shown if the animal learns to discriminate different orders of events and transfers this discrimination to new events arranged in the same order. For example, Murphy et al. (2008)[49] trained rats to discriminate between visual sequences. For one group ABA and BAB were rewarded, where A="bright light" and B="dim light". Other stimulus triplets were not rewarded. The rats learned the visual sequence, although both bright and dim lights were equally associated with reward. More importantly, in a second experiment with auditory stimuli, rats responded correctly to sequences of novel stimuli that were arranged in the same order as those previously learned. Similar sequence learning has been demonstrated in birds and other animals as well.[50]  Memory The categories that have been developed to analyze human memory (short term memory, long term memory, working memory) have been applied to the study of animal memory, and some of the phenomena characteristic of human short term memory (e.g. the serial position effect) have been detected in animals, particularly monkeys.[51] However most progress has been made in the analysis of spatial memory; some of this work has sought to clarify the physiological basis of spatial memory and the role of the hippocampus; other work has explored the spatial memory of scatter-hoarder animals such as Clark's nutcracker, certain jays, tits and certain squirrels, whose ecological niches require them to remember the locations of thousands of caches,[1][52] often following radical changes in the environment.  Memory has been widely investigated in foraging honeybees, Apis mellifera, which use both transient short-term working memory that is non-feeder specific and a feeder specific long-term reference memory.[53][54][55] Memory induced in a free-flying honeybee by a single learning trial lasts for days and, by three learning trials, for a lifetime.[56] Bombus terrestris audax workers vary in their effort investment towards memorising flower locations, with smaller workers less able to be selective and thus less interested in which flowers are richer sugar sources.[57][58] Meanwhile, bigger B. t. audax workers have more carrying capacity and thus more reason to memorise that information, and so they do.[57][58] Slugs, Limax flavus, have a short-term memory of approximately 1 min and long-term memory of 1 month.[59]  Methods As in humans, research with animals distinguishes between "working" or "short-term" memory from "reference" or long-term memory. Tests of working memory evaluate memory for events that happened in the recent past, usually within the last few seconds or minutes. Tests of reference memory evaluate memory for regularities such as "pressing a lever brings food" or "children give me peanuts".  Habituation Main article: Habituation This is one of the simplest tests for memory spanning a short time interval. The test compares an animal's response to a stimulus or event on one occasion to its response on a previous occasion. If the second response differs consistently from the first, the animal must have remembered something about the first, unless some other factor such as motivation, sensory sensitivity, or the test stimulus has changed.  Delayed response Delayed response tasks are often used to study short-term memory in animals. Introduced by Hunter (1913), a typical delayed response task presents an animal with a stimulus such a colored light, and after a short time interval the animal chooses among alternatives that match the stimulus, or are related to the stimulus in some other way. In Hunter's studies, for example, a light appeared briefly in one of three goal boxes and then later the animal chose among the boxes, finding food behind the one that had been lighted.[60] Most research has been done with some variation of the "delayed matching-to-sample" task. For example, in the initial study with this task, a pigeon was presented with a flickering or steady light. Then, a few seconds later, two pecking keys were illuminated, one with a steady light and one with a flickering light. The bird got food if it pecked the key that matched the original stimulus.[61]  A commonly-used variation of the matching-to-sample task requires the animal to use the initial stimulus to control a later choice between different stimuli. For example, if the initial stimulus is a black circle, the animal learns to choose "red" after the delay; if it is a black square, the correct choice is "green". Ingenious variations of this method have been used to explore many aspects of memory, including forgetting due to interference and memory for multiple items.[1]  Radial arm maze Main article: Radial arm maze The radial arm maze is used to test memory for spatial location and to determine the mental processes by which location is determined. In a radial maze test, an animal is placed on a small platform from which paths lead in various directions to goal boxes; the animal finds food in one or more goal boxes. Having found food in a box, the animal must return to the central platform. The maze may be used to test both reference and working memory. Suppose, for example, that over a number of sessions the same 4 arms of an 8-arm maze always lead to food. If in a later test session the animal goes to a box that has never been baited, this indicates a failure of reference memory. On the other hand, if the animal goes to a box that it has already emptied during the same test session, this indicates a failure of working memory. Various confounding factors, such as odor cues, are carefully controlled in such experiments.[62]  Water maze Main article: Morris water navigation task The water maze is used to test an animal's memory for spatial location and to discover how an animal is able to determine locations. Typically the maze is a circular tank filled with water that has been made milky so that it is opaque. Located somewhere in the maze is a small platform placed just below the surface of the water. When placed in the tank, the animal swims around until it finds and climbs up on the platform. With practice, the animal finds the platform more and more quickly. Reference memory is assessed by removing the platform and observing the relative amount of time the animal spends swimming in the area where the platform had been located. Visual and other cues in and around the tank may be varied to assess the animal's reliance on landmarks and the geometric relations among them.[63]  Novel object recognition test The novel object recognition (NOR) test is an animal behavior test that is primarily used to assess memory alterations in rodents. It is a simple behavioral test that is based on a rodents innate exploratory behavior. The test is divided into three phases: habituation, training/adaptation and test phase. During the habituation phase the animal is placed in an empty test arena. This is followed by the adaptation phase, where the animal is placed in the arena with two identical objects. In the third phase, the test phase, the animal is placed in the arena with one of the familiar objects from the previous phase and with one novel object. Based on the rodents innate curiosity, the animals that remember the familiar object will spend more time on investigating the novel object.[64]  Spatial cognition Whether an animal ranges over a territory measured in square kilometers or square meters, its survival typically depends on its ability to do such things as find a food source and then return to its nest. Sometimes such a task can be performed rather simply, for example by following a chemical trail. Typically, however, the animal must somehow acquire and use information about locations, directions, and distances. The following paragraphs outline some of the ways that animals do this.[1][65]  Beacons Animals often learn what their nest or other goal looks like, and if it is within sight they may simply move toward it; it is said to serve as a "beacon". Landmarks When an animal is unable to see its goal, it may learn the appearance of nearby objects and use these landmarks as guides. Researchers working with birds and bees have demonstrated this by moving prominent objects in the vicinity of nest sites, causing returning foragers to hunt for their nest in a new location.[1] Dead reckoning, also known as "path integration," is the process of computing one's position by starting from a known location and keeping track of the distances and directions subsequently traveled. Classic experiments have shown that the desert ant keeps track of its position in this way as it wanders for many meters searching for food. Though it travels in a randomly twisted path, it heads straight home when it finds food. However, if the ant is picked up and released some meters to the east, for example, it heads for a location displaced by the same amount to the east of its home nest. Cognitive maps Some animals appear to construct a cognitive map of their surroundings, meaning that they acquire and use information that enables them to compute how far and in what direction to go to get from one location to another. Such a map-like representation is thought to be used, for example, when an animal goes directly from one food source to another even though its previous experience has involved only travel between each source and home.[1][66] Research in this area[65] has also explored such topics as the use of geometric properties of the environment by rats and pigeons, and the ability of rats to represent a spatial pattern in either radial arm mazes or water mazes. Spatial cognition is used in visual search when an animal or human searches their environment for specific objects to focus on among other objects in the environment.[67] Detour behaviour Some animals appear to have an advanced understanding of their spatial environment and will not take the most direct route if this confers an advantage to them. Some jumping spiders take an indirect route to prey rather than the most direct route, thereby indicating flexibility in behaviour and route planning, and possibly insight learning.[68] Long-distance navigation; homing Main article: Animal navigation Many animals travel hundreds or thousands of miles in seasonal migrations or returns to breeding grounds. They may be guided by the sun, the stars, the polarization of light, magnetic cues, olfactory cues, winds, or a combination of these.[69] This extensive area of research is covered in the main article on Animal navigation.  It has been hypothesized that animals such as apes and wolves are good at spatial cognition because this skill is necessary for survival. Some researchers argue that this ability may have diminished somewhat in dogs because humans have provided necessities such as food and shelter during some 15,000 years of domestication.[70][71][72]  Timing Further information: Time perception Time of day: circadian rhythms Main article: Circadian rhythms The behavior of most animals is synchronized with the earth's daily light-dark cycle. Thus, many animals are active during the day, others are active at night, still others near dawn and dusk. Though one might think that these "circadian rhythms" are controlled simply by the presence or absence of light, nearly every animal that has been studied has been shown to have a "biological clock" that yields cycles of activity even when the animal is in constant illumination or darkness.[1] Circadian rhythms are so automatic and fundamental to living things – they occur even in plants[73] – that they are usually discussed separately from cognitive processes, and the reader is referred to the main article (Circadian rhythms) for further information.[74]  Interval timing Survival often depends on an animal's ability to time intervals. For example, rufous hummingbirds feed on the nectar of flowers, and they often return to the same flower, but only after the flower has had enough time to replenish its supply of nectar. In one experiment hummingbirds fed on artificial flowers that quickly emptied of nectar but were refilled at some fixed time (e.g. twenty minutes) later. The birds learned to come back to the flowers at about the right time, learning the refill rates of up to eight separate flowers and remembering how long ago they had visited each one.[75]  The details of interval timing have been studied in a number of species. One of the most common methods is the "peak procedure". In a typical experiment, a rat in an operant chamber presses a lever for food. A light comes on, a lever-press brings a food pellet at a fixed later time, say 10 seconds, and then the light goes off. Timing is measured during occasional test trials on which no food is presented and the light stays on. On these test trials, the rat presses the lever more and more until about 10 sec and then, when no food comes, gradually stops pressing. The time at which the rat presses most on these test trials is taken to be its estimate of the payoff time.  Experiments using the peak procedure and other methods have shown that animals can time short intervals quite exactly, can time more than one event at once, and can integrate time with spatial and other cues. Such tests have also been used for quantitative tests of theories of animal timing, such as Gibbon's Scalar Expectancy Theory ("SET"),[76] Killeen's Behavioral Theory of Timing,[77] and Machado's Learning to Time model.[78] No one theory has yet gained unanimous agreement.[1]  Tool and weapon use Main article: Tool use by animals Although tool use was long assumed to be a uniquely human trait, there is now much evidence that many animals use tools, including mammals, birds, fish, cephalopods and insects. Discussions of tool use often involve a debate about what constitutes a "tool", and they often consider the relation of tool use to the animal's intelligence and brain size.  Mammals Series of photographs showing a bonobo fishing for termites.  A bonobo inserting a stick into a termite mound.  The bonobo starts "fishing" for the termites.  The bonobo withdraws the stick and begins eating the termites.  The bonobo eats the termites extracted with the tool. Tool use has been reported many times in both wild and captive primates, particularly the great apes. The use of tools by primates is varied and includes hunting (mammals, invertebrates, fish), collecting honey, processing food (nuts, fruits, vegetables and seeds), collecting water, weapons and shelter. Research in 2007 shows that chimpanzees in the Fongoli savannah sharpen sticks to use as spears when hunting, considered the first evidence of systematic use of weapons in a species other than humans.[79] Other mammals that spontaneously use tools in the wild or in captivity include elephants, bears, cetaceans, sea otters and mongooses.  Birds Several species of birds have been observed to use tools in the wild, including warblers, parrots, Egyptian vultures, brown-headed nuthatches, gulls and owls. Some species, such as the woodpecker finch of the Galapagos Islands, use particular tools as an essential part of their foraging behavior. However, these behaviors are often quite inflexible and cannot be applied effectively in new situations. A great many species of birds build nests with a wide range of complexities, but although nest-building behaviour fulfills the criteria of some definitions of "tool-use", this is not the case with other definitions.  Several species of corvids have been trained to use tools in controlled experiments. One species examined extensively under laboratory conditions is the New Caledonian crow. One individual called “Betty” spontaneously made a wire tool to solve a novel problem. She was being tested to see whether she would select a wire hook rather than a straight wire to pull a little bucket of meat out of a well. Betty tried poking the straight wire at the meat. After a series of failures with this direct approach, she withdrew the wire and began directing it at the bottom of the well, which was secured to its base with duct tape. The wire soon became stuck, whereupon Betty pulled it sideways, bending it and unsticking it. She then inserted the hook into the well and extracted the meat. In all but one of 10 subsequent trials with only straight wire provided, she also made and used a hook in the same manner, but not before trying the straight wire first.[80][81]  Fish Main article: Fish intelligence Several species of wrasses have been observed using rocks as anvils to crack bivalve (scallops, urchins and clams) shells. This behavior was first filmed[82] in an orange-dotted tuskfish (Choerodon anchorago) in 2009 by Giacomo Bernardi. The fish fans sand to unearth the bivalve, takes it into its mouth, swims several meters to a rock, which it then uses as an anvil by smashing the mollusc apart with sideward thrashes of the head. This behaviour has also been recorded in a blackspot tuskfish (Choerodon schoenleinii) on Australia's Great Barrier Reef, yellowhead wrasse (Halichoeres garnoti) in Florida and a six-bar wrasse (Thalassoma hardwicke) in an aquarium setting. These species are at opposite ends of the phylogenetic tree in this family, so this behaviour may be a deep-seated trait in all wrasses.[83]  Invertebrates Some cephalopods are known to use coconut shells for protection or camouflage.[84]  Ants of the species Conomyrma bicolor pick up stones and other small objects with their mandibles and drop them down the vertical entrances of rival colonies, allowing workers to forage for food without competition.[85]  Reasoning and problem solving It is clear that animals of quite a range of species are capable of solving problems that appear to require abstract reasoning;[86] Wolfgang Köhler's (1917) work with chimpanzees is a famous early example. He observed that chimpanzees did not use trial and error to solve problems such as retrieving bananas hung out of reach. Instead, they behaved in a manner that was "unwaveringly purposeful," spontaneously placing boxes so that they could climb to reach the fruit.[17] Modern research has identified similar behavior in animals usually thought of as much less intelligent, if appropriate pre-training is given.[87] Causal reasoning has also been observed in rooks and New Caledonian crows.[88][89]  It has been shown that Barbados bullfinches (Loxigilla barbadensis) from urbanized areas are better at innovative problem-solving tasks than bullfinches from rural environments, but that they did not differ in colour discrimination learning.[90]  Cognitive bias Main article: Cognitive bias  Is the glass half empty or half full? A cognitive bias refers to a systematic pattern of deviation from norm or rationality in judgment, whereby inferences about other individuals or situations may be drawn in an illogical fashion.  Cognitive bias is sometimes illustrated by using answers to the question "Is the glass half empty or half full?". Choosing "half empty" is supposed to indicate pessimism whereas choosing "half full" indicates optimism. To test this in animals, an individual is trained to anticipate that stimulus A, e.g. a 100 Hz tone, precedes a positive event, e.g. highly desired food is delivered when a lever is pressed by the animal. The same individual is trained to anticipate that stimulus B, e.g. a 900 Hz tone, precedes a negative event, e.g. bland food is delivered when the animal presses a lever. The animal is then tested by being given an intermediate stimulus C, e.g. a 500 Hz tone, and observing whether the animal presses the lever associated with the positive or negative reward. This has been suggested to indicate whether the animal is in a positive or negative mood.[91]  In a study that used this approach, rats that were playfully tickled responded differently than rats that were simply handled. The rats that had been tickled were more optimistic than the handled rats.[92] The authors suggested that they had demonstrated "...for the first time a link between the directly measured positive affective state and decision making under uncertainty in an animal model".  There is some evidence for cognitive bias in a number of species, including rats, dogs, rhesus macaques, sheep, chicks, starlings and honeybees.[93]  Language Main articles: Animal language and Human-animal communication Further information: Talking animal The modeling of human language in animals is known as animal language research. In addition to the ape-language experiments mentioned above, there have also been more or less successful attempts to teach language or language-like behavior to some non-primate species, including parrots and great spotted woodpeckers. Arguing from his own results with the animal Nim Chimpsky and his analysis of others results, Herbert Terrace criticized the idea that chimps can produce new sentences.[94] Shortly thereafter Louis Herman published research on artificial language comprehension in the bottlenosed dolphin (Herman, Richards, & Wolz, 1984). Though this sort of research has been controversial, especially among cognitive linguists, many researchers agree that many animals can understand the meaning of individual words, and that some may understand simple sentences and syntactic variations, but there is little evidence that any animal can produce new strings of symbols that correspond to new sentences.[1]  Insight See also: Reason Wolfgang Köhler is usually credited with introducing the concept of insight into experimental psychology.[81] Working with chimpanzees, Köhler came to dispute Edward Thorndike's theory that animals must solve problems gradually, by trial and error. He said that Thorndike's animals could only use trial and error because the situation precluded other forms of problem solving. He provided chimps with a relatively unstructured situation, and he observed sudden "ah-ha!" insightful changes of behavior, as, for example, when a chimp suddenly moved a box into position so that it could retrieve a banana.[95] More recently, Asian elephants (Elephas maximus) were shown to exhibit similar insightful problem solving. A male was observed moving a box to a position where it could be stood upon to reach food that had been deliberately hung out of reach.[96]  Numeracy Main article: Number sense in animals A variety of studies indicates that animals are able to use and communicate quantitative information, and that some can count in a rudimentary way. Some examples of this research follow.  In one study, rhesus monkeys viewed visual displays containing, for example, 1, 2, 3, or 4 items of different sorts. They were trained to respond to them in several ways involving numerical ordering, for example touching "1" first, "2" second and so on. When tested with displays containing items they had never seen before, they continued to respond to them in order. The authors conclude that monkeys can represent the numerosities 1 to 9 at least on an ordinal scale.[97]  Ants are able to use quantitative values and transmit this information.[98][99] For instance, ants of several species are able to estimate quite precisely numbers of encounters with members of other colonies on their feeding territories.[100][101] Numeracy has been described in the yellow mealworm beetle (Tenebrio molitor)[102] and the honeybee.[103]  Western lowland gorillas given the choice between two food trays demonstrated the ability to choose the tray with more food items at a rate higher than chance after training.[104] In a similar task, chimpanzees chose the option with the larger amount of food.[105] Salamanders given a choice between two displays with differing amounts of fruit flies, used as a food reward, reliably choose the display with more flies, as shown in a particular experiment.[106]  Other experiments have been conducted that show animals' abilities to differentiate between non-food quantities. American black bears demonstrated quantity differentiation abilities in a task with a computer screen. The bears were trained to touch a computer monitor with a paw or nose to choose a quantity of dots in one of two boxes on the screen. Each bear was trained with reinforcement to pick a larger or smaller amount. During training, the bears were rewarded with food for a correct response. All bears performed better than what random error predicted on the trials with static, non-moving dots, indicating that they could differentiate between the two quantities. The bears choosing correctly in congruent (number of dots coincided with area of the dots) and incongruent (number of dots did not coincide with area of the dots) trials suggests that they were indeed choosing between quantities that appeared on the screen, not just a larger or smaller retinal image, which would indicate they are only judging size.[107]  Bottlenose dolphins have shown the ability to choose an array with fewer dots compared to one with more dots. Experimenters set up two boards showing various numbers of dots in a poolside setup. The dolphins were initially trained to choose the board with the fewer number of dots. This was done by rewarding the dolphin when it chose the board with the fewer number of dots. In the experimental trials, two boards were set up, and the dolphin would emerge from the water and point to one board. The dolphins chose the arrays with fewer dots at a rate much larger than chance, indicating they can differentiate between quantities.[108] A particular grey parrot, after training, has shown the ability to differentiate between the numbers zero through six using vocalizations. After number and vocalization training, this was done by asking the parrot how many objects there were in a display. The parrot was able to identify the correct amount at a rate higher than chance.[109] Angelfish, when put in an unfamiliar environment will group together with conspecifics, an action named shoaling. Given the choice between two groups of differing size, the angelfish will choose the larger of the two groups. This can be seen with a discrimination ratio of 2:1 or greater, such that, as long as one group has at least twice the fish as another group, it will join the larger one.[110]  Monitor lizards have been shown to be capable of numeracy, and some species can distinguish among numbers up to six.[111]  Sapience Main article: g factor in non-humans As the cognitive ability and intelligence in non-human animals cannot be measured with verbal scales, it has been measured using a variety of methods that involve such things as habit reversal, social learning, and responses to novelty. Principal Component Analysis and factor analytic studies have shown that a single factor of intelligence is responsible for 47% of the individual variance in cognitive ability measures in primates[112] and between 55% and 60% of the variance in mice.[113][114] These values are similar to the accepted variance in IQ explained by a similar single factor known as the general factor of intelligence in humans (40-50%).[115] However, results from a recent meta-analysis suggest that the average correlation between performance scores on various cognitive tasks is only 0.18.[116] Results from this study suggest that current evidence for general intelligence is weak in non-human animals.[116]  The general factor of intelligence, or g factor, is a psychometric construct that summarizes the correlations observed between an individual's scores on various measures of cognitive abilities. It has been suggested that g is related to evolutionary life histories and the evolution of intelligence[117] as well as to social learning and cultural intelligence.[118][119] Non-human models of g have been used in genetic[120] and neurological[121] research on intelligence to help understand the mechanisms behind variation in g.  Theory of mind Main article: Theory of mind in animals Theory of mind is the ability to attribute mental states, e.g. intents, desires, pretending, knowledge, to oneself and others and to understand that others have desires, intentions, and perspectives that are different from one's own.[122]  Some research with ravens provides an example of evidence for theory of mind in a non-human species. Ravens are members of the family Corvidae, which is widely regarded as having high cognitive abilities. These birds have been observed to hide their food when dominant ravens are visible and audible at the same time. Based on this observation, ravens were tested for their understanding of "seeing" as a mental state. In a first step, the birds protected their cache when dominants were visible but not when they could only be heard from an adjacent room. In the next step, they had access to a small peephole which allowed them to see into the adjacent room. With the peephole open, the ravens guarded their caches against discovery when they could hear dominants in the adjacent room, even when the dominant's sounds were playbacks of recordings.[123]  Consciousness Main article: Animal consciousness  Mirror test with a baboon The sense in which animals can be said to have consciousness or a self-concept has been hotly debated. The best known research technique in this area is the mirror test devised by Gordon G. Gallup, in which an animal's skin is marked in some way while it is asleep or sedated, and it is then allowed to see its reflection in a mirror; if the animal spontaneously directs grooming behavior towards the mark, that is taken as an indication that it is aware of itself.[124][125] Self-awareness, by this criterion, has been reported for chimpanzees[126][127] and also for other great apes,[128] the European magpie,[129] some cetaceans[130][131][132] and an Asian elephant,[133] but not for monkeys. The mirror test has been criticized by researchers because it is entirely focused on vision, the primary sense in humans, while other species rely more heavily on other senses such as the sense of smell in dogs.[134][135][136]  It has been suggested that metacognition in some animals provides some evidence for cognitive self-awareness.[137] The great apes, dolphins, and rhesus monkeys have demonstrated the ability to monitor their own mental states and use an "I don't know" response to avoid answering difficult questions. Unlike the mirror test, which reveals awareness of the condition of one's own body, this uncertainty monitoring is thought to reveal awareness of one's internal mental state. A 2007 study has provided some evidence for metacognition in rats,[138][139] although this interpretation has been questioned.[140][141] These species might also be aware of the strength of their memories.  Some researchers propose that animal calls and other vocal behaviors provide evidence of consciousness. This idea arose from research on children's crib talk by Weir (1962) and in investigations of early speech in children by Greenfield and others (1976). Some such research has been done with a macaw (see Arielle).  In July, 2012 during the "Consciousness in Human and Nonhuman Animals" conference in Cambridge a group of scientists announced and signed a declaration with the following conclusions:  Convergent evidence indicates that non-human animals have the neuroanatomical, neurochemical, and neurophysiological substrates of conscious states along with the capacity to exhibit intentional behaviors. Consequently, the weight of evidence indicates that humans are not unique in possessing the neurological substrates that generate consciousness. Non-human animals, including all mammals and birds, and many other creatures, including octopuses, also possess these neurological substrates.[142]  Biological constraints Instinctive drift can influence the interpretation of cognitive research. Instinctive drift is the tendency of an animal to revert to instinctive behaviors that can interfere with learned responses. The concept originated with Keller and Marian Breland when they taught a raccoon to put coins into a box. The raccoon drifted to its instinctive behavior of rubbing the coins with its paws, as it would do when foraging for food.[143]  Animal ability to process and respond to stimuli is correlated with brain size. Small-brain animals tend to show simple behaviors that are less dependent on learning than those of large-brained animals. Vertebrates, particularly mammals, have large brains and complex behavior that changes with experience. A formula called the encephalization quotient (EC) expresses a relationship between brain and body size; it was developed by H.J. Jerison in the late 1960s.[144] When the encephalization quotient is plotted as a curve, an animal with an EC above the curve is expected to show more cognitive ability than the average animal of its size, whereas an animal with an EC below the curve is expected to have less. Various formulas been suggested, but the equation Ew(brain) = 0.12w(body)2/3 has been found to fit data from a sample of mammals.[145] The formula is suggestive at best, and should only be applied to non-mammals with extreme caution. For some of the other vertebrate classes, the power of 3/4 rather than 2/3 is sometimes used, and for many groups of invertebrates, the formula may not give meaningful results.  Experimental evidence against animal cognition Several experiments cannot be readily reconciled with the belief that some animal species are intelligent, insightful, or possess a theory of mind.  Jean-Henri Fabre[146] (1823-1915), setting the stage for all subsequent experiments of this kind, argued that insects “obey their compelling instinct, without realizing what they do.”  For instance, to understand that she can grab her paralyzed prey by a leg instead of an antenna is utterly beyond the powers of a sand wasp. ““Her actions are like a series of echoes each awakening the next in a settled order, which allows none to sound until the previous one has sounded.” Fabre's numerous experiments led him, in turn, to the view that scientists often try to “exalt animals” instead of objectively studying them.  C. Lloyd Morgan's[147] (1852-1936) observations suggested to him that prima facie intelligent behavior in animals is often the result of either instincts or trial and error.  For instance, most visitors watching Morgan's dog smoothly lifting a latch with the back of its head (and thereby opening a garden gate and escaping) were convinced that the dog's actions involved thinking.  Morgan, however, carefully observed the dog's prior, random, purposeless actions and argued that they involved “continued trial and failure, until a happy effect is reached,” rather than “methodical planning.”  E. L. Thorndike[148] (1874 –1949) placed hungry cats and dogs in enclosures “from which they could escape by some simple act, such as pulling at a loop of cord.” Their behavior suggested to him that they did not “possess the power of rationality.”  Most books about animal behavior, Thorndike wrote, “do not give us a psychology, but rather a eulogy of animals.”  Although Wolfgang Köhler's[149] experiments are often cited as providing support for the animal cognition hypothesis, his book is replete with counterexamples. For instance, he placed chimpanzees in a situation where they could only get bananas by removing a box.  The chimpanzee, Köhler observed, “has special difficulty in solving such problems; he often draws into a situation the strangest and most distant tools, and adopts the most peculiar methods, rather than remove a simple obstacle which could be displaced with perfect ease.”  Daniel J Povinelli and Timothy Eddy[150] of the University of Louisiana showed that chimpanzees, when given a choice between two food providers, were just as likely to beg food from a person who could see the begging gesture as from a person who could not, thereby raising the possibility that chimpanzees do not understand that people see.  Moty Nissani[151] of Wayne State University trained Burmese logging elephants to lift a lid in order to retrieve food from a bucket. The lid was then placed on the ground alongside the bucket (where it no longer obstructed access to the food) while the treat was simultaneously placed inside the bucket. All elephants continued to toss the lid before retrieving the reward, thus suggesting that elephants do not grasp simple causal relationships.  Cognitive faculty by species A traditionally common image is the scala naturae, the ladder of nature on which animals of different species occupy successively higher rungs, with humans typically at the top.[152][153] However, there is some disagreement with the use of such a hierarchy, with some critics saying it may be necessary to understand specific cognitive capacities as adaptations to differing ecological niches (see Shettleworth (1998), Reznikova (2007)).  Whether fairly or not, the performance of animals is often compared to that of humans on cognitive tasks. Not surprisingly, our closest biological relatives, the great apes, tend to perform most like humans. Among the birds, corvids and parrots have typically been found to perform well on human-like tasks.[154] Some octopodes have also been shown to exhibit a number of higher-level skills such as tool use,[84] but the amount of research on cephalopod intelligence is still limited.[155]  Baboons have been shown to be capable of recognizing words.[156][157][158]  See also Anthropomorphism Biosemiotics Bird intelligence Cetacean intelligence Cognitive psychology Deception in animals Dog intelligence Fish intelligence Human-animal communication Cognitive abilities Uplift (science fiction) Evolution of cognition Number sense in animals Zoopharmacognosy Zoosemiotics References  Shettleworth SJ (2010). Cognition, Evolution and Behavior (2ND ed.). New York: Oxford Press.  Descartes R (1649). Passions of the Soul.  "Crows understand water displacement at the level of a small child: Show causal understanding of a 5- to 7-year-old child". ScienceDaily. Retrieved 2019-12-08.  Pliny the Elder (1855). The Natural History of Pliny. 2. ISBN 9780598910769.  Corcilius K, Gregoric P (2013-01-01). "Aristotle's Model of Animal Motion". Phronesis. 58 (1): 52–97. doi:10.1163/15685284-12341242. S2CID 52242579.  Morgan CL (1903). An Introduction to Comparative Psychology (2 ed.). W. Scott, London. pp. 59.  Darwin C (1871). "The descent of man, and selection in relation to sex".  Romanes JG (1883). Animal Intelligence.  Dewsbury D (1978). Comparative Animal Behavior. New York, NY: McGraw-Hill Book Company.  Thorndike EL (1911). Animal intelligence.  Pavlov IP (1928). Lectures on conditioned reflexes.  Watson JB (1913). "Psychology as the Behaviorist Views it". Psychological Review. 20 (2): 158–177. doi:10.1037/h0074428. hdl:21.11116/0000-0001-9182-7. S2CID 145372026.  Miller S, Konorski J (1928). "Sur une forme particulière des reflexes conditionels". Comptes Rendus des Séances de la Société de Biologie et de Ses Filiales. 99: 1155–1157.  Skinner BF (1932). The Behavior of Organisms.  Hull CL (1943). The Principles of Behavior.  Skinner BF (1976). About Behaviorism.  Köhler W (1917). The Mentality of Apes.  Tolman EC (1948). "Cognitive maps in rats and men". Psychological Review. 55 (4): 189–208. doi:10.1037/h0061626. PMID 18870876.  Niesser U (1967). Cognitive Psychology.  Hebb DO (1958). A Textbook of Psychology. p. 3.  Menzel R, Fischer J (2010). Animal Thinking: Contemporary Issues in Comparative Cognition. p. 2.  Wasserman EA, Zentall TR, eds. (2006). Comparative cognition: Experimental explorations of animal intelligence. USA: Oxford University Press. p. 8 ff.  Foster JJ, Smolka J, Nilsson DE, Dacke M (January 2018). "How animals follow the stars". Proceedings. Biological Sciences. 285 (1871): 20172322. doi:10.1098/rspb.2017.2322. PMC 5805938. PMID 29367394.  Grandin T, Johnson C (January 2010). Animals Make Us Human: Creating the Best Life for Animals. Houghton Mifflin Harcourt.  Stebbins WC, Berkley MA (1990). Comparative Perception, Vol. I, Basic Mechanisms; Vol. II, Complex Signals. New York: Wiley.  Smith EE, Kosslyn SM (2007). Cognitive Psychology: Mind and Brain. Pearson Prentice Hall.  Blough DS (2006). "Reaction-time explorations of visual attention, perception, and decision in pigeons.". In Wasserman EA, Zentall TR (eds.). Comparative Cognition: Experimental Explorations of Animal Intelligence'. New York: Oxford University Press. pp. 89–105.  Mackintosh NJ (1983). Conditioning and Associative Learning. New York: Oxford University Press.  Kamin LJ (1969). "Predictability, surprise, attention, and conditioning". In Campbell BA, Church RM (eds.). Punishment and Aversive Behavior. New York: Appleton-Century-Crofts. pp. 279–296.  Mackintosh NJ (1994). Animal Learning and Cognition. San Diego: Academic Press.  Zentall TR (April 2005). "Selective and divided attention in animals". Behavioural Processes. 69 (1): 1–15. doi:10.1016/j.beproc.2005.01.004. PMID 15795066. S2CID 24601938.  Blough DS (October 1969). "Attention shifts in a maintained discrimination". Science. 166 (3901): 125–6. Bibcode:1969Sci...166..125B. doi:10.1126/science.166.3901.125. PMID 5809588. S2CID 33256491.  Tinbergen L (1960). "The natural control of insects in pine woods: I. Factors influencing the intensity of predation by songbirds". Archives Néerlandaises de Zoologie. 13: 265–343. doi:10.1163/036551660X00053.  Pietrewicz AT, Kamil AC (February 1977). "Visual Detection of Cryptic Prey by Blue Jays (Cyanocitta cristata)". Science. 195 (4278): 580–2. Bibcode:1977Sci...195..580P. doi:10.1126/science.195.4278.580. PMID 17732294. S2CID 10858793.  Pietrewicz AT, Kamil AC (June 1979). "Search Image Formation in the Blue Jay (Cyanocitta cristata)". Science. 204 (4399): 1332–3. Bibcode:1979Sci...204.1332P. doi:10.1126/science.204.4399.1332. PMID 17813172. S2CID 14809014.  Blough PM (1989). "Attentional priming and visual search in pigeons". Journal of Experimental Psychology: Animal Learning and Cognition. 17 (4): 292–298. doi:10.1037/0097-7403.17.3.292. PMID 2794871.  Kamil AC, Bond AB (2006). "Selective attention, priming, and foraging behavior.". In Wasserman EA, Zentall TR (eds.). Comparative Cognition: Experimental Exploration of Animal Intelligence. New York: Oxford University Press.  Blough DS, Blough PM (1990). "Reaction-time assessments of visual processes in pigeons.". In Berkley M, Stebbins W (eds.). Comparative perception. New York: Wiley. pp. 245–276.  Smith EE, Medin DL (1981). Categories and Concepts. Harvard Univ. Press.  Zentall TR, Wasserman EA, Lazareva OF, Thompson RK, Rattermann MJ (2008). "Concept Learning in Animals". Comparative Cognition & Behavior Reviews. 3: 13–45. doi:10.3819/ccbr.2008.30002.  Dooling RJ, Okanoya K (1995). "Psychophysical methods for assessing perceptual categories.". In Klump GM, Dooling RJ, Fay RR, Stebbins WC (eds.). Methods in Comparative Psychoacoustics. Basel, Switzerland: Birkhäuser Verlag. pp. 307–318.  Herrnstein RJ, Loveland DH (October 1964). "Complex Visual Concept in the Pigeon". Science. 146 (3643): 549–51. Bibcode:1964Sci...146..549H. doi:10.1126/science.146.3643.549. PMID 14190250. S2CID 11940233.  Herrnstein RJ (1979). "Acquisition, Generalization, and Discrimination Reversal of a Natural Concept". Journal of Experimental Psychology: Animal Behavior Processes. 5 (2): 116–129. doi:10.1037/0097-7403.5.2.116. PMID 528881.  Bhatt RS, Wasserman EA, Reynolds WF, Knauss KS (July 1988). "Conceptual behavior in pigeons: Categorization of both familiar and novel examples from four classes of natural and artificial stimuli". Journal of Experimental Psychology: Animal Behavior Processes. 14 (3): 219–234. doi:10.1037/0097-7403.14.3.219.  Tu HW, Smith EW, Dooling RJ (November 2011). "Acoustic and perceptual categories of vocal elements in the warble song of budgerigars (Melopsittacus undulatus)". Journal of Comparative Psychology. 125 (4): 420–30. doi:10.1037/a0024396. PMC 4497543. PMID 22142040.  Avarguès-Weber A, Dyer AG, Giurfa M (March 2011). "Conceptualization of above and below relationships by an insect". Proceedings. Biological Sciences. 278 (1707): 898–905. doi:10.1098/rspb.2010.1891. PMC 3049051. PMID 21068040.  Vaughan Jr W (1988). "Formation of equivalence sets in pigeons". Journal of Experimental Psychology: Animal Behavior Processes. 14: 36–42. doi:10.1037/0097-7403.14.1.36.  D'Amato MR, Colombo M (April 1988). "Representation of serial order in monkeys (Cebus apella)". Journal of Experimental Psychology: Animal Behavior Processes. 14 (2): 131–9. doi:10.1037/0097-7403.14.2.131. PMID 3367099.  Murphy RA, Mondragón E, Murphy VA (March 2008). "Rule learning by rats" (PDF). Science. 319 (5871): 1849–51. Bibcode:2008Sci...319.1849M. doi:10.1126/science.1151564. PMID 18369151. S2CID 591112.  Kundey SM, Strandell B, Mathis H, Rowan JD (2010). "Learning of monotonic and nonmonotonic sequences in domesticated horses (Equus callabus") and chickens (Gallus domesticus")". Learning and Motivation. 14 (3): 213–223. doi:10.1016/j.lmot.2010.04.006.  Wright AA, Santiago HC, Sands SF, Kendrick DF, Cook RG (July 1985). "Memory processing of serial lists by pigeons, monkeys, and people". Science. 229 (4710): 287–9. Bibcode:1985Sci...229..287W. doi:10.1126/science.9304205. PMID 9304205.  Balda R, Kamil AC (1992). "Long-term spatial memory in Clark's nutcracker, Nucifraga columbiana". Animal Behaviour. 44 (4): 761–769. doi:10.1016/S0003-3472(05)80302-1. S2CID 54277040.  Greggers U, Menzel R (1993). "Memory dynamics and foraging strategies of honeybees". Behavioral Ecology and Sociobiology. 32: 17–29. doi:10.1007/BF00172219. S2CID 36624838.  Menzel R (1993). "Associative learning in honey-bees". Apidologie. 24 (3): 157–168. doi:10.1051/apido:19930301.  Wüstenberg D, Gerber B, Menzel R (August 1998). "Short communication: long- but not medium-term retention of olfactory memories in honeybees is impaired by actinomycin D and anisomycin". The European Journal of Neuroscience. 10 (8): 2742–5. doi:10.1046/j.1460-9568.1998.00319.x. PMID 9767405. S2CID 23691527.  Hammer M, Menzel R (March 1995). "Learning and memory in the honeybee". The Journal of Neuroscience. 15 (3 Pt 1): 1617–30. doi:10.1523/JNEUROSCI.15-03-01617.1995. PMC 6578179. PMID 7891123.  University of Exeter (2020-12-28). "Big bumblebees learn locations of best flowers". Phys.org. Retrieved 2020-12-29.  Frasnelli, Elisa; Robert, Théo; Chow, Pizza Ka Yee; Scales, Ben; Gibson, Sam; Manning, Nicola; Philippides, Andrew O.; Collett, Thomas S.; Hempel de Ibarra, Natalie (2020). "Small and Large Bumblebees Invest Differently when Learning about Flowers". Current Biology. Elsevier BV. 31 (5): 1058–1064.e3. doi:10.1016/j.cub.2020.11.062. ISSN 0960-9822. PMID 33373638.  Yamada A, Sekiguchi T, Suzuki H, Mizukami A (March 1992). "Behavioral analysis of internal memory states using cooling-induced retrograde amnesia in Limax flavus". The Journal of Neuroscience. 12 (3): 729–35. doi:10.1523/JNEUROSCI.12-03-00729.1992. PMC 6576046. PMID 1545237.  Hunter WS (1913). The delayed reaction in animals and children. Behavior Monographs. 2.  Blough DS (April 1959). "Delayed matching in the pigeon". Journal of the Experimental Analysis of Behavior. 2 (2): 151–60. doi:10.1901/jeab.1959.2-151. PMC 1403892. PMID 13801643.  Shettleworth SJ (2010). Cognition, Evolution, and Behavior (2nd ed.). New York: Oxford University Press. ISBN 978-0-19-971781-1.  Vorhees CV, Williams MT (2006). "Morris water maze: procedures for assessing spatial and related forms of learning and memory". Nature Protocols. 1 (2): 848–58. doi:10.1038/nprot.2006.116. PMC 2895266. PMID 17406317.  Antunes M, Biala G (May 2012). "The novel object recognition memory: neurobiology, test procedure, and its modifications". Cognitive Processing. 13 (2): 93–110. doi:10.1007/s10339-011-0430-z. PMC 3332351. PMID 22160349.  Brown MF, Cook RG, eds. (2006). Animal Spatial Cognition: Comparative, Neural, and Computational Approaches. [On-line].  Lund N (2002). Animal cognition. Psychology Press. p. 4. ISBN 978-0-415-25298-0.  Treisman AM, Gelade G (January 1980). "A feature-integration theory of attention". Cognitive Psychology. 12 (1): 97–136. doi:10.1016/0010-0285(80)90005-5. PMID 7351125. S2CID 353246.  Sherwin CM (2001). "Can invertebrates suffer? Or, how robust is argument-by-analogy?". Animal Welfare. 10 (supplement): S103–S118.  Gauthreaux SA (1980). Animal Migration, Orientation, and Navigation. Academic Press.  Savolainen P, Zhang YP, Luo J, Lundeberg J, Leitner T (November 2002). "Genetic evidence for an East Asian origin of domestic dogs". Science. 298 (5598): 1610–3. Bibcode:2002Sci...298.1610S. doi:10.1126/science.1073906. PMID 12446907. S2CID 32583311.  Fiset S, Plourde V (May 2013). "Object permanence in domestic dogs (Canis lupus familiaris) and gray wolves (Canis lupus)". Journal of Comparative Psychology. 127 (2): 115–27. doi:10.1037/a0030595. PMID 23106804.  Bräuer J, Kaminski J, Riedel J, Call J, Tomasello M (February 2006). "Making inferences about the location of hidden food: social dog, causal ape". Journal of Comparative Psychology. 120 (1): 38–47. doi:10.1037/0735-7036.120.1.38. PMID 16551163. S2CID 10162449.  Webb AR (2003). "The physiology of circadian rhythms in plants". New Phytologist. 160 (2): 281–303. doi:10.1046/j.1469-8137.2003.00895.x. PMID 33832173. S2CID 15688409.  Call JE, Burghardt GM, Pepperberg IM, Snowdon CT, Zentall TE, eds. (2017). "Chapter 23 : Timing in Animals". APA handbook of comparative psychology: Perception, learning, and cognition. 2. Washington D.C.: APA.  Henderson J, Hurly TA, Bateson M, Healy SD (March 2006). "Timing in free-living rufous hummingbirds, Selasphorus rufus". Current Biology. 16 (5): 512–5. doi:10.1016/j.cub.2006.01.054. PMID 16527747.  Gibbon J (1977). "Scalar expectancy theory and Weber's law in animal timing". Psychological Review. 84 (3): 279–325. doi:10.1037/0033-295x.84.3.279.  Killeen PR (1991). "Behavior's time.". In Bower G (ed.). The psychology of learning and motivation. 27. New York: Academic Press. pp. 294–334.  Machado A, Pata P (2005). "Testing the Scalar Expectancy Theory (SET) and the Learning to Time model (LeT) in a double bisection task". Behavior and Learning. 33 (1): 111–122. doi:10.3758/BF03196055. PMID 15971498. S2CID 16623835.  Roach J (February 22, 2007). "Chimps Use "Spears" to Hunt Mammals, Study Says". National Geographic News. Retrieved June 12, 2010.  Hunt GR (1996). "Manufacture and use of hook-tools by New Caledonian crows". Nature. 379 (6562): 249–251. Bibcode:1996Natur.379..249H. doi:10.1038/379249a0. S2CID 4352835.  Shettleworth SJ (December 2012). "Do animals have insight, and what is insight anyway?". Canadian Journal of Experimental Psychology. 66 (4): 217–26. doi:10.1037/a0030674. PMID 23231629.  "Video shows first tool use by a fish". ScienceBlog.com. 28 September 2011.  Bernardi G (2011). "The use of tools by wrasses (Labridae)" (PDF). Coral Reefs. 31: 39. doi:10.1007/s00338-011-0823-6. S2CID 37924172. Retrieved 7 July 2013.  Finn JK, Tregenza T, Norman MD (December 2009). "Defensive tool use in a coconut-carrying octopus". Current Biology. 19 (23): R1069-70. doi:10.1016/j.cub.2009.10.052. PMID 20064403. S2CID 26835945.  Möglich MH, Alpert GD (1979). "Stone dropping by Conomyrma bicolor (Hymenoptera: Formicidae): A new technique of interference competition". Behavioral Ecology and Sociobiology. 2 (6): 105–113. doi:10.1007/bf00292556. JSTOR 4599265. S2CID 27266459.  For chimpanzees, see for example Premack D, Premack AJ (1983). The Mind of an Ape. New York: Norton. ISBN 978-0-393-30160-1. OCLC 152413818.  Pepperberg IM (1999). The Alex Studies: Cognitive and Communicative Abilities of Grey Parrots. Cambridge MA: Harvard University Press.  Tebbich S, Seed AM, Emery NJ, Clayton NS (April 2007). "Non-tool-using rooks, Corvus frugilegus, solve the trap-tube problem". Animal Cognition. 10 (2): 225–31. doi:10.1007/s10071-006-0061-4. PMID 17171360. S2CID 13611664.  Taylor AH, Hunt GR, Medina FS, Gray RD (January 2009). "Do new caledonian crows solve physical problems through causal reasoning?". Proceedings. Biological Sciences. 276 (1655): 247–54. doi:10.1098/rspb.2008.1107. PMC 2674354. PMID 18796393.  Audet JN, Ducatez S, Lefebvre L (2015). "The town bird and the country bird: problem solving and immunocompetence vary with urbanization". Behavioral Ecology. 27 (2): 637–644. doi:10.1093/beheco/arv201.  Harding EJ, Paul ES, Mendl M (January 2004). "Animal behaviour: cognitive bias and affective state". Nature. 427 (6972): 312. Bibcode:2004Natur.427..312H. doi:10.1038/427312a. PMID 14737158. S2CID 4411418.  Rygula R, Pluta H, Popik P (2012). "Laughing rats are optimistic". PLOS ONE. 7 (12): e51959. Bibcode:2012PLoSO...751959R. doi:10.1371/journal.pone.0051959. PMC 3530570. PMID 23300582.  Haselton MG, Nettle D, Andrews PW (2005). "The evolution of cognitive bias.". In Buss DM (ed.). The Handbook of Evolutionary Psychology. Hoboken, NJ, US: John Wiley & Sons Inc. pp. 724–746.  Terrace HS, Petitto LA, Sanders RJ, Bever TG (November 1979). "Can an ape create a sentence?". Science. New York, N.Y. 206 (4421): 891–902. Bibcode:1979Sci...206..891T. doi:10.1126/science.504995. PMID 504995.  Köhler W (1917). Mentality of Apes.  Foerder P, Galloway M, Barthel T, Moore DE, Reiss D (2011). Samuel A (ed.). "Insightful problem solving in an Asian elephant". PLOS ONE. 6 (8): e23251. Bibcode:2011PLoSO...623251F. doi:10.1371/journal.pone.0023251. PMC 3158079. PMID 21876741.  Brannon EM, Terrace HS (January 2000). "Representation of the numerosities 1-9 by rhesus macaques (Macaca mulatta)" (PDF). Journal of Experimental Psychology: Animal Behavior Processes. 26 (1): 31–49. doi:10.1037//0097-7403.26.1.31. PMID 10650542.  Reznikova Z, Ryabko B (2001). "A Study of Ants' Numerical Competence". Electronic Transactions on Artificial Intelligence. 5: 111–126.  Reznikova ZI (2007). Animal Intelligence: From Individual to Social Cognition. Cambridge University Press.  Reznikova ZI (1999). "Ethological mechanisms of population dynamic in species ant communities". Russian Journal of Ecology. 30 (3): 187–197.  Brown MJ, Gordon DM (2000). "How resources and encounters affect the distribution of foraging activity in a seed-harvesting ants". Behavioral Ecology and Sociobiology. 47 (3): 195–203. doi:10.1007/s002650050011. S2CID 15454830.  Carazo P, Font E, Forteza-Behrendt E, Desfilis E (May 2009). "Quantity discrimination in Tenebrio molitor: evidence of numerosity discrimination in an invertebrate?". Animal Cognition. 12 (3): 463–70. doi:10.1007/s10071-008-0207-7. PMID 19118405. S2CID 14502342.  Dacke M, Srinivasan MV (October 2008). "Evidence for counting in insects". Animal Cognition. 11 (4): 683–9. doi:10.1007/s10071-008-0159-y. PMID 18504627. S2CID 22273226.  Anderson US, Stoinski TS, Bloomsmith MA, Marr MJ, Smith AD, Maple TL (August 2005). "Relative numerousness judgment and summation in young and old Western lowland gorillas". Journal of Comparative Psychology. 119 (3): 285–95. doi:10.1037/0735-7036.119.3.285. PMID 16131257.  Boysen ST, Berntson GG, Mukobi KL (March 2001). "Size matters: impact of item size and quantity on array choice by chimpanzees (Pan troglodytes)". Journal of Comparative Psychology. 115 (1): 106–10. doi:10.1037/0735-7036.115.1.106. PMID 11334213.  Uller C, Jaeger R, Guidry G, Martin C (June 2003). "Salamanders ( Plethodon cinereus) go for more: rudiments of number in an amphibian". Animal Cognition. 6 (2): 105–12. doi:10.1007/s10071-003-0167-x. PMID 12709845. S2CID 147018.  Vonk J, Beran MJ (July 2012). "Bears "Count" Too: Quantity Estimation and Comparison in Black Bears (Ursus Americanus)". Animal Behaviour. 84 (1): 231–238. doi:10.1016/j.anbehav.2012.05.001. PMC 3398692. PMID 22822244.  Jaakkola K, Fellner W, Erb L, Rodriguez M, Guarino E (August 2005). "Understanding of the concept of numerically "less" by bottlenose dolphins (Tursiops truncatus)". Journal of Comparative Psychology. 119 (3): 296–303. doi:10.1037/0735-7036.119.3.296. PMID 16131258.  Pepperberg IM (October 2006). "Grey parrot numerical competence: a review". Animal Cognition. 9 (4): 377–91. doi:10.1007/s10071-006-0034-7. PMID 16909236. S2CID 30689821.  Gómez-Laplaza LM, Gerlai R (January 2011). "Can angelfish (Pterophyllum scalare) count? Discrimination between different shoal sizes follows Weber's law". Animal Cognition. 14 (1): 1–9. doi:10.1007/s10071-010-0337-6. PMID 20607574. S2CID 26488837.  King D, Green B (1999). Goannas: The Biology of Varanid Lizards. University of New South Wales Press. p. 43. ISBN 0-86840-456-X.  Reader SM, Hager Y, Laland KN (April 2011). "The evolution of primate general and cultural intelligence". Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences. 366 (1567): 1017–27. doi:10.1098/rstb.2010.0342. PMC 3049098. PMID 21357224.  Locurto C, Durkin E. "Problem-solving and individual differences in mice (Mus musculus) using water reinforcement". J Comp Psychol.  Locurto C, Scanlon C (1998). "Individual differences and a spatial learning factor in two strains of mice (Mus musculus)". J. Comp. Psychol. 112 (4): 344–352. doi:10.1037/0735-7036.112.4.344.  Kamphaus RW (2005). Clinical assessment of child and adolescent intelligence. Springer Science & Business Media. ISBN 978-0-387-29149-9.  Poirier, Marc-Antoine; Kozlovsky, Dovid Y.; Morand-Ferron, Julie; Careau, Vincent (2020-12-09). "How general is cognitive ability in non-human animals? A meta-analytical and multi-level reanalysis approach". Proceedings of the Royal Society B: Biological Sciences. 287 (1940): 20201853. doi:10.1098/rspb.2020.1853. ISSN 0962-8452. PMC 7739923. PMID 33290683.  Rushton JP (2004). "Placing intelligence into an evolutionary framework or how g fits into the r–K matrix of life-history traits including longevity". Intelligence. 32 (4): 321–328. doi:10.1016/j.intell.2004.06.003.  van Schaik CP, Burkart JM (April 2011). "Social learning and evolution: the cultural intelligence hypothesis". Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences. 366 (1567): 1008–16. doi:10.1098/rstb.2010.0304. PMC 3049085. PMID 21357223.  Herrmann E, Call J, Hernàndez-Lloreda MV, Hare B, Tomasello M (September 2007). "Humans have evolved specialized skills of social cognition: the cultural intelligence hypothesis". Science. 317 (5843): 1360–6. Bibcode:2007Sci...317.1360H. doi:10.1126/science.1146282. PMID 17823346.  Plomin R (February 2001). "The genetics of g in human and mouse". Nature Reviews. Neuroscience. 2 (2): 136–41. doi:10.1038/35053584. PMID 11252993. S2CID 205013267.  Anderson B (2000). Bock GR, Goode JA, Webb K (eds.). "The g factor in non-human animals". Novartis Foundation Symposium. 233: 79–90, discussion 90–5. ISBN 978-0-471-49434-8. PMID 11276911.  Premack D, Woodruff G (1978). "Does the chimpanzee have a theory of mind?". Behavioral and Brain Sciences. 1 (4): 515–526. doi:10.1017/S0140525X00076512.  Bugnyar T, Reber SA, Buckner C (February 2016). "Ravens attribute visual access to unseen competitors". Nature Communications. 7: 10506. Bibcode:2016NatCo...710506B. doi:10.1038/ncomms10506. PMC 4740864. PMID 26835849.  Bischof-Köhler D (1991). "The development of empathy in infants". In Lamb ME, Keller H (eds.). Infant Development. Perspectives from German speaking countries. pp. 245–273. ISBN 978-1-317-72827-6.  Prior H, Schwarz A, Güntürkün O (August 2008). "Mirror-induced behavior in the magpie (Pica pica): evidence of self-recognition". PLOS Biology. 6 (8): e202. doi:10.1371/journal.pbio.0060202. PMC 2517622. PMID 18715117.  Gallop GG (January 1970). "Chimpanzees: self-recognition". Science. 167 (3914): 86–7. Bibcode:1970Sci...167...86G. doi:10.1126/science.167.3914.86. PMID 4982211. S2CID 145295899.  Walraven V, van Elsacker L, Verheyen R (1995). "Reactions of a group of pygmy chimpanzees (Pan paniscus) to their mirror images: evidence of self-recognition". Primates. 36: 145–150. doi:10.1007/bf02381922. S2CID 38985498.  Patterson FGP, Cohn RH (1994) Self-recognition and self-awareness in lowland gorillas. In: Parker ST, Mitchell RW, editors. Self-awareness in animals and humans: developmental perspectives. New York (New York): Cambridge University Press. pp. 273–290.  Prior H, Schwarz A, Güntürkün O (August 2008). De Waal F (ed.). "Mirror-induced behavior in the magpie (Pica pica): evidence of self-recognition" (PDF). PLOS Biology. 6 (8): e202. doi:10.1371/journal.pbio.0060202. PMC 2517622. PMID 18715117. Archived from the original (PDF) on 2008-11-19.  Marten K, Psarakos S (1995). "Evidence of self-awareness in the bottlenose dolphin (Tursiops truncatus)". In Parker ST, Mitchell R, Boccia M (eds.). Self-awareness in Animals and Humans: Developmental Perspectives. Cambridge University Press. pp. 361–379. Archived from the original on 13 October 2008.  Reiss D, Marino L (May 2001). "Mirror self-recognition in the bottlenose dolphin: a case of cognitive convergence". Proceedings of the National Academy of Sciences of the United States of America. 98 (10): 5937–42. Bibcode:2001PNAS...98.5937R. doi:10.1073/pnas.101086398. PMC 33317. PMID 11331768.  Delfour F, Marten K (April 2001). "Mirror image processing in three marine mammal species: killer whales (Orcinus orca), false killer whales (Pseudorca crassidens) and California sea lions (Zalophus californianus)". Behavioural Processes. 53 (3): 181–190. doi:10.1016/s0376-6357(01)00134-6. PMID 11334706. S2CID 31124804.  Plotnik JM, de Waal FB, Reiss D (November 2006). "Self-recognition in an Asian elephant". Proceedings of the National Academy of Sciences of the United States of America. 103 (45): 17053–7. Bibcode:2006PNAS..10317053P. doi:10.1073/pnas.0608062103. PMC 1636577. PMID 17075063.  Lea SE (2010). "Concept learning in nonprimate mammals: In search of evidence". In Mareschal D, Quinn PC, Lea SE (eds.). The Making of Human Concepts. Oxford University Press. pp. 173–199. ISBN 978-0-19-954922-1.  Meng J (2012). "The Superior Human?". Documentary. Transcription on the official website. The Superior Human.  Gatti RC (2015). "Self-consciousness: beyond the looking-glass and what dogs found there". Ethology Ecology & Evolution. 28 (2): 232–240. doi:10.1080/03949370.2015.1102777. S2CID 217507938.  Couchman JJ, Coutinho MV, Beran MJ, Smith JD (November 2010). "Beyond stimulus cues and reinforcement signals: a new approach to animal metacognition" (PDF). Journal of Comparative Psychology. 124 (4): 356–68. doi:10.1037/a0020129. PMC 2991470. PMID 20836592.  "Rats Capable Of Reflecting On Mental Processes". ScienceDaily. 9 March 2007.  Foote AL, Crystal JD (March 2007). "Metacognition in the rat". Current Biology. 17 (6): 551–5. doi:10.1016/j.cub.2007.01.061. PMC 1861845. PMID 17346969.  Smith JD, Beran MJ, Couchman JJ, Coutinho MV (August 2008). "The comparative study of metacognition: sharper paradigms, safer inferences". Psychonomic Bulletin & Review. 15 (4): 679–91. doi:10.3758/PBR.15.4.679. PMC 4607312. PMID 18792496.  Jozefowiez J, Staddon JE, Cerutti DT (2009). "Metacognition in animals: how do we know that they know?". Comparative Cognition & Behavior Reviews. 4: 29–39. doi:10.3819/ccbr.2009.40003.  "The Cambridge Declaration on Consciousness" (PDF). Retrieved 12 August 2012.  Breland K, Breland M (1961). "The misbehavior of organisms". American Psychologist. 16 (11): 681–684. doi:10.1037/h0040090. S2CID 51818837.  Brett-Surman MK, Holtz TR, Farlow JO, eds. (2012-06-27). The complete dinosaur. Illustrated by Bob Walters (2nd ed.). Bloomington, Ind.: Indiana University Press. pp. 191–208. ISBN 978-0-253-00849-7.  Moore J (1999). "Allometry". University of California San Diego.  Fabre JH (1919). The Hunting Wasps. New York: Dodd, Mead and Company. ISBN 978-1587760280.  Morgan CL (1920). Animal Behaviour (Second ed.). London: Edward Arnold.  Thorndike EL (1911). Animal Intelligence. New York: Macmillan.  Köhler W (1925). Winter E (ed.). The mentality of apes, transl (2nd German ed.). London: Kegan, Trench. ISBN 978-0871401083. Original was Intelligenzprüfungen an Anthropoiden, Berlin 1917. 2nd German edition was titled Intelligenzprüfungen an Menschenaffen, Berlin: Springer 1921.  Povinelli DJ, Eddy TJ (1996). What young chimpanzees know about seeing. Monographs of the Society for Research in Child Development. 61. pp. 1–189.  Nissani M (2005). "Do Asian elephants apply causal reasoning to tool use tasks? 31: 91–96". Journal of Experimental Psychology: Animal Behavior Processes. 31: 91–96.  Campbell CB, Hodos W (September 1991). "The Scala naturae revisited: evolutionary scales and anagenesis in comparative psychology". Journal of Comparative Psychology. 105 (3): 211–21. doi:10.1037/0735-7036.105.3.211. PMID 1935002.  Gopnik A (May 2016). "How Animals Think; A new look at what humans can learn from nonhuman minds". The Atlantic. Retrieved 25 April 2016.  Starr M (2017-12-31). "13 Surprisingly Weird Reasons Why Crows And Ravens Are The Best Birds, No Question". ScienceAlert. Retrieved 2020-04-04.  Mather JA, Kuba MJ (May 2013). "The cephalopod specialties: complex nervous systems, learning and cognition". Canadian Journal of Zoology. 91 (6): 431–449. doi:10.1139/cjz-2013-0009.  Haghighat L (12 April 2012). "Baboons can learn to recognize words; Monkeys' ability suggests that reading taps into general systems of pattern recognition". Nature.  Brown E (12 April 2012). "Baboons can recognize written words, study finds; The monkeys don't assign meaning to them, but learn what letter combinations are common to real words, the study authors say". Los Angeles Times.  Bower B (5 May 2012). "Baboons show their word skills; Reading may stem from a visual aptitude shared by all primates". ScienceNews. Further reading Bateson P (2017). Behaviour, Development and Evolution. Cambridge: Open Book Publishers. doi:10.11647/OBP.0097. ISBN 978-1-78374-248-6. Brown MF, Cook RG, eds. (2006). Animal Spatial Cognition: Comparative, Neural, and Computational Approaches. [On-line]. Goodall J (1991). Through a window. London: Penguin. Griffin, Donald R. (2001). Animal minds : beyond cognition to consciousness. University of Chicago Press. ISBN 9780226308654. Hilgard ER (1958). Theories of learning (2nd ed.). London: Methuen. Lurz RW (2009). Mindreading Animals: The Debate over What Animals Know about Other Minds. The MIT Press. Narby, Jeremy (2005). Intelligence in nature : an inquiry into knowledge. New York: Jeremy P. Tarcher/Penguin. ISBN 1585424617. Neisser U (1967). Cognitive psychology. New York: Appleton-Century-Crofts. Romanes GJ (1886). Animal intelligence (4th ed.). London: Kegan Paul, Trench. Shettleworth, Sara J. (2010). Cognition, evolution, and behavior (2nd ed.). Oxford: Oxford University Press. ISBN 9780195319842. Skinner BF (1969). Contingencies of reinforcement: a theoretical analysis. New York: Appleton-Century-Crofts. de Waal F (2016). Are We Smart Enough to Know How Smart Animals Are?. W. W. Norton & Company. ISBN 978-0393246186. External links 	Wikiquote has quotations related to: Animal cognition 	Wikimedia Commons has media related to Animal cognition. Allen C. "Animal Consciousness". In Zalta EN (ed.). Stanford Encyclopedia of Philosophy. Andrews K. "Animal Cognition". In Zalta EN (ed.). Stanford Encyclopedia of Philosophy. Fox D (14 June 2011). "The limits of intelligence". Scientific American. 305 (1): 36–43. doi:10.1038/scientificamerican0711-36. PMID 21717956. Kamil A, Bond A. "Center for Avian Cognition". University of Nebraska. "Animal Cognition Network". Archived from the original on 2008-05-09. "Animal Minds". Internet Encyclopedia of Philosophy. vte Animal cognition Cognition	 Animal communicationAnimal consciousnessAnimal languageCognitive bias in animalsCognitive ethologyComparative cognitionEmotion in animalsInsectMirror testNeuroethologyObservational learningTool use by animalsVocal learning Intelligence	 Bird talkingCatCephalopodCetaceanDogElephantFishPrimate HominidSwarm Pain	 Pain in amphibiansPain in animalsPain in cephalopodsPain in crustaceansPain in fishPain in invertebrates Relation to brain	 Brain sizeBrain-to-body mass ratioEncephalization quotientNeuroscience and intelligenceNumber of neurons Category Category vte Animal communication vte Animal rights vte Ethology vte Great ape language Categories: Animal cognitionAnimal intelligenceAnimal rightsAnimal welfareHuman–animal communicationZoology Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadEditView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikiquote  Languages العربية Español Français Bahasa Indonesia Bahasa Melayu Русский Svenska Türkçe 中文 14 more Edit links This page was last edited on 8 September 2021, at 12:49 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki   Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more Scientific journal From Wikipedia, the free encyclopedia Jump to navigationJump to search This article is about scientific academic journals. For a broader class of journals, see Academic journal. For scientific magazines, see List of science magazines. "Science journal" redirects here. For the journal named 'Science', see Science (journal). For the defunct magazine named 'Science Journal', see New Scientist. For broader coverage of this topic, see Scientific literature.  Cover of the first issue of Nature, 4 November 1869 In academic publishing, a scientific journal is a periodical publication intended to further the progress of science, usually by reporting new research.   Contents 1	Content 2	Scope 3	Wording 4	History 5	Publishing process 6	Standards and impact 7	Reproducibility and replicability 8	Types of articles 9	Electronic publishing 10	Cost 11	Copyright 12	See also 13	References 14	External links Content Articles in scientific journals are mostly written by active scientists such as students, researchers and professors instead of professional journalists. There are thousands of scientific journals in publication, and many more have been published at various points in the past (see list of scientific journals). Most journals are highly specialized, although some of the oldest journals such as Nature publish articles and scientific papers across a wide range of scientific fields. Scientific journals contain articles that have been peer reviewed, in an attempt to ensure that articles meet the journal's standards of quality, and scientific validity. Although scientific journals are superficially similar to professional magazines, they are actually quite different. Issues of a scientific journal are rarely read casually, as one would read a magazine. The publication of the results of research is an essential part of the scientific method. If they are describing experiments or calculations, they must supply enough details that an independent researcher could repeat the experiment or calculation to verify the results. Each such journal article becomes part of the permanent scientific record.  Scope Articles in scientific journals can be used in research and higher education. Scientific articles allow researchers to keep up to date with the developments of their field and direct their own research. An essential part of a scientific article is citation of earlier work. The impact of articles and journals is often assessed by counting citations (citation impact). Some classes are partially devoted to the explication of classic articles, and seminar classes can consist of the presentation by each student of a classic or current paper. Schoolbooks and textbooks have been written usually only on established topics, while the latest research and more obscure topics are only accessible through scientific articles. In a scientific research group or academic department it is usual for the content of current scientific journals to be discussed in journal clubs. Public funding bodies often require the results to be published in scientific journals. Academic credentials for promotion into academic ranks are established in large part by the number and impact of scientific articles published. Many doctoral programs allow for thesis by publication, where the candidate is required to publish a certain number of scientific articles.  Wording Articles tend to be highly technical, representing the latest theoretical research and experimental results in the field of science covered by the journal. They are often incomprehensible to anyone except for researchers in the field and advanced students. In some subjects this is inevitable given the nature of the content. Usually, rigorous rules of scientific writing are enforced by the editors; however, these rules may vary from journal to journal, especially between journals from different publishers. Articles are usually either original articles reporting completely new results or reviews of current literature. There are also scientific publications that bridge the gap between articles and books by publishing thematic volumes of chapters from different authors. Many journals have a regional focus, specializing in publishing papers from a particular geographic region, like African Invertebrates.  History The history of scientific journals dates from 1665, when the French Journal des sçavans and the English Philosophical Transactions of the Royal Society first began systematically publishing research results. Over a thousand, mostly ephemeral, were founded in the 18th century, and the number has increased rapidly after that.[1]  Prior to mid-20th century, peer review was not always necessary, but gradually it became essentially compulsory.[citation needed]  Publishing process The authors of scientific articles are active researchers instead of journalists; typically, a graduate student or a researcher writes a paper with a professor. As such, the authors are unpaid and receive no compensation from the journal. However, their funding bodies may require them to publish in scientific journals. The paper is submitted to the journal office, where the editor considers the paper for appropriateness, potential scientific impact and novelty. If the journal's editor considers the paper appropriate, the paper is submitted to scholarly peer review. Depending on the field, journal and paper, the paper is sent to 1–3 reviewers for evaluation before they can be granted permission to publish. Reviewers are expected to check the paper for soundness of its scientific argument, including whether the author(s) are sufficiently acquainted with recent relevant research that bears on their study, whether the data was collected or considered appropriately and reproducibly, and whether the data discussed supports the conclusion offered and the implications suggested. Novelty is also key: existing work must be appropriately considered and referenced, and new results improving on the state of the art presented. Reviewers are usually unpaid and not a part of the journal staff—instead, they should be "peers", i.e. researchers in the same field as the paper in question.  Standards and impact The standards that a journal uses to determine publication can vary widely. Some journals, such as Nature, Science, PNAS, and Physical Review Letters, have a reputation of publishing articles that mark a fundamental breakthrough in their respective fields.[citation needed] In many fields, a formal or informal hierarchy of scientific journals exists; the most prestigious journal in a field tends to be the most selective in terms of the articles it will select for publication, and usually will also have the highest impact factor. In some countries, journal rankings can be utilized for funding decisions[2] and even evaluation of individual researchers, although they are poorly suited for that purpose.[3]  Reproducibility and replicability For scientific journals, reproducibility and replicability of the scientific results are core concepts that allow other scientists to check and reproduce the results under the same conditions described in the paper or at least similar conditions and produce similar results with similar measurements of the same measurand or carried out under changed conditions of measurement.  Types of articles Further information: Scientific paper See also: Categories of academic articles  Title page of the first volume of the Philosophical Transactions of the Royal Society, the first journal in the world exclusively devoted to science There are several types of journal articles; the exact terminology and definitions vary by field and specific journal, but often include:  Letters (also called communications, and not to be confused with letters to the editor) are short descriptions of important current research findings that are usually fast-tracked for immediate publication because they are considered urgent. Research notes are short descriptions of current research findings that are considered less urgent or important than Letters. Articles are usually between five and twenty pages and are complete descriptions of current original research findings, but there are considerable variations between scientific fields and journals—80-page articles are not rare in mathematics or theoretical computer science. Supplemental articles contain a large volume of tabular data that is the result of current research and may be dozens or hundreds of pages with mostly numerical data. Some journals now only publish this data electronically on the Internet. Supplemental information also contains other voluminous material not appropriate for the main body of the article, like descriptions of routine procedures, derivations of equations, source code, non-essential data, spectra or other such miscellaneous information. Review articles do not cover original research but rather accumulate the results of many different articles on a particular topic into a coherent narrative about the state of the art in that field. Review articles provide information about the topic and also provide journal references to the original research. Reviews may be entirely narrative, or may provide quantitative summary estimates resulting from the application of meta-analytical methods. Data papers are articles dedicated to describe datasets. This type of article is becoming popular and journals exclusively dedicated to them have been established, e.g. Scientific Data and Earth System Science Data. Video papers are a recent addition to practice of scientific publications. They most often combine an online video demonstration of a new technique or protocol combined with a rigorous textual description.[4][5] The formats of journal articles vary, but many follow the general IMRAD scheme recommended by the International Committee of Medical Journal Editors. Such articles begin with an abstract, which is a one-to-four-paragraph summary of the paper. The introduction describes the background for the research including a discussion of similar research. The materials and methods or experimental section provides specific details of how the research was conducted. The results and discussion section describes the outcome and implications of the research, and the conclusion section places the research in context and describes avenues for further exploration.  In addition to the above, some scientific journals such as Science will include a news section where scientific developments (often involving political issues) are described. These articles are often written by science journalists and not by scientists. In addition, some journals will include an editorial section and a section for letters to the editor. While these are articles published within a journal, in general they are not regarded as scientific journal articles because they have not been peer-reviewed.  Electronic publishing Main articles: Eprint, Electronic article, and Electronic journal Electronic publishing is a new area of information dissemination. One definition of electronic publishing is in the context of the scientific journal. It is the presentation of scholarly scientific results in only an electronic (non-paper) form. This is from its first write-up, or creation, to its publication or dissemination. The electronic scientific journal is specifically designed to be presented on the internet. It is defined as not being previously printed material adapted, or retooled, and then delivered electronically.[6][7]  Electronic publishing will likely continue to exist alongside paper publishing for the foreseeable future, since whilst output to a screen is important for browsing and searching, it is not well suited for extensive reading. Formats suitable both for reading on paper, and for manipulation by the reader's computer will need to be integrated.[6][7] Many journals are electronically available in formats readable on screen via web browsers, as well as in portable document format PDF, suitable for printing and storing on a local desktop or laptop computer. New tools such as JATS and Utopia Documents provide a 'bridge' to the 'web-versions' in that they connect the content in PDF versions directly to the World Wide Web via hyperlinks that are created 'on-the-fly'. The PDF version of an article is usually seen as the version of record, but the matter is subject to some debate.[8]  Electronic counterparts of established print journals already promote and deliver rapid dissemination of peer-reviewed and edited, "published" articles. Other journals, whether spin-offs of established print journals, or created as electronic only, have come into existence promoting the rapid dissemination capability, and availability, on the Internet. In tandem with this is the speeding up of peer review, copyediting, page makeup, and other steps in the process to support rapid dissemination.[9]  Other improvements, benefits and unique values of electronically publishing the scientific journal are easy availability of supplementary materials (data, graphics and video), lower cost, and availability to more people, especially scientists from non-developed countries. Hence, research results from more developed nations are becoming more accessible to scientists from non-developed countries.[6]  Moreover, electronic publishing of scientific journals has been accomplished without compromising the standards of the refereed, peer review process.[6][7]  One form is the online equivalent of the conventional paper journal. By 2006, almost all scientific journals have, while retaining their peer-review process, established electronic versions; a number have moved entirely to electronic publication. In a similar manner, most academic libraries buy the electronic version and purchase a paper copy only for the most important or most-used titles.  There is usually a delay of several months after an article is written before it is published in a journal, making paper journals not an ideal format for announcing the latest research. Many journals now publish the final papers in their electronic version as soon as they are ready, without waiting for the assembly of a complete issue, as is necessary with paper. In many fields in which even greater speed is wanted, such as physics, the role of the journal at disseminating the latest research has largely been replaced by preprint databases such as arXiv.org. Almost all such articles are eventually published in traditional journals, which still provide an important role in quality control, archiving papers, and establishing scientific credit.  Cost Main article: Academic publishing § Publishers and business aspects See also: Academic journal § Costs Many scientists and librarians have long protested the cost of journals, especially as they see these payments going to large for-profit publishing houses.[10] To allow their researchers online access to journals, many universities purchase site licenses, permitting access from anywhere in the university, and, with appropriate authorization, by university-affiliated users at home or elsewhere. These may be quite expensive, sometimes much more than the cost for a print subscription, although this may reflect the number of people who will be using the license—while a print subscription is the cost for one person to receive the journal; a site-license can allow thousands of people to gain access.[citation needed]  Publications by scholarly societies, also known as not-for-profit-publishers, usually cost less than commercial publishers, but the prices of their scientific journals are still usually several thousand dollars a year. In general, this money is used to fund the activities of the scientific societies that run such journals, or is invested in providing further scholarly resources for scientists; thus, the money remains in and benefits the scientific sphere.  Despite the transition to electronic publishing, the serials crisis persists.[11]  Concerns about cost and open access have led to the creation of free-access journals such as the Public Library of Science (PLoS) family and partly open or reduced-cost journals such as the Journal of High Energy Physics. However, professional editors still have to be paid, and PLoS still relies heavily on donations from foundations to cover the majority of its operating costs; smaller journals do not often have access to such resources.  Based on statistical arguments, it has been shown that electronic publishing online, and to some extent open access, both provide wider dissemination and increase the average number of citations an article receives.[12]  Copyright Traditionally, the author of an article was required to transfer the copyright to the journal publisher. Publishers claimed this was necessary in order to protect authors' rights, and to coordinate permissions for reprints or other use. However, many authors, especially those active in the open access movement, found this unsatisfactory,[13] and have used their influence to effect a gradual move towards a license to publish instead. Under such a system, the publisher has permission to edit, print, and distribute the article commercially, but the authors retain the other rights themselves.  Even if they retain the copyright to an article, most journals allow certain rights to their authors. These rights usually include the ability to reuse parts of the paper in the author's future work, and allow the author to distribute a limited number of copies. In the print format, such copies are called reprints; in the electronic format, they are called postprints. Some publishers, for example the American Physical Society, also grant the author the right to post and update the article on the author's or employer's website and on free e-print servers, to grant permission to others to use or reuse figures, and even to reprint the article as long as no fee is charged.[14] The rise of open access journals, in which the author retains the copyright but must pay a publication charge, such as the Public Library of Science family of journals, is another recent response to copyright concerns.[15]  See also Academic journal Academic authorship Academic conference Citation index Copyright policies of scientific publishers Medical journal Mega journal Open access journal Publish or perish Scientific writing List of scientific journals San Francisco Declaration on Research Assessment References  D. A. Kronick, History of Scientific and Technical Periodicals, 2nd ed. Scarecrow, 1976  "Background - julkaisufoorumi.fi". julkaisufoorumi.fi. Archived from the original on 30 September 2017. Retrieved 6 May 2018.  "FAQ - julkaisufoorumi.fi". julkaisufoorumi.fi. Archived from the original on 27 November 2017. Retrieved 6 May 2018.  "JoVE - Peer Reviewed Scientific Video Journal - Methods and Protocols". jove.com. Archived from the original on 22 March 2018. Retrieved 6 May 2018.  "Научный журнал "Видеонаука"". Scientific journal "Videonauka". Archived from the original on 2016-03-11.  Heller, Stephen, R. (1998). "Electronic Publishing of Scientific Manuscripts". Encyclopedia of Computational Chemistry. 02. John Wiley & Sons. pp. 871–875. Archived from the original on 2010-07-03. Retrieved 2010-06-16.  Boyce, Peter B.; Heather Dalterio (January 1996). "Electronic Publishing of Scientific Journals" (Article available to the public in HTML.). Physics Today. American Institute of Physics. 49 (1): 42. Bibcode:1996PhT....49a..42B. doi:10.1063/1.881598. Archived from the original on 2011-04-10.  Pettifer, S.; McDermott, P.; Marsh, J.; Thorne, D.; Villeger, A.; Attwood, T.K. (2011). "Ceci n'est pas un hamburger: modelling and representing the scholarly article". Learned Publishing. 24 (3): 207–220. doi:10.1087/20110309.  Swygart-Hobaugh, Rob Kling, Amanda J. "The Internet and the Velocity of Scholarly Journal Publishing". scholarworks.iu.edu. Archived from the original on 2016-10-27. Retrieved 2016-10-26.  Weinstein, Deborah (1 Feb 2012). "Elsevier begins outreach as push-back on publisher threatens to widen". MM&M. Archived from the original on 2018-02-15.  Sample, Ian (24 April 2012). "Harvard University says it can't afford journal publishers' prices". The Guardian. Archived from the original on 7 December 2016.  Lawrence, Steve. "Online Or Invisible?". NEC Research Institute. Archived from the original on 2007-03-16.  Di Cosmo, Roberto (June 2006). "The Role of Public Administrations in The ICT Era" (PDF). UPGRADE: The European Journal for the Informatics Professional. 7 (3): 41–8. ISSN 1684-5285. Archived (PDF) from the original on 2011-07-17.  "APS Copyright Policies and Frequently Asked Questions". Archived from the original on 2006-10-09.  Is it time to end copyright for scientific journals? Gizmodo, 2011 A.J. Meadows, ed. The Scientific Journal. London : Aslib, c1979. ISBN 0-85142-118-0 R.E. Abel et al. "Scholarly Publishing: Books Journals, Publishers, and Libraries in the Twentieth Century". N.Y.: Wiley, 2002. ISBN 0-471-21929-0 D.W. King et al. "Scientific Journals in the United States: their Production, Use, and Economics". Stroudsberg, PA: Hutchinson-Ross, 1981 ISBN 0-87933-380-4 A. Gielas & A. Fyfe, eds. "Editorship and the Editing of Scientific Journals, 1750–1950", Special Issue: Centaurus. International Journal for the History of Science and its Cultural Aspects, 2020. External links 	Wikimedia Commons has media related to Scientific journals. The cost of publishing in a scientific journal, some examples and recommended reading from OpenWetWare life scientists' wiki vte Academic publishing Journals	 Academic journalScientific journalOpen access journalPublic health journal Papers	 Scholarly paperReview articlePosition paperLiterature review Grey literature	 Working paperWhite paperTechnical reportAnnual reportPamphletEssayLab notes Other types of publication	 Thesis (Collection of articles, Monograph)Specialized patent (biological, chemical)BookBook chapterPoster sessionAbstract Impact and ranking	 Acknowledgment indexAltmetricsArticle-level metricsAuthor-level metricsBibliometricsCitation impactCitation indexJournal rankingEigenfactorh-indexImpact factorSCImago Journal RankScientometrics Reform	 Academic journal publishing reformFull-text-on-the-Net bias (FUTON bias)Open accessSerials crisisSci-Hub#ICanHazPDF Versioning	 PreprintPostprintVersion of RecordErratum/corrigendumRetraction Indexes and search engines	 Google ScholarAMinerBASEMicrosoft AcademicCORESemantic ScholarScopusWeb of Science Related topics	 ImprintScientific writingPeer reviewProceedingsScientific literatureLearned societyOpen researchOpen science dataORCIDElectronic publishingIngelfinger ruleLeast publishable unitPublish or perish Lists	 Academic journalsScientific journalsOpen-access journalsAcademic databases and search enginesUniversity pressesCopyright policiesPreprint policiesStyle/formatting guidesCategory:Academic publishingCategory:Scientific documents Portal Portal Authority control Edit this at Wikidata	 Integrated Authority File (Germany) Categories: Scientific journalsTechnical communication17th-century introductions Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadEditView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons  Languages العربية Deutsch Español Français Bahasa Indonesia Bahasa Melayu Русский Türkçe 中文 32 more Edit links This page was last edited on 8 September 2021, at 22:41 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki   Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more Page semi-protected Science From Wikipedia, the free encyclopedia Jump to navigationJump to search This article is about a branch of knowledge. For other uses, see Science (disambiguation). Part of a series on Science Overview Branches Society OutlineNuvola apps kalzium.svg Science portalCategory Category vte  The Universe represented as multiple disk-shaped slices across time, which passes from left to right Science (from Latin scientia 'knowledge')[1] is a systematic enterprise that builds and organizes knowledge in the form of testable explanations and predictions about the world.[2][3][4]  The earliest roots of science can be traced to Ancient Egypt and Mesopotamia in around 3000 to 1200 BCE.[5][6] Their contributions to mathematics, astronomy, and medicine entered and shaped Greek natural philosophy of classical antiquity, whereby formal attempts were made to provide explanations of events in the physical world based on natural causes.[5][6] After the fall of the Western Roman Empire, knowledge of Greek conceptions of the world deteriorated in Western Europe during the early centuries (400 to 1000 CE) of the Middle Ages,[7] but was preserved in the Muslim world during the Islamic Golden Age.[8] The recovery and assimilation of Greek works and Islamic inquiries into Western Europe from the 10th to 13th century revived "natural philosophy",[7][9] which was later transformed by the Scientific Revolution that began in the 16th century[10] as new ideas and discoveries departed from previous Greek conceptions and traditions.[11][12][13][14] The scientific method soon played a greater role in knowledge creation and it was not until the 19th century that many of the institutional and professional features of science began to take shape;[15][16][17] along with the changing of "natural philosophy" to "natural science."[18]  Modern science is typically divided into three major branches[19] that consist of the natural sciences (e.g., biology, chemistry, and physics), which study nature in the broadest sense; the social sciences (e.g., economics, psychology, and sociology), which study individuals and societies;[20][21] and the formal sciences (e.g., logic, mathematics, and theoretical computer science), which deal with symbols governed by rules.[22][23] There is disagreement,[24][25][26] however, on whether the formal sciences actually constitute a science as they do not rely on empirical evidence.[27][25] Disciplines that use existing scientific knowledge for practical purposes, such as engineering and medicine, are described as applied sciences.[28][29][30][31][32]  New knowledge in science is advanced by research from scientists who are motivated by curiosity about the world and a desire to solve problems.[33][34] Contemporary scientific research is highly collaborative and is usually done by teams in academic and research institutions,[35] government agencies, and companies.[36][37] The practical impact of their work has led to the emergence of science policies that seek to influence the scientific enterprise by prioritizing the development of commercial products, armaments, health care, public infrastructure, and environmental protection.   Contents 1	History 1.1	Earliest roots 1.2	Classical antiquity 1.3	Medieval science 1.4	Renaissance and early modern science 1.5	Age of Enlightenment 1.6	19th century 1.7	20th century 1.8	21st century 2	Branches of science 2.1	Natural science 2.2	Social science 2.3	Formal science 2.4	Applied science 3	Scientific research 3.1	Scientific method 3.1.1	Verifiability 3.2	Role of mathematics 3.3	Philosophy of science 3.3.1	Certainty and science 3.4	Scientific literature 3.5	Practical impacts 3.6	Challenges 3.6.1	Replication crisis 3.6.2	Fringe science, pseudoscience, and junk science 4	Scientific community 4.1	Scientists 4.1.1	Women in science 4.2	Learned societies 5	Science and the public 5.1	Science policy 5.1.1	Funding of science 5.2	Public awareness of science 5.3	Science journalism 5.4	Politicization of science 6	See also 7	Notes 8	References 8.1	Works cited 9	Further reading 10	External links History Further information: History of science Science in a broad sense existed before the modern era and in many historical civilizations.[38] Modern science is distinct in its approach and successful in its results, so it now defines what science is in the strictest sense of the term.[3][5][39] Science in its original sense was a word for a type of knowledge, rather than a specialized word for the pursuit of such knowledge. In particular, it was the type of knowledge that people can communicate to each other and share. For example, knowledge about the working of natural things was gathered long before recorded history and led to the development of complex abstract thought. This is shown by the construction of complex calendars, techniques for making poisonous plants edible, public works at a national scale, such as those which harnessed the floodplain of the Yangtse with reservoirs,[40] dams, and dikes, and buildings such as the Pyramids. However, no consistent conscious distinction was made between knowledge of such things, which are true in every community, and other types of communal knowledge, such as mythologies and legal systems. Metallurgy was known in prehistory, and the Vinča culture was the earliest known producer of bronze-like alloys. It is thought that early experimentation with heating and mixing of substances over time developed into alchemy.  Earliest roots Further information: History of science in early cultures  Clay models of animal livers dating between the nineteenth and eighteenth centuries BCE, found in the royal palace in Mari, Syria The earliest roots of science can be traced to Ancient Egypt and Mesopotamia in around 3000 to 1200 BCE.[5] Although the words and concepts of "science" and "nature" were not part of the conceptual landscape at the time, the ancient Egyptians and Mesopotamians made contributions that would later find a place in Greek and medieval science: mathematics, astronomy, and medicine.[41][5] Starting in around 3000 BCE, the ancient Egyptians developed a numbering system that was decimal in character and had orientated their knowledge of geometry to solving practical problems such as those of surveyors and builders.[5] They even developed an official calendar that contained twelve months, thirty days each, and five days at the end of the year.[5] Based on the medical papyri written in the 2500-1200 BCE, the ancient Egyptians believed that disease was mainly caused by the invasion of bodies by evil forces or spirits. Thus, in addition to drug treatments, healing therapies would involve prayer, incantation, and ritual.[5]  The ancient Mesopotamians used knowledge about the properties of various natural chemicals for manufacturing pottery, faience, glass, soap, metals, lime plaster, and waterproofing;[42] they also studied animal physiology, anatomy, and behavior for divinatory purposes[42] and made extensive records of the movements of astronomical objects for their study of astrology.[43] The Mesopotamians had intense interest in medicine[42] and the earliest medical prescriptions appear in Sumerian during the Third Dynasty of Ur (c. 2112 BCE – c. 2004 BCE).[44] Nonetheless, the Mesopotamians seem to have had little interest in gathering information about the natural world for the mere sake of gathering information[42] and mainly only studied scientific subjects which had obvious practical applications or immediate relevance to their religious system.[42]  Classical antiquity Further information: History of science in classical antiquity and Nature (philosophy) In classical antiquity, there is no real ancient analog of a modern scientist. Instead, well-educated, usually upper-class, and almost universally male individuals performed various investigations into nature whenever they could afford the time.[45] Before the invention or discovery of the concept of "nature" (ancient Greek phusis) by the Pre-Socratic philosophers, the same words tend to be used to describe the natural "way" in which a plant grows,[46] and the "way" in which, for example, one tribe worships a particular god. For this reason, it is claimed these men were the first philosophers in the strict sense, and also the first people to clearly distinguish "nature" and "convention."[47]: 209  Natural philosophy, the precursor of natural science, was thereby distinguished as the knowledge of nature and things which are true for every community, and the name of the specialized pursuit of such knowledge was philosophy – the realm of the first philosopher-physicists. They were mainly speculators or theorists, particularly interested in astronomy. In contrast, trying to use knowledge of nature to imitate nature (artifice or technology, Greek technē) was seen by classical scientists as a more appropriate interest for artisans of lower social class.[48]   The universe as conceived of by Aristotle and Ptolemy from Peter Apian's 1524 work Cosmographia. The earth is composed of four elements: Earth, Water, Fire and Air. The earth does not move or rotate. It is surrounded by concentric spheres containing the planets, the sun, the stars, and heaven.[49] The early Greek philosophers of the Milesian school, which was founded by Thales of Miletus and later continued by his successors Anaximander and Anaximenes, were the first to attempt to explain natural phenomena without relying on the supernatural.[50] The Pythagoreans developed a complex number philosophy[51]: 467–68  and contributed significantly to the development of mathematical science.[51]: 465  The theory of atoms was developed by the Greek philosopher Leucippus and his student Democritus.[52][53] The Greek doctor Hippocrates established the tradition of systematic medical science[54][55] and is known as "The Father of Medicine".[56]  A turning point in the history of early philosophical science was Socrates' example of applying philosophy to the study of human matters, including human nature, the nature of political communities, and human knowledge itself. The Socratic method as documented by Plato's dialogues is a dialectic method of hypothesis elimination: better hypotheses are found by steadily identifying and eliminating those that lead to contradictions. This was a reaction to the Sophist emphasis on rhetoric. The Socratic method searches for general, commonly held truths that shape beliefs and scrutinizes them to determine their consistency with other beliefs.[57] Socrates criticized the older type of study of physics as too purely speculative and lacking in self-criticism. Socrates was later, in the words of his Apology, accused of corrupting the youth of Athens because he did "not believe in the gods the state believes in, but in other new spiritual beings". Socrates refuted these claims,[58] but was sentenced to death.[59]: 30e   Aristotle later created a systematic programme of teleological philosophy: Motion and change is described as the actualization of potentials already in things, according to what types of things they are. In his physics, the Sun goes around the Earth, and many things have it as part of their nature that they are for humans. Each thing has a formal cause, a final cause, and a role in a cosmic order with an unmoved mover. The Socratics also insisted that philosophy should be used to consider the practical question of the best way to live for a human being (a study Aristotle divided into ethics and political philosophy). Aristotle maintained that man knows a thing scientifically "when he possesses a conviction arrived at in a certain way, and when the first principles on which that conviction rests are known to him with certainty".[60]  The Greek astronomer Aristarchus of Samos (310–230 BCE) was the first to propose a heliocentric model of the universe, with the Sun at the center and all the planets orbiting it.[61] Aristarchus's model was widely rejected because it was believed to violate the laws of physics.[61] The inventor and mathematician Archimedes of Syracuse made major contributions to the beginnings of calculus[62] and has sometimes been credited as its inventor,[62] although his proto-calculus lacked several defining features.[62] Pliny the Elder was a Roman writer and polymath, who wrote the seminal encyclopedia Natural History,[63][64][65] dealing with history, geography, medicine, astronomy, earth science, botany, and zoology.[63] Other scientists or proto-scientists in Antiquity were Theophrastus, Euclid, Herophilos, Hipparchus, Ptolemy, and Galen.  Medieval science Further information: Byzantine science, Science in the medieval Islamic world, and European science in the Middle Ages  De potentiis anime sensitive, Gregor Reisch (1504) Margarita philosophica. Medieval science postulated a ventricle of the brain as the location for our common sense,[66]: 189  where the forms from our sensory systems commingled. Because of the collapse of the Western Roman Empire due to the Migration Period an intellectual decline took place in the western part of Europe in the 400s. In contrast, the Byzantine Empire resisted the attacks from invaders, and preserved and improved upon the learning. John Philoponus, a Byzantine scholar in the 500s, questioned Aristotle's teaching of physics, noting its flaws.[67]: pp.307, 311, 363, 402  John Philoponus' criticism of Aristotelian principles of physics served as an inspiration to medieval scholars as well as to Galileo Galilei who ten centuries later, during the Scientific Revolution, extensively cited Philoponus in his works while making the case for why Aristotelian physics was flawed.[67][68]  During late antiquity and the early Middle Ages, the Aristotelian approach to inquiries on natural phenomena was used. Aristotle's four causes prescribed that the question "why" should be answered in four ways in order to explain things scientifically.[69] Some ancient knowledge was lost, or in some cases kept in obscurity, during the fall of the Western Roman Empire and periodic political struggles. However, the general fields of science (or "natural philosophy" as it was called) and much of the general knowledge from the ancient world remained preserved through the works of the early Latin encyclopedists like Isidore of Seville.[70] However, Aristotle's original texts were eventually lost in Western Europe, and only one text by Plato was widely known, the Timaeus, which was the only Platonic dialogue, and one of the few original works of classical natural philosophy, available to Latin readers in the early Middle Ages. Another original work that gained influence in this period was Ptolemy's Almagest, which contains a geocentric description of the solar system.  During late antiquity, in the Byzantine empire many Greek classical texts were preserved. Many Syriac translations were done by groups such as the Nestorians and Monophysites.[71] They played a role when they translated Greek classical texts into Arabic under the Caliphate, during which many types of classical learning were preserved and in some cases improved upon.[71][a] In addition, the neighboring Sassanid Empire established the medical Academy of Gondeshapur where Greek, Syriac, and Persian physicians established the most important medical center of the ancient world during the 6th and 7th centuries.[72]  The House of Wisdom was established in Abbasid-era Baghdad, Iraq,[73] where the Islamic study of Aristotelianism flourished. Al-Kindi (801–873) was the first of the Muslim Peripatetic philosophers, and is known for his efforts to introduce Greek and Hellenistic philosophy to the Arab world.[74] The Islamic Golden Age flourished from this time until the Mongol invasions of the 13th century. Ibn al-Haytham (Alhazen), as well as his predecessor Ibn Sahl, was familiar with Ptolemy's Optics, and used experiments as a means to gain knowledge.[b][75][76]: 463–65  Alhazen disproved Ptolemy's theory of vision,[77] but did not make any corresponding changes to Aristotle's metaphysics. Furthermore, doctors and alchemists such as the Persians Avicenna and Al-Razi also greatly developed the science of Medicine with the former writing the Canon of Medicine, a medical encyclopedia used until the 18th century and the latter discovering multiple compounds like alcohol. Avicenna's canon is considered to be one of the most important publications in medicine and they both contributed significantly to the practice of experimental medicine, using clinical trials and experiments to back their claims.[78]  In Classical antiquity, Greek and Roman taboos had meant that dissection was usually banned in ancient times, but in Middle Ages it changed: medical teachers and students at Bologna began to open human bodies, and Mondino de Luzzi (c. 1275–1326) produced the ﬁrst known anatomy textbook based on human dissection.[79][80]  By the eleventh century, most of Europe had become Christian; stronger monarchies emerged; borders were restored; technological developments and agricultural innovations were made which increased the food supply and population. In addition, classical Greek texts started to be translated from Arabic and Greek into Latin, giving a higher level of scientific discussion in Western Europe.[7]  By 1088, the first university in Europe (the University of Bologna) had emerged from its clerical beginnings. Demand for Latin translations grew (for example, from the Toledo School of Translators); western Europeans began collecting texts written not only in Latin, but also Latin translations from Greek, Arabic, and Hebrew. Manuscript copies of Alhazen's Book of Optics also propagated across Europe before 1240,[81]: Intro. p. xx  as evidenced by its incorporation into Vitello's Perspectiva. Avicenna's Canon was translated into Latin.[82] In particular, the texts of Aristotle, Ptolemy,[c] and Euclid, preserved in the Houses of Wisdom and also in the Byzantine Empire,[83] were sought amongst Catholic scholars. The influx of ancient texts caused the Renaissance of the 12th century and the flourishing of a synthesis of Catholicism and Aristotelianism known as Scholasticism in western Europe, which became a new geographic center of science. An experiment in this period would be understood as a careful process of observing, describing, and classifying.[84] One prominent scientist in this era was Roger Bacon. Scholasticism had a strong focus on revelation and dialectic reasoning, and gradually fell out of favour over the next centuries, as alchemy's focus on experiments that include direct observation and meticulous documentation slowly increased in importance.  Renaissance and early modern science Further information: Scientific Revolution  Astronomy became more accurate after Tycho Brahe devised his scientific instruments for measuring angles between two celestial bodies, before the invention of the telescope. Brahe's observations were the basis for Kepler's laws. New developments in optics played a role in the inception of the Renaissance, both by challenging long-held metaphysical ideas on perception, as well as by contributing to the improvement and development of technology such as the camera obscura and the telescope. Before what we now know as the Renaissance started, Roger Bacon, Vitello, and John Peckham each built up a scholastic ontology upon a causal chain beginning with sensation, perception, and finally apperception of the individual and universal forms of Aristotle.[85] A model of vision later known as perspectivism was exploited and studied by the artists of the Renaissance. This theory uses only three of Aristotle's four causes: formal, material, and final.[86]  In the sixteenth century, Copernicus formulated a heliocentric model of the solar system unlike the geocentric model of Ptolemy's Almagest. This was based on a theorem that the orbital periods of the planets are longer as their orbs are farther from the centre of motion, which he found not to agree with Ptolemy's model.[87]  Kepler and others challenged the notion that the only function of the eye is perception, and shifted the main focus in optics from the eye to the propagation of light.[86][88]: 102  Kepler modelled the eye as a water-filled glass sphere with an aperture in front of it to model the entrance pupil. He found that all the light from a single point of the scene was imaged at a single point at the back of the glass sphere. The optical chain ends on the retina at the back of the eye.[d] Kepler is best known, however, for improving Copernicus' heliocentric model through the discovery of Kepler's laws of planetary motion. Kepler did not reject Aristotelian metaphysics and described his work as a search for the Harmony of the Spheres.  Galileo made innovative use of experiment and mathematics. However, he became persecuted after Pope Urban VIII blessed Galileo to write about the Copernican system. Galileo had used arguments from the Pope and put them in the voice of the simpleton in the work "Dialogue Concerning the Two Chief World Systems", which greatly offended Urban VIII.[89]  In Northern Europe, the new technology of the printing press was widely used to publish many arguments, including some that disagreed widely with contemporary ideas of nature. René Descartes and Francis Bacon published philosophical arguments in favor of a new type of non-Aristotelian science. Descartes emphasized individual thought and argued that mathematics rather than geometry should be used in order to study nature. Bacon emphasized the importance of experiment over contemplation. Bacon further questioned the Aristotelian concepts of formal cause and final cause, and promoted the idea that science should study the laws of "simple" natures, such as heat, rather than assuming that there is any specific nature, or "formal cause", of each complex type of thing. This new science began to see itself as describing "laws of nature". This updated approach to studies in nature was seen as mechanistic. Bacon also argued that science should aim for the first time at practical inventions for the improvement of all human life.  Age of Enlightenment Further information: Age of Enlightenment  Isaac Newton's copy of Principia from 1687. Newton made seminal contributions to classical mechanics, gravity, and optics. Newton also shares credit with Gottfried Leibniz for the development of calculus. As a precursor to the Age of Enlightenment, Isaac Newton and Gottfried Wilhelm Leibniz succeeded in developing a new physics, now referred to as classical mechanics, which could be confirmed by experiment and explained using mathematics (Newton (1687), Philosophiæ Naturalis Principia Mathematica). Leibniz also incorporated terms from Aristotelian physics, but now being used in a new non-teleological way, for example, "energy" and "potential" (modern versions of Aristotelian "energeia and potentia"). This implied a shift in the view of objects: Where Aristotle had noted that objects have certain innate goals that can be actualized, objects were now regarded as devoid of innate goals. In the style of Francis Bacon, Leibniz assumed that different types of things all work according to the same general laws of nature, with no special formal or final causes for each type of thing.[90] It is during this period that the word "science" gradually became more commonly used to refer to a type of pursuit of a type of knowledge, especially knowledge of nature – coming close in meaning to the old term "natural philosophy."  During this time, the declared purpose and value of science became producing wealth and inventions that would improve human lives, in the materialistic sense of having more food, clothing, and other things. In Bacon's words, "the real and legitimate goal of sciences is the endowment of human life with new inventions and riches", and he discouraged scientists from pursuing intangible philosophical or spiritual ideas, which he believed contributed little to human happiness beyond "the fume of subtle, sublime, or pleasing speculation".[91]  Science during the Enlightenment was dominated by scientific societies[92] and academies, which had largely replaced universities as centres of scientific research and development. Societies and academies were also the backbones of the maturation of the scientific profession. Another important development was the popularization of science among an increasingly literate population. Philosophes introduced the public to many scientific theories, most notably through the Encyclopédie and the popularization of Newtonianism by Voltaire as well as by Émilie du Châtelet, the French translator of Newton's Principia.  Some historians have marked the 18th century as a drab period in the history of science;[93] however, the century saw significant advancements in the practice of medicine, mathematics, and physics; the development of biological taxonomy; a new understanding of magnetism and electricity; and the maturation of chemistry as a discipline, which established the foundations of modern chemistry.  Enlightenment philosophers chose a short history of scientific predecessors – Galileo, Boyle, and Newton principally – as the guides and guarantors of their applications of the singular concept of nature and natural law to every physical and social field of the day. In this respect, the lessons of history and the social structures built upon it could be discarded.[94]  Ideas on human nature, society, and economics also evolved during the Enlightenment. Hume and other Scottish Enlightenment thinkers developed a "science of man",[95] which was expressed historically in works by authors including James Burnett, Adam Ferguson, John Millar and William Robertson, all of whom merged a scientific study of how humans behaved in ancient and primitive cultures with a strong awareness of the determining forces of modernity. Modern sociology largely originated from this movement.[96] In 1776, Adam Smith published The Wealth of Nations, which is often considered the first work on modern economics.[97]  19th century  The first diagram of an evolutionary tree made by Charles Darwin in 1837, which eventually led to his most famous work, On the Origin of Species, in 1859. The nineteenth century is a particularly important period in the history of science since during this era many distinguishing characteristics of contemporary modern science began to take shape such as: transformation of the life and physical sciences, frequent use of precision instruments, emergence of terms like "biologist", "physicist", "scientist"; slowly moving away from antiquated labels like "natural philosophy" and "natural history", increased professionalization of those studying nature lead to reduction in amateur naturalists, scientists gained cultural authority over many dimensions of society, economic expansion and industrialization of numerous countries, thriving of popular science writings and emergence of science journals.[17]  Early in the 19th century, John Dalton suggested the modern atomic theory, based on Democritus's original idea of indivisible particles called atoms.  Both John Herschel and William Whewell systematized methodology: the latter coined the term scientist.[98]  During the mid-19th century, Charles Darwin and Alfred Russel Wallace independently proposed the theory of evolution by natural selection in 1858, which explained how different plants and animals originated and evolved. Their theory was set out in detail in Darwin's book On the Origin of Species, which was published in 1859.[99] Separately, Gregor Mendel presented his paper, "Versuche über Pflanzenhybriden" ("Experiments on Plant Hybridization"), in 1865,[100] which outlined the principles of biological inheritance, serving as the basis for modern genetics.[101]  The laws of conservation of energy, conservation of momentum and conservation of mass suggested a highly stable universe where there could be little loss of resources. With the advent of the steam engine and the industrial revolution, there was, however, an increased understanding that all forms of energy as defined in physics were not equally useful: they did not have the same energy quality. This realization led to the development of the laws of thermodynamics, in which the free energy of the universe is seen as constantly declining: the entropy of a closed universe increases over time.  The electromagnetic theory was also established in the 19th century by the works of Hans Christian Ørsted, André-Marie Ampère, Michael Faraday, James Clerk Maxwell, Oliver Heaviside, and Heinrich Hertz. The new theory raised questions that could not easily be answered using Newton's framework. The phenomena that would allow the deconstruction of the atom were discovered in the last decade of the 19th century: the discovery of X-rays inspired the discovery of radioactivity. In the next year came the discovery of the first subatomic particle, the electron.  During the late 19th century, psychology emerged as a separate discipline from philosophy when Wilhelm Wundt founded the first laboratory for psychological research in 1879.[102]  20th century  The DNA double helix is a molecule that encodes the genetic instructions used in the development and functioning of all known living organisms and many viruses. Albert Einstein's theory of relativity and the development of quantum mechanics led to the replacement of classical mechanics with a new physics which contains two parts that describe different types of events in nature.  In the first half of the century, the development of antibiotics and artificial fertilizers made global human population growth possible. At the same time, the structure of the atom and its nucleus was discovered, leading to the release of "atomic energy" (nuclear power). In addition, the extensive use of technological innovation stimulated by the wars of this century led to revolutions in transportation (automobiles and aircraft), the development of ICBMs, a space race, and a nuclear arms race.  Evolution became a unified theory in the early 20th-century when the modern synthesis reconciled Darwinian evolution with classical genetics.[103] The molecular structure of DNA was discovered by James Watson and Francis Crick in 1953.  The discovery of the cosmic microwave background radiation in 1964 led to a rejection of the Steady State theory of the universe in favor of the Big Bang theory of Georges Lemaître.  The development of spaceflight in the second half of the century allowed the first astronomical measurements done on or near other objects in space, including six manned landings on the Moon. Space telescopes lead to numerous discoveries in astronomy and cosmology.  Widespread use of integrated circuits in the last quarter of the 20th century combined with communications satellites led to a revolution in information technology and the rise of the global internet and mobile computing, including smartphones. The need for mass systematization of long, intertwined causal chains and large amounts of data led to the rise of the fields of systems theory and computer-assisted scientific modelling, which are partly based on the Aristotelian paradigm.[104]  Harmful environmental issues such as ozone depletion, acidification, eutrophication and climate change came to the public's attention in the same period, and caused the onset of environmental science and environmental technology.  21st century  A simulated event in the CMS detector of the Large Hadron Collider, featuring a possible appearance of the Higgs boson The Human Genome Project was completed in 2003, determining the sequence of nucleotide base pairs that make up human DNA, and identifying and mapping all of the genes of the human genome.[105] Induced pluripotent stem cells were developed in 2006, a technology allowing adult cells to be transformed into stem cells capable of giving rise to any cell type found in the body, potentially of huge importance to the field of regenerative medicine.[106]  With the discovery of the Higgs boson in 2012, the last particle predicted by the Standard Model of particle physics was found. In 2015, gravitational waves, predicted by general relativity a century before, were first observed.[107][108]  In 2019, the Event Horizon Telescope Observatory announced its first results in simultaneous press conferences around the world on April 10, 2019.[109] Press conferences presented the first direct image of a black hole, where the supermassive black hole appeared in the heart of the galaxy Messier 87, which is 55 million light-years away from Earth. The scientific findings are presented in a series of six papers published in The Astrophysical Journal.[110]  Branches of science Further information: Branches of science  The scale of the Universe mapped to branches of science and showing how one system is built atop the next through the hierarchy of the sciences Modern science is commonly divided into three major branches: natural science, social science, and formal science.[19] Each of these branches comprises various specialized yet overlapping scientific disciplines that often possess their own nomenclature and expertise.[111] Both natural and social sciences are empirical sciences,[112] as their knowledge is based on empirical observations and is capable of being tested for its validity by other researchers working under the same conditions.[113]  There are also closely related disciplines that use science, such as engineering and medicine, which are sometimes described as applied sciences. The relationships between the branches of science are summarized by the following table.  Science Empirical sciences	Formal science Natural science	Social science Basic	Physics, chemistry, biology, earth science, and space science	Anthropology, economics, political science, human geography, psychology, and sociology	Logic, mathematics, and statistics Applied	Engineering, agricultural science, medicine, and materials science	Business administration, public policy, marketing, law, pedagogy, and international development	Computer science Natural science Further information: Natural science and Outline of natural science Natural science is the study of the physical world. It can be divided into two main branches: life science (or biological science) and physical science. These two branches may be further divided into more specialized disciplines. For example, physical science can be subdivided into physics, chemistry, astronomy, and earth science. Modern natural science is the successor to the natural philosophy that began in Ancient Greece. Galileo, Descartes, Bacon, and Newton debated the benefits of using approaches which were more mathematical and more experimental in a methodical way. Still, philosophical perspectives, conjectures, and presuppositions, often overlooked, remain necessary in natural science.[114] Systematic data collection, including discovery science, succeeded natural history, which emerged in the 16th century by describing and classifying plants, animals, minerals, and so on.[115] Today, "natural history" suggests observational descriptions aimed at popular audiences.[116]  Social science Further information: Social science and Outline of social science  In economics, the supply and demand model describes how prices vary in a market economy as a result of a balance between product availability and consumer demand. Social science is the study of human behavior and functioning of societies.[20][21] It has many disciplines that include, but are not limited to anthropology, economics, history, human geography, political science, psychology, and sociology.[20] In the social sciences, there are many competing theoretical perspectives, many of which are extended through competing research programs such as the functionalists, conflict theorists, and interactionists in sociology.[20] Due to the limitations of conducting controlled experiments involving large groups of individuals or complex situations, social scientists may adopt other research methods such as the historical method, case studies, and cross-cultural studies. Moreover, if quantitative information is available, social scientists may rely on statistical approaches to better understand social relationships and processes.[20]  Formal science Further information: Formal science and Outline of formal science Formal science is an area of study that generates knowledge using formal systems.[117][22][23] It includes mathematics,[118][119] systems theory, and theoretical computer science. The formal sciences share similarities with the other two branches by relying on objective, careful, and systematic study of an area of knowledge. They are, however, different from the empirical sciences as they rely exclusively on deductive reasoning, without the need for empirical evidence, to verify their abstract concepts.[27][120][113] The formal sciences are therefore a priori disciplines and because of this, there is disagreement on whether they actually constitute a science.[24][26] Nevertheless, the formal sciences play an important role in the empirical sciences. Calculus, for example, was initially invented to understand motion in physics.[121] Natural and social sciences that rely heavily on mathematical applications include mathematical physics, mathematical chemistry, mathematical biology, mathematical finance, and mathematical economics.  Applied science Further information: Applied science and Outline of applied science  Louis Pasteur's pasteurization experiment illustrates that the spoilage of liquid is caused by particles in the air rather than the liquid itself. Pasteur also discovered the principles of vaccination and fermentation. Applied science is the use of the scientific method and knowledge to attain practical goals and includes a broad range of disciplines such as engineering and medicine.[28][29][30][31][32] Engineering is the use of scientific principles to design and build machines, structures, and other items, including bridges, tunnels, roads, vehicles, and buildings.[122] Engineering itself encompasses a range of more specialized fields of engineering, each with a more specific emphasis on particular areas of applied mathematics, science, and types of application. Medicine is the practice of caring for patients by maintaining and restoring health through the prevention, diagnosis, and treatment of injury or disease.[123][124][125][126] Contemporary medicine applies biomedical sciences, medical research, genetics, and medical technology to prevent, diagnose, and treat injury and disease, typically through the use of medications, medical devices, surgery, and non-pharmacological interventions. The applied sciences are often contrasted with the basic sciences, which are focused on advancing scientific theories and laws that explain and predict events in the natural world.  Scientific research Further information: Research Scientific research can be labeled as either basic or applied research. Basic research is the search for knowledge and applied research is the search for solutions to practical problems using this knowledge. Although some scientific research is applied research into specific problems, a great deal of our understanding comes from the curiosity-driven undertaking of basic research. This leads to options for technological advances that were not planned or sometimes even imaginable. This point was made by Michael Faraday when allegedly in response to the question "what is the use of basic research?" he responded: "Sir, what is the use of a new-born child?".[127] For example, research into the effects of red light on the human eye's rod cells did not seem to have any practical purpose; eventually, the discovery that our night vision is not troubled by red light would lead search and rescue teams (among others) to adopt red light in the cockpits of jets and helicopters.[128] Finally, even basic research can take unexpected turns, and there is some sense in which the scientific method is built to harness luck.  Scientific method Further information: Scientific method  The scientific method originated with Aristotle's idea that knowledge came from careful observation, and was brought into modern form by Galileo's collection of empirical evidence.[129] Scientific research involves using the scientific method, which seeks to objectively explain the events of nature in a reproducible way.[130] An explanatory thought experiment or hypothesis is put forward as explanation using principles such as parsimony (also known as "Occam's Razor") and are generally expected to seek consilience – fitting well with other accepted facts related to the phenomena.[131] This new explanation is used to make falsifiable predictions that are testable by experiment or observation. The predictions are to be posted before a confirming experiment or observation is sought, as proof that no tampering has occurred. Disproof of a prediction is evidence of progress.[e][f][130][132] This is done partly through observation of natural phenomena, but also through experimentation that tries to simulate natural events under controlled conditions as appropriate to the discipline (in the observational sciences, such as astronomy or geology, a predicted observation might take the place of a controlled experiment). Experimentation is especially important in science to help establish causal relationships (to avoid the correlation fallacy).  When a hypothesis proves unsatisfactory, it is either modified or discarded.[133] If the hypothesis survived testing, it may become adopted into the framework of a scientific theory, a logically reasoned, self-consistent model or framework for describing the behavior of certain natural phenomena. A theory typically describes the behavior of much broader sets of phenomena than a hypothesis; commonly, a large number of hypotheses can be logically bound together by a single theory. Thus a theory is a hypothesis explaining various other hypotheses. In that vein, theories are formulated according to most of the same scientific principles as hypotheses. In addition to testing hypotheses, scientists may also generate a model, an attempt to describe or depict the phenomenon in terms of a logical, physical or mathematical representation and to generate new hypotheses that can be tested, based on observable phenomena.[134]  While performing experiments to test hypotheses, scientists may have a preference for one outcome over another, and so it is important to ensure that science as a whole can eliminate this bias.[135][136] This can be achieved by careful experimental design, transparency, and a thorough peer review process of the experimental results as well as any conclusions.[137][138] After the results of an experiment are announced or published, it is normal practice for independent researchers to double-check how the research was performed, and to follow up by performing similar experiments to determine how dependable the results might be.[139] Taken in its entirety, the scientific method allows for highly creative problem solving while minimizing any effects of subjective bias on the part of its users (especially the confirmation bias).[140]  Verifiability John Ziman points out that intersubjective verifiability is fundamental to the creation of all scientific knowledge.[141] Ziman shows how scientists can identify patterns to each other across centuries; he refers to this ability as "perceptual consensibility."[141] He then makes consensibility, leading to consensus, the touchstone of reliable knowledge.[142]  Role of mathematics Further information: Mathematics and Formal science  Calculus, the mathematics of continuous change, underpins many of the sciences. Mathematics is essential in the formation of hypotheses, theories, and laws[143] in the natural and social sciences. For example, it is used in quantitative scientific modeling, which can generate new hypotheses and predictions to be tested. It is also used extensively in observing and collecting measurements. Statistics, a branch of mathematics, is used to summarize and analyze data, which allow scientists to assess the reliability and variability of their experimental results.  Computational science applies computing power to simulate real-world situations, enabling a better understanding of scientific problems than formal mathematics alone can achieve. The use of machine learning (also artificial intelligence) is becoming a central feature of computational contributions to science for example in agent-based computational economics, random forests, topic modelling and various forms of prediction. According to the Society for Industrial and Applied Mathematics, computation is now as important as theory and experiment in advancing scientific knowledge.[144] However, machines alone rarely advance knowledge as they require human guidance and capacity to reason; and they can introduce bias against certain social groups or sometimes underperform compared to humans.[145][146][147][148] Thus, machine learning is often used in science as prediction in the service of estimation.  Philosophy of science Further information: Philosophy of science Scientists usually take for granted a set of basic assumptions that are needed to justify the scientific method: (1) that there is an objective reality shared by all rational observers; (2) that this objective reality is governed by natural laws; (3) that these laws can be discovered by means of systematic observation and experimentation.[3] The philosophy of science seeks a deep understanding of what these underlying assumptions mean and whether they are valid.  The belief that scientific theories should and do represent metaphysical reality is known as realism. It can be contrasted with anti-realism, the view that the success of science does not depend on it being accurate about unobservable entities such as electrons. One form of anti-realism is idealism, the belief that the mind or consciousness is the most basic essence, and that each mind generates its own reality.[g] In an idealistic world view, what is true for one mind need not be true for other minds.  There are different schools of thought in the philosophy of science. The most popular position is empiricism,[h] which holds that knowledge is created by a process involving observation and that scientific theories are the result of generalizations from such observations.[149] Empiricism generally encompasses inductivism, a position that tries to explain the way general theories can be justified by the finite number of observations humans can make and hence the finite amount of empirical evidence available to confirm scientific theories. This is necessary because the number of predictions those theories make is infinite, which means that they cannot be known from the finite amount of evidence using deductive logic only. Many versions of empiricism exist, with the predominant ones being Bayesianism[150] and the hypothetico-deductive method.[149]   The Horse in Motion (1878) falsifies the flying gallop. Karl Popper, best known for his work on empirical falsification, proposed replacing verifiability with conjecture and refutation as the landmark of scientific theories. Empiricism has stood in contrast to rationalism, the position originally associated with Descartes, which holds that knowledge is created by the human intellect, not by observation.[151] Critical rationalism is a contrasting 20th-century approach to science, first defined by Austrian-British philosopher Karl Popper. Popper rejected the way that empiricism describes the connection between theory and observation. He claimed that theories are not generated by observation, but that observation is made in the light of theories and that the only way a theory can be affected by observation is when it comes in conflict with it.[152] Popper proposed replacing verifiability with falsifiability as the landmark of scientific theories and replacing induction with falsification as the empirical method.[152] Popper further claimed that there is actually only one universal method, not specific to science: the negative method of criticism, trial and error.[153] It covers all products of the human mind, including science, mathematics, philosophy, and art.[154]  Another approach, instrumentalism, emphasizes the utility of theories as instruments for explaining and predicting phenomena.[155] It views scientific theories as black boxes with only their input (initial conditions) and output (predictions) being relevant. Consequences, theoretical entities, and logical structure are claimed to be something that should simply be ignored and that scientists should not make a fuss about (see interpretations of quantum mechanics). Close to instrumentalism is constructive empiricism, according to which the main criterion for the success of a scientific theory is whether what it says about observable entities is true.   For Kuhn, the addition of epicycles in Ptolemaic astronomy was "normal science" within a paradigm, whereas the Copernican revolution was a paradigm shift. Thomas Kuhn argued that the process of observation and evaluation takes place within a paradigm, a logically consistent "portrait" of the world that is consistent with observations made from its framing. He characterized normal science as the process of observation and "puzzle solving" which takes place within a paradigm, whereas revolutionary science occurs when one paradigm overtakes another in a paradigm shift.[156] Each paradigm has its own distinct questions, aims, and interpretations. The choice between paradigms involves setting two or more "portraits" against the world and deciding which likeness is most promising. A paradigm shift occurs when a significant number of observational anomalies arise in the old paradigm and a new paradigm makes sense of them. That is, the choice of a new paradigm is based on observations, even though those observations are made against the background of the old paradigm. For Kuhn, acceptance or rejection of a paradigm is a social process as much as a logical process. Kuhn's position, however, is not one of relativism.[157]  Finally, another approach often cited in debates of scientific skepticism against controversial movements like "creation science" is methodological naturalism. Its main point is that a difference between natural and supernatural explanations should be made and that science should be restricted methodologically to natural explanations.[158][i] That the restriction is merely methodological (rather than ontological) means that science should not consider supernatural explanations itself, but should not claim them to be wrong either. Instead, supernatural explanations should be left a matter of personal belief outside the scope of science. Methodological naturalism maintains that proper science requires strict adherence to empirical study and independent verification as a process for properly developing and evaluating explanations for observable phenomena.[159] The absence of these standards, arguments from authority, biased observational studies and other common fallacies are frequently cited by supporters of methodological naturalism as characteristic of the non-science they criticize.  Certainty and science A scientific theory is empirical[h][160] and is always open to falsification if new evidence is presented. That is, no theory is ever considered strictly certain as science accepts the concept of fallibilism.[j] The philosopher of science Karl Popper sharply distinguished truth from certainty. He wrote that scientific knowledge "consists in the search for truth," but it "is not the search for certainty ... All human knowledge is fallible and therefore uncertain."[161]  New scientific knowledge rarely results in vast changes in our understanding. According to psychologist Keith Stanovich, it may be the media's overuse of words like "breakthrough" that leads the public to imagine that science is constantly proving everything it thought was true to be false.[128] While there are such famous cases as the theory of relativity that required a complete reconceptualization, these are extreme exceptions. Knowledge in science is gained by a gradual synthesis of information from different experiments by various researchers across different branches of science; it is more like a climb than a leap.[128] Theories vary in the extent to which they have been tested and verified, as well as their acceptance in the scientific community.[k] For example, heliocentric theory, the theory of evolution, relativity theory, and germ theory still bear the name "theory" even though, in practice, they are considered factual.[162] Philosopher Barry Stroud adds that, although the best definition for "knowledge" is contested, being skeptical and entertaining the possibility that one is incorrect is compatible with being correct. Therefore, scientists adhering to proper scientific approaches will doubt themselves even once they possess the truth.[163] The fallibilist C. S. Peirce argued that inquiry is the struggle to resolve actual doubt and that merely quarrelsome, verbal, or hyperbolic doubt is fruitless[164] – but also that the inquirer should try to attain genuine doubt rather than resting uncritically on common sense.[165] He held that the successful sciences trust not to any single chain of inference (no stronger than its weakest link) but to the cable of multiple and various arguments intimately connected.[166]  Stanovich also asserts that science avoids searching for a "magic bullet"; it avoids the single-cause fallacy. This means a scientist would not ask merely "What is the cause of ...", but rather "What are the most significant causes of ...". This is especially the case in the more macroscopic fields of science (e.g. psychology, physical cosmology).[128] Research often analyzes few factors at once, but these are always added to the long list of factors that are most important to consider.[128] For example, knowing the details of only a person's genetics, or their history and upbringing, or the current situation may not explain a behavior, but a deep understanding of all these variables combined can be very predictive.  Scientific literature Further information: Scientific literature  Cover of the first volume of the scientific journal Science in 1880 Scientific research is published in an enormous range of scientific literature.[167] Scientific journals communicate and document the results of research carried out in universities and various other research institutions, serving as an archival record of science. The first scientific journals, Journal des Sçavans followed by the Philosophical Transactions, began publication in 1665. Since that time the total number of active periodicals has steadily increased. In 1981, one estimate for the number of scientific and technical journals in publication was 11,500.[168] The United States National Library of Medicine currently indexes 5,516 journals that contain articles on topics related to the life sciences. Although the journals are in 39 languages, 91 percent of the indexed articles are published in English.[169]  Most scientific journals cover a single scientific field and publish the research within that field; the research is normally expressed in the form of a scientific paper. Science has become so pervasive in modern societies that it is generally considered necessary to communicate the achievements, news, and ambitions of scientists to a wider populace.  Science magazines such as New Scientist, Science & Vie, and Scientific American cater to the needs of a much wider readership and provide a non-technical summary of popular areas of research, including notable discoveries and advances in certain fields of research. Science books engage the interest of many more people. Tangentially, the science fiction genre, primarily fantastic in nature, engages the public imagination and transmits the ideas, if not the methods, of science.  Recent efforts to intensify or develop links between science and non-scientific disciplines such as literature or more specifically, poetry, include the Creative Writing Science resource developed through the Royal Literary Fund.[170]  Practical impacts Discoveries in fundamental science can be world-changing. For example:  Research	Impact Static electricity and magnetism (c. 1600) Electric current (18th century)	All electric appliances, dynamos, electric power stations, modern electronics, including electric lighting, television, electric heating, transcranial magnetic stimulation, deep brain stimulation, magnetic tape, loudspeaker, and the compass and lightning rod. Diffraction (1665)	Optics, hence fiber optic cable (1840s), modern intercontinental communications, and cable TV and internet. Germ theory (1700)	Hygiene, leading to decreased transmission of infectious diseases; antibodies, leading to techniques for disease diagnosis and targeted anticancer therapies. Vaccination (1798)	Leading to the elimination of most infectious diseases from developed countries and the worldwide eradication of smallpox. Photovoltaic effect (1839)	Solar cells (1883), hence solar power, solar powered watches, calculators and other devices. The strange orbit of Mercury (1859) and other research leading to special (1905) and general relativity (1916)	Satellite-based technology such as GPS (1973), satnav and satellite communications.[l] Radio waves (1887)	Radio had become used in innumerable ways beyond its better-known areas of telephony, and broadcast television (1927) and radio (1906) entertainment. Other uses included – emergency services, radar (navigation and weather prediction), medicine, astronomy, wireless communications, geophysics, and networking. Radio waves also led researchers to adjacent frequencies such as microwaves, used worldwide for heating and cooking food. Radioactivity (1896) and antimatter (1932)	Cancer treatment (1896), Radiometric dating (1905), nuclear reactors (1942) and weapons (1945), mineral exploration, PET scans (1961), and medical research (via isotopic labeling). X-rays (1896)	Medical imaging, including computed tomography. Crystallography and quantum mechanics (1900)	Semiconductor devices (1906), hence modern computing and telecommunications including the integration with wireless devices: the mobile phone,[l] LED lamps and lasers. Plastics (1907)	Starting with Bakelite, many types of artificial polymers for numerous applications in industry and daily life. Antibiotics (1880s, 1928)	Salvarsan, Penicillin, doxycycline, etc. Nuclear magnetic resonance (1930s)	Nuclear magnetic resonance spectroscopy (1946), magnetic resonance imaging (1971), functional magnetic resonance imaging (1990s). Challenges Replication crisis Further information: Replication crisis and Metascience The replication crisis is an ongoing methodological crisis primarily affecting parts of the social and life sciences in which scholars have found that the results of many scientific studies are difficult or impossible to replicate or reproduce on subsequent investigation, either by independent researchers or by the original researchers themselves.[171][172] The crisis has long-standing roots; the phrase was coined in the early 2010s[173] as part of a growing awareness of the problem. The replication crisis represents an important body of research in metascience, which aims to improve the quality of all scientific research while reducing waste.[174]  Fringe science, pseudoscience, and junk science An area of study or speculation that masquerades as science in an attempt to claim a legitimacy that it would not otherwise be able to achieve is sometimes referred to as pseudoscience, fringe science, or junk science.[m] Physicist Richard Feynman coined the term "cargo cult science" for cases in which researchers believe they are doing science because their activities have the outward appearance of science but actually lack the "kind of utter honesty" that allows their results to be rigorously evaluated.[175] Various types of commercial advertising, ranging from hype to fraud, may fall into these categories. Science has been described as "the most important tool" for separating valid claims from invalid ones.[176]  There can also be an element of political or ideological bias on all sides of scientific debates. Sometimes, research may be characterized as "bad science," research that may be well-intended but is actually incorrect, obsolete, incomplete, or over-simplified expositions of scientific ideas. The term "scientific misconduct" refers to situations such as where researchers have intentionally misrepresented their published data or have purposely given credit for a discovery to the wrong person.[177]  Scientific community Further information: Scientific community The scientific community is a group of all interacting scientists, along with their respective societies and institutions.  Scientists Further information: Scientist  German-born scientist Albert Einstein (1879–1955) developed the theory of relativity. He also won the Nobel Prize in Physics in 1921 for his explanation of the photoelectric effect. Scientists are individuals who conduct scientific research to advance knowledge in an area of interest.[178][179] The term scientist was coined by William Whewell in 1833. In modern times, many professional scientists are trained in an academic setting and upon completion, attain an academic degree, with the highest degree being a doctorate such as a Doctor of Philosophy (PhD).[180] Many scientists pursue careers in various sectors of the economy such as academia, industry, government, and nonprofit organizations.[181][182][183]  Scientists exhibit a strong curiosity about reality, with some scientists having a desire to apply scientific knowledge for the benefit of health, nations, environment, or industries. Other motivations include recognition by their peers and prestige. The Nobel Prize, a widely regarded prestigious award,[184] is awarded annually to those who have achieved scientific advances in the fields of medicine, physics, chemistry, and economics.  Women in science Further information: Women in science and Women in STEM fields  Marie Curie was the first person to be awarded two Nobel Prizes: Physics in 1903 and Chemistry in 1911.[185] Science has historically been a male-dominated field, with some notable exceptions.[n] Women faced considerable discrimination in science, much as they did in other areas of male-dominated societies, such as frequently being passed over for job opportunities and denied credit for their work.[o] For example, Christine Ladd (1847–1930) was able to enter a Ph.D. program as "C. Ladd"; Christine "Kitty" Ladd completed the requirements in 1882, but was awarded her degree only in 1926, after a career which spanned the algebra of logic (see truth table), color vision, and psychology. Her work preceded notable researchers like Ludwig Wittgenstein and Charles Sanders Peirce. The achievements of women in science have been attributed to the defiance of their traditional role as laborers within the domestic sphere.[186]  In the late 20th century, active recruitment of women and elimination of institutional discrimination on the basis of sex greatly increased the number of women scientists, but large gender disparities remain in some fields; in the early 21st century over half of the new biologists were female, while 80% of PhDs in physics are given to men.[citation needed] In the early part of the 21st century, women in the United States earned 50.3% of bachelor's degrees, 45.6% of master's degrees, and 40.7% of PhDs in science and engineering fields. They earned more than half of the degrees in psychology (about 70%), social sciences (about 50%), and biology (about 50–60%) but earned less than half the degrees in the physical sciences, earth sciences, mathematics, engineering, and computer science.[187] Lifestyle choice also plays a major role in female engagement in science; women with young children are 28% less likely to take tenure-track positions due to work-life balance issues,[188] and female graduate students' interest in careers in research declines dramatically over the course of graduate school, whereas that of their male colleagues remains unchanged.[189]  Learned societies Further information: Learned society  Physicists in front of the Royal Society building in London (1952) Learned societies for the communication and promotion of scientific thought and experimentation have existed since the Renaissance.[190] Many scientists belong to a learned society that promotes their respective scientific discipline, profession, or group of related disciplines.[191] Membership may be open to all, may require possession of some scientific credentials, or may be an honor conferred by election.[192] Most scientific societies are non-profit organizations, and many are professional associations. Their activities typically include holding regular conferences for the presentation and discussion of new research results and publishing or sponsoring academic journals in their discipline. Some also act as professional bodies, regulating the activities of their members in the public interest or the collective interest of the membership. Scholars in the sociology of science[who?] argue that learned societies are of key importance and their formation assists in the emergence and development of new disciplines or professions.  The professionalization of science, begun in the 19th century, was partly enabled by the creation of distinguished academy of sciences in a number of countries such as the Italian Accademia dei Lincei in 1603,[193] the British Royal Society in 1660, the French Académie des Sciences in 1666,[194] the American National Academy of Sciences in 1863, the German Kaiser Wilhelm Institute in 1911, and the Chinese Academy of Sciences in 1928. International scientific organizations, such as the International Council for Science, have since been formed to promote cooperation between the scientific communities of different nations.  Science and the public "Science and society" redirects here. For the academic journal, see Science & Society. For the study of science as a social activity, see Sociology of scientific knowledge. Science policy Further information: Science policy, History of science policy, and Economics of science  The United Nations Global Science-Policy-Business Forum on the Environment in Nairobi, Kenya (2017) Science policy is an area of public policy concerned with the policies that affect the conduct of the scientific enterprise, including research funding, often in pursuance of other national policy goals such as technological innovation to promote commercial product development, weapons development, health care, and environmental monitoring. Science policy also refers to the act of applying scientific knowledge and consensus to the development of public policies. Science policy thus deals with the entire domain of issues that involve the natural sciences. In accordance with public policy being concerned about the well-being of its citizens, science policy's goal is to consider how science and technology can best serve the public.  State policy has influenced the funding of public works and science for thousands of years, particularly within civilizations with highly organized governments such as imperial China and the Roman Empire. Prominent historical examples include the Great Wall of China, completed over the course of two millennia through the state support of several dynasties, and the Grand Canal of the Yangtze River, an immense feat of hydraulic engineering begun by Sunshu Ao (孫叔敖 7th cent. BCE), Ximen Bao (西門豹 5th cent. BCE), and Shi Chi (4th cent. BCE). This construction dates from the 6th century BCE under the Sui Dynasty and is still in use today. In China, such state-supported infrastructure and scientific research projects date at least from the time of the Mohists, who inspired the study of logic during the period of the Hundred Schools of Thought and the study of defensive fortifications like the Great Wall of China during the Warring States period.  Public policy can directly affect the funding of capital equipment and intellectual infrastructure for industrial research by providing tax incentives to those organizations that fund research. Vannevar Bush, director of the Office of Scientific Research and Development for the United States government, the forerunner of the National Science Foundation, wrote in July 1945 that "Science is a proper concern of government."[195]  Funding of science Further information: Funding of science  The Commonwealth Scientific and Industrial Research Organisation (CSIRO) Main Entomology Building in Australia Scientific research is often funded through a competitive process in which potential research projects are evaluated and only the most promising receive funding. Such processes, which are run by government, corporations, or foundations, allocate scarce funds. Total research funding in most developed countries is between 1.5% and 3% of GDP.[196] In the OECD, around two-thirds of research and development in scientific and technical fields is carried out by industry, and 20% and 10% respectively by universities and government. The government funding proportion in certain industries is higher, and it dominates research in social science and humanities. Similarly, with some exceptions (e.g. biotechnology) government provides the bulk of the funds for basic scientific research. Many governments have dedicated agencies to support scientific research. Prominent scientific organizations include the National Science Foundation in the United States, the National Scientific and Technical Research Council in Argentina, Commonwealth Scientific and Industrial Research Organisation (CSIRO) in Australia, Centre national de la recherche scientifique in France, the Max Planck Society and Deutsche Forschungsgemeinschaft in Germany, and CSIC in Spain. In commercial research and development, all but the most research-oriented corporations focus more heavily on near-term commercialisation possibilities rather than "blue-sky" ideas or technologies (such as nuclear fusion).  Public awareness of science Further information: Public awareness of science, Science outreach, and Science communication  Dinosaur exhibit in the Houston Museum of Natural Science The public awareness of science relates to the attitudes, behaviors, opinions, and activities that make up the relations between science and the general public. It integrates various themes and activities such as science communication, science museums, science festivals, science fairs, citizen science, and science in popular culture. Social scientists have devised various metrics to measure the public understanding of science such as factual knowledge, self-reported knowledge, and structural knowledge.[197][198]  Science journalism Further information: Science journalism The mass media face a number of pressures that can prevent them from accurately depicting competing scientific claims in terms of their credibility within the scientific community as a whole. Determining how much weight to give different sides in a scientific debate may require considerable expertise regarding the matter.[199] Few journalists have real scientific knowledge, and even beat reporters who know a great deal about certain scientific issues may be ignorant about other scientific issues that they are suddenly asked to cover.[200][201]  Politicization of science Further information: Politicization of science  Academic studies of scientific agreement on human-caused global warming among climate experts (2010-2015) reflect that the level of consensus correlates with expertise in climate science.[202] A 2019 study found scientific consensus to be at 100%.[203] Results stand in contrast to the political controversy over this issue, particularly in the United States. Politicization of science occurs when government, business, or advocacy groups use legal or economic pressure to influence the findings of scientific research or the way it is disseminated, reported, or interpreted. Many factors can act as facets of the politicization of science such as populist anti-intellectualism, perceived threats to religious beliefs, postmodernist subjectivism, and fear for business interests.[204] Politicization of science is usually accomplished when scientific information is presented in a way that emphasizes the uncertainty associated with the scientific evidence.[205] Tactics such as shifting conversation, failing to acknowledge facts, and capitalizing on doubt of scientific consensus have been used to gain more attention for views that have been undermined by scientific evidence.[206] Examples of issues that have involved the politicization of science include the global warming controversy, health effects of pesticides, and health effects of tobacco.[206][207]  See also Antiquarian science books Antiscience Criticism of science Index of branches of science List of scientific occupations Normative science Outline of science Pathological science Protoscience Science in popular culture Science wars Scientific dissent Scientism Sociology of scientific knowledge Wissenschaft – all areas of scholarly study Notes  Alhacen had access to the optics books of Euclid and Ptolemy, as is shown by the title of his lost work A Book in which I have Summarized the Science of Optics from the Two Books of Euclid and Ptolemy, to which I have added the Notions of the First Discourse which is Missing from Ptolemy's Book From Ibn Abi Usaibia's catalog, as cited in (Smith 2001): 91(vol .1), p. xv   "[Ibn al-Haytham] followed Ptolemy's bridge building ... into a grand synthesis of light and vision. Part of his effort consisted in devising ranges of experiments, of a kind probed before but now undertaken on larger scale."— Cohen 2010, p. 59  The translator, Gerard of Cremona (c. 1114–1187), inspired by his love of the Almagest, came to Toledo, where he knew he could find the Almagest in Arabic. There he found Arabic books of every description, and learned Arabic in order to translate these books into Latin, being aware of 'the poverty of the Latins'. —As cited by Burnett, Charles (2002). "The Coherence of the Arabic-Latin Translation Program in Toledo in the Twelfth Century" (PDF). Science in Context. 14 (1–2): 249–88. doi:10.1017/S0269889701000096. S2CID 143006568. Archived from the original (PDF) on February 10, 2020.  Kepler, Johannes (1604) Ad Vitellionem paralipomena, quibus astronomiae pars opticae traditur (Supplements to Witelo, in which the optical part of astronomy is treated) as cited in Smith, A. Mark (January 1, 2004). "What Is the History of Medieval Optics Really about?". Proceedings of the American Philosophical Society. 148 (2): 180–94. JSTOR 1558283. PMID 15338543. The full title translation is from p. 60 of James R. Voelkel (2001) Johannes Kepler and the New Astronomy Oxford University Press. Kepler was driven to this experiment after observing the partial solar eclipse at Graz, July 10, 1600. He used Tycho Brahe's method of observation, which was to project the image of the Sun on a piece of paper through a pinhole aperture, instead of looking directly at the Sun. He disagreed with Brahe's conclusion that total eclipses of the Sun were impossible because there were historical accounts of total eclipses. Instead, he deduced that the size of the aperture controls the sharpness of the projected image (the larger the aperture, the more accurate the image – this fact is now fundamental for optical system design). Voelkel, p. 61, notes that Kepler's experiments produced the first correct account of vision and the eye because he realized he could not accurately write about astronomical observation by ignoring the eye.  di Francia 1976, pp. 4–5: "One learns in a laboratory; one learns how to make experiments only by experimenting, and one learns how to work with his hands only by using them. The first and fundamental form of experimentation in physics is to teach young people to work with their hands. Then they should be taken into a laboratory and taught to work with measuring instruments – each student carrying out real experiments in physics. This form of teaching is indispensable and cannot be read in a book."  Fara 2009, p. 204: "Whatever their discipline, scientists claimed to share a common scientific method that ... distinguished them from non-scientists."  This realization is the topic of intersubjective verifiability, as recounted, for example, by Max Born (1949, 1965) Natural Philosophy of Cause and Chance, who points out that all knowledge, including natural or social science, is also subjective. p. 162: "Thus it dawned upon me that fundamentally everything is subjective, everything without exception. That was a shock."  In his investigation of the law of falling bodies, Galileo (1638) serves as an example for scientific investigation: Two New Sciences "A piece of wooden moulding or scantling, about 12 cubits long, half a cubit wide, and three finger-breadths thick, was taken; on its edge was cut a channel a little more than one finger in breadth; having made this groove very straight, smooth, and polished, and having lined it with parchment, also as smooth and polished as possible, we rolled along it a hard, smooth, and very round bronze ball. Having placed this board in a sloping position, by lifting one end some one or two cubits above the other, we rolled the ball, as I was just saying, along the channel, noting, in a manner presently to be described, the time required to make the descent. We ... now rolled the ball only one-quarter the length of the channel; and having measured the time of its descent, we found it precisely one-half of the former. Next, we tried other distances, comparing the time for the whole length with that for the half, or with that for two-thirds, or three-fourths, or indeed for any fraction; in such experiments, repeated many, many, times." Galileo solved the problem of time measurement by weighing a jet of water collected during the descent of the bronze ball, as stated in his Two New Sciences.  credits Willard Van Orman Quine (1969) "Epistemology Naturalized" Ontological Relativity and Other Essays New York: Columbia University Press, as well as John Dewey, with the basic ideas of naturalism – Naturalized Epistemology, but Godfrey-Smith diverges from Quine's position: according to Godfrey-Smith, "A naturalist can think that science can contribute to answers to philosophical questions, without thinking that philosophical questions can be replaced by science questions.".  "No amount of experimentation can ever prove me right; a single experiment can prove me wrong." —Albert Einstein, noted by Alice Calaprice (ed. 2005) The New Quotable Einstein Princeton University Press and Hebrew University of Jerusalem, ISBN 978-0-691-12074-4 p. 291. Calaprice denotes this not as an exact quotation, but as a paraphrase of a translation of A. Einstein's "Induction and Deduction". Collected Papers of Albert Einstein 7 Document 28. Volume 7 is The Berlin Years: Writings, 1918–1921. A. Einstein; M. Janssen, R. Schulmann, et al., eds.  Fleck, Ludwik (1979). Trenn, Thaddeus J.; Merton, Robert K (eds.). Genesis and Development of a Scientific Fact. Chicago: University of Chicago Press. ISBN 978-0-226-25325-1. Claims that before a specific fact "existed", it had to be created as part of a social agreement within a community. Steven Shapin (1980) "A view of scientific thought" Science ccvii (Mar 7, 1980) 1065–66 states "[To Fleck,] facts are invented, not discovered. Moreover, the appearance of scientific facts as discovered things is itself a social construction: a made thing. "  Evicting Einstein, March 26, 2004, NASA. "Both [relativity and quantum mechanics] are extremely successful. The Global Positioning System (GPS), for instance, wouldn't be possible without the theory of relativity. Computers, telecommunications, and the Internet, meanwhile, are spin-offs of quantum mechanics."  "Pseudoscientific – pretending to be scientific, falsely represented as being scientific", from the Oxford American Dictionary, published by the Oxford English Dictionary; Hansson, Sven Ove (1996)."Defining Pseudoscience", Philosophia Naturalis, 33: 169–76, as cited in "Science and Pseudo-science" (2008) in Stanford Encyclopedia of Philosophy. The Stanford article states: "Many writers on pseudoscience have emphasized that pseudoscience is non-science posing as science. The foremost modern classic on the subject (Gardner 1957) bears the title Fads and Fallacies in the Name of Science. According to Brian Baigrie (1988, 438), "[w]hat is objectionable about these beliefs is that they masquerade as genuinely scientific ones." These and many other authors assume that to be pseudoscientific, an activity or a teaching has to satisfy the following two criteria (Hansson 1996): (1) it is not scientific, and (2) its major proponents try to create the impression that it is scientific". For example, Hewitt et al. Conceptual Physical Science Addison Wesley; 3 edition (July 18, 2003) ISBN 978-0-321-05173-8, Bennett et al. The Cosmic Perspective 3e Addison Wesley; 3 edition (July 25, 2003) ISBN 978-0-8053-8738-4; See also, e.g., Gauch HG Jr. Scientific Method in Practice (2003). A 2006 National Science Foundation report on Science and engineering indicators quoted Michael Shermer's (1997) definition of pseudoscience: '"claims presented so that they appear [to be] scientific even though they lack supporting evidence and plausibility" (p. 33). In contrast, science is "a set of methods designed to describe and interpret observed and inferred phenomena, past or present, and aimed at building a testable body of knowledge open to rejection or confirmation" (p. 17)'.Shermer M. (1997). Why People Believe Weird Things: Pseudoscience, Superstition, and Other Confusions of Our Time. New York: W. H. Freeman and Company. ISBN 978-0-7167-3090-3. as cited by National Science Board. National Science Foundation, Division of Science Resources Statistics (2006). "Science and Technology: Public Attitudes and Understanding". Science and engineering indicators 2006. Archived from the original on February 1, 2013. "A pretended or spurious science; a collection of related beliefs about the world mistakenly regarded as being based on scientific method or as having the status that scientific truths now have," from the Oxford English Dictionary, second edition 1989.  Women in science have included: Hypatia (c. 350–415 CE), of the Library of Alexandria. Trotula of Salerno, a physician c. 1060 CE. Caroline Herschel, one of the first professional astronomers of the 18th and 19th centuries. Christine Ladd-Franklin, a doctoral student of C.S. Peirce, who published Wittgenstein's proposition 5.101 in her dissertation, 40 years before Wittgenstein's publication of Tractatus Logico-Philosophicus. Henrietta Leavitt, a professional human computer and astronomer, who first published the significant relationship between the luminosity of Cepheid variable stars and their distance from Earth. This allowed Hubble to make the discovery of the expanding universe, which led to the Big Bang theory. Emmy Noether, who proved the conservation of energy and other constants of motion in 1915. Marie Curie, who made discoveries relating to radioactivity along with her husband, and for whom Curium is named. Rosalind Franklin, who worked with X-ray diffraction. Jocelyn Bell Burnell, at first not allowed to study science in her preparatory school, persisted, and was the first to observe and precisely analyse the radio pulsars, for which her supervisor was recognized by the 1974 Nobel prize in Physics. (Later awarded a Special Breakthrough Prize in Physics in 2018, she donated the cash award in order that women, ethnic minority, and refugee students might become physics researchers.) In 2018 Donna Strickland became the third woman (the second being Maria Goeppert-Mayer in 1962) to be awarded the Nobel Prize in Physics, for her work in chirped pulse amplification of lasers. Frances H. Arnold became the fifth woman to be awarded the Nobel Prize in Chemistry for the directed evolution of enzymes. See the project of Jess Wade (Christina Zdanowicz (27 July 2018), CNN A physicist is writing one Wikipedia entry a day to recognize women in science )  Nina Byers, Contributions of 20th Century Women to Physics which provides details on 83 female physicists of the 20th century. By 1976, more women were physicists, and the 83 who were detailed were joined by other women in noticeably larger numbers. References  Harper, Douglas. "science". Online Etymology Dictionary. Retrieved September 20, 2014.  Wilson, E.O. (1999). "The natural sciences". Consilience: The Unity of Knowledge (Reprint ed.). New York, New York: Vintage. pp. 49–71. ISBN 978-0-679-76867-8.  "... modern science is a discovery as well as an invention. It was a discovery that nature generally acts regularly enough to be described by laws and even by mathematics; and required invention to devise the techniques, abstractions, apparatus, and organization for exhibiting the regularities and securing their law-like descriptions."— p.vii Heilbron, J.L. (editor-in-chief) (2003). "Preface". The Oxford Companion to the History of Modern Science. New York: Oxford University Press. pp. vii–X. ISBN 978-0-19-511229-0.  "science". Merriam-Webster Online Dictionary. Merriam-Webster, Inc. Archived from the original on September 1, 2019. Retrieved October 16, 2011. 3 a: knowledge or a system of knowledge covering general truths or the operation of general laws especially as obtained and tested through scientific method b: such knowledge or such a system of knowledge concerned with the physical world and its phenomena.  "The historian ... requires a very broad definition of "science" – one that ... will help us to understand the modern scientific enterprise. We need to be broad and inclusive, rather than narrow and exclusive ... and we should expect that the farther back we go [in time] the broader we will need to be."  p.3—Lindberg, David C. (2007). "Science before the Greeks". The beginnings of Western science: the European Scientific tradition in philosophical, religious, and institutional context (Second ed.). Chicago, Illinois: University of Chicago Press. pp. 1–20. ISBN 978-0-226-48205-7.  Grant, Edward (2007). "Ancient Egypt to Plato". A History of Natural Philosophy: From the Ancient World to the Nineteenth Century (First ed.). New York, New York: Cambridge University Press. pp. 1–26. ISBN 978-052-1-68957-1.  Lindberg, David C. (2007). "The revival of learning in the West". The beginnings of Western science: the European Scientific tradition in philosophical, religious, and institutional context (Second ed.). Chicago, Illinois: University of Chicago Press. pp. 193–224. ISBN 978-0-226-48205-7.  Lindberg, David C. (2007). "Islamic science". The beginnings of Western science: the European Scientific tradition in philosophical, religious, and institutional context (Second ed.). Chicago, Illinois: University of Chicago Press. pp. 163–92. ISBN 978-0-226-48205-7.  Lindberg, David C. (2007). "The recovery and assimilation of Greek and Islamic science". The beginnings of Western science: the European Scientific tradition in philosophical, religious, and institutional context (2nd ed.). Chicago, Illinois: University of Chicago Press. pp. 225–53. ISBN 978-0-226-48205-7.  Principe, Lawrence M. (2011). "Introduction". Scientific Revolution: A Very Short Introduction (First ed.). New York, New York: Oxford University Press. pp. 1–3. ISBN 978-0-199-56741-6.  Lindberg, David C. (1990). "Conceptions of the Scientific Revolution from Baker to Butterfield: A preliminary sketch". In Lindberg, David C.; Westman, Robert S. (eds.). Reappraisals of the Scientific Revolution (First ed.). Chicago, Illinois: Cambridge University Press. pp. 1–26. ISBN 978-0-521-34262-9.  Lindberg, David C. (2007). "The legacy of ancient and medieval science". The beginnings of Western science: the European Scientific tradition in philosophical, religious, and institutional context (2nd ed.). Chicago, Illinois: University of Chicago Press. pp. 357–368. ISBN 978-0-226-48205-7.  Del Soldato, Eva (2016). Zalta, Edward N. (ed.). The Stanford Encyclopedia of Philosophy (Fall 2016 ed.). Metaphysics Research Lab, Stanford University. Archived from the original on December 11, 2019. Retrieved June 1, 2018.  Grant, Edward (2007). "Transformation of medieval natural philosophy from the early period modern period to the end of the nineteenth century". A History of Natural Philosophy: From the Ancient World to the Nineteenth Century (First ed.). New York, New York: Cambridge University Press. pp. 274–322. ISBN 978-052-1-68957-1.  Cahan, David, ed. (2003). From Natural Philosophy to the Sciences: Writing the History of Nineteenth-Century Science. Chicago, Illinois: University of Chicago Press. ISBN 978-0-226-08928-7.  The Oxford English Dictionary dates the origin of the word "scientist" to 1834.  Lightman, Bernard (2011). "13. Science and the Public". In Shank, Michael; Numbers, Ronald; Harrison, Peter (eds.). Wrestling with Nature : From Omens to Science. Chicago: University of Chicago Press. p. 367. ISBN 978-0-226-31783-0.  Harrison, Peter (2015). The Territories of Science and Religion. Chicago: University of Chicago Press. pp. 164–165. ISBN 978-0-226-18451-7. The changing character of those engaged in scientific endeavors was matched by a new nomenclature for their endeavors. The most conspicuous marker of this change was the replacement of "natural philosophy" by "natural science". In 1800 few had spoken of the "natural sciences" but by 1880, this expression had overtaken the traditional label "natural philosophy". The persistence of "natural philosophy" in the twentieth century is owing largely to historical references to a past practice (see figure 11). As should now be apparent, this was not simply the substitution of one term by another, but involved the jettisoning of a range of personal qualities relating to the conduct of philosophy and the living of the philosophical life.  Cohen, Eliel (2021). "The boundary lens: theorising academic actitity". The University and its Boundaries: Thriving or Surviving in the 21st Century 1st Edition. New York, New York: Routledge. pp. 14–41. ISBN 978-0367562984.  Colander, David C.; Hunt, Elgin F. (2019). "Social science and its methods". Social Science: An Introduction to the Study of Society (17th ed.). New York, NY: Routledge. pp. 1–22.  Nisbet, Robert A.; Greenfeld, Liah (October 16, 2020). "Social Science". Encyclopedia Britannica. Encyclopædia Britannica, Inc. Retrieved May 9, 2021.  Löwe, Benedikt (2002). "The formal sciences: their scope, their foundations, and their unity". Synthese. 133 (1/2): 5–11. doi:10.1023/A:1020887832028. S2CID 9272212.  Rucker, Rudy (2019). "Robots and souls". Infinity and the Mind: The Science and Philosophy of the Infinite (Reprint ed.). Princeton, New Jersey: Princeton University Press. pp. 157–188. ISBN 978-0691191386.  Bishop, Alan (1991). "Environmental activities and mathematical culture". Mathematical Enculturation: A Cultural Perspective on Mathematics Education. Norwell, Massachusetts: Kluwer Academic Publishers. pp. 20–59. ISBN 978-0-792-31270-3. Archived from the original on December 25, 2020. Retrieved March 24, 2018.  Nickles, Thomas (2013). "The Problem of Demarcation". Philosophy of Pseudoscience: Reconsidering the Demarcation Problem. Chicago: The University of Chicago Press. p. 104.  Bunge, Mario (1998). "The Scientific Approach". Philosophy of Science: Volume 1, From Problem to Theory. 1 (revised ed.). New York, New York: Routledge. pp. 3–50. ISBN 978-0-765-80413-6.  Fetzer, James H. (2013). "Computer reliability and public policy: Limits of knowledge of computer-based systems". Computers and Cognition: Why Minds are not Machines (1st ed.). Newcastle, United Kingdom: Kluwer Academic Publishers. pp. 271–308. ISBN 978-1-443-81946-6.  Fischer, M.R.; Fabry, G (2014). "Thinking and acting scientifically: Indispensable basis of medical education". GMS Zeitschrift für Medizinische Ausbildung. 31 (2): Doc24. doi:10.3205/zma000916. PMC 4027809. PMID 24872859.  Abraham, Reem Rachel (2004). "Clinically oriented physiology teaching: strategy for developing critical-thinking skills in undergraduate medical students". Advances in Physiology Education. 28 (3): 102–04. doi:10.1152/advan.00001.2004. PMID 15319191. S2CID 21610124. Archived from the original on January 22, 2020. Retrieved December 4, 2019.  Sinclair, Marius (1993). "On the Differences between the Engineering and Scientific Methods". The International Journal of Engineering Education. Archived from the original on November 15, 2017. Retrieved September 7, 2018.  "About Engineering Technology". Purdue School of Engineering & Technology. Archived from the original on May 22, 2019. Retrieved September 7, 2018.  Bunge, M (1966). "Technology as applied science". In Rapp, F. (ed.). Contributions to a Philosophy of Technology. Theory and Decision Library (An International Series in the Philosophy and Methodology of the Social and Behavioral Sciences). Dordrecht, Netherlands: Springer. pp. 19–39. doi:10.1007/978-94-010-2182-1_2. ISBN 978-94-010-2184-5. Archived from the original on March 31, 2021. Retrieved March 25, 2021.  MacRitchie, Finlay (2011). "Introduction". Scientific Research as a Career (1st ed.). New York, New York: Routledge. pp. 1–6. ISBN 9781439869659.  Marder, Michael P. (2011). "Curiosity and research". Research Methods for Science (1st ed.). New York, New York: Cambridge University Press. pp. 1–17. ISBN 978-0521145848.  de Ridder, Jeroen (2020). "How many scientists does it take to have knowledge?". In McCain, Kevin; Kampourakis, Kostas (eds.). What is Scientific Knowledge? An Introduction to Contemporary Epistemology of Science (1st ed.). New York, New York: Routledge. pp. 3–17. ISBN 9781138570160.  Lindberg, David C. (2007). "Islamic science". The beginnings of Western science: the European Scientific tradition in philosophical, religious, and institutional context (Second ed.). Chicago, Illinois: University of Chicago Press. pp. 163–192. ISBN 978-0-226-48205-7.  Szycher, Michael (2016). "Establishing your dream team". Commercialization Secrets for Scientists and Engineers (1st ed.). New York, New York: Routledge. pp. 159–176. ISBN 978-1138407411.  Grant, Edward (January 1, 1997). "History of Science: When Did Modern Science Begin?". The American Scholar. 66 (1): 105–113. JSTOR 41212592.  Pingree, David (December 1992). "Hellenophilia versus the History of Science". Isis. 83 (4): 554–63. Bibcode:1992Isis...83..554P. doi:10.1086/356288. JSTOR 234257. S2CID 68570164.  Sima Qian (司馬遷, d. 86 BCE) in his Records of the Grand Historian (太史公書) covering some 2500 years of Chinese history, records Sunshu Ao (孫叔敖, fl. c. 630–595 BCE – Zhou dynasty), the first known hydraulic engineer of China, cited in (Joseph Needham et al. (1971) Science and Civilisation in China 4.3 p. 271) as having built a reservoir which has lasted to this day.  Rochberg, Francesca (2011). "Ch.1 Natural Knowledge in Ancient Mesopotamia". In Shank, Michael; Numbers, Ronald; Harrison, Peter (eds.). Wrestling with Nature : From Omens to Science. Chicago: University of Chicago Press. p. 9. ISBN 978-0-226-31783-0.  McIntosh, Jane R. (2005). Ancient Mesopotamia: New Perspectives. Santa Barbara, California, Denver, Colorado, and Oxford, England: ABC-CLIO. pp. 273–76. ISBN 978-1-57607-966-9. Archived from the original on February 5, 2021. Retrieved October 20, 2020.  A. Aaboe (May 2, 1974). "Scientific Astronomy in Antiquity". Philosophical Transactions of the Royal Society. 276 (1257): 21–42. Bibcode:1974RSPTA.276...21A. doi:10.1098/rsta.1974.0007. JSTOR 74272. S2CID 122508567.  Biggs, R D. (2005). "Medicine, Surgery, and Public Health in Ancient Mesopotamia". Journal of Assyrian Academic Studies. 19 (1): 7–18.  Lehoux, Daryn (2011). "2. Natural Knowledge in the Classical World". In Shank, Michael; Numbers, Ronald; Harrison, Peter (eds.). Wrestling with Nature : From Omens to Science. Chicago: University of Chicago Press. p. 39. ISBN 978-0-226-31783-0.  See the quotation in Homer (8th century BCE) Odyssey 10.302–03  "Progress or Return" in An Introduction to Political Philosophy: Ten Essays by Leo Strauss (Expanded version of Political Philosophy: Six Essays by Leo Strauss, 1975.) Ed. Hilail Gilden. Detroit: Wayne State UP, 1989.  Cropsey; Strauss (eds.). History of Political Philosophy (3rd ed.). p. 209.  Van Norden, Bryan W. "The Geocentric Paradigm". vassar. Retrieved March 31, 2021.  O'Grady, Patricia F. (2016). Thales of Miletus: The Beginnings of Western Science and Philosophy. New York City, New York and London, England: Routledge. p. 245. ISBN 978-0-7546-0533-1. Archived from the original on March 31, 2021. Retrieved October 20, 2020.  Burkert, Walter (June 1, 1972). Lore and Science in Ancient Pythagoreanism. Cambridge, Massachusetts: Harvard University Press. ISBN 978-0-674-53918-1. Archived from the original on January 29, 2018.  Pullman, Bernard (1998). The Atom in the History of Human Thought. pp. 31–33. Bibcode:1998ahht.book.....P. ISBN 978-0-19-515040-7. Archived from the original on February 5, 2021. Retrieved October 20, 2020.  Cohen, Henri; Lefebvre, Claire, eds. (2017). Handbook of Categorization in Cognitive Science (Second ed.). Amsterdam, The Netherlands: Elsevier. p. 427. ISBN 978-0-08-101107-2. Archived from the original on February 5, 2021. Retrieved October 20, 2020.  Margotta, Roberto (1968). The Story of Medicine. New York City, New York: Golden Press. Archived from the original on February 5, 2021. Retrieved November 18, 2020.  Touwaide, Alain (2005). Glick, Thomas F.; Livesey, Steven; Wallis, Faith (eds.). Medieval Science, Technology, and Medicine: An Encyclopedia. New York City, New York and London, England: Routledge. p. 224. ISBN 978-0-415-96930-7. Archived from the original on February 6, 2021. Retrieved October 20, 2020.  Leff, Samuel; Leff, Vera (1956). From Witchcraft to World Health. London, England: Macmillan. Archived from the original on February 5, 2021. Retrieved August 23, 2020.  "Plato, Apology". p. 17. Archived from the original on January 29, 2018. Retrieved November 1, 2017.  "Plato, Apology". p. 27. Archived from the original on January 29, 2018. Retrieved November 1, 2017.  "Plato, Apology, section 30". Perseus Digital Library. Tufts University. 1966. Archived from the original on January 27, 2017. Retrieved November 1, 2016.  Aristotle. Nicomachean Ethics (H. Rackham ed.). Archived from the original on March 17, 2012. Retrieved September 22, 2010. 1139b  McClellan III, James E.; Dorn, Harold (2015). Science and Technology in World History: An Introduction. Baltimore, Maryland: Johns Hopkins University Press. pp. 99–100. ISBN 978-1-4214-1776-9. Archived from the original on February 6, 2021. Retrieved October 20, 2020.  Edwards, C.H. Jr. (1979). The Historical Development of the Calculus (First ed.). New York City, New York: Springer-Verlag. p. 75. ISBN 978-0-387-94313-8. Archived from the original on February 5, 2021. Retrieved October 20, 2020.  Lawson, Russell M. (2004). Science in the Ancient World: An Encyclopedia. Santa Barbara, California: ABC-CLIO. pp. 190–91. ISBN 978-1-85109-539-1. Archived from the original on February 5, 2021. Retrieved October 20, 2020.  Murphy, Trevor Morgan (2004). Pliny the Elder's Natural History: The Empire in the Encyclopedia. Oxford, England: Oxford University Press. p. 1. ISBN 978-0-19-926288-5. Archived from the original on February 6, 2021. Retrieved October 20, 2020.  Doode, Aude (2010). Pliny's Encyclopedia: The Reception of the Natural History. Cambridge, England: Cambridge University Press. p. 1. ISBN 978-1-139-48453-4. Archived from the original on March 31, 2021. Retrieved October 20, 2020.  Smith, A. Mark (June 2004). "What is the History of Medieval Optics Really About?". Proceedings of the American Philosophical Society. 148 (2): 180–94. JSTOR 1558283. PMID 15338543.  Lindberg, David C. (2007). "Roman and early medieval science". The beginnings of Western science: the European Scientific tradition in philosophical, religious, and institutional context (Second ed.). Chicago, Illinois: University of Chicago Press. pp. 132–162. ISBN 978-0-226-48205-7.  Wildberg, Christian (May 1, 2018). Zalta, Edward N. (ed.). The Stanford Encyclopedia of Philosophy. Metaphysics Research Lab, Stanford University. Archived from the original on August 22, 2019. Retrieved May 1, 2018 – via Stanford Encyclopedia of Philosophy.  Falcon, Andrea (2019). "Aristotle on Causality". In Zalta, Edward (ed.). Stanford Encyclopedia of Philosophy (Spring 2019 ed.). Metaphysics Research Lab, Stanford University. Archived from the original on October 9, 2020. Retrieved October 3, 2020.  Grant, Edward (1996). The Foundations of Modern Science in the Middle Ages: Their Religious, Institutional and Intellectual Contexts. Cambridge Studies in the History of Science. Cambridge University Press. pp. 7–17. ISBN 978-0521567626. Archived from the original on August 21, 2019. Retrieved November 9, 2018.  Grant, Edward (2007). "Islam and the eastward shift of Aristotelian natural philosophy". A History of Natural Philosophy: From the Ancient World to the Nineteenth Century. Cambridge University Press. pp. 62–67. ISBN 978-0-521-68957-1.  Fisher, W.B. (William Bayne) (1968–1991). The Cambridge history of Iran. Cambridge: University Press. ISBN 978-0-521-20093-6. OCLC 745412.  "Bayt al-Hikmah". Encyclopædia Britannica. Archived from the original on November 4, 2016. Retrieved November 3, 2016.  Klein-Frank, F. Al-Kindi. In Leaman, O & Nasr, H (2001). History of Islamic Philosophy. London: Routledge. p. 165. Felix Klein-Frank (2001) Al-Kindi, pp. 166–67. In Oliver Leaman & Hossein Nasr. History of Islamic Philosophy. London: Routledge.  "Science in Islam". Oxford Dictionary of the Middle Ages. 2009.  Toomer, G.J. (1964). "Reviewed work: Ibn al-Haythams Weg zur Physik, Matthias Schramm". Isis. 55 (4): 463–65. doi:10.1086/349914. JSTOR 228328. See p. 464: "Schramm sums up [Ibn Al-Haytham's] achievement in the development of scientific method.", p. 465: "Schramm has demonstrated .. beyond any dispute that Ibn al-Haytham is a major figure in the Islamic scientific tradition, particularly in the creation of experimental techniques." p. 465: "only when the influence of ibn al-Haytam and others on the mainstream of later medieval physical writings has been seriously investigated can Schramm's claim that ibn al-Haytam was the true founder of modern physics be evaluated."  Smith 2001: Book I, [6.54]. p. 372   Selin, H (2006). Encyclopaedia of the History of Science, Technology, and Medicine in Non-Western Cultures. pp. 155–156. Bibcode:2008ehst.book.....S. ISBN 978-1-4020-4559-2.  Numbers, Ronald (2009). Galileo Goes to Jail and Other Myths about Science and Religion. Harvard University Press. p. 45. ISBN 978-0-674-03327-6. Archived from the original on January 20, 2021. Retrieved March 27, 2018.  Shwayder, Maya (April 7, 2011). "Debunking a myth". The Harvard Gazette. Archived from the original on July 28, 2019. Retrieved May 11, 2019.  Smith 2001  McGinnis, Jon (2010). The Canon of Medicine. Oxford University. p. 227.  Lindberg, David (1992). The Beginnings of Western Science. University of Chicago Press. p. 162. ISBN 978-0-226-48204-0.  "St. Albertus Magnus | German theologian, scientist, and philosopher". Archived from the original on October 28, 2017. Retrieved October 27, 2017.  Smith 2001: Book I   Smith, A. Mark (1981). "Getting the Big Picture in Perspectivist Optics". Isis. 72 (4): 568–89. doi:10.1086/352843. JSTOR 231249. PMID 7040292. S2CID 27806323.  Goldstein, Bernard R (2016). "Copernicus and the Origin of his Heliocentric System" (PDF). Journal for the History of Astronomy. 33 (3): 219–35. doi:10.1177/002182860203300301. S2CID 118351058. Archived (PDF) from the original on April 12, 2020. Retrieved April 12, 2020.  Cohen, H. Floris (2010). How modern science came into the world. Four civilizations, one 17th-century breakthrough (Second ed.). Amsterdam: Amsterdam University Press. ISBN 978-90-8964-239-4.  van Helden, Al (1995). "Pope Urban VIII". The Galileo Project. Archived from the original on November 11, 2016. Retrieved November 3, 2016.  "Gottfried Leibniz - Biography". Maths History. Archived from the original on July 11, 2017. Retrieved March 2, 2021.  Freudenthal, Gideon; McLaughlin, Peter (May 20, 2009). The Social and Economic Roots of the Scientific Revolution: Texts by Boris Hessen and Henryk Grossmann. Springer Science & Business Media. ISBN 978-1-4020-9604-4. Archived from the original on January 19, 2020. Retrieved July 25, 2018.  Thomas G. Bergin (ed.), Encyclopedia of the Renaissance (Oxford and New York: New Market Books, 1987).  see Hall (1954), iii; Mason (1956), 223.  Cassels, Alan. Ideology and International Relations in the Modern World. p. 2.  M. Magnusson (November 10, 2003), "Review of James Buchan, Capital of the Mind: how Edinburgh Changed the World", New Statesman, archived from the original on June 6, 2011, retrieved April 27, 2014  Swingewood, Alan (1970). "Origins of Sociology: The Case of the Scottish Enlightenment". The British Journal of Sociology. 21 (2): 164–180. doi:10.2307/588406. JSTOR 588406.  M. Fry, Adam Smith's Legacy: His Place in the Development of Modern Economics (Routledge, 1992).  Ross, Sydney (1962). "Scientist: The story of a word" (PDF). Annals of Science. 18 (2): 65–85. doi:10.1080/00033796200202722. Retrieved March 8, 2011. To be exact, the person who coined the term scientist was referred to in Whewell 1834 only as "some ingenious gentleman." Ross added a comment that this "some ingenious gentleman" was Whewell himself, without giving the reason for the identification. Ross 1962, p. 72.  Padian, Kevin (2008). "Darwin's enduring legacy". Nature. 451 (7179): 632–634. Bibcode:2008Natur.451..632P. doi:10.1038/451632a. PMID 18256649.  Henig (2000). Op. cit. pp. 134–138.  Miko, Ilona (2008). "Gregor Mendel's principles of inheritance form the cornerstone of modern genetics. So just what are they?". Nature Education. 1 (1): 134.  Leahey, Thomas Hardy (2018). "The psychology of consciousness". A History of Psychology: From Antiquity to Modernity (8th ed.). New York, NY: Routledge. pp. 219–253. ISBN 978-1138652422.  Futuyma & Kirkpatrick 2017, pp. 3–26, Chapter 1: Evolutionary Biology  von Bertalanffy, Ludwig (1972). "The History and Status of General Systems Theory". The Academy of Management Journal. 15 (4): 407–26. doi:10.2307/255139. JSTOR 255139.  Naidoo, Nasheen; Pawitan, Yudi; Soong, Richie; Cooper, David N.; Ku, Chee-Seng (October 2011). "Human genetics and genomics a decade after the release of the draft sequence of the human genome". Human Genomics. 5 (6): 577–622. doi:10.1186/1479-7364-5-6-577. PMC 3525251. PMID 22155605.  Rashid, S. Tamir; Alexander, Graeme J.M. (March 2013). "Induced pluripotent stem cells: from Nobel Prizes to clinical applications". Journal of Hepatology. 58 (3): 625–629. doi:10.1016/j.jhep.2012.10.026. ISSN 1600-0641. PMID 23131523.  Abbott, B.P.; Abbott, R.; Abbott, T.D.; Acernese, F.; Ackley, K.; Adams, C.; Adams, T.; Addesso, P.; Adhikari, R.X.; Adya, V.B.; Affeldt, C.; Afrough, M.; Agarwal, B.; Agathos, M.; Agatsuma, K.; Aggarwal, N.; Aguiar, O.D.; Aiello, L.; Ain, A.; Ajith, P.; Allen, B.; Allen, G.; Allocca, A.; Altin, P.A.; Amato, A.; Ananyeva, A.; Anderson, S.B.; Anderson, W.G.; Angelova, S.V.; et al. (2017). "Multi-messenger Observations of a Binary Neutron Star Merger". The Astrophysical Journal. 848 (2): L12. arXiv:1710.05833. Bibcode:2017ApJ...848L..12A. doi:10.3847/2041-8213/aa91c9. S2CID 217162243.  Cho, Adrian (2017). "Merging neutron stars generate gravitational waves and a celestial light show". Science. doi:10.1126/science.aar2149.  "Media Advisory: First Results from the Event Horizon Telescope to be Presented on April 10th | Event Horizon Telescope". April 20, 2019. Archived from the original on April 20, 2019. Retrieved September 21, 2021.  "Astronomers Capture First Image of a Black Hole | ESO". May 20, 2019. Archived from the original on May 20, 2019. Retrieved September 21, 2021.  "Scientific Method: Relationships Among Scientific Paradigms". Seed Magazine. March 7, 2007. Archived from the original on November 1, 2016. Retrieved November 4, 2016.  Bunge, Mario Augusto (1998). Philosophy of Science: From Problem to Theory. Transaction Publishers. p. 24. ISBN 978-0-7658-0413-6.  Popper, Karl R. (2002a) [1959]. "A survey of some fundamental problems". The Logic of Scientific Discovery. New York, New York: Routledge Classics. pp. 3–26. ISBN 978-0-415-27844-7. OCLC 59377149.  Gauch Jr., Hugh G. (2003). "Science in perspective". Scientific Method in Practice. Cambridge, United Kingdom: Cambridge University Press. pp. 21–73. ISBN 978-0-52-101708-4. Archived from the original on December 25, 2020. Retrieved September 3, 2018.  Oglivie, Brian W. (2008). "Introduction". The Science of Describing: Natural History in Renaissance Europe (Paperback ed.). Chicago, Illinois: University of Chicago Press. pp. 1–24. ISBN 978-0-226-62088-6.  "Natural History". Princeton University WordNet. Archived from the original on March 3, 2012. Retrieved October 21, 2012.  "Formal Sciences: Washington and Lee University". Washington and Lee University. Retrieved May 14, 2021. A "formal science" is an area of study that uses formal systems to generate knowledge such as in Mathematics and Computer Science. Formal sciences are important subjects because all of quantitative science depends on them.  Tomalin, Marcus (2006). Linguistics and the Formal Sciences. doi:10.2277/0521854814.  Löwe, Benedikt (2002). "The Formal Sciences: Their Scope, Their Foundations, and Their Unity". Synthese. 133: 5–11. doi:10.1023/a:1020887832028. S2CID 9272212.  Bill, Thompson (2007). "2.4 Formal Science and Applied Mathematics". The Nature of Statistical Evidence. Lecture Notes in Statistics. 189 (1st ed.). Springer. p. 15.  Mujumdar, Anshu Gupta; Singh, Tejinder (2016). "Cognitive science and the connection between physics and mathematics". In Aguirre, Anthony; Foster, Brendan (eds.). Trick or Truth?: The Mysterious Connection Between Physics and Mathematics. The Frontiers Collection (1st ed.). Switzerland: SpringerNature. pp. 201–218. ISBN 978-3-319-27494-2.  "Cambridge Dictionary". Cambridge University Press. Archived from the original on August 19, 2019. Retrieved March 25, 2021.  Panda SC (January 2006). "Medicine: science or art?". Mens Sana Monogr. 4 (1): 127–38. doi:10.4103/0973-1229.27610. PMC 3190445. PMID 22013337.  Firth, John (2020). "Science in medicine: when, how, and what". Oxford textbook of medicine. Oxford: Oxford University Press. ISBN 978-0198746690.  Saunders J (June 2000). "The practice of clinical medicine as an art and as a science". Med Humanit. 26 (1): 18–22. doi:10.1136/mh.26.1.18. PMID 12484313. S2CID 73306806.  "Dictionary, medicine". Archived from the original on March 4, 2016. Retrieved December 2, 2013.  Dawkins, Richard (May 10, 2006). "To Live at All Is Miracle Enough". RichardDawkins.net. Archived from the original on January 19, 2012. Retrieved February 5, 2012.  Stanovich, Keith E. (2007). How to Think Straight About Psychology. Boston: Pearson Education. pp. 106–147. ISBN 978-0-205-68590-5.  Mitchell, Jacqueline S. (February 18, 2003). "The Origins of Science". Scientific American Frontiers. PBS. Archived from the original on March 3, 2003. Retrieved November 3, 2016.  "The amazing point is that for the first time since the discovery of mathematics, a method has been introduced, the results of which have an intersubjective value!" (Author's punctuation) —di Francia, Giuliano Toraldo (1976). "The method of physics". The Investigation of the Physical World. Cambridge, United Kingdom: Cambridge University Press. pp. 1–52. ISBN 978-0-521-29925-1.  Wilson, Edward (1999). Consilience: The Unity of Knowledge. New York: Vintage. ISBN 978-0-679-76867-8.  Fara, Patricia (2009). "Decisions". Science: A Four Thousand Year History. Oxford, United Kingdom: Oxford University Press. p. 408. ISBN 978-0-19-922689-4.  Nola, Robert; Irzik, Gürol (2005k). "naive inductivism as a methodology in science". Philosophy, science, education and culture. Science & technology education library. 28. Springer. pp. 207–230. ISBN 978-1-4020-3769-6.  Nola, Robert; Irzik, Gürol (2005j). "The aims of science and critical inquiry". Philosophy, science, education and culture. Science & technology education library. 28. Springer. pp. 207–230. ISBN 978-1-4020-3769-6.  van Gelder, Tim (1999). ""Heads I win, tails you lose": A Foray Into the Psychology of Philosophy" (PDF). University of Melbourne. Archived from the original (PDF) on April 9, 2008. Retrieved March 28, 2008.  Pease, Craig (September 6, 2006). "Chapter 23. Deliberate bias: Conflict creates bad science". Science for Business, Law and Journalism. Vermont Law School. Archived from the original on June 19, 2010.  Shatz, David (2004). Peer Review: A Critical Inquiry. Rowman & Littlefield. ISBN 978-0-7425-1434-8. OCLC 54989960.  Krimsky, Sheldon (2003). Science in the Private Interest: Has the Lure of Profits Corrupted the Virtue of Biomedical Research. Rowman & Littlefield. ISBN 978-0-7425-1479-9. OCLC 185926306.  Bulger, Ruth Ellen; Heitman, Elizabeth; Reiser, Stanley Joel (2002). The Ethical Dimensions of the Biological and Health Sciences (2nd ed.). Cambridge University Press. ISBN 978-0-521-00886-0. OCLC 47791316.  Backer, Patricia Ryaby (October 29, 2004). "What is the scientific method?". San Jose State University. Archived from the original on April 8, 2008. Retrieved March 28, 2008.  Ziman, John (1978c). "Common observation". Reliable knowledge: An exploration of the grounds for belief in science. Cambridge: Cambridge University Press. pp. 42–76. ISBN 978-0-521-22087-3.  Ziman, John (1978c). "The stuff of reality". Reliable knowledge: An exploration of the grounds for belief in science. Cambridge: Cambridge University Press. pp. 95–123. ISBN 978-0-521-22087-3.  Popper, Karl R. (2002e) [1959]. "The problem of the empirical basis". The Logic of Scientific Discovery. New York, New York: Routledge Classics. pp. 3–26. ISBN 978-0-415-27844-7. OCLC 59377149.  "SIAM: Graduate Education for Computational Science and Engineering". Society for Industrial and Applied Mathematics. Archived from the original on December 28, 2016. Retrieved November 4, 2016.  Breznau, Nate (2021). "Integrating Computer Prediction Methods in Social Science: A Comment on Hofman et al. (2021)". Social Science Computer Review. in–press – via SocArXiv.  Hofman, Jake M.; Watts, Duncan J.; Athey, Susan; Garip, Filiz; Griffiths, Thomas L.; Kleinberg, Jon; Margetts, Helen; Mullainathan, Sendhil; Salganik, Matthew J.; Vazire, Simine; Vespignani, Alessandro (July 2021). "Integrating explanation and prediction in computational social science". Nature. 595 (7866): 181–188. Bibcode:2021Natur.595..181H. doi:10.1038/s41586-021-03659-0. ISSN 1476-4687. PMID 34194044. S2CID 235697917.  McKay, Stephen (January 1, 2019). "When 4 ≈ 10,000: The Power of Social Science Knowledge in Predictive Performance". Socius. 5: 2378023118811774. doi:10.1177/2378023118811774. ISSN 2378-0231. S2CID 131892827.  Bender, Emily M.; Gebru, Timnit; McMillan-Major, Angelina; Shmitchell, Shmargaret (March 3, 2021). "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜". Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency. FAccT '21. New York, NY, USA: Association for Computing Machinery: 610–623. doi:10.1145/3442188.3445922. ISBN 978-1-4503-8309-7.  Godfrey-Smith, Peter (2003c). "Induction and confirmation". Theory and Reality: An Introduction to the Philosophy of Science (1st ed.). Chicago, Illinois: University of Chicago. pp. 39–56. ISBN 978-0-226-30062-7.  Godfrey-Smith, Peter (2003o). "Empiricism, naturalism, and scientific realism?". Theory and Reality: An Introduction to the Philosophy of Science (1st ed.). Chicago, Illinois: University of Chicago. pp. 219–232. ISBN 978-0-226-30062-7.  Godfrey-Smith, Peter (2003b). "Logic plus empiricism". Theory and Reality: An Introduction to the Philosophy of Science (1st ed.). Chicago, Illinois: University of Chicago. pp. 19–38. ISBN 978-0-226-30062-7.  Godfrey-Smith, Peter (2003d). "Popper: Conjecture and refutation". Theory and Reality: An Introduction to the Philosophy of Science (1st ed.). Chicago, Illinois: University of Chicago. pp. 57–74. ISBN 978-0-226-30062-7.  Godfrey-Smith, Peter (2003g). "Lakatos, Laudan, Feyerabend, and frameworks". Theory and Reality: An Introduction to the Philosophy of Science (1st ed.). Chicago, Illinois: University of Chicago. pp. 102–121. ISBN 978-0-226-30062-7.  Popper, Karl (1972). Objective Knowledge.  Newton-Smith, W.H. (1994). The Rationality of Science. London: Routledge. p. 30. ISBN 978-0-7100-0913-5.  Bird, Alexander (2013). Zalta, Edward N. (ed.). "Thomas Kuhn". Stanford Encyclopedia of Philosophy. Archived from the original on July 15, 2020. Retrieved October 26, 2015.  T.S. Kuhn, The Structure of Scientific Revolutions, 2nd. ed., Chicago: Univ. of Chicago Pr., 1970, p. 206. ISBN 978-0-226-45804-5  Godfrey-Smith, Peter (2003j). "Naturalistic philosophy in theory and practice". Theory and Reality: An Introduction to the Philosophy of Science (1st ed.). Chicago, Illinois: University of Chicago. pp. 149–162. ISBN 978-0-226-30062-7.  Brugger, E. Christian (2004). "Casebeer, William D. Natural Ethical Facts: Evolution, Connectionism, and Moral Cognition". The Review of Metaphysics. 58 (2).  Winther, Rasmus Grønfeldt (2015). "The Structure of Scientific Theories". Stanford Encyclopedia of Philosophy. Archived from the original on June 11, 2018. Retrieved November 4, 2016.  Popper, Karl Raimund (1996). In Search of a Better World: Lectures and Essays From Thirty Years. New York, New York: Routledge. ISBN 978-0-415-13548-1.  Dawkins, Richard; Coyne, Jerry (September 2, 2005). "One side can be wrong". The Guardian. London. Archived from the original on December 26, 2013.  "Barry Stroud on Scepticism". philosophy bites. December 16, 2007. Archived from the original on January 23, 2012. Retrieved February 5, 2012.  Peirce (1877), "The Fixation of Belief", Popular Science Monthly, v. 12, pp. 1–15, see §IV on pp. 6–7 Archived April 15, 2016, at the Wayback Machine. Reprinted Collected Papers v. 5, paragraphs 358–87 (see 374–76), Writings v. 3, pp. 242–57 (see 247–48), Essential Peirce v. 1, pp. 109–23 (see 114–15), and elsewhere.  Peirce (1905), "Issues of Pragmaticism", The Monist, v. XV, n. 4, pp. 481–99, see "Character V" on p. 491. Reprinted in Collected Papers v. 5, paragraphs 438–63 (see 451), Essential Peirce v. 2, pp. 346–59 (see 353), and elsewhere.  Peirce (1868), "Some Consequences of Four Incapacities", Journal of Speculative Philosophy v. 2, n. 3, pp. 140–57, see p. 141 Archived April 15, 2016, at the Wayback Machine. Reprinted in Collected Papers, v. 5, paragraphs 264–317, Writings v. 2, pp. 211–42, Essential Peirce v. 1, pp. 28–55, and elsewhere.  Ziman, J.M. (1980). "The proliferation of scientific literature: a natural process". Science. 208 (4442): 369–71. Bibcode:1980Sci...208..369Z. doi:10.1126/science.7367863. PMID 7367863.  Subramanyam, Krishna; Subramanyam, Bhadriraju (1981). Scientific and Technical Information Resources. CRC Press. ISBN 978-0-8247-8297-9. OCLC 232950234.  "MEDLINE Fact Sheet". Washington DC: United States National Library of Medicine. Archived from the original on October 16, 2011. Retrieved October 15, 2011.  Petrucci, Mario. "Creative Writing – Science". Archived from the original on January 6, 2009. Retrieved April 27, 2008.  Schooler, J. W. (2014). "Metascience could rescue the 'replication crisis'". Nature. 515 (7525): 9. Bibcode:2014Natur.515....9S. doi:10.1038/515009a. PMID 25373639.  Smith, Noah (November 2, 2017). "Why 'Statistical Significance' Is Often Insignificant". Bloomberg.com. Retrieved November 7, 2017.  Pashler, Harold; Wagenmakers, Eric Jan (2012). "Editors' Introduction to the Special Section on Replicability in Psychological Science: A Crisis of Confidence?" (PDF). Perspectives on Psychological Science. 7 (6): 528–530. doi:10.1177/1745691612465253. PMID 26168108. S2CID 26361121. Archived (PDF) from the original on February 28, 2019. Retrieved April 12, 2020.  Ioannidis, John P. A.; Fanelli, Daniele; Dunne, Debbie Drake; Goodman, Steven N. (October 2, 2015). "Meta-research: Evaluation and Improvement of Research Methods and Practices". PLOS Biology. 13 (10): –1002264. doi:10.1371/journal.pbio.1002264. ISSN 1545-7885. PMC 4592065. PMID 26431313.  Feynman, Richard (1974). "Cargo Cult Science". Center for Theoretical Neuroscience. Columbia University. Archived from the original on March 4, 2005. Retrieved November 4, 2016.  Novella, Steven, et al. The Skeptics' Guide to the Universe: How to Know What's Really Real in a World Increasingly Full of Fake. Grand Central Publishing, 2018. pp. 162.  "Coping with fraud" (PDF). The COPE Report 1999: 11–18. Archived from the original (PDF) on September 28, 2007. Retrieved July 21, 2011. It is 10 years, to the month, since Stephen Lock ... Reproduced with kind permission of the Editor, The Lancet.  "Eusocial climbers" (PDF). E.O. Wilson Foundation. Archived (PDF) from the original on April 27, 2019. Retrieved September 3, 2018. But he’s not a scientist, he’s never done scientific research. My definition of a scientist is that you can complete the following sentence: ‘he or she has shown that...’," Wilson says.  "Our definition of a scientist". Science Council. Archived from the original on August 23, 2019. Retrieved September 7, 2018. A scientist is someone who systematically gathers and uses research and evidence, making a hypothesis and testing it, to gain and share understanding and knowledge.  Cyranoski, David; Gilbert, Natasha; Ledford, Heidi; Nayar, Anjali; Yahia, Mohammed (2011). "Education: The PhD factory". Nature. 472 (7343): 276–79. Bibcode:2011Natur.472..276C. doi:10.1038/472276a. PMID 21512548.  Kwok, Roberta (2017). "Flexible working: Science in the gig economy". Nature. 550: 419–21. doi:10.1038/nj7677-549a.  Woolston, Chris (2007). Editorial (ed.). "Many junior scientists need to take a hard look at their job prospects". Nature. 550: 549–552. doi:10.1038/nj7677-549a.  Lee, Adrian; Dennis, Carina; Campbell, Phillip (2007). "Graduate survey: A love–hurt relationship". Nature. 550 (7677): 549–52. doi:10.1038/nj7677-549a.  Stockton, Nick (October 7, 2014). "How did the Nobel Prize become the biggest award on Earth?". Wired. Archived from the original on June 19, 2019. Retrieved September 3, 2018.  "Nobel Prize Facts". Nobel Foundation. Archived from the original on July 8, 2017. Retrieved October 11, 2015.  Spanier, Bonnie (1995). "From Molecules to Brains, Normal Science Supports Sexist Beliefs about Difference". Im/partial Science: Gender Identity in Molecular Biology. Indiana University Press. ISBN 978-0-253-20968-9.  Rosser, Sue V. (March 12, 2012). Breaking into the Lab: Engineering Progress for Women in Science. New York: New York University Press. p. 7. ISBN 978-0-8147-7645-2.  Goulden, Mark; Frasch, Karie; Mason, Mary Ann (2009). Staying Competitive: Patching America's Leaky Pipeline in the Sciences. University of Berkeley Law.  Change of Heart: Career intentions and the chemistry PhD. Royal Society of Chemistry. 2008.  Parrott, Jim (August 9, 2007). "Chronicle for Societies Founded from 1323 to 1599". Scholarly Societies Project. Archived from the original on January 6, 2014. Retrieved September 11, 2007.  "The Environmental Studies Association of Canada - What is a Learned Society?". Archived from the original on May 29, 2013. Retrieved May 10, 2013.  "Learned societies & academies". Archived from the original on June 3, 2014. Retrieved May 10, 2013.  "Accademia Nazionale dei Lincei" (in Italian). 2006. Archived from the original on February 28, 2010. Retrieved September 11, 2007.  Meynell, G.G. "The French Academy of Sciences, 1666–91: A reassessment of the French Académie royale des sciences under Colbert (1666–83) and Louvois (1683–91)". Archived from the original on January 18, 2012. Retrieved October 13, 2011.  Bush, Vannevar (July 1945). "Science the Endless Frontier". National Science Foundation. Archived from the original on November 7, 2016. Retrieved November 4, 2016.  "Main Science and Technology Indicators – 2008-1" (PDF). OECD. Archived from the original (PDF) on February 15, 2010.  Ladwig, Peter (2012). "Perceived familiarity or factual knowledge? Comparing operationalizations of scientific understanding" (PDF). Science and Public Policy. 39 (6): 761–74. doi:10.1093/scipol/scs048. S2CID 144610587. Archived (PDF) from the original on February 28, 2020. Retrieved April 12, 2020.  Eveland, William (2004). "How Web Site Organization Influences Free Recall, Factual Knowledge, and Knowledge Structure Density". Human Communication Research. 30 (2): 208–33. doi:10.1111/j.1468-2958.2004.tb00731.x.  Dickson, David (October 11, 2004). "Science journalism must keep a critical edge". Science and Development Network. Archived from the original on June 21, 2010.  Mooney, Chris (November–December 2004). "Blinded By Science, How 'Balanced' Coverage Lets the Scientific Fringe Hijack Reality". Columbia Journalism Review. Vol. 43 no. 4. Archived from the original on January 17, 2010. Retrieved February 20, 2008.  McIlwaine, S.; Nguyen, D.A. (2005). "Are Journalism Students Equipped to Write About Science?". Australian Studies in Journalism. 14: 41–60. Archived from the original on August 1, 2008. Retrieved February 20, 2008.  Cook, John; Oreskes, Naomi; Doran, Peter T.; Anderegg, William R. L.; et al. (2016). "Consensus on consensus: a synthesis of consensus estimates on human-caused global warming". Environmental Research Letters. 11 (4): 048002. Bibcode:2016ERL....11d8002C. doi:10.1088/1748-9326/11/4/048002.  Powell, James (November 20, 2019). "Scientists Reach 100% Consensus on Anthropogenic Global Warming". Bulletin of Science, Technology & Society. 37 (4): 183–184. doi:10.1177/0270467619886266. S2CID 213454806. Archived from the original on December 7, 2020. Retrieved November 15, 2020.  Goldberg, Jeanne (2017). "The Politicization of Scientific Issues: Looking through Galileo's Lens or through the Imaginary Looking Glass". Skeptical Inquirer. 41 (5): 34–39. Archived from the original on August 16, 2018. Retrieved August 16, 2018.  Bolsen, Toby; Druckman, James N. (2015). "Counteracting the Politicization of Science". Journal of Communication (65): 746.  Freudenberg, William F.; Gramling, Robert; Davidson, Debra J. (2008). "Scientific Certainty Argumentation Methods (SCAMs): Science and the Politics of Doubt" (PDF). Sociological Inquiry. 78: 2–38. doi:10.1111/j.1475-682X.2008.00219.x. Archived (PDF) from the original on November 26, 2020. Retrieved April 12, 2020.  van der Linden, Sander; Leiserowitz, Anthony; Rosenthal, Seth; Maibach, Edward (2017). "Inoculating the Public against Misinformation about Climate Change" (PDF). Global Challenges. 1 (2): 1. doi:10.1002/gch2.201600008. PMC 6607159. PMID 31565263. Archived (PDF) from the original on April 4, 2020. Retrieved August 25, 2019. Works cited Smith, A. Mark (2001). Alhacen's Theory of Visual Perception: A Critical Edition, with English Translation and Commentary, of the First Three Books of Alhacen's De Aspectibus, the Medieval Latin Version of Ibn al-Haytham's Kitāb al-Manāẓir, 2 vols. Transactions of the American Philosophical Society. 91. Philadelphia: American Philosophical Society. ISBN 978-0-87169-914-5. OCLC 47168716. Smith, A. Mark (2001). "Alhacen's Theory of Visual Perception: A Critical Edition, with English Translation and Commentary, of the First Three Books of Alhacen's "De aspectibus", the Medieval Latin Version of Ibn al-Haytham's "Kitāb al-Manāẓir": Volume One". Transactions of the American Philosophical Society. 91 (4): i–337. JSTOR 3657358. Smith, A. Mark (2001). "Alhacen's Theory of Visual Perception: A Critical Edition, with English Translation and Commentary, of the First Three Books of Alhacen's "De aspectibus", the Medieval Latin Version of Ibn al-Haytham's "Kitāb al-Manāẓir": Volume Two". Transactions of the American Philosophical Society. 91 (5): 339–819. doi:10.2307/3657357. JSTOR 3657357. Further reading Augros, Robert M.; Stanciu, George N. (c. 1984). The New Story of Science: mind and the universe. Lake Bluff, Ill.: Regnery Gateway. ISBN 978-0-89526-833-4. Becker, Ernest (1968). The structure of evil; an essay on the unification of the science of man. New York: G. Braziller. Burguete, Maria; Lam, Lui, eds. (2014). All About Science: Philosophy, History, Sociology & Communication. Singapore: World Scientific. ISBN 978-981-4472-92-0. Cole, K.C. (March 23, 1986). "Things your teacher never told you about science: Nine shocking revelations". Newsday. Long Island, New York. pp. 21–. Crease, Robert P. (2011). World in the Balance: the historic quest for an absolute system of measurement. New York: W.W. Norton. p. 317. ISBN 978-0-393-07298-3. Denworth, Lydia (October 2019). "A Significant Problem: Standard scientific methods are under fire. Will anything change?". Scientific American. Vol. 321 no. 4. pp. 62–67. Feyerabend, Paul (2005). "Science, history of the philosophy". In Honderich, Ted (ed.). The Oxford companion to philosophy. Oxford Oxfordshire: Oxford University Press. ISBN 978-0-19-926479-7. OCLC 173262485. Feynman, Richard P. (1999). Robbins, Jeffrey (ed.). The pleasure of finding things out the best short works of Richard P. Feynman. Cambridge, Massachusetts: Perseus Books. ISBN 978-0-465-01312-8. Feynman, R.P. (1999). The Pleasure of Finding Things Out: The Best Short Works of Richard P. Feynman. Perseus Books Group. ISBN 978-0-465-02395-0. OCLC 181597764. Feynman, Richard P. (1974). "Cargo Cult Science" (PDF). Engineering and Science. 37 (7): 10–13. ISSN 0013-7812. Archived (PDF) from the original on December 1, 2013. Retrieved January 25, 2021. Gaukroger, Stephen (2006). The Emergence of a Scientific Culture: Science and the Shaping of Modernity 1210–1685. Oxford: Oxford University Press. ISBN 978-0-19-929644-6. Gopnik, Alison (Winter 2004). "Finding Our Inner Scientist" (PDF). Daedalus. 133: 21–28. doi:10.1162/001152604772746666. S2CID 57562993. Archived (PDF) from the original on April 12, 2016. Retrieved October 9, 2008. Krige, John; Pestre, Dominique, eds. (2003). Science in the Twentieth Century. Routledge. ISBN 978-0-415-28606-0. Levin, Yuval (2008). Imagining the Future: Science and American Democracy. New York: Encounter Books. ISBN 978-1-59403-209-7. Lindberg, D.C. (1976). Theories of Vision from al-Kindi to Kepler. Chicago: University of Chicago Press. Kuhn, Thomas (1962). The Structure of Scientific Revolutions. William F., McComas (1998). "The principal elements of the nature of science: Dispelling the myths" (PDF). In McComas, William F. (ed.). The nature of science in science education: rationales and strategies. Springer. ISBN 978-0-7923-6168-8. Archived (PDF) from the original on December 2, 2020. Retrieved November 4, 2006. Needham, Joseph (1954). Science and Civilisation in China: Introductory Orientations. 1. Cambridge University Press. Obler, Paul C.; Estrin, Herman A. (1962). The New Scientist: Essays on the Methods and Values of Modern Science. Anchor Books, Doubleday. Papineau, David (2005). "Science, problems of the philosophy of". In Honderich, Ted (ed.). The Oxford companion to philosophy. Oxford Oxfordshire: Oxford University Press. ISBN 978-0-19-926479-7. OCLC 173262485. Parkin, D. (1991). "Simultaneity and Sequencing in the Oracular Speech of Kenyan Diviners". In Peek, Philip M. (ed.). African Divination Systems: Ways of Knowing. Indianapolis, IN: Indiana University Press. Riskin, Jessica, "Just Use Your Thinking Pump!" (review of Henry M. Cowles, The Scientific Method: An Evolution of Thinking from Darwin to Dewey, Harvard University Press, 372 pp.), The New York Review of Books, vol. LXVII, no. 11 (2 July 2020), pp. 48–50. Russell, Bertrand (1985) [1952]. The Impact of Science on Society. London: Unwin. ISBN 978-0-04-300090-8. Rutherford, F. James; Ahlgren, Andrew (1990). Science for all Americans. New York, NY: American Association for the Advancement of Science, Oxford University Press. ISBN 978-0-19-506771-2. Thurs, Daniel Patrick (2007). Science Talk: Changing Notions of Science in American Popular Culture. ISBN 978-0-8135-4073-3. External links Publications   GCSE Science at Wikibooks Resources  Euroscience Classification of the Sciences in Dictionary of the History of Ideas. (Dictionary's new electronic format is badly botched, entries after "Design" are inaccessible. Internet Archive old version). United States Science Initiative Selected science information provided by US Government agencies, including research & development results How science works University of California Museum of Paleontology "How Do We Know What Is True?" (animated video; 2:52) "Science", an overview of the concept, plantspeopleplanet.org.au Science ISKO Encyclopedia of Knowledge Organization vte Glossaries of science and engineering Science portal Authority control Edit this at Wikidata Categories: ScienceObservationMain topic articles Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadView sourceView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikibooks Wikinews Wikiquote Wikiversity Wikivoyage  Languages العربية Български Deutsch Ελληνικά Français Italiano Македонски Shqip Türkçe 217 more Edit links This page was last edited on 7 October 2021, at 02:09 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki The Scientific Revolution was a series of events that marked the emergence of modern science during the early modern period, when developments in mathematics, physics, astronomy, biology and chemistry transformed the views of society about nature. The Scientific Revolution took place in Europe towards the end of the Renaissance period and continued through the late 18th century, influencing the intellectual social movement known as the Enlightenment. While its dates are debated, the publication in 1543 of Nicolaus Copernicus' De revolutionibus orbium coelestium is often cited as marking the beginning of the Scientific Revolution.     Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more Page semi-protected Knowledge From Wikipedia, the free encyclopedia Jump to navigationJump to search For other uses, see Knowledge (disambiguation). Part of a series on Epistemology CategoryIndexOutline Core concepts  BeliefJustificationKnowledgeTruth Distinctions  A priori vs. A posterioriAnalytic vs. synthetic Schools of thought  EmpiricismNaturalismPragmatismRationalismRelativismSkepticism Topics and views  CertaintyCoherentismContextualismDogmatismExperienceFallibilismFoundationalismInductionInfallibilismInfinitismPerspectivismRationalityReasonSolipsism Specialized domains of inquiry  Applied epistemologyEvolutionary epistemologyFeminist epistemologyFormal epistemologyMetaepistemologySocial epistemology Notable epistemologists  René DescartesSextus EmpiricusEdmund GettierDavid HumeImmanuel KantW. V. O. Quinemore... Related fields  Epistemic logicPhilosophy of mindPhilosophy of perceptionPhilosophy of scienceProbability vte Knowledge is a familiarity, awareness, or understanding of someone or something, such as facts (descriptive knowledge), skills (procedural knowledge), or objects (acquaintance knowledge). By most accounts, knowledge can be acquired in many different ways and from many sources, including but not limited to perception, reason, memory, testimony, scientific inquiry, education, and practice. The philosophical study of knowledge is called epistemology.  The term "knowledge" can refer to a theoretical or practical understanding of a subject. It can be implicit (as with practical skill or expertise) or explicit (as with the theoretical understanding of a subject); formal or informal; systematic or particular.[1] The philosopher Plato argued that there was a distinction between knowledge and true belief in the Theaetetus, leading many to attribute to him a definition of knowledge as "justified true belief".[2][3] The difficulties with this definition raised by the Gettier problem have been the subject of extensive debate in epistemology for more than half a century.[2]   Contents 1	Theories of knowledge 2	Self-knowledge 3	The value of knowledge 4	Scientific knowledge 5	Situated knowledge 6	Partial knowledge 7	Religious concepts of knowledge 7.1	Christianity 7.2	Hinduism 7.3	Islam 7.4	Judaism 8	See also 9	References 10	External links Theories of knowledge  Robert Reid, Knowledge (1896). Thomas Jefferson Building, Washington, D.C. Main article: Epistemology The eventual demarcation of philosophy from science was made possible by the notion that philosophy's core was "theory of knowledge," a theory distinct from the sciences because it was their foundation... Without this idea of a "theory of knowledge," it is hard to imagine what "philosophy" could have been in the age of modern science.  — Richard Rorty, Philosophy and the Mirror of Nature Knowledge is the primary subject of the field of epistemology, which studies what we know, how we come to know it, and what it means to know something.[4] Defining knowledge is an important aspect of epistemology, because it does not suffice to have a belief; one must also have good reasons for that belief, because otherwise there would be no reason to prefer one belief over another.  The definition of knowledge is a matter of ongoing debate among epistemologists. The classical definition, described but not ultimately endorsed by Plato,[5] specifies that a statement must meet three criteria in order to be considered knowledge: it must be justified, true, and believed. Epistemologists today generally agree that these conditions are not sufficient, as various Gettier cases are thought to demonstrate. There are a number of alternative definitions which have been proposed, including Robert Nozick's proposal that all instances of knowledge must 'track the truth' and Simon Blackburn's proposal that those who have a justified true belief 'through a defect, flaw, or failure' fail to have knowledge. Richard Kirkham suggests that our definition of knowledge requires that the evidence for the belief necessitates its truth.[6]  In contrast to this approach, Ludwig Wittgenstein observed, following Moore's paradox, that one can say "He believes it, but it isn't so," but not "He knows it, but it isn't so."[7] He goes on to argue that these do not correspond to distinct mental states, but rather to distinct ways of talking about conviction. What is different here is not the mental state of the speaker, but the activity in which they are engaged. For example, on this account, to know that the kettle is boiling is not to be in a particular state of mind, but to perform a particular task with the statement that the kettle is boiling. Wittgenstein sought to bypass the difficulty of definition by looking to the way "knowledge" is used in natural languages. He saw knowledge as a case of a family resemblance. Following this idea, "knowledge" has been reconstructed as a cluster concept that points out relevant features but that is not adequately captured by any definition.[8]  Self-knowledge “Self-knowledge” usually refers to a person's knowledge of their own sensations, thoughts, beliefs, and other mental states.[9] A number of questions regarding self-knowledge have been the subject of extensive debates in philosophy, including whether self-knowledge differs from other types of knowledge, whether we have privileged self-knowledge compared to knowledge of other minds, and the nature of our acquaintance with ourselves.[9] David Hume expressed skepticism about whether we could ever have self-knowledge over and above our immediate awareness of a "bundle of perceptions", which was part of his broader skepticism about personal identity.[9]  The value of knowledge  Los portadores de la antorcha (The Torch-Bearers) – Sculpture by Anna Hyatt Huntington symbolizing the transmission of knowledge from one generation to the next (Ciudad Universitaria, Madrid, Spain) It is generally assumed that knowledge is more valuable than mere true belief. If so, what is the explanation? A formulation of the value problem in epistemology first occurs in Plato's Meno. Socrates points out to Meno that a man who knew the way to Larissa could lead others there correctly. But so, too, could a man who had true beliefs about how to get there, even if he had not gone there or had any knowledge of Larissa. Socrates says that it seems that both knowledge and true opinion can guide action. Meno then wonders why knowledge is valued more than true belief and why knowledge and true belief are different. Socrates responds that knowledge is more valuable than mere true belief because it is tethered or justified. Justification, or working out the reason for a true belief, locks down true belief.[10]  The problem is to identify what (if anything) makes knowledge more valuable than mere true belief, or that makes knowledge more valuable than a mere minimal conjunction of its components, such as justification, safety, sensitivity, statistical likelihood, and anti-Gettier conditions, on a particular analysis of knowledge that conceives of knowledge as divided into components (to which knowledge-first epistemological theories, which posit knowledge as fundamental, are notable exceptions).[11] The value problem re-emerged in the philosophical literature on epistemology in the twenty-first century following the rise of virtue epistemology in the 1980s, partly because of the obvious link to the concept of value in ethics.[12]  In contemporary philosophy, epistemologists including Ernest Sosa, John Greco, Jonathan Kvanvig,[13] Linda Zagzebski, and Duncan Pritchard have defended virtue epistemology as a solution to the value problem. They argue that epistemology should also evaluate the "properties" of people as epistemic agents (i.e. intellectual virtues), rather than merely the properties of propositions and propositional mental attitudes.  Scientific knowledge Main article: Philosophy of science  Sir Francis Bacon, "Knowledge is Power" The development of the scientific method has made a significant contribution to how knowledge of the physical world and its phenomena is acquired.[14] To be termed scientific, a method of inquiry must be based on gathering observable and measurable evidence subject to specific principles of reasoning and experimentation.[15] The scientific method consists of the collection of data through observation and experimentation, and the formulation and testing of hypotheses.[16] Science, and the nature of scientific knowledge have also become the subject of philosophy. As science itself has developed, scientific knowledge now includes a broader usage[17] in the soft sciences such as biology and the social sciences – discussed elsewhere as meta-epistemology, or genetic epistemology, and to some extent related to "theory of cognitive development". Note that "epistemology" is the study of knowledge and how it is acquired. Science is "the process used everyday to logically complete thoughts through inference of facts determined by calculated experiments." Sir Francis Bacon was critical in the historical development of the scientific method; his works established and popularized an inductive methodology for scientific inquiry. His aphorism, "knowledge is power", is found in the Meditations Sacrae (1597).[18]  Until recent times, at least in the Western tradition, it was simply taken for granted that knowledge was something possessed only by humans – and probably adult humans at that. Sometimes the notion might stretch to Society-as-such, as in (e. g.) "the knowledge possessed by the Coptic culture" (as opposed to its individual members), but that was not assured either. Nor was it usual to consider unconscious knowledge in any systematic way until this approach was popularized by Freud.[19]  Situated knowledge "Situated knowledges" redirects here. For the Donna Haraway essay, see Situated Knowledges. Situated knowledge is knowledge specific to a particular situation. It was used by Donna Haraway as an extension of the feminist approaches of "successor science" suggested by Sandra Harding, one which "offers a more adequate, richer, better account of a world, in order to live in it well and in critical, reflexive relation to our own as well as others' practices of domination and the unequal parts of privilege and oppression that makes up all positions."[20] This situation partially transforms science into a narrative, which Arturo Escobar explains as, "neither fictions nor supposed facts." This narrative of situation is historical textures woven of fact and fiction, and as Escobar explains further, "even the most neutral scientific domains are narratives in this sense," insisting that rather than a purpose dismissing science as a trivial matter of contingency, "it is to treat (this narrative) in the most serious way, without succumbing to its mystification as 'the truth' or to the ironic skepticism common to many critiques."[21]  Haraway's argument stems from the limitations of the human perception, as well as the overemphasis of the sense of vision in science. According to Haraway, vision in science has been, "used to signify a leap out of the marked body and into a conquering gaze from nowhere." This is the "gaze that mythically inscribes all the marked bodies, that makes the unmarked category claim the power to see and not be seen, to represent while escaping representation."[20] This causes a limitation of views in the position of science itself as a potential player in the creation of knowledge, resulting in a position of "modest witness". This is what Haraway terms a "god trick", or the aforementioned representation while escaping representation.[22] In order to avoid this, "Haraway perpetuates a tradition of thought which emphasizes the importance of the subject in terms of both ethical and political accountability".[23]  Some methods of generating knowledge, such as trial and error, or learning from experience, tend to create highly situational knowledge. Situational knowledge is often embedded in language, culture, or traditions. This integration of situational knowledge is an allusion to the community, and its attempts at collecting subjective perspectives into an embodiment "of views from somewhere."[20] Knowledge is also said to be related to the capacity of acknowledgement in human beings.[24]  Even though Haraway's arguments are largely based on feminist studies,[20] this idea of different worlds, as well as the skeptic stance of situated knowledge is present in the main arguments of post-structuralism. Fundamentally, both argue the contingency of knowledge on the presence of history; power, and geography, as well as the rejection of universal rules or laws or elementary structures; and the idea of power as an inherited trait of objectification.[25]  Partial knowledge  This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (June 2020) (Learn how and when to remove this template message)  The parable of the blind men and the elephant suggests that people tend to project their partial experiences as the whole truth One discipline of epistemology focuses on partial knowledge. In most cases, it is not possible to understand an information domain exhaustively; our knowledge is always incomplete or partial. Most real problems have to be solved by taking advantage of a partial understanding of the problem context and problem data, unlike the typical math problems one might solve at school, where all data is given and one is given a complete understanding of formulas necessary to solve them (False consensus effect).  This idea is also present in the concept of bounded rationality which assumes that in real-life situations people often have a limited amount of information and make decisions accordingly.  Religious concepts of knowledge Christianity In many expressions of Christianity, such as Catholicism[26] and Anglicanism,[27] knowledge is one of the seven gifts of the Holy Spirit.  "The knowledge that comes from the Holy Spirit, however, is not limited to human knowledge; it is a special gift, which leads us to grasp, through creation, the greatness and love of God and his profound relationship with every creature." (Pope Francis, papal audience May 21, 2014)[28]  Hinduism विद्या दान (Vidya Daan) i.e. knowledge sharing is a major part of Daan, a tenet of all Dharmic Religions.[29] Hindu Scriptures present two kinds of knowledge, Paroksh Gyan and Prataksh Gyan. Paroksh Gyan (also spelled Paroksha-Jnana) is secondhand knowledge: knowledge obtained from books, hearsay, etc. Pratyaksh Gyan (also spelled Pratyaksha-Jnana) is the knowledge borne of direct experience, i.e., knowledge that one discovers for oneself.[30] Jnana yoga ("path of knowledge") is one of three main types of yoga expounded by Krishna in the Bhagavad Gita. (It is compared and contrasted with Bhakti Yoga and Karma yoga.)  Islam Main article: Knowledge in Islam In Islam, knowledge (Arabic: علم, ʿilm) is given great significance. "The Knowing" (al-ʿAlīm) is one of the 99 names reflecting distinct attributes of God. The Qur'an asserts that knowledge comes from God (2:239) and various hadith encourage the acquisition of knowledge. Muhammad is reported to have said "Seek knowledge from the cradle to the grave" and "Verily the men of knowledge are the inheritors of the prophets". Islamic scholars, theologians and jurists are often given the title alim, meaning "knowledgeble".[31]  Judaism In Jewish tradition, knowledge (Hebrew: דעת da'ath) is considered one of the most valuable traits a person can acquire. Observant Jews recite three times a day in the Amidah "Favor us with knowledge, understanding and discretion that come from you. Exalted are you, Existent-One, the gracious giver of knowledge." The Tanakh states, "A wise man gains power, and a man of knowledge maintains power", and "knowledge is chosen above gold".  The Old Testament's tree of the knowledge of good and evil contained the knowledge that separated Man from God: "And the LORD God said, Behold, the man is become as one of us, to know good and evil..." (Genesis 3:22)  See also Omniscience Outline of knowledge – guide to the subject of knowledge presented as a tree structured list of its subtopics. Outline of human intelligence - list of subtopics in tree structure Analytic-synthetic distinction Decolonization of knowledge Desacralization of knowledge Descriptive knowledge Epistemic modal logic Gnosticism Inductive inference Inductive probability Intelligence Metaknowledge Procedural knowledge Society for the Diffusion of Useful Knowledge References  "knowledge: definition of knowledge in Oxford dictionary (American English) (US)". oxforddictionaries.com. Archived from the original on 14 July 2010.  "The Analysis of Knowledge". Stanford Encyclopedia of Philosophy. Retrieved 13 June 2020.  Paul Boghossian (2007), Fear of Knowledge: Against relativism and constructivism, Oxford: Clarendon Press, ISBN 978-0199230419, Chapter 7, pp. 95–101.  "Epistemology". Stanford Encyclopedia of Philosophy. Retrieved 30 June 2020.  In Plato's Theaetetus, Socrates and Theaetetus discuss three definitions of knowledge: knowledge as nothing but perception, knowledge as true judgment, and, finally, knowledge as a true judgment with an account. Each of these definitions is shown to be unsatisfactory.  Kirkham, Richard L. (October 1984). "Does the Gettier Problem Rest on a Mistake?". Mind. New Series. 93 (372): 501–513. doi:10.1093/mind/XCIII.372.501. JSTOR 2254258. jstor (subscription required)[dead link]  Ludwig Wittgenstein, On Certainty, remark 42  Gottschalk-Mazouz, N. (2008): "Internet and the flow of knowledge," in: Hrachovec, H.; Pichler, A. (Hg.): Philosophy of the Information Society. Proceedings of the 30. International Ludwig Wittgenstein Symposium Kirchberg am Wechsel, Austria 2007. Volume 2, Frankfurt, Paris, Lancaster, New Brunswik: Ontos, S. 215–232. "Archived copy" (PDF). Archived from the original (PDF) on 24 May 2015. Retrieved 24 May 2015.  "Self-Knowledge". Stanford Encyclopedia of Philosophy. Retrieved 16 July 2020.  Plato (2002). Five Dialogues. Indianapolis, IN: Hackett Pub. Co. pp. 89–90, 97b–98a. ISBN 978-0-87220-633-5.  Pritchard, Duncan; Turri, John. "The Value of Knowledge". Stanford Encyclopedia of Philosophy. Retrieved 24 February 2016.  Pritchard, Duncan (April 2007). "Recent Work on Epistemic Value". American Philosophical Quarterly. 44 (2): 85–110. JSTOR 20464361.  Kvanvig, Jonathan L. (2003). The Value of Knowledge and the Pursuit of Understanding. Cambridge University Press. ISBN 9781139442282.[page needed]  "Science – Definition of science by Merriam-Webster". merriam-webster.com.  "[4] Rules for the study of natural philosophy", Newton 1999, pp. 794–796, from the General Scholium, which follows Book 3, The System of the World.  scientific method, Merriam-Webster Dictionary.  Wilson, Timothy D. (12 July 2012). "Stop bullying the 'soft' sciences". Los Angeles Times.  "Sir Francis Bacon – Quotationspage.com". Retrieved 8 July 2009.  There is quite a good case for this exclusive specialization used by philosophers, in that it allows for in-depth study of logic-procedures and other abstractions which are not found elsewhere. However, this may lead to problems whenever the topic spills over into those excluded domains – e. g. when Kant (following Newton) dismissed Space and Time as axiomatically "transcendental" and "a priori" – a claim later disproved by Piaget's clinical studies. It also seems likely that the vexed problem of "infinite regress" can be largely (but not completely) solved by proper attention to how unconscious concepts are actually developed, both during infantile learning and as inherited "pseudo-transcendentals" inherited from the trial-and-error of previous generations. See also "Tacit knowledge". Piaget, J., and B.Inhelder (1927/1969). The child's conception of time. Routledge & Kegan Paul: London. Piaget, J., and B. Inhelder (1948/1956). The child's conception of space. Routledge & Kegan Paul: London.  "Situated Knowledges: The Science Question in Feminism and the Privilege of Partial Perspective". Haraway, Donna. Feminist Studies Vol. 14, No. 3. pp. 575–599. 1988.  "Introduction: Development and the Anthropology of Modernity". Escobar, Arturo. Encountering Development: The Making and Unmaking of the Third World.  Chapter 1. Haraway, Donna. Modest_Witness@Second_Millennium. FemaleMan© Meets_OncoMouse2. Feminism and Technoscience. 1997.  Braidotti, Rosi (2006). "Posthuman, All Too Human". Theory, Culture & Society. 23 (7–8): 197–208. doi:10.1177/0263276406069232.  Stanley Cavell, "Knowing and Acknowledging", Must We Mean What We Say? (Cambridge University Press, 2002), 238–266.  "The Subject and Power". Foucault, Michel. Critical Inquiry Volume 9, No. 4. pp. 777–795. 1982  "Part Three, No. 1831". Catechism of the Catholic Church. Archived from the original on 4 May 2007. Retrieved 20 April 2007.  "Seven Gifts of the Holy Spirit", An Episcopal Dictionary of the Church  "The gifts of the Holy Spirit open us to divine inspirations", Catholic News Service, September 10, 2020  "विद्या दान ही सबसे बडा दान : विहिप – Vishva Hindu Parishad – Official Website". vhp.org. Archived from the original on 20 August 2011.  Swami Krishnananda. "Chapter 7". The Philosophy of the Panchadasi. The Divine Life Society. Retrieved 5 July 2008.  "Alim". Lexico. Oxford. Retrieved 13 March 2021. External links Knowledge at Wikipedia's sister projects Definitions from Wiktionary Media from Wikimedia Commons News from Wikinews Quotations from Wikiquote Texts from Wikisource Textbooks from Wikibooks Resources from Wikiversity Knowledge at PhilPapers "Knowledge". Internet Encyclopedia of Philosophy. Zalta, Edward N. (ed.). "The Value of Knowledge". Stanford Encyclopedia of Philosophy. Zalta, Edward N. (ed.). "The Analysis of Knowledge". Stanford Encyclopedia of Philosophy. Zalta, Edward N. (ed.). "Knowledge by Acquaintance vs. Description". Stanford Encyclopedia of Philosophy. Knowledge at the Indiana Philosophy Ontology Project Links to related articles Authority control Edit this at Wikidata	 Integrated Authority File (Germany) Categories: KnowledgeConcepts in epistemologyIntelligenceMental contentVirtueMain topic articles Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadView sourceView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikiquote  Languages Български Deutsch Ελληνικά Français हिन्दी Македонски Shqip Türkçe 中文 121 more Edit links This page was last edited on 8 October 2021, at 21:55 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki   Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more Epistemology From Wikipedia, the free encyclopedia Jump to navigationJump to search "Theory of knowledge" redirects here. For other uses, see Theory of knowledge (disambiguation). "Epistemic" redirects here. For the alternative name for cognitive science, see Epistemics. For the album, see Epistemology (album). Part of a series on Epistemology CategoryIndexOutline Core concepts  BeliefJustificationKnowledgeTruth Distinctions  A priori vs. A posterioriAnalytic vs. synthetic Schools of thought  EmpiricismNaturalismPragmatismRationalismRelativismSkepticism Topics and views  CertaintyCoherentismContextualismDogmatismExperienceFallibilismFoundationalismInductionInfallibilismInfinitismPerspectivismRationalityReasonSolipsism Specialized domains of inquiry  Applied epistemologyEvolutionary epistemologyFeminist epistemologyFormal epistemologyMetaepistemologySocial epistemology Notable epistemologists  René DescartesSextus EmpiricusEdmund GettierDavid HumeImmanuel KantW. V. O. Quinemore... Related fields  Epistemic logicPhilosophy of mindPhilosophy of perceptionPhilosophy of scienceProbability vte Part of a series on Philosophy Left to right: Plato, Kant, Nietzsche, Buddha, Confucius, Averroes About this image PlatoKantNietzsche BuddhaConfuciusAverroes Branches AestheticsAxiologyCosmologyEpistemologyEthicsLegalLinguisticLogicMentalMetaphilosophyMetaphysicsPoliticalReligiousScientificSocial Periods Traditions Literature Philosophers Lists Socrates.png Philosophy portal vte Epistemology (/ɪˌpɪstɪˈmɒlədʒi/ (About this soundlisten); from Greek ἐπιστήμη, epistēmē 'knowledge', and -logy) is the branch of philosophy concerned with knowledge. Epistemologists study the nature, origin, and scope of knowledge, epistemic justification, the rationality of belief, and various related issues. Epistemology is considered a major subfield of philosophy, along with other major subfields such as ethics, logic, and metaphysics.[1]  Debates in epistemology are generally clustered around four core areas:[2][3][4]  The philosophical analysis of the nature of knowledge and the conditions required for a belief to constitute knowledge, such as truth and justification Potential sources of knowledge and justified belief, such as perception, reason, memory, and testimony The structure of a body of knowledge or justified belief, including whether all justified beliefs must be derived from justified foundational beliefs or whether justification requires only a coherent set of beliefs Philosophical skepticism, which questions the possibility of knowledge, and related problems, such as whether skepticism poses a threat to our ordinary knowledge claims and whether it is possible to refute skeptical arguments In these debates and others, epistemology aims to answer questions such as "What do we know?", "What does it mean to say that we know something?", "What makes justified beliefs justified?", and "How do we know that we know?".[1][2][5][6][7]   Contents 1	Background 1.1	Etymology 1.2	History of epistemology 1.2.1	Contemporary historiography 2	Central concepts in epistemology 2.1	Knowledge 2.1.1	A priori and a posteriori knowledge 2.2	Belief 2.3	Truth 2.4	Justification 2.4.1	Internalism and externalism 3	Defining knowledge 3.1	The Gettier problem 3.1.1	"No false premises" response 3.1.2	Reliabilist response 3.1.3	Infallibilist response 3.1.4	Indefeasibility condition 3.1.5	Tracking condition 3.1.6	Knowledge-first response 3.1.7	Causal theory and naturalized epistemology 3.2	The value problem 3.2.1	Virtue epistemology 4	Acquiring knowledge 4.1	Sources of knowledge 4.2	Important distinctions 4.2.1	A priori–a posteriori distinction 4.2.2	Analytic–synthetic distinction 4.3	Science as knowledge acquisition 5	The regress problem 5.1	Responses to the regress problem 5.1.1	Foundationalism 5.1.2	Coherentism 5.1.3	Infinitism 5.1.4	Foundherentism 6	Philosophical skepticism 6.1	Pyrrhonism 6.2	Cartesian skepticism 6.3	Responses to philosophical skepticism 7	Schools of thought in epistemology 7.1	Empiricism 7.2	Rationalism 7.3	Skepticism 7.4	Pragmatism 7.5	Naturalized epistemology 7.6	Feminist epistemology 7.7	Epistemic relativism 7.8	Epistemic constructivism 7.9	Epistemic idealism 7.10	Bayesian epistemology 7.11	Indian pramana 8	Domains of inquiry in epistemology 8.1	Social epistemology 8.2	Formal epistemology 8.3	Metaepistemology 9	See also 10	References 10.1	Notes 10.2	Citations 10.3	Sources 11	External links Background Etymology The word epistemology is derived from the ancient Greek epistēmē, meaning "knowledge", and the suffix -logia, meaning "logical discourse" (derived from the Greek word logos meaning "discourse").[8] The word's appearance in English was predated by the German term Wissenschaftslehre (literally, theory of science), which was introduced by philosophers Johann Fichte and Bernard Bolzano in the late 18th century. The word "epistemology" first appeared in 1847, in a review in New York's Eclectic Magazine. It was first used as a translation of the word Wissenschaftslehre as it appears in a philosophical novel by German author Jean Paul:  The title of one of the principal works of Fichte is 'Wissenschaftslehre,' which, after the analogy of technology ... we render epistemology.[9]  The word "epistemology" was properly introduced into Anglophone philosophical literature by Scottish philosopher James Frederick Ferrier in 1854, who used it in his Institutes of Metaphysics:  This section of the science is properly termed the Epistemology—the doctrine or theory of knowing, just as ontology is the science of being... It answers the general question, 'What is knowing and the known?'—or more shortly, 'What is knowledge?'[10]  It is important to note that the French term épistémologie is used with a different and far narrower meaning than the English term "epistemology", being used by French philosophers to refer solely to philosophy of science. For instance, Émile Meyerson opened his Identity and Reality, written in 1908, with the remark that the word 'is becoming current' as equivalent to 'the philosophy of the sciences.'[11]  History of epistemology Epistemology, as a distinct field of inquiry, predates the introduction of the term into the lexicon of philosophy. John Locke, for instance, described his efforts in Essay Concerning Human Understanding (1689) as an inquiry "into the original, certainty, and extent of human knowledge, together with the grounds and degrees of belief, opinion, and assent".[12]   René Descartes, who is often credited as the father of modern philosophy, was often preoccupied with epistemological questions in his work. Almost every major historical philosopher has considered questions about what we know and how we know it.[1] Among the Ancient Greek philosophers, Plato distinguished between inquiry regarding what we know and inquiry regarding what exists, particularly in the Republic, the Theaetetus, and the Meno.[1] A number of important epistemological concerns also appeared in the works of Aristotle.[1]  During the subsequent Hellenistic period, philosophical schools began to appear which had a greater focus on epistemological questions, often in the form of philosophical skepticism.[1] For instance, the Pyrrhonian skepticism of Pyrrho and Sextus Empiricus held that eudaimonia (flourishing, happiness, or "the good life") could be attained through the application of epoché (suspension of judgment) regarding all non-evident matters. Pyrrhonism was particularly concerned with undermining the epistemological dogmas of Stoicism and Epicureanism.[1] The other major school of Hellenistic skepticism was Academic skepticism, most notably defended by Carneades and Arcesilaus, which predominated in the Platonic Academy for almost two centuries.[1]  In ancient India the Ajñana school of ancient Indian philosophy promoted skepticism. Ajñana was a Śramaṇa movement and a major rival of early Buddhism, Jainism and the Ājīvika school. They held that it was impossible to obtain knowledge of metaphysical nature or ascertain the truth value of philosophical propositions; and even if knowledge was possible, it was useless and disadvantageous for final salvation. They were specialized in refutation without propagating any positive doctrine of their own.  After the ancient philosophical era but before the modern philosophical era, a number of Medieval philosophers also engaged with epistemological questions at length. Most notable among the Medievals for their contributions to epistemology were Thomas Aquinas, John Duns Scotus, and William of Ockham.[1]  In the Islamic epistemology Islamic Golden Age which was booming prior to the Age of Enlightenment in Europe. One of the most prominent and influential philosophers, theologians, jurists, logicians and mystics Abu Hamid Al-Ghazali wrote over 70 books, including his best-known work in 1107 CE, his spiritual autobiography, "Deliverance from Error" (Al-Munqidh min al-Dalal). In this book Al-Ghazali was seeking to know what we can be certain about: what is true knowledge and not just opinion? To accomplish this goal, he would first consider what kinds of things we can know. This involves a study of epistemology, the theory of knowledge.[citation needed]  Epistemology largely came to the fore in philosophy during the early modern period, which historians of philosophy traditionally divide up into a dispute between empiricists (including Francis Bacon, John Locke, David Hume, and George Berkeley) and rationalists (including René Descartes, Baruch Spinoza, and Gottfried Leibniz).[1] The debate between them has often been framed using the question of whether knowledge comes primarily from sensory experience (empiricism), or whether a significant portion of our knowledge is derived entirely from our faculty of reason (rationalism). According to some scholars, this dispute was resolved in the late 18th century by Immanuel Kant, whose transcendental idealism famously made room for the view that "though all our knowledge begins with experience, it by no means follows that all [knowledge] arises out of experience".[13][non-primary source needed]  Contemporary historiography Unbalanced scales.svg The neutrality of this section is disputed. Relevant discussion may be found on the talk page. Please do not remove this message until conditions to do so are met. (August 2021) (Learn how and when to remove this template message) There are a number of different methods that contemporary scholars use when trying to understand the relationship between past epistemology and contemporary epistemology. One of the most contentious questions is this: "Should we assume that the problems of epistemology are perennial, and that trying to reconstruct and evaluate Plato's or Hume's or Kant's arguments is meaningful for current debates, too?"[14] Similarly, there is also a question of whether contemporary philosophers should aim to rationally reconstruct and evaluate historical views in epistemology, or to merely describe them.[14] Barry Stroud claims that doing epistemology competently requires the historical study of past attempts to find philosophical understanding of the nature and scope of human knowledge.[15] He argues that since inquiry may progress over time, we may not realize how different the questions that contemporary epistemologists ask are from questions asked at various different points in the history of philosophy.[15]  Central concepts in epistemology Knowledge  Bertrand Russell famously brought attention to the distinction between propositional knowledge and knowledge by acquaintance. Main article: Knowledge Nearly all debates in epistemology are in some way related to knowledge. Most generally, "knowledge" is a familiarity, awareness, or understanding of someone or something, which might include facts (propositional knowledge), skills (procedural knowledge), or objects (acquaintance knowledge). Philosophers tend to draw an important distinction between three different senses of "knowing" something: "knowing that" (knowing the truth of propositions), "knowing how" (understanding how to perform certain actions), and "knowing by acquaintance" (directly perceiving an object, being familiar with it, or otherwise coming into contact with it).[16] Epistemology is primarily concerned with the first of these forms of knowledge, propositional knowledge. All three senses of "knowing" can be seen in our ordinary use of the word. In mathematics, you can know that 2 + 2 = 4, but there is also knowing how to add two numbers, and knowing a person (e.g., knowing other persons,[17] or knowing oneself), place (e.g., one's hometown), thing (e.g., cars), or activity (e.g., addition). While these distinctions are not explicit in English, they are explicitly made in other languages, including French, Portuguese, Spanish, Romanian, German and Dutch (although some languages related to English have been said to retain these verbs, such as Scots).[note 1] The theoretical interpretation and significance of these linguistic issues remains controversial.  In his paper On Denoting and his later book Problems of Philosophy, Bertrand Russell brought a great deal of attention to the distinction between "knowledge by description" and "knowledge by acquaintance". Gilbert Ryle is similarly credited with bringing more attention to the distinction between knowing how and knowing that in The Concept of Mind. In Personal Knowledge, Michael Polanyi argues for the epistemological relevance of knowledge how and knowledge that; using the example of the act of balance involved in riding a bicycle, he suggests that the theoretical knowledge of the physics involved in maintaining a state of balance cannot substitute for the practical knowledge of how to ride, and that it is important to understand how both are established and grounded. This position is essentially Ryle's, who argued that a failure to acknowledge the distinction between "knowledge that" and "knowledge how" leads to infinite regress.  A priori and a posteriori knowledge Main article: A priori and a posteriori One of the most important distinctions in epistemology is between what can be known a priori (independently of experience) and what can be known a posteriori (through experience). The terms originate from the Analytic methods of Aristotle's Organon, and may be roughly defined as follows:[19]  A priori knowledge is knowledge that is known independently of experience (that is, it is non-empirical, or arrived at before experience, usually by reason). It will henceforth be acquired through anything that is independent from experience. A posteriori knowledge is knowledge that is known by experience (that is, it is empirical, or arrived at through experience). Views that emphasize the importance of a priori knowledge are generally classified as rationalist. Views that emphasize the importance of a posteriori knowledge are generally classified as empiricist.[citation needed]  Belief Main article: Belief One of the core concepts in epistemology is belief. A belief is an attitude that a person holds regarding anything that they take to be true.[20] For instance, to believe that snow is white is comparable to accepting the truth of the proposition "snow is white". Beliefs can be occurrent (e.g. a person actively thinking "snow is white"), or they can be dispositional (e.g. a person who if asked about the color of snow would assert "snow is white"). While there is not universal agreement about the nature of belief, most contemporary philosophers hold the view that a disposition to express belief B qualifies as holding the belief B.[20] There are various different ways that contemporary philosophers have tried to describe beliefs, including as representations of ways that the world could be (Jerry Fodor), as dispositions to act as if certain things are true (Roderick Chisholm), as interpretive schemes for making sense of someone's actions (Daniel Dennett and Donald Davidson), or as mental states that fill a particular function (Hilary Putnam).[20] Some have also attempted to offer significant revisions to our notion of belief, including eliminativists about belief who argue that there is no phenomenon in the natural world which corresponds to our folk psychological concept of belief (Paul Churchland) and formal epistemologists who aim to replace our bivalent notion of belief ("either I have a belief or I don't have a belief") with the more permissive, probabilistic notion of credence ("there is an entire spectrum of degrees of belief, not a simple dichotomy between belief and non-belief").[20][21]  While belief plays a significant role in epistemological debates surrounding knowledge and justification, it also has many other philosophical debates in its own right. Notable debates include: "What is the rational way to revise one's beliefs when presented with various sorts of evidence?"; "Is the content of our beliefs entirely determined by our mental states, or do the relevant facts have any bearing on our beliefs (e.g. if I believe that I'm holding a glass of water, is the non-mental fact that water is H2O part of the content of that belief)?"; "How fine-grained or coarse-grained are our beliefs?"; and "Must it be possible for a belief to be expressible in language, or are there non-linguistic beliefs?"[20]  Truth Main article: Truth Truth is the property or state of being in accordance with facts or reality.[22] On most views, truth is the correspondence of language or thought to a mind-independent world. This is called the correspondence theory of truth. Among philosophers who think that it is possible to analyze the conditions necessary for knowledge, virtually all of them accept that truth is such a condition. There is much less agreement about the extent to which a knower must know why something is true in order to know. On such views, something being known implies that it is true. However, this should not be confused for the more contentious view that one must know that one knows in order to know (the KK principle).[2]  Epistemologists disagree about whether belief is the only truth-bearer. Other common suggestions for things that can bear the property of being true include propositions, sentences, thoughts, utterances, and judgments. Plato, in his Gorgias, argues that belief is the most commonly invoked truth-bearer.[23][clarification needed]  Many of the debates regarding truth are at the crossroads of epistemology and logic.[22] Some contemporary debates regarding truth include: How do we define truth? Is it even possible to give an informative definition of truth? What things are truth-bearers and are therefore capable of being true or false? Are truth and falsity bivalent, or are there other truth values? What are the criteria of truth that allow us to identify it and to distinguish it from falsity? What role does truth play in constituting knowledge? And is truth absolute, or is it merely relative to one's perspective?[22]  Justification Main article: Justification (epistemology) As the term "justification" is used in epistemology, a belief is justified if one has good reason for holding it. Loosely speaking, justification is the reason that someone holds a rationally admissible belief, on the assumption that it is a good reason for holding it. Sources of justification might include perceptual experience (the evidence of the senses), reason, and authoritative testimony, among others. Importantly however, a belief being justified does not guarantee that the belief is true, since a person could be justified in forming beliefs based on very convincing evidence that was nonetheless deceiving.  In Plato's Theaetetus, Socrates considers a number of theories as to what knowledge is, first excluding merely true belief as an adequate account. For example, an ill person with no medical training, but with a generally optimistic attitude, might believe that he will recover from his illness quickly. Nevertheless, even if this belief turned out to be true, the patient would not have known that he would get well since his belief lacked justification. The last account that Plato considers is that knowledge is true belief "with an account" that explains or defines it in some way. According to Edmund Gettier, the view that Plato is describing here is that knowledge is justified true belief. The truth of this view would entail that in order to know that a given proposition is true, one must not only believe the relevant true proposition, but must also have a good reason for doing so.[24] One implication of this would be that no one would gain knowledge just by believing something that happened to be true.[25]  Edmund Gettier's famous 1963 paper, "Is Justified True Belief Knowledge?", popularized the claim that the definition of knowledge as justified true belief had been widely accepted throughout the history of philosophy.[26] The extent to which this is true is highly contentious, since Plato himself disavowed the "justified true belief" view at the end of the Theaetetus.[27][1] Regardless of the accuracy of the claim, Gettier's paper produced major widespread discussion which completely reoriented epistemology in the second half of the 20th century, with a newfound focus on trying to provide an airtight definition of knowledge by adjusting or replacing the "justified true belief" view.[note 2] Today there is still little consensus about whether any set of conditions succeeds in providing a set of necessary and sufficient conditions for knowledge, and many contemporary epistemologists have come to the conclusion that no such exception-free definition is possible.[27] However, even if justification fails as a condition for knowledge as some philosophers claim, the question of whether or not a person has good reasons for holding a particular belief in a particular set of circumstances remains a topic of interest to contemporary epistemology and is unavoidably linked to questions about rationality.[27]  Internalism and externalism Main article: Internalism and externalism A central debate about the nature of justification is a debate between epistemological externalists on the one hand and epistemological internalists on the other. While epistemic externalism first arose in attempts to overcome the Gettier problem, it has flourished in the time since as an alternative way of conceiving of epistemic justification. The initial development of epistemic externalism is often attributed to Alvin Goldman, although numerous other philosophers have worked on the topic in the time since.[27]  Externalists hold that factors deemed "external", meaning outside of the psychological states of those who gain knowledge, can be conditions of justification. For example, an externalist response to the Gettier problem is to say that for a justified true belief to count as knowledge, there must be a link or dependency between the belief and the state of the external world. Usually, this is understood to be a causal link. Such causation, to the extent that it is "outside" the mind, would count as an external, knowledge-yielding condition. Internalists, on the other hand, assert that all knowledge-yielding conditions are within the psychological states of those who gain knowledge.  Though unfamiliar with the internalist/externalist debate himself, many point to René Descartes as an early example of the internalist path to justification. He wrote that because the only method by which we perceive the external world is through our senses, and that, because the senses are not infallible, we should not consider our concept of knowledge infallible. The only way to find anything that could be described as "indubitably true", he advocates, would be to see things "clearly and distinctly".[28] He argued that if there is an omnipotent, good being who made the world, then it's reasonable to believe that people are made with the ability to know. However, this does not mean that man's ability to know is perfect. God gave man the ability to know but not with omniscience. Descartes said that man must use his capacities for knowledge correctly and carefully through methodological doubt.[29]  The dictum "Cogito ergo sum" (I think, therefore I am) is also commonly associated with Descartes' theory. In his own methodological doubt—doubting everything he previously knew so he could start from a blank slate—the first thing that he could not logically bring himself to doubt was his own existence: "I do not exist" would be a contradiction in terms. The act of saying that one does not exist assumes that someone must be making the statement in the first place. Descartes could doubt his senses, his body, and the world around him—but he could not deny his own existence, because he was able to doubt and must exist to manifest that doubt. Even if some "evil genius" were deceiving him, he would have to exist to be deceived. This one sure point provided him with what he called his Archimedean point, in order to further develop his foundation for knowledge. Simply put, Descartes' epistemological justification depended on his indubitable belief in his own existence and his clear and distinct knowledge of God.[30]  Defining knowledge The Gettier problem Main article: Gettier problem  An Euler diagram representing a version of the traditional definition of knowledge that is adapted to the Gettier problem. This problem gives us reason to think that not all justified true beliefs constitute knowledge. Edmund Gettier is best known for his 1963 paper entitled "Is Justified True Belief Knowledge?", which called into question the common conception of knowledge as justified true belief.[31] In just two and a half pages, Gettier argued that there are situations in which one's belief may be justified and true, yet fail to count as knowledge. That is, Gettier contended that while justified belief in a true proposition is necessary for that proposition to be known, it is not sufficient.  According to Gettier, there are certain circumstances in which one does not have knowledge, even when all of the above conditions are met. Gettier proposed two thought experiments, which have become known as Gettier cases, as counterexamples to the classical account of knowledge.[27] One of the cases involves two men, Smith and Jones, who are awaiting the results of their applications for the same job. Each man has ten coins in his pocket. Smith has excellent reasons to believe that Jones will get the job (the head of the company told him); and furthermore, Smith knows that Jones has ten coins in his pocket (he recently counted them). From this Smith infers: "The man who will get the job has ten coins in his pocket." However, Smith is unaware that he also has ten coins in his own pocket. Furthermore, it turns out that Smith, not Jones, is going to get the job. While Smith has strong evidence to believe that Jones will get the job, he is wrong. Smith therefore has a justified true belief that the man who will get the job has ten coins in his pocket; however, according to Gettier, Smith does not know that the man who will get the job has ten coins in his pocket, because Smith's belief is "...true by virtue of the number of coins in Jones's pocket, while Smith does not know how many coins are in Smith's pocket, and bases his belief... on a count of the coins in Jones's pocket, whom he falsely believes to be the man who will get the job."[31]: 122  These cases fail to be knowledge because the subject's belief is justified, but only happens to be true by virtue of luck. In other words, he made the correct choice (believing that the man who will get the job has ten coins in his pocket) for the wrong reasons. Gettier then goes on to offer a second similar case, providing the means by which the specifics of his examples can be generalized into a broader problem for defining knowledge in terms of justified true belief.  There have been various notable responses to the Gettier problem. Typically, they have involved substantial attempts to provide a new definition of knowledge that is not susceptible to Gettier-style objections, either by providing an additional fourth condition that justified true beliefs must meet to constitute knowledge, or proposing a completely new set of necessary and sufficient conditions for knowledge. While there have been far too many published responses for all of them to be mentioned, some of the most notable responses are discussed below.  "No false premises" response See also: Gettier problem § Trouble for the "no false premises" approach One of the earliest suggested replies to Gettier, and perhaps the most intuitive ways to respond to the Gettier problem, is the "no false premises" response, sometimes also called the "no false lemmas" response. Most notably, this reply was defended by David Malet Armstrong in his 1973 book, Belief, Truth, and Knowledge.[32] The basic form of the response is to assert that the person who holds the justified true belief (for instance, Smith in Gettier's first case) made the mistake of inferring a true belief (e.g. "The person who will get the job has ten coins in his pocket") from a false belief (e.g. "Jones will get the job"). Proponents of this response therefore propose that we add a fourth necessary and sufficient condition for knowledge, namely, "the justified true belief must not have been inferred from a false belief".  This reply to the Gettier problem is simple, direct, and appears to isolate what goes wrong in forming the relevant beliefs in Gettier cases. However, the general consensus is that it fails.[27] This is because while the original formulation by Gettier includes a person who infers a true belief from a false belief, there are many alternate formulations in which this is not the case. Take, for instance, a case where an observer sees what appears to be a dog walking through a park and forms the belief "There is a dog in the park". In fact, it turns out that the observer is not looking at a dog at all, but rather a very lifelike robotic facsimile of a dog. However, unbeknownst to the observer, there is in fact a dog in the park, albeit one standing behind the robotic facsimile of a dog. Since the belief "There is a dog in the park" does not involve a faulty inference, but is instead formed as the result of misleading perceptual information, there is no inference made from a false premise. It therefore seems that while the observer does in fact have a true belief that her perceptual experience provides justification for holding, she does not actually know that there is a dog in the park. Instead, she just seems to have formed a "lucky" justified true belief.[27]  Reliabilist response Main article: Reliabilism Reliabilism has been a significant line of response to the Gettier problem among philosophers, originating with work by Alvin Goldman in the 1960s. According to reliabilism, a belief is justified (or otherwise supported in such a way as to count towards knowledge) only if it is produced by processes that typically yield a sufficiently high ratio of true to false beliefs. In other words, this theory states that a true belief counts as knowledge only if it is produced by a reliable belief-forming process. Examples of reliable processes include standard perceptual processes, remembering, good reasoning, and introspection.[33]  One commonly discussed challenge for reliabilism is the case of Henry and the barn façades.[27] In this thought experiment, a man, Henry, is driving along and sees a number of buildings that resemble barns. Based on his perception of one of these, he concludes that he is looking at a barn. While he is indeed looking at a barn, it turns out that all of the other barn-like buildings he saw were façades. According to the challenge, Henry does not know that he has seen a barn, despite his belief being true, and despite his belief having been formed on the basis of a reliable process (i.e. his vision), since he only acquired his reliably formed true belief by accident.[34] In other words, since he could have just as easily been looking at a barn façade and formed a false belief, the reliability of perception in general does not mean that his belief wasn't merely formed luckily, and this luck seems to preclude him from knowledge.[27]  Infallibilist response One less common response to the Gettier problem is defended by Richard Kirkham, who has argued that the only definition of knowledge that could ever be immune to all counterexamples is the infallibilist definition.[35] To qualify as an item of knowledge, goes the theory, a belief must not only be true and justified, the justification of the belief must necessitate its truth. In other words, the justification for the belief must be infallible.  While infallibilism is indeed an internally coherent response to the Gettier problem, it is incompatible with our everyday knowledge ascriptions. For instance, as the Cartesian skeptic will point out, all of my perceptual experiences are compatible with a skeptical scenario in which I am completely deceived about the existence of the external world, in which case most (if not all) of my beliefs would be false.[29][36] The typical conclusion to draw from this is that it is possible to doubt most (if not all) of my everyday beliefs, meaning that if I am indeed justified in holding those beliefs, that justification is not infallible. For the justification to be infallible, my reasons for holding my everyday beliefs would need to completely exclude the possibility that those beliefs were false. Consequently, if a belief must be infallibly justified in order to constitute knowledge, then it must be the case that we are mistaken in most (if not all) instances in which we claim to have knowledge in everyday situations.[37] While it is indeed possible to bite the bullet and accept this conclusion, most philosophers find it implausible to suggest that we know nothing or almost nothing, and therefore reject the infallibilist response as collapsing into radical skepticism.[36]  Indefeasibility condition Another possible candidate for the fourth condition of knowledge is indefeasibility. Defeasibility theory maintains that there should be no overriding or defeating truths for the reasons that justify one's belief. For example, suppose that person S believes he saw Tom Grabit steal a book from the library and uses this to justify the claim that Tom Grabit stole a book from the library. A possible defeater or overriding proposition for such a claim could be a true proposition like, "Tom Grabit's identical twin Sam is currently in the same town as Tom." When no defeaters of one's justification exist, a subject would be epistemologically justified.  In a similar vein, the Indian philosopher B.K. Matilal drew on the Navya-Nyāya fallibilist tradition to respond to the Gettier problem. Nyaya theory distinguishes between know p and know that one knows p—these are different events, with different causal conditions. The second level is a sort of implicit inference that usually follows immediately the episode of knowing p (knowledge simpliciter). The Gettier case is examined by referring to a view of Gangesha Upadhyaya (late 12th century), who takes any true belief to be knowledge; thus a true belief acquired through a wrong route may just be regarded as knowledge simpliciter on this view. The question of justification arises only at the second level, when one considers the knowledge-hood of the acquired belief. Initially, there is lack of uncertainty, so it becomes a true belief. But at the very next moment, when the hearer is about to embark upon the venture of knowing whether he knows p, doubts may arise. "If, in some Gettier-like cases, I am wrong in my inference about the knowledge-hood of the given occurrent belief (for the evidence may be pseudo-evidence), then I am mistaken about the truth of my belief—and this is in accordance with Nyaya fallibilism: not all knowledge-claims can be sustained."[38]  Tracking condition Robert Nozick has offered a definition of knowledge according to which S knows that P if and only if:  P is true; S believes that P; if P were false, S would not believe that P; if P were true, S would believe that P.[39] Nozick argues that the third of these conditions serves to address cases of the sort described by Gettier. Nozick further claims this condition addresses a case of the sort described by D.M. Armstrong:[40] A father believes his daughter is innocent of committing a particular crime, both because of faith in his baby girl and (now) because he has seen presented in the courtroom a conclusive demonstration of his daughter's innocence. His belief via the method of the courtroom satisfies the four subjunctive conditions, but his faith-based belief does not. If his daughter were guilty, he would still believe her innocence, on the basis of faith in his daughter; this would violate the third condition.  The British philosopher Simon Blackburn has criticized this formulation by suggesting that we do not want to accept as knowledge beliefs which, while they "track the truth" (as Nozick's account requires), are not held for appropriate reasons. He says that "we do not want to award the title of knowing something to someone who is only meeting the conditions through a defect, flaw, or failure, compared with someone else who is not meeting the conditions."[41] In addition to this, externalist accounts of knowledge, such as Nozick's, are often forced to reject closure in cases where it is intuitively valid.  An account similar to Nozick's has also been offered by Fred Dretske, although his view focuses more on relevant alternatives that might have obtained if things had turned out differently. Views of both the Nozick variety and the Dretske variety have faced serious problems suggested by Saul Kripke.[27]  Knowledge-first response Timothy Williamson has advanced a theory of knowledge according to which knowledge is not justified true belief plus some extra conditions, but primary. In his book Knowledge and its Limits, Williamson argues that the concept of knowledge cannot be broken down into a set of other concepts through analysis—instead, it is sui generis. Thus, according to Williamson, justification, truth, and belief are necessary but not sufficient for knowledge. Williamson is also known for being one of the only philosophers who take knowledge to be a mental state;[42] most epistemologists assert that belief (as opposed to knowledge) is a mental state. As such, Williamson's claim has been seen to be highly counterintuitive.[43]  Causal theory and naturalized epistemology In an earlier paper that predates his development of reliabilism, Alvin Goldman writes in his "Causal Theory of Knowing" that knowledge requires a causal link between the truth of a proposition and the belief in that proposition. A similar view has also been defended by Hilary Kornblith in Knowledge and its Place in Nature, although his view is meant to capture an empirical scientific conception of knowledge, not an analysis of the everyday concept "knowledge".[44] Kornblith, in turn, takes himself to be elaborating on the naturalized epistemology framework first suggested by W.V.O. Quine.  The value problem Main article: Virtue epistemology We generally assume that knowledge is more valuable than mere true belief. If so, what is the explanation? A formulation of the value problem in epistemology first occurs in Plato's Meno. Socrates points out to Meno that a man who knew the way to Larissa could lead others there correctly. But so, too, could a man who had true beliefs about how to get there, even if he had not gone there or had any knowledge of Larissa. Socrates says that it seems that both knowledge and true opinion can guide action. Meno then wonders why knowledge is valued more than true belief and why knowledge and true belief are different. Socrates responds that knowledge is more valuable than mere true belief because it is tethered or justified. Justification, or working out the reason for a true belief, locks down true belief.[45]  The problem is to identify what (if anything) makes knowledge more valuable than mere true belief, or that makes knowledge more valuable than a mere minimal conjunction of its components, such as justification, safety, sensitivity, statistical likelihood, and anti-Gettier conditions, on a particular analysis of knowledge that conceives of knowledge as divided into components (to which knowledge-first epistemological theories, which posit knowledge as fundamental, are notable exceptions).[46] The value problem re-emerged in the philosophical literature on epistemology in the twenty-first century following the rise of virtue epistemology in the 1980s, partly because of the obvious link to the concept of value in ethics.[47]  Virtue epistemology In contemporary philosophy, epistemologists including Ernest Sosa, John Greco, Jonathan Kvanvig,[48] Linda Zagzebski, and Duncan Pritchard have defended virtue epistemology as a solution to the value problem. They argue that epistemology should also evaluate the "properties" of people as epistemic agents (i.e. intellectual virtues), rather than merely the properties of propositions and propositional mental attitudes.  The value problem has been presented as an argument against epistemic reliabilism by Linda Zagzebski, Wayne Riggs, and Richard Swinburne, among others. Zagzebski analogizes the value of knowledge to the value of espresso produced by an espresso maker: "The liquid in this cup is not improved by the fact that it comes from a reliable espresso maker. If the espresso tastes good, it makes no difference if it comes from an unreliable machine."[49] For Zagzebski, the value of knowledge deflates to the value of mere true belief. She assumes that reliability in itself has no value or disvalue, but Goldman and Olsson disagree. They point out that Zagzebski's conclusion rests on the assumption of veritism: all that matters is the acquisition of true belief.[50] To the contrary, they argue that a reliable process for acquiring a true belief adds value to the mere true belief by making it more likely that future beliefs of a similar kind will be true. By analogy, having a reliable espresso maker that produced a good cup of espresso would be more valuable than having an unreliable one that luckily produced a good cup because the reliable one would more likely produce good future cups compared to the unreliable one.  The value problem is important to assessing the adequacy of theories of knowledge that conceive of knowledge as consisting of true belief and other components. According to Kvanvig, an adequate account of knowledge should resist counterexamples and allow an explanation of the value of knowledge over mere true belief. Should a theory of knowledge fail to do so, it would prove inadequate.[51]  One of the more influential responses to the problem is that knowledge is not particularly valuable and is not what ought to be the main focus of epistemology. Instead, epistemologists ought to focus on other mental states, such as understanding.[52] Advocates of virtue epistemology have argued that the value of knowledge comes from an internal relationship between the knower and the mental state of believing.[46]  Acquiring knowledge Sources of knowledge There are many proposed sources of knowledge and justified belief which we take to be actual sources of knowledge in our everyday lives. Some of the most commonly discussed include perception, reason, memory, and testimony.[3][6]  Important distinctions A priori–a posteriori distinction Main article: A priori and a posteriori As mentioned above, epistemologists draw a distinction between what can be known a priori (independently of experience) and what can only be known a posteriori (through experience). Much of what we call a priori knowledge is thought to be attained through reason alone, as featured prominently in rationalism. This might also include a non-rational faculty of intuition, as defended by proponents of innatism. In contrast, a posteriori knowledge is derived entirely through experience or as a result of experience, as emphasized in empiricism. This also includes cases where knowledge can be traced back to an earlier experience, as in memory or testimony.[19]  A way to look at the difference between the two is through an example. Bruce Russell gives two propositions in which the reader decides which one he believes more.[clarification needed] Option A: All crows are birds. Option B: All crows are black. If you believe option A, then you are a priori justified in believing it because you don't have to see a crow to know it's a bird. If you believe in option B, then you are posteriori justified to believe it because you have seen many crows therefore knowing they are black. He goes on to say that it doesn't matter if the statement is true or not, only that if you believe in one or the other that matters.[19]  The idea of a priori knowledge is that it is based on intuition or rational insights. Laurence BonJour says in his article "The Structure of Empirical Knowledge",[53] that a "rational insight is an immediate, non-inferential grasp, apprehension or 'seeing' that some proposition is necessarily true." (3) Going back to the crow example, by Laurence BonJour's definition the reason you would believe in option A is because you have an immediate knowledge that a crow is a bird, without ever experiencing one.  Evolutionary psychology takes a novel approach to the problem. It says that there is an innate predisposition for certain types of learning. "Only small parts of the brain resemble a tabula rasa; this is true even for human beings. The remainder is more like an exposed negative waiting to be dipped into a developer fluid".[54]  Analytic–synthetic distinction  The analytic–synthetic distinction was first proposed by Immanuel Kant. Main article: Analytic–synthetic distinction Immanuel Kant, in his Critique of Pure Reason, drew a distinction between "analytic" and "synthetic" propositions. He contended that some propositions are such that we can know they are true just by understanding their meaning. For example, consider, "My father's brother is my uncle." We can know it is true solely by virtue of our understanding in what its terms mean. Philosophers call such propositions "analytic". Synthetic propositions, on the other hand, have distinct subjects and predicates. An example would be, "My father's brother has black hair." Kant stated that all mathematical and scientific statements are analytic priori propositions because they are necessarily true but our knowledge about the attributes of the mathematical or physical subjects we can only get by logical inference.  While this distinction is first and foremost about meaning and is therefore most relevant to the philosophy of language, the distinction has significant epistemological consequences, seen most prominently in the works of the logical positivists.[55] In particular, if the set of propositions which can only be known a posteriori is coextensive with the set of propositions which are synthetically true, and if the set of propositions which can be known a priori is coextensive with the set of propositions which are analytically true (or in other words, which are true by definition), then there can only be two kinds of successful inquiry: Logico-mathematical inquiry, which investigates what is true by definition, and empirical inquiry, which investigates what is true in the world. Most notably, this would exclude the possibility that branches of philosophy like metaphysics could ever provide informative accounts of what actually exists.[19][55]  The American philosopher Willard Van Orman Quine, in his paper "Two Dogmas of Empiricism", famously challenged the analytic-synthetic distinction, arguing that the boundary between the two is too blurry to provide a clear division between propositions that are true by definition and propositions that are not. While some contemporary philosophers take themselves to have offered more sustainable accounts of the distinction that are not vulnerable to Quine's objections, there is no consensus about whether or not these succeed.[56]  Science as knowledge acquisition Main article: Philosophy of science Science is often considered to be a refined, formalized, systematic, institutionalized form of the pursuit and acquisition of empirical knowledge. As such, the philosophy of science may be viewed variously as an application of the principles of epistemology or as a foundation for epistemological inquiry.  The regress problem Main article: Regress argument The regress problem (also known as Agrippa's Trilemma) is the problem of providing a complete logical foundation for human knowledge. The traditional way of supporting a rational argument is to appeal to other rational arguments, typically using chains of reason and rules of logic. A classic example that goes back to Aristotle is deducing that Socrates is mortal. We have a logical rule that says All humans are mortal and an assertion that Socrates is human and we deduce that Socrates is mortal. In this example how do we know that Socrates is human? Presumably we apply other rules such as: All born from human females are human. Which then leaves open the question how do we know that all born from humans are human? This is the regress problem: how can we eventually terminate a logical argument with some statements that do not require further justification but can still be considered rational and justified? As John Pollock stated:  ... to justify a belief one must appeal to a further justified belief. This means that one of two things can be the case. Either there are some beliefs that we can be justified for holding, without being able to justify them on the basis of any other belief, or else for each justified belief there is an infinite regress of (potential) justification [the nebula theory]. On this theory there is no rock bottom of justification. Justification just meanders in and out through our network of beliefs, stopping nowhere.[57]  The apparent impossibility of completing an infinite chain of reasoning is thought by some to support skepticism. It is also the impetus for Descartes' famous dictum: I think, therefore I am. Descartes was looking for some logical statement that could be true without appeal to other statements.  Responses to the regress problem Many epistemologists studying justification have attempted to argue for various types of chains of reasoning that can escape the regress problem.  Foundationalism Foundationalists respond to the regress problem by asserting that certain "foundations" or "basic beliefs" support other beliefs but do not themselves require justification from other beliefs. These beliefs might be justified because they are self-evident, infallible, or derive from reliable cognitive mechanisms. Perception, memory, and a priori intuition are often considered possible examples of basic beliefs.  The chief criticism of foundationalism is that if a belief is not supported by other beliefs, accepting it may be arbitrary or unjustified.[58]  Coherentism Another response to the regress problem is coherentism, which is the rejection of the assumption that the regress proceeds according to a pattern of linear justification. To avoid the charge of circularity, coherentists hold that an individual belief is justified circularly by the way it fits together (coheres) with the rest of the belief system of which it is a part. This theory has the advantage of avoiding the infinite regress without claiming special, possibly arbitrary status for some particular class of beliefs. Yet, since a system can be coherent while also being wrong, coherentists face the difficulty of ensuring that the whole system corresponds to reality. Additionally, most logicians agree that any argument that is circular is, at best, only trivially valid. That is, to be illuminating, arguments must operate with information from multiple premises, not simply conclude by reiterating a premise.  Nigel Warburton writes in Thinking from A to Z that "[c]ircular arguments are not invalid; in other words, from a logical point of view there is nothing intrinsically wrong with them. However, they are, when viciously circular, spectacularly uninformative."[59]  Infinitism An alternative resolution to the regress problem is known as "infinitism". Infinitists take the infinite series to be merely potential, in the sense that an individual may have indefinitely many reasons available to them, without having consciously thought through all of these reasons when the need arises. This position is motivated in part by the desire to avoid what is seen as the arbitrariness and circularity of its chief competitors, foundationalism and coherentism. The most prominent defense of infinitism has been given by Peter Klein.[60]  Foundherentism An intermediate position, known as "foundherentism", is advanced by Susan Haack. Foundherentism is meant to unify foundationalism and coherentism. Haack explains the view by using a crossword puzzle as an analogy. Whereas, for example, infinitists regard the regress of reasons as taking the form of a single line that continues indefinitely, Haack has argued that chains of properly justified beliefs look more like a crossword puzzle, with various different lines mutually supporting each other.[61] Thus, Haack's view leaves room for both chains of beliefs that are "vertical" (terminating in foundational beliefs) and chains that are "horizontal" (deriving their justification from coherence with beliefs that are also members of foundationalist chains of belief).  Philosophical skepticism Main article: Philosophical skepticism Epistemic skepticism questions whether knowledge is possible at all. Generally speaking, skeptics argue that knowledge requires certainty, and that most or all of our beliefs are fallible (meaning that our grounds for holding them always, or almost always, fall short of certainty), which would together entail that knowledge is always or almost always impossible for us.[62] Characterizing knowledge as strong or weak is dependent on a person's viewpoint and their characterization of knowledge.[62] Much of modern epistemology is derived from attempts to better understand and address philosophical skepticism.[63]  Pyrrhonism Main article: Pyrrhonism One of the oldest forms of epistemic skepticism can be found in Agrippa's trilemma (named after the Pyrrhonist philosopher Agrippa the Skeptic) which demonstrates that certainty can not be achieved with regard to beliefs.[64] Pyrrhonism dates back to Pyrrho of Elis from the 4th century BCE, although most of what we know about Pyrrhonism today is from the surviving works of Sextus Empiricus.[64] Pyrrhonists claim that for any argument for a non-evident proposition, an equally convincing argument for a contradictory proposition can be produced. Pyrrhonists do not dogmatically deny the possibility of knowledge, but instead point out that beliefs about non-evident matters cannot be substantiated.  Cartesian skepticism The Cartesian evil demon problem, first raised by René Descartes,[note 3] supposes that our sensory impressions may be controlled by some external power rather than the result of ordinary veridical perception.[65] In such a scenario, nothing we sense would actually exist, but would instead be mere illusion. As a result, we would never be able to know anything about the world, since we would be systematically deceived about everything. The conclusion often drawn from evil demon skepticism is that even if we are not completely deceived, all of the information provided by our senses is still compatible with skeptical scenarios in which we are completely deceived, and that we must therefore either be able to exclude the possibility of deception or else must deny the possibility of infallible knowledge (that is, knowledge which is completely certain) beyond our immediate sensory impressions.[66] While the view that no beliefs are beyond doubt other than our immediate sensory impressions is often ascribed to Descartes, he in fact thought that we can exclude the possibility that we are systematically deceived, although his reasons for thinking this are based on a highly contentious ontological argument for the existence of a benevolent God who would not allow such deception to occur.[65]  Responses to philosophical skepticism Epistemological skepticism can be classified as either "mitigated" or "unmitigated" skepticism. Mitigated skepticism rejects "strong" or "strict" knowledge claims but does approve weaker ones, which can be considered "virtual knowledge", but only with regard to justified beliefs. Unmitigated skepticism rejects claims of both virtual and strong knowledge.[62] Characterizing knowledge as strong, weak, virtual or genuine can be determined differently depending on a person's viewpoint as well as their characterization of knowledge.[62] Some of the most notable attempts to respond to unmitigated skepticism include direct realism, disjunctivism, common sense philosophy, pragmatism, fideism, and fictionalism.[67]  Schools of thought in epistemology Empiricism  David Hume, one of the most staunch defenders of empiricism. Main article: Empiricism Empiricism is a view in the theory of knowledge which focuses on the role of experience, especially experience based on perceptual observations by the senses, in the generation of knowledge.[68] Certain forms exempt disciplines such as mathematics and logic from these requirements.[69]  There are many variants of empiricism, including British empiricism, logical empiricism, phenomenalism, and some versions of common sense philosophy. Most forms of empiricism give epistemologically privileged status to sensory impressions or sense data, although this plays out very differently in different cases. Some of the most famous historical empiricists include John Locke, David Hume, George Berkeley, Francis Bacon, John Stuart Mill, Rudolf Carnap, and Bertrand Russell.  Rationalism Main article: Rationalism Rationalism is the epistemological view that reason is the chief source of knowledge and the main determinant of what constitutes knowledge. More broadly, it can also refer to any view which appeals to reason as a source of knowledge or justification. Rationalism is one of the two classical views in epistemology, the other being empiricism. Rationalists claim that the mind, through the use of reason, can directly grasp certain truths in various domains, including logic, mathematics, ethics, and metaphysics. Rationalist views can range from modest views in mathematics and logic (such as that of Gottlob Frege) to ambitious metaphysical systems (such as that of Baruch Spinoza).  Some of the most famous rationalists include Plato, René Descartes, Baruch Spinoza, and Gottfried Leibniz.  Skepticism Main article: Philosophical skepticism Skepticism is a position that questions the possibility of human knowledge, either in particular domains or on a general level.[63] Skepticism does not refer to any one specific school of philosophy, but is rather a thread that runs through many epistemological debates. Ancient Greek skepticism began during the Hellenistic period in philosophy, which featured both Pyrrhonism (notably defended by Pyrrho and Sextus Empiricus) and Academic skepticism (notably defended by Arcesilaus and Carneades). Among ancient Indian philosophers, skepticism was notably defended by the Ajñana school and in the Buddhist Madhyamika tradition. In modern philosophy, René Descartes' famous inquiry into mind and body began as an exercise in skepticism, in which he started by trying to doubt all purported cases of knowledge in order to search for something that was known with absolute certainty.[70]  Pragmatism Main article: Pragmatism Pragmatism is an empiricist epistemology formulated by Charles Sanders Peirce, William James, and John Dewey, which understands truth as that which is practically applicable in the world. Pragmatists often treat "truth" as the final outcome of ideal scientific inquiry, meaning that something cannot be true unless it is potentially observable.[note 4] Peirce formulates the maxim: 'Consider what effects, that might conceivably have practical bearings, we conceive the object of our conception to have. Then, our conception of these effects is the whole of our conception of the object.'[71] This suggests that we are to analyse ideas and objects in the world for their practical value.[clarification needed] This is in contrast to any correspondence theory of truth that holds that what is true is what corresponds to an external reality. William James suggests that through a pragmatist epistemology, theories "become instruments, not answers to enigmas in which we can rest."[72]  Contemporary versions of pragmatism have been most notably developed by Richard Rorty and Hilary Putnam. Rorty proposed that values were historically contingent and dependent upon their utility within a given historical period,[73] Contemporary philosophers working in pragmatism are called neopragmatists, and also include Nicholas Rescher, Robert Brandom, Susan Haack, and Cornel West.  Naturalized epistemology Main article: Naturalized epistemology In certain respects an intellectual descendant of pragmatism, naturalized epistemology considers the evolutionary role of knowledge for agents living and evolving in the world.[74] It de-emphasizes the questions around justification and truth, and instead asks, empirically, how reliable beliefs are formed and the role that evolution played in the development of such processes. It suggests a more empirical approach to the subject as a whole, leaving behind philosophical definitions and consistency arguments, and instead using psychological methods to study and understand how "knowledge" is actually formed and is used in the natural world. As such, it does not attempt to answer the analytic questions of traditional epistemology, but rather replace them with new empirical ones.[75]  Naturalized epistemology was first proposed in "Epistemology Naturalized", a seminal paper by W.V.O. Quine.[74] A less radical view has been defended by Hilary Kornblith in Knowledge and its Place in Nature, in which he seeks to turn epistemology towards empirical investigation without completely abandoning traditional epistemic concepts.[44]  Feminist epistemology Main article: Feminist epistemology Feminist epistemology is a subfield of epistemology which applies feminist theory to epistemological questions. It began to emerge as a distinct subfield in the 20th century. Prominent feminist epistemologists include Miranda Fricker (who developed the concept of epistemic injustice), Donna Haraway (who first proposed the concept of situated knowledge), Sandra Harding, and Elizabeth Anderson.[76] Harding proposes that feminist epistemology can be broken into three distinct categories: Feminist empiricism, standpoint epistemology, and postmodern epistemology.  Feminist epistemology has also played a significant role in the development of many debates in social epistemology.[77]  Epistemic relativism Main article: Relativism Epistemic relativism is the view that what is true, rational, or justified for one person need not be true, rational, or justified for another person. Epistemic relativists therefore assert that while there are relative facts about truth, rationality, justification, and so on, there is no perspective-independent fact of the matter.[78] Note that this is distinct from epistemic contextualism, which holds that the meaning of epistemic terms vary across contexts (e.g. "I know" might mean something different in everyday contexts and skeptical contexts). In contrast, epistemic relativism holds that the relevant facts vary, not just linguistic meaning. Relativism about truth may also be a form of ontological relativism, insofar as relativists about truth hold that facts about what exists vary based on perspective.[78]  Epistemic constructivism Main article: Social constructivism Constructivism is a view in philosophy according to which all "knowledge is a compilation of human-made constructions",[79] "not the neutral discovery of an objective truth".[80] Whereas objectivism is concerned with the "object of our knowledge", constructivism emphasizes "how we construct knowledge".[81] Constructivism proposes new definitions for knowledge and truth, which emphasize intersubjectivity rather than objectivity, and viability rather than truth. The constructivist point of view is in many ways comparable to certain forms of pragmatism.[82]  Epistemic idealism Main article: Idealism Idealism is a broad term referring to both an ontological view about the world being in some sense mind-dependent and a corresponding epistemological view that everything we know can be reduced to mental phenomena. First and foremost, "idealism" is a metaphysical doctrine. As an epistemological doctrine, idealism shares a great deal with both empiricism and rationalism. Some of the most famous empiricists have been classified as idealists (particularly Berkeley), and yet the subjectivism inherent to idealism also resembles that of Descartes in many respects. Many idealists believe that knowledge is primarily (at least in some areas) acquired by a priori processes, or that it is innate—for example, in the form of concepts not derived from experience.[83] The relevant theoretical concepts may purportedly be part of the structure of the human mind (as in Kant's theory of transcendental idealism), or they may be said to exist independently of the mind (as in Plato's theory of Forms).  Some of the most famous forms of idealism include transcendental idealism (developed by Immanuel Kant), subjective idealism (developed by George Berkeley), and absolute idealism (developed by Georg Wilhelm Friedrich Hegel and Friedrich Schelling).  Bayesian epistemology Bayesian epistemology is a formal approach to various topics in epistemology that has its roots in Thomas Bayes' work in the field of probability theory. One advantage of its formal method in contrast to traditional epistemology is that its concepts and theorems can be defined with a high degree of precision. It is based on the idea that beliefs can be interpreted as subjective probabilities. As such, they are subject to the laws of probability theory, which act as the norms of rationality. These norms can be divided into static constraints, governing the rationality of beliefs at any moment, and dynamic constraints, governing how rational agents should change their beliefs upon receiving new evidence. The most characteristic Bayesian expression of these principles is found in the form of Dutch books, which illustrate irrationality in agents through a series of bets that lead to a loss for the agent no matter which of the probabilistic events occurs. Bayesians have applied these fundamental principles to various epistemological topics but Bayesianism does not cover all topics of traditional epistemology.[84][85][86][87]  Indian pramana Main article: Pramana Indian schools of philosophy, such as the Hindu Nyaya and Carvaka schools, and the Jain and Buddhist philosophical schools, developed an epistemological tradition independently of the Western philosophical tradition called "pramana". Pramana can be translated as "instrument of knowledge" and refers to various means or sources of knowledge that Indian philosophers held to be reliable. Each school of Indian philosophy had their own theories about which pramanas were valid means to knowledge and which were unreliable (and why).[88] A Vedic text, Taittirīya Āraṇyaka (c. 9th–6th centuries BCE), lists "four means of attaining correct knowledge": smṛti ("tradition" or "scripture"), pratyakṣa ("perception"), aitihya ("communication by one who is expert", or "tradition"), and anumāna ("reasoning" or "inference").[89][90]  In the Indian traditions, the most widely discussed pramanas are: Pratyakṣa (perception), Anumāṇa (inference), Upamāṇa (comparison and analogy), Arthāpatti (postulation, derivation from circumstances), Anupalabdi (non-perception, negative/cognitive proof) and Śabda (word, testimony of past or present reliable experts). While the Nyaya school (beginning with the Nyāya Sūtras of Gotama, between 6th-century BCE and 2nd-century CE[91][92]) were a proponent of realism and supported four pramanas (perception, inference, comparison/analogy and testimony), the Buddhist epistemologists (Dignaga and Dharmakirti) generally accepted only perception and inference. The Carvaka school of materialists only accepted the pramana of perception, and hence were among the first empiricists in the Indian traditions.[93] Another school, the Ajñana, included notable proponents of philosophical skepticism.  The theory of knowledge of the Buddha in the early Buddhist texts has been interpreted as a form of pragmatism as well as a form of correspondence theory.[94] Likewise, the Buddhist philosopher Dharmakirti has been interpreted both as holding a form of pragmatism or correspondence theory for his view that what is true is what has effective power (arthakriya).[95][96] The Buddhist Madhyamika school's theory of emptiness (shunyata) meanwhile has been interpreted as a form of philosophical skepticism.[97]  The main contribution to epistemology by the Jains has been their theory of "many sided-ness" or "multi-perspectivism" (Anekantavada), which says that since the world is multifaceted, any single viewpoint is limited (naya – a partial standpoint).[98] This has been interpreted as a kind of pluralism or perspectivism.[99][100] According to Jain epistemology, none of the pramanas gives absolute or perfect knowledge since they are each limited points of view.  Domains of inquiry in epistemology Social epistemology Main article: Social epistemology Social epistemology deals with questions about knowledge in contexts where our knowledge attributions cannot be explained by simply examining individuals in isolation from one another, meaning that the scope of our knowledge attributions must be widened to include broader social contexts.[101] It also explores the ways in which interpersonal beliefs can be justified in social contexts.[101] The most common topics discussed in contemporary social epistemology are testimony, which deals with the conditions under which a belief "x is true" which resulted from being told "x is true" constitutes knowledge; peer disagreement, which deals with when and how I should revise my beliefs in light of other people holding beliefs that contradict mine; and group epistemology, which deals with what it means to attribute knowledge to groups rather than individuals, and when group knowledge attributions are appropriate.  Formal epistemology Main article: Formal epistemology Formal epistemology uses formal tools and methods from decision theory, logic, probability theory and computability theory to model and reason about issues of epistemological interest.[102] Work in this area spans several academic fields, including philosophy, computer science, economics, and statistics. The focus of formal epistemology has tended to differ somewhat from that of traditional epistemology, with topics like uncertainty, induction, and belief revision garnering more attention than the analysis of knowledge, skepticism, and issues with justification.  Metaepistemology Main article: Metaepistemology Metaepistemology is the metaphilosophical study of the methods, aims, and subject matter of epistemology.[103] In general, metaepistemology aims to better understand our first-order epistemological inquiry. Some goals of metaepistemology are identifying inaccurate assumptions made in epistemological debates and determining whether the questions asked in mainline epistemology are the right epistemological questions to be asking.  See also 	Philosophy portal For a topical guide to this subject, see Outline of epistemology. Epistemological pluralism Evolutionary epistemology Feminist epistemology Knowledge-first epistemology Moral epistemology Noölogy Reformed epistemology Self-evidence Sociology of knowledge Virtue epistemology References Notes  In Scots, the distinction is between wit and ken). In French, Portuguese, Spanish, Romanian, German and Dutch 'to know (a person)' is translated using connaître, conhecer, conocer, a cunoaște and kennen (both German and Dutch) respectively, whereas 'to know (how to do something)' is translated using savoir, saber (both Portuguese and Spanish), a şti, wissen, and weten. Modern Greek has the verbs γνωρίζω (gnorízo) and ξέρω (kséro). Italian has the verbs conoscere and sapere and the nouns for 'knowledge' are conoscenza and sapienza. German has the verbs wissen and kennen; the former implies knowing a fact, the latter knowing in the sense of being acquainted with and having a working knowledge of; there is also a noun derived from kennen, namely Erkennen, which has been said to imply knowledge in the form of recognition or acknowledgment.[18] The verb itself implies a process: you have to go from one state to another, from a state of "not-erkennen" to a state of true erkennen. This verb seems the most appropriate in terms of describing the "episteme" in one of the modern European languages, hence the German name "Erkenntnistheorie".  See the main page on epistemic justification for other views on whether or not justification is a necessary condition for knowledge.  Skeptical scenarios in a similar vein date back to Plato's Allegory of the Cave, although Plato's Allegory was quite different in both presentation and interpretation. In contemporary philosophical literature, something akin to evil demon skepticism is presented in brain in a vat scenarios. See also the New Evil Demon Problem (IEP).  Compare to verificationism. Citations  "Epistemology". Encyclopedia Britannica. Retrieved 22 June 2020.  Steup, Matthias (2005). Zalta, Edward N. (ed.). "Epistemology". Stanford Encyclopedia of Philosophy (Spring 2014 ed.).  "Epistemology". Internet Encyclopedia of Philosophy. Retrieved 10 June 2020.  Borchert, Donald M., ed. (1967). "Epistemology". Encyclopedia of Philosophy. 3. Macmillan.  Carl J. Wenning. "Scientific epistemology: How scientists know what they know" (PDF).  "Epistemology". Stanford Encyclopedia of Philosophy. Retrieved 30 June 2020.  "The Epistemology of Ethics". 1 September 2011.[better source needed]  "Epistemology". Oxford English Dictionary (3rd ed.). Oxford University Press. 2014.  anonymous (November 1847). "Jean-Paul Frederich Richter". The Eclectic Magazine of Foreign Literature, Science and Art. 12: 317. hdl:2027/iau.31858055206621..  Ferrier, James Frederick (1854). Institutes of metaphysic: the theory of knowing and being. Edinburgh: W. Blackwood. p. 46. Retrieved 21 June 2018.  Meyerson, Émile (1908). Identité et réalité. Paris: F. Alcan. p. i. Retrieved 21 June 2018.. See also Suchting, Wal. "Epistemology". Historical Materialism: 331–345.  Locke, John (1689). "Introduction". An Essay Concerning Human Understanding.  Kant, Immanuel (1787). Critique of Pure Reason.  Sturm, Thomas (2011). "Historical Epistemology or History of Epistemology? The Case of the Relation Between Perception and Judgment". Erkenntnis. 75 (3): 303–324. doi:10.1007/s10670-011-9338-3. S2CID 142375514.  Stroud, Barry (2011). "The History of Epistemology". Erkenntnis. 75 (3): 495–503. doi:10.1007/s10670-011-9337-4. S2CID 143497596.  John Bengson (Editor), Marc A. Moffett (Editor): Essays on Knowledge, Mind, and Action. New York: Oxford University Press. 2011  For example, Talbert, Bonnie (2015). "Knowing Other People". Ratio. 28 (2): 190–206. doi:10.1111/rati.12059. and Benton, Matthew (2017). "Epistemology Personalized". The Philosophical Quarterly. 67 (269): 813–834. doi:10.1093/pq/pqx020.  For related linguistic data, see Benton, Matthew (2017). "Epistemology Personalized". The Philosophical Quarterly. 67 (269): 813–834. doi:10.1093/pq/pqx020., esp. Section 1.  "A Priori Justification and Knowledge". Stanford Encyclopedia of Philosophy. Retrieved 6 July 2020.  "Belief". Stanford Encyclopedia of Philosophy. Retrieved 22 June 2020.  "Formal Representations of Belief". Stanford Encyclopedia of Philosophy. Retrieved 22 June 2020.  "Truth". Stanford Encyclopedia of Philosophy. Retrieved 29 June 2020.  Gorgias. Project Gutenberg. 5 October 2008. Retrieved 31 March 2017.  Benardete, Seth (1984). The Being of the Beautiful. Chicago: The University of Chicago Press. p. I.169. ISBN 978-0-226-67038-6.  Benardete, Seth (1984). The Being of the Beautiful. Chicago: The University of Chicago Press. p. I.175. ISBN 978-0-226-67038-6.  Edmund L. Gettier, "Is Justified True Belief Knowledge?" Analysis, Vol. 23, pp. 121–123 (1963). doi:10.1093/analys/23.6.121  "The Analysis of Knowledge". Stanford Encyclopedia of Philosophy. Retrieved 12 June 2020.  Descartes, Rene (1985). The Philosophical Writings of Rene Descartes Vol. I. Cambridge University Press. ISBN 978-0-521-28807-1.  Descartes, Rene (1985). Philosophical Writings of Rene Descartes Vol. II. Cambridge University Press. ISBN 978-0-521-28808-8.  Descartes, Rene (1985). The Philosophical Writings of Rene Descartes. Cambridge University Press. ISBN 978-0-521-28808-8.  Gettier, Edmund (1963). "Is Justified True Belief Knowledge?" (PDF). Analysis. 23 (6): 121–123. doi:10.2307/3326922. JSTOR 3326922.  Armstrong, D.M. (1973). Belief, Truth, and Knowledge. Cambridge: Cambridge University Press. p. 152.  Goldman, Alvin I. (1979). "Reliabilism: What Is Justified Belief?". In Pappas, G.S. (ed.). Justification and Knowledge. Dordrecht, Holland: Reidel. p. 11. ISBN 978-90-277-1024-6.  Goldman, Alan H. (December 1976). "Appearing as Irreducible in Perception". Philosophy and Phenomenological Research. 37 (2): 147–164. doi:10.2307/2107188. JSTOR 2107188.  Richard L. Kirkham (1984). "Does the Gettier Problem Rest on a Mistake?" (PDF). Mind. 93 (372): 501–513. doi:10.1093/mind/XCIII.372.501. Archived from the original (PDF) on 29 May 2010.  "Epistemic Contextualism". Stanford Encyclopedia of Philosophy. Retrieved 20 June 2020.  "Certainty". Stanford Encyclopedia of Philosophy. Retrieved 20 June 2020.  Bimal Krishna Matilal (1986). Perception: An essay on Classical Indian Theories of Knowledge. Oxford India 2002. ISBN 978-0-19-824625-1. The Gettier problem is dealt with in Chapter 4, Knowledge as a mental episode. The thread continues in the next chapter Knowing that one knows. It is also discussed in Matilal's Word and the World p. 71–72.  Robert Nozick (1981). Philosophical Explanations. Harvard University Press. ISBN 978-0-674-66448-7.Philosophical Explanations Chapter 3 "Knowledge and Skepticism" I. Knowledge Conditions for Knowledge pp. 172–178.  D.M. Armstrong (1973). Belief, Truth and Knowledge. Cambridge University Press. ISBN 978-0-521-09737-6.  Blackburn, Simon (1999). Think: A compelling introduction to philosophy. Oxford University Press. ISBN 978-0-19-976984-1.  Nagel, Jennifer (25 April 2013), "Knowledge as a Mental State", Oxford Studies in Epistemology Volume 4, Oxford University Press, pp. 272–308, doi:10.1093/acprof:oso/9780199672707.003.0010, ISBN 978-0-19-967270-7  Brueckner, Anthony (2002). "Williamson on the primeness of knowing". Analysis. 62 (275): 197–202. doi:10.1111/1467-8284.00355. ISSN 1467-8284.  Kornblith, Hilary (2002). Knowledge and its Place in Nature. Oxford University Press.  Plato (2002). Five Dialogues. Indianapolis, IN: Hackett Pub. Co. pp. 89–90, 97b–98a. ISBN 978-0-87220-633-5.  Pritchard, Duncan; Turri, John. "The Value of Knowledge". Stanford Encyclopedia of Philosophy. Retrieved 24 February 2016.  Pritchard, Duncan (April 2007). "Recent Work on Epistemic Value". American Philosophical Quarterly. 44 (2): 85–110. JSTOR 20464361.  Kvanvig, Jonathan L. (2003). The Value of Knowledge and the Pursuit of Understanding. Cambridge University Press. ISBN 9781139442282.[page needed]  Zagzebski, Linda. "The Search for the Source of Epistemic Good" (PDF). Metaphilosophy. 34 (1/2): 13.  Goldman, Alvin I. & Olsson, E.J. (2009). "Reliabilism and the Value of Knowledge". In Haddock, A.; Millar, A. & Pritchard, D. (eds.). Epistemic Value. Oxford University Press. p. 24. ISBN 978-0-19-923118-8.  Kvanvig, Jonathan (2003). The Value of Knowledge and the Pursuit of Understanding. Cambridge; New York: Cambridge University Press. p. 5. ISBN 978-0-521-03786-0.  Kvanvig, Jonathan (2003). The Value of Knowledge and the Pursuit of Understanding. Cambridge; New York: Cambridge University Press. ISBN 978-0-521-03786-0.  BonJour, Laurence, 1985, The Structure of Empirical Knowledge, Cambridge, MA: Harvard University Press.  Wilson, E.O., Sociobiology: The New Synthesis. Cambridge, Massachusetts: The Belknap Press of Harvard University Press. 1975  "The Analytic/Synthetic Distinction". Stanford Encyclopedia of Philosophy. Retrieved 7 July 2020.  Russell, G.: Truth in Virtue of Meaning: A Defence of the Analytic/Synthetic Distinction. Oxford: Oxford University Press. 2008  John L. Pollock (1975). Knowledge and Justification. Princeton University Press, Princeton, New Jersey. ISBN 978-0-691-07203-6. p. 26.  Zalta, Edward N. (ed.). "Foundational Theories of Epistemic Justification". Stanford Encyclopedia of Philosophy.  Warburton, Nigel (1996). Thinking from A to Z. Routledge. ISBN 978-0415433716.  Klein, Peter D.; Turri, John. "Infinitism in Epistemology". Internet Encyclopedia of Philosophy. Retrieved 8 June 2020.  Haack, Susan (1993). Evidence and Inquiry: Towards Reconstruction in Epistemology. Wiley-Blackwell. ISBN 978-0-631-19679-2.  "Skepticism". Encyclopedia of Empiricism. 1997.  Klein, Peter (2015), "Skepticism", in Zalta, Edward N. (ed.), The Stanford Encyclopedia of Philosophy (Summer 2015 ed.), Metaphysics Research Lab, Stanford University, retrieved 1 October 2018  "Ancient Skepticism". Stanford Encyclopedia of Philosophy.  "Descartes' Epistemology". Stanford Encyclopedia of Philosophy. Retrieved 16 June 2020.  "Descartes". Internet Encyclopedia of Philosophy. Retrieved 16 June 2020.  Peter Suber, "Classical Skepticism"  Psillos, Stathis; Curd, Martin (2010). The Routledge companion to philosophy of science (1. publ. in paperback ed.). London: Routledge. pp. 129–138. ISBN 978-0-415-54613-3.  Uebel, Thomas (2015). Empiricism at the Crossroads: The Vienna Circle's Protocol-Sentence Debate Revisited. Open Court. p. 14. ISBN 978-0-8126-9929-6.  Popkin, Richard (1972). "Skepticism". In Edwards, Paul (ed.). Encyclopedia of Philosophy Volume 7. Macmillan. pp. 449–461. ISBN 978-0-02-864651-0.  "How to Make Our Ideas Clear". Archived from the original on 3 October 2018. Retrieved 15 February 2018.  James, W. and Gunn, G. (2000). Pragmatism and other essays. New York: Penguin Books.  Rorty, R. and Saatkamp, H. (n.d.). Rorty & Pragmatism. Nashville [u.a.]: Vanderbilt Univ. Press.  Quine, Willard (2004). "Epistemology Naturalized". In E. Sosa & J. Kim (ed.). Epistemology: An Anthology. Malden, MA: Blackwell Publishing. pp. 292–300. ISBN 978-0-631-19724-9.  Kim, Jaegwon (1988). "What Is Naturalized Epistemology?". Philosophical Perspectives. 2: 381–405. doi:10.2307/2214082. JSTOR 2214082.  "Feminist Epistemology". Stanford Encyclopedia of Philosophy. Retrieved 17 June 2020.  "Feminist Social Epistemology". Stanford Encyclopedia of Philosophy. Retrieved 17 June 2020.  Boghossian, Paul (2006). Fear of Knowledge. Oxford: Oxford University Press.  Raskin, J.D. (2002). Constructivism in psychology: Personal construct psychology, radical constructivism, and social constructivism. In J.D. Raskin & S.K. Bridges (Eds.), Studies in meaning: Exploring constructivist psychology (pp. 1–25). New York: Pace University Press. p. 4  Castelló M., & Botella, L. (2006). Constructivism and educational psychology. In J.L. Kincheloe & R.A. Horn (Eds.), The Praeger handbook of education and psychology (Vol. 2, pp. 263–270). Westport, CT: Praeger. p. 263  Jonassen, David H. (1991). "Objectivism versus constructivism: Do we need a new philosophical paradigm?". Educational Technology Research and Development. 39 (3): 5–14. doi:10.1007/bf02296434. S2CID 53412771.  For an example, see Weber, Eric Thomas. 2010. Rawls, Dewey, and Constructivism: On the Epistemology of Justice (London: Continuum).  Markie, Peter. "Rationalism vs. Empiricism". The Stanford Encyclopedia of Philosophy. Stanford University. Retrieved 17 July 2012.  Talbott, William (2016). "Bayesian Epistemology". The Stanford Encyclopedia of Philosophy. Metaphysics Research Lab, Stanford University. Retrieved 6 March 2021.  Olsson, Erik J. (2018). "Bayesian Epistemology". Introduction to Formal Philosophy. Springer. pp. 431–442.  Hartmann, Stephan; Sprenger, Jan (2010). "Bayesian Epistemology". The Routledge Companion to Epistemology. London: Routledge. pp. 609–620.  Hájek, Alan; Lin, Hanti (2017). "A Tale of Two Epistemologies?". Res Philosophica. 94 (2): 207–232. doi:10.5840/resphilosophica201794264 (inactive 30 May 2021).  James Lochtefeld, "Pramana" in The Illustrated Encyclopedia of Hinduism, Vol. 2: N–Z, Rosen Publishing. ISBN 0-8239-2287-1, pp. 520–521  A.B. Keith (1989), The Religion and Philosophy of the Veda and Upanishads, Part II, p.482  S. C. Vidyabhusana (1971). A History of Indian Logic: Ancient, Mediaeval, and Modern Schools, p.23  Jeaneane Fowler (2002), Perspectives of Reality: An Introduction to the Philosophy of Hinduism, Sussex Academic Press, ISBN 978-1-898723-94-3, p. 129  B.K. Matilal "Perception. An Essay on Classical Indian Theories of Knowledge" (Oxford University Press, 1986), p. xiv.  MM Kamal (1998), The Epistemology of the Cārvāka Philosophy, Journal of Indian and Buddhist Studies, 46(2): 13–16  Jayatilleke, K.N.; Early Buddhist Theory of Knowledge, p. 356  Cabezón, José I., 2000, "Truth in Buddhist Theology," in R. Jackson and J. Makransky, (eds.), Buddhist Theology, Critical Reflections by Contemporary Buddhist Scholars. London: Curzon, 136–154.  Tom Tillemans (2011), Dharmakirti, Stanford Encyclopedia of Philosophy  Arnold, Dan; Buddhists, Brahmins, and Belief: Epistemology in South Asian Philosophy of belief and religion, p. 132.  Griffin, David Ray (2005) p. 145  Stroud, Scott R; Anekantavada and Engaged Rhetorical Pluralism: Explicating Jaina Views on Perspectivism, Violence, and Rhetoric.  D. Long, Jeffery; Jainism: An Introduction 125.  Goldman, Alvin; Blanchard, Thomas (2015). "Social Epistemology". In Zalta, Edward N. (ed.). Stanford Encyclopedia of Philosophy.  "Formal Epistemology". Stanford Encyclopedia of Philosophy. Retrieved 6 July 2020.  Gerken, Mikkel (2016). "Metaepistemology". Routledge Encyclopedia of Philosophy (1 ed.). London: Routledge. ISBN 978-0-415-25069-6. Retrieved 24 May 2021. Sources Works cited Annis, David (1978). "A Contextualist Theory of Epistemic Justification". American Philosophical Quarterly. 15: 213–219. Ayer, Alfred Jules. 1936. Language, Truth, and Logic. BonJour, Laurence. 2002. Epistemology: Classic Problems and Contemporary Responses. Lanham, MD: Rowman & Littlefield. Bovens, Luc & Hartmann, Stephan. 2003. Bayesian Epistemology. Oxford: Oxford University Press. Butchvarov, Panayot. 1970. The Concept of Knowledge. Evanston, Northwestern University Press. Cohen, Stewart (1998). "Contextualist Solutions to Epistemological Problems: Skepticism, Gettier, and the Lottery". Australasian Journal of Philosophy. 76 (2): 289–306. doi:10.1080/00048409812348411. Cohen, Stewart. 1999. "Contextualism, Skepticism, and Reasons", in Tomberlin 1999. Dancy, Jonathan. 1991. An Introduction to Contemporary Epistemology (Second Edition). John Wiley & Sons. ISBN 0-631-13622-3 DeRose, Keith (1992). "Contextualism and Knowledge Attributions". Philosophy and Phenomenological Research. 15: 213–219. DeRose, Keith. 1999. "Contextualism: An Explanation and Defense", in Greco and Sosa 1999. Descartes, Rene. 1641. Meditations on First Philosophy Feldman, Richard. 1999. "Contextualism and Skepticism", in Tomberlin 1999, pp. 91–114. Gettier, Edmund. 1963. "Is Justified True Belief Knowledge?", Analysis, Vol. 23, pp. 121–123. Online text. Greco, J. & Sosa, E. 1999. Blackwell Guide to Epistemology, Blackwell Publishing. Harris, Errol E. 1970. Hypothesis And Perception, George Allen and Unwin, London, Reprinted 2002 Routledge, London. Harwood, Sterling (1989). "Taking Skepticism Seriously – And In Context". Philosophical Investigations. 12 (3): 223–233. doi:10.1111/j.1467-9205.1989.tb00275.x. Hay, Clare. 2008. The Theory of Knowledge: A Coursebook, The Lutterworth Press, Cambridge. ISBN 978-0-7188-3088-5 Hawthorne, John. 2005. "The Case for Closure", Contemporary Debates in Epistemology, Peter Sosa and Matthias Steup (ed.): 26–43. Hendricks, Vincent F. 2006. Mainstream and Formal Epistemology, New York: Cambridge University Press. Kant, Immanuel. 1781. Critique of Pure Reason. Keeton, Morris T. 1962. "Empiricism", in Dictionary of Philosophy, Dagobert D. Runes (ed.), Littlefield, Adams, and Company, Totowa, NJ, pp. 89–90. Kirkham, Richard. 1984. "Does the Gettier Problem Rest on a Mistake?" Mind, 93. Klein, Peter. 1981. Certainty: a Refutation of Skepticism, Minneapolis, MN: University of Minnesota Press. Kyburg, H.E. 1961. Probability and the Logic of Rational Belief, Middletown, CT: Wesleyan University Press. Korzybski, Alfred. 1994 (1933). Science and Sanity: An Introduction to Non-Aristotelian Systems and General Semantics, Fifth Edition. Ft. Worth, TX: Institute of General Semantics. Lewis, David (1996). "Elusive Knowledge". Australasian Journal of Philosophy. 74 (4): 549–567. doi:10.1080/00048409612347521. Morin, Edgar. 1986. La Méthode, Tome 3, La Connaissance de la connaissance (Method, 3rd volume : The knowledge of knowledge) Morton, Adam. 2002. A Guide Through the Theory of Knowledge (Third Edition) Oxford: Blackwell Publishing. ISBN 1-4051-0012-5 Nelson, Quee. 2007. The Slightest Philosophy, Indianapolis, IN: Dog Ear Publishing, 296 pages. Niiniluoto, Ilkka. 2002. Critical Scientific Realism, Oxford: Oxford Univ. Press. Plato. Meno. Popper, Karl R. 1972. Objective Knowledge: An Evolutionary Approach, Oxford: Oxford Univ. Press. Preyer, G./Siebelt, F./Ulfig, A. 1994. Language, Mind and Epistemology, Dordrecht: Kluwer Academic Publishers. Russell, Bertrand. 1912. The Problems of Philosophy, New York: Oxford University Press. Russell, Bertrand. 1940. An Inquiry into Meaning and Truth, Nottingham: Spokesman Books. Santayana, George. 1923. Scepticism and Animal Faith, New York: Charles Scribner's Sons – London: Constable and Co. Spir, African. 1877. Denken und Wirklichkeit: Versuch einer Erneuerung der kritischen Philosophie (Thought and Reality: Attempt at a Renewal of Critical Philosophy), (Second Edition) Leipzig: J.G. Findel. Schiffer, Stephen (1996). "Contextualist Solutions to Skepticism". Proceedings of the Aristotelian Society. 96: 317–333. doi:10.1093/aristotelian/96.1.317. Steup, Matthias. 2005. "Knowledge and Skepticism", Contemporary Debates in Epistemology, Peter Sosa and Matthias Steup (eds.): 1–13. Tomberlin, James (ed.). 1999. Philosophical Perspectives 13, Epistemology, Blackwell Publishing. Turri, John (2016). Knowledge and the Norm of Assertion: An Essay in Philosophical Science. Cambridge: Open Book Publishers. Open Book Publishers. doi:10.11647/OBP.0083. ISBN 978-1-78374-183-0. Wittgenstein, Ludwig. 1922. Tractatus Logico-Philosophicus, Frank P. Ramsey and C.K. Ogden (trns.), Dover. Online text. External links Epistemology at Wikipedia's sister projects Definitions from Wiktionary Media from Wikimedia Commons Quotations from Wikiquote Texts from Wikisource Textbooks from Wikibooks Resources from Wikiversity Data from Wikidata Library resources about Epistemology Resources in your library Resources in other libraries Stanford Encyclopedia of Philosophy articles "Epistemology" entry in the Stanford Encyclopedia of Philosophy "Bayesian Epistemology" entry in the Stanford Encyclopedia of Philosophy "Evolutionary Epistemology" entry in the Stanford Encyclopedia of Philosophy "Feminist Epistemology and Philosophy of Science" entry in the Stanford Encyclopedia of Philosophy "Naturalized Epistemology" entry in the Stanford Encyclopedia of Philosophy "Social Epistemology" entry in the Stanford Encyclopedia of Philosophy "Virtue Epistemology" entry in the Stanford Encyclopedia of Philosophy "Knowledge How" entry in the Stanford Encyclopedia of Philosophy Internet Encyclopedia of Philosophy articles "Epistemology". Internet Encyclopedia of Philosophy. "Coherentism". Internet Encyclopedia of Philosophy. "Contextualism in Epistemology". Internet Encyclopedia of Philosophy. "Epistemic Circularity". Internet Encyclopedia of Philosophy. "Epistemic Justification". Internet Encyclopedia of Philosophy. "Epistemology of Perception". Internet Encyclopedia of Philosophy. "Ethnoepistemology". Internet Encyclopedia of Philosophy. "Evolutionary Epistemology". Internet Encyclopedia of Philosophy. "Fallibilism". Internet Encyclopedia of Philosophy. "Feminist Epistemology". Internet Encyclopedia of Philosophy. "Infinitism in Epistemology". Internet Encyclopedia of Philosophy. "Internalism and Externalism in Epistemology". Internet Encyclopedia of Philosophy. "Moral Epistemology". Internet Encyclopedia of Philosophy. "Naturalistic Epistemology". Internet Encyclopedia of Philosophy. "Virtue Epistemology". Internet Encyclopedia of Philosophy. "Understanding in Epistemology". Internet Encyclopedia of Philosophy. Encyclopedia Britannica Epistemology by Avrum Stroll and A.P. Martinich Other links The London Philosophy Study Guide offers many suggestions on what to read, depending on the student's familiarity with the subject: Epistemology & Methodology Epistemology at PhilPapers Knowledge-How at Philpapers Epistemology at the Indiana Philosophy Ontology Project What Is Epistemology? – a brief introduction to the topic by Keith DeRose. Justified True Belief and Critical Rationalism by Mathew Toll Epistemology Introduction, Part 1 and Part 2 by Paul Newall at the Galilean Library. Teaching Theory of Knowledge (1986) – Marjorie Clay (ed.), an electronic publication from The Council for Philosophical Studies. An Introduction to Epistemology by Paul Newall, aimed at beginners. A short film about epistemology, for beginners on YouTube vte Epistemology Articles related to epistemology Authority control Edit this at Wikidata Categories: Epistemology Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadEditView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikiquote  Languages Български Deutsch Ελληνικά Español Français Македонски Português Shqip Türkçe 106 more Edit links This page was last edited on 7 October 2021, at 15:09 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki   Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more Outline of philosophy From Wikipedia, the free encyclopedia Jump to navigationJump to search The following outline is provided as an overview of and topical guide to philosophy:  Philosophy is the study of general and fundamental problems concerning matters such as existence, knowledge, values, reason, mind, and language.[1][2] It is distinguished from other ways of addressing fundamental questions (such as mysticism, myth, or religion) by its critical, generally systematic approach and its reliance on rational argument.[3] It involves logical analysis of language and clarification of the meaning of words and concepts.  The word "philosophy" comes from the Greek philosophia (φιλοσοφία), which literally means "love of wisdom".[4][5][6]   Contents 1	Branches of philosophy 1.1	Aesthetics 1.2	Epistemology 1.3	Ethics 1.4	Logic 1.5	Metaphysics 1.6	Philosophy of mind 1.7	Philosophy of science 1.8	Other 2	Philosophic traditions by region 2.1	African philosophy 2.2	Eastern philosophy 2.3	Western philosophy 3	History of philosophy 3.1	Timeline of philosophy 3.2	Ancient and classical philosophy 3.3	Medieval and post-classical philosophy 3.4	Modern and contemporary philosophy 4	Philosophical schools of thought 4.1	Aesthetical movements 4.2	Epistemological stances 4.3	Ethical theories 4.4	Logical systems 4.5	Metaphysical stances 4.6	Political philosophies 4.7	Philosophy of language theories and stances 4.8	Philosophy of mind theories and stances 4.9	Philosophy of religion stances 4.10	Philosophy of science theories and stances 5	Philosophical literature 5.1	Reference works 6	Philosophers 7	See also 8	References 9	External links Branches of philosophy The branches of philosophy and their sub-branches that are used in contemporary philosophy.  Aesthetics Aesthetics is study of the nature of beauty, art, and taste, and the creation of personal kinds of truth  Applied aesthetics – application of the philosophy of aesthetics to art and culture. Epistemology Epistemology is the branch of philosophy that studies the source, nature and validity of knowledge.  Social epistemology – inquiry into the social aspects of knowledge. Formal epistemology – the application of formal models to study knowledge. Metaepistemology – studying the foundations of epistemology itself. Ethics Ethics – study of value and morality.  Applied ethics – philosophical examination, from a moral standpoint, of particular issues in private and public life that are matters of moral judgment. It is thus the attempts to use philosophical methods to identify the morally correct course of action in various fields of human life. Bioethics – study of the typically controversial ethical issues emerging from new situations and possibilities brought about by advances in biology and medicine. Environmental ethics – studies ethical issues concerning the non-human world. It exerts influence on a large range of disciplines including environmental law, environmental sociology, ecotheology, ecological economics, ecology and environmental geography. Medical ethics – studies ethical issues concerning medicine and medical research Professional ethics – ethics to improve professionalism Descriptive ethics – study of people's beliefs about morality Discourse ethics – discovery of ethical principles through the study of language Formal ethics – discovery of ethical principles through the application of logic Normative ethics – study of ethical theories that prescribe how people ought to act Metaethics – branch of ethics that seeks to understand the nature of ethical properties, statements, attitudes, and judgments Logic Logic – the systematic study of the form of valid inference and reasoning.  Classical logic Propositional logic First-order logic Second-order logic Higher-order logic Non-classical logic Description logic Digital logic Fuzzy logic Intuitionistic logic Many-valued logic Modal logic Alethic logic Deontic logic Doxastic logic Epistemic logic Temporal logic Paraconsistent logic Substructural logic Metaphysics Metaphysics – concerned with explaining the fundamental nature of being and the world that encompasses it.  Cosmology – the study of the nature and origins of the universe. Ontology – philosophical study of the nature of being, becoming, existence, or reality, as well as the basic categories of being and their relations. Meta-ontology – study of the ontological foundations of ontology itself. Philosophy of space and time – branch of philosophy concerned with the issues surrounding the ontology, epistemology, and character of space and time. Philosophy of mind Philosophy of mind – studies the nature of the mind, mental properties, consciousness, and their relationship to the physical body, particularly the brain.  Philosophy of action – theories about the processes causing willful human bodily movements of a more or less complex kind. This area of thought has attracted the strong interest of philosophers ever since Aristotle's Nicomachean Ethics (Third Book). Philosophy of self – The philosophy of self is the study of the many conditions of identity that make one subject of experience distinct from other experiences Philosophy of science Philosophy of science – the branch of philosophy dealing with the epistemology, methodology and foundations of science  Philosophy of anthropology Philosophy of archaeology Philosophy of biology Philosophy of chemistry Philosophy of computer science Philosophy of artificial intelligence Philosophy of geography Philosophy of medicine Philosophy of physics Interpretations of quantum mechanics Philosophy of social science Philosophy of economics Philosophy of psychology Other Meta-philosophy Philosophy of education Philosophy of history Philosophy of language Philosophy of law Philosophy of mathematics Philosophy of religion Political philosophy Environmental philosophy Philosophic traditions by region Regional variations of philosophy.  African philosophy Main article: African philosophy Africana philosophy Ethiopian philosophy Ubuntu philosophy Eastern philosophy Main article: Eastern philosophy Chinese philosophy Indian philosophy Indonesian philosophy Iranian philosophy Japanese philosophy Korean philosophy Vietnamese philosophy Western philosophy Main article: Western philosophy American philosophy Australian philosophy British philosophy Scottish philosophy Czech philosophy Dutch philosophy French philosophy German philosophy Italian philosophy Yugoslav philosophy History of philosophy Main article: History of philosophy The history of philosophy in specific contexts of time and space.  Timeline of philosophy Main articles: Timeline of philosophers and List of years in philosophy 11th century in philosophy 12th century in philosophy 13th century in philosophy 14th century in philosophy 15th century in philosophy 16th century in philosophy 17th century in philosophy 18th century in philosophy 19th-century philosophy 20th-century philosophy Ancient and classical philosophy Main article: Ancient philosophy Philosophies during ancient history.  Ancient Greek and Roman philosophy Main articles: Ancient Greek philosophy and Ancient Roman philosophy Pre-Socratic philosophy Milesian school Pythagoreanism Ephesian school Eleatics Pluralist school Atomism Sophism Classical Greek philosophy Cynicism Cyrenaics Platonism Peripatetic school Megarian school Eretrian school Hellenistic philosophy Academic skepticism Epicureanism Neoplatonism Neopythagoreanism Pyrrhonism Stoicism Classical Chinese philosophy Hundred Schools of Thought Confucianism Legalism Taoism Mohism School of Naturalists School of Names School of Diplomacy Agriculturalism Syncretism Yangism Classical Indian philosophy Orthodox schools Samkhya Yoga Nyaya Vaisheshika Mīmāṃsā Vedanta Heterodox schools Ajñana Jain philosophy Buddhist philosophy Ājīvika Charvaka Medieval and post-classical philosophy Main article: Medieval philosophy Philosophies during post-classical history.  Christian philosophy Main article: Christian philosophy Scholasticism Thomism Islamic philosophy Main article: Early Islamic philosophy Avicennism Averroism Illuminationism Jewish philosophy Main article: Medieval Jewish philosophy Judeo-Islamic philosophies Post-classical Chinese philosophy Neo-Confucianism Xuanxue Zen Modern and contemporary philosophy Main article: Modern philosophy Philosophies during the modern era.  Renaissance philosophy Main article: Renaissance philosophy Renaissance humanism Renaissance Jewish philosophy Machiavellianism Neostoicism Ramism School of Salamanca Early modern philosophy Main article: Early modern philosophy Empiricism Rationalism Idealism Contemporary philosophy Main article: Contemporary philosophy Analytic philosophy Continental philosophy Existentialism Phenomenology Contemporary Asian philosophy Buddhist modernism New Confucianism Maoism Kyoto School Neo-Vedanta Contemporary Islamic philosophy Transcendent theosophy Pragmatism Traditionalist School Philosophical schools of thought Main articles: List of philosophies and Glossary of philosophy Philosophical schools of thought not tied to particular historic contexts.  Aesthetical movements See also: List of art movements Symbolism Romanticism Historicism Classicism Modernism Postmodernism Psychoanalytic theory Epistemological stances Coherentism Constructivist epistemology Contextualism Embodied cognition Empiricism Fallibilism Foundationalism Holism Infinitism Innatism Internalism and externalism Logical positivism Naïve realism Naturalized epistemology Objectivist epistemology Phenomenalism Positivism Reductionism Reliabilism Representative realism Rationalism Situated cognition Skepticism Theory of Forms Transcendental idealism Uniformitarianism Ethical theories Consequentialism Deontology Virtue ethics Moral realism Moral relativism Error theory Non-cognitivism Ethical egoism Cultural relativism Evolutionary ethics Evolution of morality Logical systems Classical logic Intermediate logic Intuitionistic logic Minimal logic Relevant logic Affine logic Linear logic Ordered logic Dialetheism Metaphysical stances Absurdism Anti-realism Cartesian dualism Free will Materialism Meaning of life Idealism Existentialism Essentialism Libertarianism Determinism Compatibilism Naturalism Monism Platonic idealism Hindu idealism Phenomenalism Nihilism Realism Physicalism MOQ Relativism Scientific realism Solipsism Subjectivism Substance theory Type theory Emergentism Emanationism Political philosophies Anarchism Authoritarianism Conservatism Liberalism Libertarianism Social democracy Socialism Communism Philosophy of language theories and stances Causal theory of reference Contrast theory of meaning Contrastivism Conventionalism Cratylism Deconstruction Descriptivist theory of names Direct reference theory Dramatism Expressivism Linguistic determinism Logical atomism Mediated reference theory Nominalism Non-cognitivism Phallogocentrism Quietism Relevance theory Semantic externalism Semantic holism Structuralism Supposition theory Symbiosism Theological noncognitivism Theory of descriptions Verification theory Philosophy of mind theories and stances Behaviourism Biological naturalism Consciousness Disjunctivism Dualism Eliminative materialism Emergent materialism Enactivism Epiphenomenalism Functionalism Identity theory Idealism Interactionism Materialism Monism Neutral monism Panpsychism Phenomenalism Phenomenology Physicalism Property dualism Representational theory of mind Sense datum theory Solipsism Substance dualism Qualia theory Philosophy of religion stances Theories of religion Acosmism Agnosticism Animism Antireligion Atheism Dharmism Deism Divine command theory Dualistic cosmology Esotericism Exclusivism Existentialism Christian Agnostic Atheist Feminist theology Fideism Fundamentalism Gnosticism Henotheism Humanism Religious Secular Christian Inclusivism Monism Monotheism Mysticism Naturalism Metaphysical Religious Humanistic New Age Nondualism Nontheism Pandeism Pantheism Perennialism Polytheism Process theology Spiritualism Shamanism Taoic Theism Transcendentalism Philosophy of science theories and stances Confirmation holism Coherentism Contextualism Conventionalism Deductive-nomological model Determinism Empiricism Fallibilism Foundationalism Hypothetico-deductive model Infinitism Instrumentalism Positivism Pragmatism Rationalism Received view of theories Reductionism Semantic view of theories Scientific realism Scientism Scientific anti-realism Skepticism Uniformitarianism Vitalism Philosophical literature Blackwell Companion to Philosophy A History of Western Philosophy by Bertrand Russell A History of Philosophy by Frederick Copleston Reference works Encyclopedia of Philosophy – one of the major English encyclopedias of philosophy. The second edition, edited by Donald M. Borchert, was published in ten volumes in 2006 by Thomson Gale. Volumes 1–9 contain alphabetically ordered articles. Internet Encyclopedia of Philosophy – free online encyclopedia on philosophical topics and philosophers founded by James Fieser in 1995. The current general editors are James Fieser (Professor of Philosophy at the University of Tennessee at Martin) and Bradley Dowden (Professor of Philosophy at California State University, Sacramento). The staff also includes numerous area editors as well as volunteers. Routledge Encyclopedia of Philosophy – encyclopedia of philosophy edited by Edward Craig that was first published by Routledge in 1998 (ISBN 978-0415073103). Originally published in both 10 volumes of print and as a CD-ROM, in 2002 it was made available online on a subscription basis. The online version is regularly updated with new articles and revisions to existing articles. It has 1,300 contributors providing over 2,000 scholarly articles. Stanford Encyclopedia of Philosophy – combines an online encyclopedia of philosophy with peer reviewed publication of original papers in philosophy, freely-accessible to internet users. Each entry is written and maintained by an expert in the field, including professors from many academic institutions worldwide. Philosophers Lists of philosophers  Timeline of Western philosophers Timeline of Eastern philosophers See also 	Philosophy portal Outline of philosophy of artificial intelligence List of important publications in philosophy List of philosophy awards Index of philosophy Index of philosophy of science articles Unsolved problems in philosophy References  Jenny Teichmann and Katherine C. Evans, Philosophy: A Beginner's Guide (Blackwell Publishing, 1999), p. 1: "Philosophy is a study of problems which are ultimate, abstract and very general. These problems are concerned with the nature of existence, knowledge, morality, reason and human purpose."  A.C. Grayling, Philosophy 1: A Guide through the Subject (Oxford University Press, 1998), p. 1: "The aim of philosophical inquiry is to gain insight into questions about knowledge, truth, reason, reality, meaning, mind, and value."  Anthony Quinton, in T. Honderich (ed.), The Oxford Companion to Philosophy (Oxford University Press, 1995), p. 666: "Philosophy is rationally critical thinking, of a more or less systematic kind about the general nature of the world (metaphysics or theory of existence), the justification of belief (epistemology or theory of knowledge), and the conduct of life (ethics or theory of value). Each of the three elements in this list has a non-philosophical counterpart, from which it is distinguished by its explicitly rational and critical way of proceeding and by its systematic nature. Everyone has some general conception of the nature of the world in which they live and of their place in it. Metaphysics replaces the unargued assumptions embodied in such a conception with a rational and organized body of beliefs about the world as a whole. Everyone has occasion to doubt and question beliefs, their own or those of others, with more or less success and without any theory of what they are doing. Epistemology seeks by argument to make explicit the rules of correct belief formation. Everyone governs their conduct by directing it to desired or valued ends. Ethics, or moral philosophy, in its most inclusive sense, seeks to articulate, in rationally systematic form, the rules or principles involved."  Philosophia, Henry George Liddell, Robert Scott, A Greek-English Lexicon, at Perseus  Online Etymology Dictionary  The definition of philosophy is: "1.orig., love of, or the search for, wisdom or knowledge 2.theory or logical analysis of the principles underlying conduct, thought, knowledge, and the nature of the universe". Webster's New World Dictionary (Second College ed.). External links Philosophy at Wikipedia's sister projects Definitions from Wiktionary Media from Wikimedia Commons News from Wikinews Quotations from Wikiquote Texts from Wikisource Textbooks from Wikibooks Resources from Wikiversity Taxonomy of Philosophy – topic outline developed by David Chalmers as the category structure for the table of contents of the PhilPapers academic directory. PhilPapers – comprehensive directory of online philosophical articles and books. Dictionary of Philosophical Terms and Names Guide to Philosophy on the Internet The Internet Encyclopedia of Philosophy The Ism Book Introducing Philosophy Series. By Paul Newall (for beginners) Philosophical positions (philosophy, movement, school, theory, etc.) The Problems of Philosophy, by Bertrand Russell (links provided to full text) Stanford Encyclopedia of Philosophy vte Wikipedia Outlines General reference Culture and the artsGeography and placesHealth and fitnessHistory and eventsMathematics and logicNatural and physical sciencesPeople and selfPhilosophy and thinkingReligion and belief systemsSociety and social sciencesTechnology and applied sciences Categories: Outlines of philosophy topicsWikipedia outlines Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadEditView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version  Languages বাংলা 日本語 Română Slovenčina 中文 Edit links This page was last edited on 6 October 2021, at 23:11 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki   Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more Reason From Wikipedia, the free encyclopedia Jump to navigationJump to search This article is about the human faculty of reason and rationality. For other uses, see Reason (disambiguation). Part of a series on Philosophy Left to right: Plato, Kant, Nietzsche, Buddha, Confucius, Averroes About this image PlatoKantNietzsche BuddhaConfuciusAverroes Branches Periods Traditions Literature Philosophers Lists Socrates.png Philosophy portal vte Reason is the capacity of consciously applying logic by drawing conclusions from new or existing information, with the aim of seeking the truth.[1][2] It is closely associated with such characteristically human activities as philosophy, science, language, mathematics, and art, and is normally considered to be a distinguishing ability possessed by humans.[3] Reason is sometimes referred to as rationality.[4]  Reasoning is associated with the acts of thinking and cognition, and involves using one's intellect. The field of logic studies the ways in which humans can use formal reasoning to produce logically valid arguments.[5] Reasoning may be subdivided into forms of logical reasoning, such as: deductive reasoning, inductive reasoning, and abductive reasoning. Aristotle drew a distinction between logical discursive reasoning (reason proper), and intuitive reasoning,[6] in which the reasoning process through intuition—however valid—may tend toward the personal and the subjectively opaque. In some social and political settings logical and intuitive modes of reasoning may clash, while in other contexts intuition and formal reason are seen as complementary rather than adversarial. For example, in mathematics, intuition is often necessary for the creative processes involved with arriving at a formal proof, arguably the most difficult of formal reasoning tasks.  Reasoning, like habit or intuition, is one of the ways by which thinking moves from one idea to a related idea. For example, reasoning is the means by which rational individuals understand sensory information from their environments, or conceptualize abstract dichotomies such as cause and effect, truth and falsehood, or ideas regarding notions of good or evil. Reasoning, as a part of executive decision making, is also closely identified with the ability to self-consciously change, in terms of goals, beliefs, attitudes, traditions, and institutions, and therefore with the capacity for freedom and self-determination.[7]  In contrast to the use of "reason" as an abstract noun, a reason is a consideration given which either explains or justifies events, phenomena, or behavior.[8] Reasons justify decisions, reasons support explanations of natural phenomena; reasons can be given to explain the actions (conduct) of individuals.  Using reason, or reasoning, can also be described more plainly as providing good, or the best, reasons. For example, when evaluating a moral decision, "morality is, at the very least, the effort to guide one's conduct by reason—that is, doing what there are the best reasons for doing—while giving equal [and impartial] weight to the interests of all those affected by what one does."[9]  Psychologists and cognitive scientists have attempted to study and explain how people reason, e.g. which cognitive and neural processes are engaged, and how cultural factors affect the inferences that people draw. The field of automated reasoning studies how reasoning may or may not be modeled computationally. Animal psychology considers the question of whether animals other than humans can reason.   Contents 1	Etymology and related words 2	Philosophical history 2.1	Classical philosophy 2.2	Christian and Islamic philosophy 2.3	Subject-centred reason in early modern philosophy 2.4	Substantive and formal reason 2.5	The critique of reason 3	Reason compared to related concepts 3.1	Compared to logic 3.2	Reason compared to cause-and-effect thinking, and symbolic thinking 3.3	Reason, imagination, mimesis, and memory 3.4	Logical reasoning methods and argumentation 3.4.1	Deductive reasoning 3.4.2	Inductive reasoning 3.4.3	Analogical reasoning 3.4.4	Abductive reasoning 3.4.5	Fallacious reasoning 4	Traditional problems raised concerning reason 4.1	Reason versus truth, and "first principles" 4.2	Reason versus emotion or passion 4.3	Reason versus faith or tradition 5	Reason in particular fields of study 5.1	Psychology and cognitive science 5.1.1	Behavioral experiments on human reasoning 5.1.2	Developmental studies of children's reasoning 5.1.3	Neuroscience of reasoning 5.2	Computer science 5.2.1	Automated reasoning 5.2.2	Meta-reasoning 5.3	Evolution of reason 5.4	Reason in political philosophy and ethics 6	See also 7	References 8	Further reading Etymology and related words In the English language and other modern European languages, "reason", and related words, represent words which have always been used to translate Latin and classical Greek terms in the sense of their philosophical usage.  The original Greek term was "λόγος" logos, the root of the modern English word "logic" but also a word which could mean for example "speech" or "explanation" or an "account" (of money handled).[10] As a philosophical term logos was translated in its non-linguistic senses in Latin as ratio. This was originally not just a translation used for philosophy, but was also commonly a translation for logos in the sense of an account of money.[11] French raison is derived directly from Latin, and this is the direct source of the English word "reason".[8] The earliest major philosophers to publish in English, such as Francis Bacon, Thomas Hobbes, and John Locke also routinely wrote in Latin and French, and compared their terms to Greek, treating the words "logos", "ratio", "raison" and "reason" as interchangeable. The meaning of the word "reason" in senses such as "human reason" also overlaps to a large extent with "rationality" and the adjective of "reason" in philosophical contexts is normally "rational", rather than "reasoned" or "reasonable".[12] Some philosophers, Thomas Hobbes for example, also used the word ratiocination as a synonym for "reasoning".  Philosophical history  Francisco de Goya, The Sleep of Reason Produces Monsters (El sueño de la razón produce monstruos), c. 1797 The proposal that reason gives humanity a special position in nature has been argued to be a defining characteristic of western philosophy and later western modern science, starting with classical Greece. Philosophy can be described as a way of life based upon reason, and in the other direction, reason has been one of the major subjects of philosophical discussion since ancient times. Reason is often said to be reflexive, or "self-correcting", and the critique of reason has been a persistent theme in philosophy.[13] It has been defined in different ways, at different times, by different thinkers about human nature.  Classical philosophy For many classical philosophers, nature was understood teleologically, meaning that every type of thing had a definitive purpose that fit within a natural order that was itself understood to have aims. Perhaps starting with Pythagoras or Heraclitus, the cosmos is even said to have reason.[14] Reason, by this account, is not just one characteristic that humans happen to have, and that influences happiness amongst other characteristics. Reason was considered of higher stature than other characteristics of human nature, such as sociability, because it is something humans share with nature itself, linking an apparently immortal part of the human mind with the divine order of the cosmos itself. Within the human mind or soul (psyche), reason was described by Plato as being the natural monarch which should rule over the other parts, such as spiritedness (thumos) and the passions. Aristotle, Plato's student, defined human beings as rational animals, emphasizing reason as a characteristic of human nature. He defined the highest human happiness or well being (eudaimonia) as a life which is lived consistently, excellently, and completely in accordance with reason.[15]  The conclusions to be drawn from the discussions of Aristotle and Plato on this matter are amongst the most debated in the history of philosophy.[16] But teleological accounts such as Aristotle's were highly influential for those who attempt to explain reason in a way that is consistent with monotheism and the immortality and divinity of the human soul. For example, in the neoplatonist account of Plotinus, the cosmos has one soul, which is the seat of all reason, and the souls of all individual humans are part of this soul. Reason is for Plotinus both the provider of form to material things, and the light which brings individuals souls back into line with their source.[17]  Christian and Islamic philosophy The classical view of reason, like many important Neoplatonic and Stoic ideas, was readily adopted by the early Church [18] as the Church Fathers saw Greek Philosophy as an indispensable instrument given to mankind so that we may understand revelation.[19] For example, the greatest among the early saint Church Fathers and Doctors of the Church such as Augustine of Hippo, Basil of Caesarea and Gregory of Nyssa were as much Neoplatonic philosophers as they were Christian theologians and adopted the Neoplatonic view of human reason together with the associated implications for our relationship to creation, to ourselves and to God. Such Neoplatonist accounts of the rational part of the human soul were also standard amongst medieval Islamic philosophers and remain important in Iranian philosophy.[16] As European intellectualism recovered from the post-Roman dark ages, the Christian Patristic heritage and the influence of the great Islamic scholars such as Averroes and Avicenna produced the Scholastic (see Scholasticism) view of reason from which our modern idea of this concept has developed.[20] Among the Scholastics who relied on the classical concept of reason for the development of their doctrines, none were more influential than Saint Thomas Aquinas, who put this concept at the heart of his Natural Law. In this doctrine, Thomas concludes that because humans have reason and because reason is a spark of the divine, every single human life is invaluable, all humans are equal and every human is born with an intrinsic and permanent set of basic rights.[21] On this foundation, the idea of human rights would later be constructed by Spanish theologians at the School of Salamanca. Other Scholastics, such as Roger Bacon and Albertus Magnus, following the example of Islamic scholars such as Alhazen, emphasised reason an intrinsic human ability to decode the created order and the structures that underlie our experienced physical reality. This interpretation of reason was instrumental to the development of the scientific method in the early Universities of the high middle ages.[22]  Subject-centred reason in early modern philosophy The early modern era was marked by a number of significant changes in the understanding of reason, starting in Europe. One of the most important of these changes involved a change in the metaphysical understanding of human beings. Scientists and philosophers began to question the teleological understanding of the world.[23] Nature was no longer assumed to be human-like, with its own aims or reason, and human nature was no longer assumed to work according to anything other than the same "laws of nature" which affect inanimate things. This new understanding eventually displaced the previous world view that derived from a spiritual understanding of the universe.   René Descartes Accordingly, in the 17th century, René Descartes explicitly rejected the traditional notion of humans as "rational animals", suggesting instead that they are nothing more than "thinking things" along the lines of other "things" in nature. Any grounds of knowledge outside that understanding was, therefore, subject to doubt.  In his search for a foundation of all possible knowledge, Descartes deliberately decided to throw into doubt all knowledge – except that of the mind itself in the process of thinking:  At this time I admit nothing that is not necessarily true. I am therefore precisely nothing but a thinking thing; that is a mind, or intellect, or understanding, or reason – words of whose meanings I was previously ignorant.[24]  This eventually became known as epistemological or "subject-centred" reason, because it is based on the knowing subject, who perceives the rest of the world and itself as a set of objects to be studied, and successfully mastered by applying the knowledge accumulated through such study. Breaking with tradition and many thinkers after him, Descartes explicitly did not divide the incorporeal soul into parts, such as reason and intellect, describing them as one indivisible incorporeal entity.  A contemporary of Descartes, Thomas Hobbes described reason as a broader version of "addition and subtraction" which is not limited to numbers.[25] This understanding of reason is sometimes termed "calculative" reason. Similar to Descartes, Hobbes asserted that "No discourse whatsoever, can end in absolute knowledge of fact, past, or to come" but that "sense and memory" is absolute knowledge.[26]  In the late 17th century, through the 18th century, John Locke and David Hume developed Descartes' line of thought still further. Hume took it in an especially skeptical direction, proposing that there could be no possibility of deducing relationships of cause and effect, and therefore no knowledge is based on reasoning alone, even if it seems otherwise.[27][28]  Hume famously remarked that, "We speak not strictly and philosophically when we talk of the combat of passion and of reason. Reason is, and ought only to be the slave of the passions, and can never pretend to any other office than to serve and obey them."[29] Hume also took his definition of reason to unorthodox extremes by arguing, unlike his predecessors, that human reason is not qualitatively different from either simply conceiving individual ideas, or from judgments associating two ideas,[30] and that "reason is nothing but a wonderful and unintelligible instinct in our souls, which carries us along a certain train of ideas, and endows them with particular qualities, according to their particular situations and relations."[31] It followed from this that animals have reason, only much less complex than human reason.  In the 18th century, Immanuel Kant attempted to show that Hume was wrong by demonstrating that a "transcendental" self, or "I", was a necessary condition of all experience. Therefore, suggested Kant, on the basis of such a self, it is in fact possible to reason both about the conditions and limits of human knowledge. And so long as these limits are respected, reason can be the vehicle of morality, justice, aesthetics, theories of knowledge (epistemology), and understanding.  Substantive and formal reason In the formulation of Kant, who wrote some of the most influential modern treatises on the subject, the great achievement of reason (German: Vernunft) is that it is able to exercise a kind of universal law-making. Kant was able therefore to reformulate the basis of moral-practical, theoretical and aesthetic reasoning, on "universal" laws.  Here practical reasoning is the self-legislating or self-governing formulation of universal norms, and theoretical reasoning the way humans posit universal laws of nature.[32]  Under practical reason, the moral autonomy or freedom of human beings depends on their ability to behave according to laws that are given to them by the proper exercise of that reason. This contrasted with earlier forms of morality, which depended on religious understanding and interpretation, or nature for their substance.[33]  According to Kant, in a free society each individual must be able to pursue their goals however they see fit, so long as their actions conform to principles given by reason. He formulated such a principle, called the "categorical imperative", which would justify an action only if it could be universalized:  Act only according to that maxim whereby you can, at the same time, will that it should become a universal law.[34]  In contrast to Hume then, Kant insists that reason itself (German Vernunft) has natural ends itself, the solution to the metaphysical problems, especially the discovery of the foundations of morality. Kant claimed that this problem could be solved with his "transcendental logic" which unlike normal logic is not just an instrument, which can be used indifferently, as it was for Aristotle, but a theoretical science in its own right and the basis of all the others.[35]  According to Jürgen Habermas, the "substantive unity" of reason has dissolved in modern times, such that it can no longer answer the question "How should I live?" Instead, the unity of reason has to be strictly formal, or "procedural". He thus described reason as a group of three autonomous spheres (on the model of Kant's three critiques):  Cognitive–instrumental reason is the kind of reason employed by the sciences. It is used to observe events, to predict and control outcomes, and to intervene in the world on the basis of its hypotheses; Moral–practical reason is what we use to deliberate and discuss issues in the moral and political realm, according to universalizable procedures (similar to Kant's categorical imperative); and Aesthetic reason is typically found in works of art and literature, and encompasses the novel ways of seeing the world and interpreting things that those practices embody. For Habermas, these three spheres are the domain of experts, and therefore need to be mediated with the "lifeworld" by philosophers. In drawing such a picture of reason, Habermas hoped to demonstrate that the substantive unity of reason, which in pre-modern societies had been able to answer questions about the good life, could be made up for by the unity of reason's formalizable procedures.[36]  The critique of reason Hamann, Herder, Kant, Hegel, Kierkegaard, Nietzsche, Heidegger, Foucault, Rorty, and many other philosophers have contributed to a debate about what reason means, or ought to mean. Some, like Kierkegaard, Nietzsche, and Rorty, are skeptical about subject-centred, universal, or instrumental reason, and even skeptical toward reason as a whole. Others, including Hegel, believe that it has obscured the importance of intersubjectivity, or "spirit" in human life, and attempt to reconstruct a model of what reason should be.  Some thinkers, e.g. Foucault, believe there are other forms of reason, neglected but essential to modern life, and to our understanding of what it means to live a life according to reason.[13]  In the last several decades, a number of proposals have been made to "re-orient" this critique of reason, or to recognize the "other voices" or "new departments" of reason:  For example, in opposition to subject-centred reason, Habermas has proposed a model of communicative reason that sees it as an essentially cooperative activity, based on the fact of linguistic intersubjectivity.[37]  Nikolas Kompridis has proposed a widely encompassing view of reason as "that ensemble of practices that contributes to the opening and preserving of openness" in human affairs, and a focus on reason's possibilities for social change.[38]  The philosopher Charles Taylor, influenced by the 20th century German philosopher Martin Heidegger, has proposed that reason ought to include the faculty of disclosure, which is tied to the way we make sense of things in everyday life, as a new "department" of reason.[39]  In the essay "What is Enlightenment?", Michel Foucault proposed a concept of critique based on Kant's distinction between "private" and "public" uses of reason. This distinction, as suggested, has two dimensions:  Private reason is the reason that is used when an individual is "a cog in a machine" or when one "has a role to play in society and jobs to do: to be a soldier, to have taxes to pay, to be in charge of a parish, to be a civil servant". Public reason is the reason used "when one is reasoning as a reasonable being (and not as a cog in a machine), when one is reasoning as a member of reasonable humanity". In these circumstances, "the use of reason must be free and public."[40] Reason compared to related concepts Compared to logic See also: Logic The terms logic or logical are sometimes used as if they were identical with the term reason or with the concept of being rational, or sometimes logic is seen as the most pure or the defining form of reason: "Logic is about reasoning—about going from premises to a conclusion. ... When you do logic, you try to clarify reasoning and separate good from bad reasoning."[41] In modern economics, rational choice is assumed to equate to logically consistent choice.[42]  Reason and logic can however be thought of as distinct, although logic is one important aspect of reason. Author Douglas Hofstadter, in Gödel, Escher, Bach, characterizes the distinction in this way: Logic is done inside a system while reason is done outside the system by such methods as skipping steps, working backward, drawing diagrams, looking at examples, or seeing what happens if you change the rules of the system.[43] Psychologists Mark H. Bickard and Robert L. Campbell argued that "rationality cannot be simply assimilated to logicality"; they noted that "human knowledge of logic and logical systems has developed" over time through reasoning, and logical systems "can't construct new logical systems more powerful than themselves", so reasoning and rationality must involve more than a system of logic.[44][45] Psychologist David Moshman, citing Bickhard and Campbell, argued for a "metacognitive conception of rationality" in which a person's development of reason "involves increasing consciousness and control of logical and other inferences".[45][46]  Reason is a type of thought, and logic involves the attempt to describe a system of formal rules or norms of appropriate reasoning.[45] The oldest surviving writing to explicitly consider the rules by which reason operates are the works of the Greek philosopher Aristotle, especially Prior Analysis and Posterior Analysis.[47][non-primary source needed] Although the Ancient Greeks had no separate word for logic as distinct from language and reason, Aristotle's newly coined word "syllogism" (syllogismos) identified logic clearly for the first time as a distinct field of study.[citation needed] When Aristotle referred to "the logical" (hē logikē), he was referring more broadly to rational thought.[48]  Reason compared to cause-and-effect thinking, and symbolic thinking Main articles: Causality and Symbols As pointed out by philosophers such as Hobbes, Locke and Hume, some animals are also clearly capable of a type of "associative thinking", even to the extent of associating causes and effects. A dog once kicked, can learn how to recognize the warning signs and avoid being kicked in the future, but this does not mean the dog has reason in any strict sense of the word. It also does not mean that humans acting on the basis of experience or habit are using their reason.[49]  Human reason requires more than being able to associate two ideas, even if those two ideas might be described by a reasoning human as a cause and an effect, perceptions of smoke, for example, and memories of fire. For reason to be involved, the association of smoke and the fire would have to be thought through in a way which can be explained, for example as cause and effect. In the explanation of Locke, for example, reason requires the mental use of a third idea in order to make this comparison by use of syllogism.[50]  More generally, reason in the strict sense requires the ability to create and manipulate a system of symbols, as well as indices and icons, according to Charles Sanders Peirce, the symbols having only a nominal, though habitual, connection to either smoke or fire.[51] One example of such a system of artificial symbols and signs is language.  The connection of reason to symbolic thinking has been expressed in different ways by philosophers. Thomas Hobbes described the creation of "Markes, or Notes of remembrance" (Leviathan Ch. 4) as speech. He used the word speech as an English version of the Greek word logos so that speech did not need to be communicated.[52] When communicated, such speech becomes language, and the marks or notes or remembrance are called "Signes" by Hobbes. Going further back, although Aristotle is a source of the idea that only humans have reason (logos), he does mention that animals with imagination, for whom sense perceptions can persist, come closest to having something like reasoning and nous, and even uses the word "logos" in one place to describe the distinctions which animals can perceive in such cases.[53]  Reason, imagination, mimesis, and memory Main articles: Imagination, Mimesis, Memory, and Recollection Reason and imagination rely on similar mental processes.[54] Imagination is not only found in humans. Aristotle, for example, stated that phantasia (imagination: that which can hold images or phantasmata) and phronein (a type of thinking that can judge and understand in some sense) also exist in some animals.[55] According to him, both are related to the primary perceptive ability of animals, which gathers the perceptions of different senses and defines the order of the things that are perceived without distinguishing universals, and without deliberation or logos. But this is not yet reason, because human imagination is different.  The recent modern writings of Terrence Deacon and Merlin Donald, writing about the origin of language, also connect reason connected to not only language, but also mimesis.[56] More specifically they describe the ability to create language as part of an internal modeling of reality specific to humankind. Other results are consciousness, and imagination or fantasy. In contrast, modern proponents of a genetic predisposition to language itself include Noam Chomsky and Steven Pinker, to whom Donald and Deacon can be contrasted.  As reason is symbolic thinking, and peculiarly human, then this implies that humans have a special ability to maintain a clear consciousness of the distinctness of "icons" or images and the real things they represent. Starting with a modern author, Merlin Donald writes[57]  A dog might perceive the "meaning" of a fight that was realistically play-acted by humans, but it could not reconstruct the message or distinguish the representation from its referent (a real fight). [...] Trained apes are able to make this distinction; young children make this distinction early – hence, their effortless distinction between play-acting an event and the event itself  In classical descriptions, an equivalent description of this mental faculty is eikasia, in the philosophy of Plato.[58] This is the ability to perceive whether a perception is an image of something else, related somehow but not the same, and therefore allows humans to perceive that a dream or memory or a reflection in a mirror is not reality as such. What Klein refers to as dianoetic eikasia is the eikasia concerned specifically with thinking and mental images, such as those mental symbols, icons, signes, and marks discussed above as definitive of reason. Explaining reason from this direction: human thinking is special in the way that we often understand visible things as if they were themselves images of our intelligible "objects of thought" as "foundations" (hypothēses in Ancient Greek). This thinking (dianoia) is "...an activity which consists in making the vast and diffuse jungle of the visible world depend on a plurality of more 'precise' noēta".[59]  Both Merlin Donald and the Socratic authors such as Plato and Aristotle emphasize the importance of mimesis, often translated as imitation or representation. Donald writes[60]  Imitation is found especially in monkeys and apes [... but ...] Mimesis is fundamentally different from imitation and mimicry in that it involves the invention of intentional representations. [...] Mimesis is not absolutely tied to external communication.  Mimēsis is a concept, now popular again in academic discussion, that was particularly prevalent in Plato's works, and within Aristotle, it is discussed mainly in the Poetics. In Michael Davis's account of the theory of man in this work.[61]  It is the distinctive feature of human action, that whenever we choose what we do, we imagine an action for ourselves as though we were inspecting it from the outside. Intentions are nothing more than imagined actions, internalizings of the external. All action is therefore imitation of action; it is poetic...[62]  Donald like Plato (and Aristotle, especially in On Memory and Recollection), emphasizes the peculiarity in humans of voluntary initiation of a search through one's mental world. The ancient Greek anamnēsis, normally translated as "recollection" was opposed to mneme or memory. Memory, shared with some animals,[63] requires a consciousness not only of what happened in the past, but also that something happened in the past, which is in other words a kind of eikasia[64] "...but nothing except man is able to recollect."[65] Recollection is a deliberate effort to search for and recapture something once known. Klein writes that, "To become aware of our having forgotten something means to begin recollecting."[66] Donald calls the same thing autocueing, which he explains as follows:[67] "Mimetic acts are reproducible on the basis of internal, self-generated cues. This permits voluntary recall of mimetic representations, without the aid of external cues – probably the earliest form of representational thinking."  In a celebrated paper in modern times, the fantasy author and philologist J.R.R. Tolkien wrote in his essay "On Fairy Stories" that the terms "fantasy" and "enchantment" are connected to not only "....the satisfaction of certain primordial human desires...." but also "...the origin of language and of the mind".  Logical reasoning methods and argumentation A subdivision of philosophy is logic. Logic is the study of reasoning. Looking at logical categorizations of different types of reasoning, the traditional main division made in philosophy is between deductive reasoning and inductive reasoning. Formal logic has been described as the science of deduction.[68] The study of inductive reasoning is generally carried out within the field known as informal logic or critical thinking.  Deductive reasoning Main article: Deductive reasoning Deduction is a form of reasoning in which a conclusion follows necessarily from the stated premises. A deduction is also the conclusion reached by a deductive reasoning process. One classic example of deductive reasoning is that found in syllogisms like the following:  Premise 1: All humans are mortal. Premise 2: Socrates is a human. Conclusion: Socrates is mortal. The reasoning in this argument is deductively valid because there is no way in which the premises, 1 and 2, could be true and the conclusion, 3, be false.  Inductive reasoning Main article: Inductive reasoning Induction is a form of inference producing propositions about unobserved objects or types, either specifically or generally, based on previous observation. It is used to ascribe properties or relations to objects or types based on previous observations or experiences, or to formulate general statements or laws based on limited observations of recurring phenomenal patterns.  Inductive reasoning contrasts strongly with deductive reasoning in that, even in the best, or strongest, cases of inductive reasoning, the truth of the premises does not guarantee the truth of the conclusion. Instead, the conclusion of an inductive argument follows with some degree of probability. Relatedly, the conclusion of an inductive argument contains more information than is already contained in the premises. Thus, this method of reasoning is ampliative.  A classic example of inductive reasoning comes from the empiricist David Hume:  Premise: The sun has risen in the east every morning up until now. Conclusion: The sun will also rise in the east tomorrow. Analogical reasoning Main article: Analogical reasoning Analogical reasoning is a form of inductive reasoning from a particular to a particular. It is often used in case-based reasoning, especially legal reasoning.[69] An example follows:  Premise 1: Socrates is human and mortal. Premise 2: Plato is human. Conclusion: Plato is mortal. Analogical reasoning is a weaker form of inductive reasoning from a single example, because inductive reasoning typically uses a large number of examples to reason from the particular to the general.[70] Analogical reasoning often leads to wrong conclusions. For example:  Premise 1: Socrates is human and male. Premise 2: Ada Lovelace is human. Conclusion: Therefore Ada Lovelace is male. Abductive reasoning Main article: Abductive reasoning Abductive reasoning, or argument to the best explanation, is a form of reasoning that doesn't fit in deductive or inductive, since it starts with incomplete set of observations and proceeds with likely possible explanations so the conclusion in an abductive argument does not follow with certainty from its premises and concerns something unobserved. What distinguishes abduction from the other forms of reasoning is an attempt to favour one conclusion above others, by subjective judgement or attempting to falsify alternative explanations or by demonstrating the likelihood of the favoured conclusion, given a set of more or less disputable assumptions. For example, when a patient displays certain symptoms, there might be various possible causes, but one of these is preferred above others as being more probable.  Fallacious reasoning Main articles: Fallacy, Formal fallacy, and Informal fallacy Flawed reasoning in arguments is known as fallacious reasoning. Bad reasoning within arguments can be because it commits either a formal fallacy or an informal fallacy.  Formal fallacies occur when there is a problem with the form, or structure, of the argument. The word "formal" refers to this link to the form of the argument. An argument that contains a formal fallacy will always be invalid.  An informal fallacy is an error in reasoning that occurs due to a problem with the content, rather than mere structure, of the argument.  Traditional problems raised concerning reason Philosophy is sometimes described as a life of reason, with normal human reason pursued in a more consistent and dedicated way than usual. Two categories of problem concerning reason have long been discussed by philosophers concerning reason, essentially being reasonings about reasoning itself as a human aim, or philosophizing about philosophizing. The first question is concerning whether we can be confident that reason can achieve knowledge of truth better than other ways of trying to achieve such knowledge. The other question is whether a life of reason, a life that aims to be guided by reason, can be expected to achieve a happy life more so than other ways of life (whether such a life of reason results in knowledge or not).  Reason versus truth, and "first principles" See also: Truth, First principle, and Nous Since classical times a question has remained constant in philosophical debate (which is sometimes seen as a conflict between movements called Platonism and Aristotelianism) concerning the role of reason in confirming truth. People use logic, deduction, and induction, to reach conclusions they think are true. Conclusions reached in this way are considered, according to Aristotle, more certain than sense perceptions on their own.[71] On the other hand, if such reasoned conclusions are only built originally upon a foundation of sense perceptions, then, our most logical conclusions can never be said to be certain because they are built upon the very same fallible perceptions they seek to better.[72]  This leads to the question of what types of first principles, or starting points of reasoning, are available for someone seeking to come to true conclusions. In Greek, "first principles" are archai, "starting points",[73] and the faculty used to perceive them is sometimes referred to in Aristotle[74] and Plato[75] as nous which was close in meaning to awareness or consciousness.[76]  Empiricism (sometimes associated with Aristotle[77] but more correctly associated with British philosophers such as John Locke and David Hume, as well as their ancient equivalents such as Democritus) asserts that sensory impressions are the only available starting points for reasoning and attempting to attain truth. This approach always leads to the controversial conclusion that absolute knowledge is not attainable. Idealism, (associated with Plato and his school), claims that there is a "higher" reality, from which certain people can directly arrive at truth without needing to rely only upon the senses, and that this higher reality is therefore the primary source of truth.  Philosophers such as Plato, Aristotle, Al-Farabi, Avicenna, Averroes, Maimonides, Aquinas and Hegel are sometimes said to have argued that reason must be fixed and discoverable—perhaps by dialectic, analysis, or study. In the vision of these thinkers, reason is divine or at least has divine attributes. Such an approach allowed religious philosophers such as Thomas Aquinas and Étienne Gilson to try to show that reason and revelation are compatible. According to Hegel, "...the only thought which Philosophy brings with it to the contemplation of History, is the simple conception of reason; that reason is the Sovereign of the World; that the history of the world, therefore, presents us with a rational process."[78]  Since the 17th century rationalists, reason has often been taken to be a subjective faculty, or rather the unaided ability (pure reason) to form concepts. For Descartes, Spinoza and Leibniz, this was associated with mathematics. Kant attempted to show that pure reason could form concepts (time and space) that are the conditions of experience. Kant made his argument in opposition to Hume, who denied that reason had any role to play in experience.  Reason versus emotion or passion See also: Emotion and Passion (emotion) After Plato and Aristotle, western literature often treated reason as being the faculty that trained the passions and appetites.[citation needed] Stoic philosophy, by contrast, claimed most emotions were merely false judgements.[79][80] According to the stoics the only good is virtue, and the only evil is vice, therefore emotions that judged things other than vice to be bad (such as fear or distress), or things other than virtue to be good (such as greed) were simply false judgements and should be discarded (though positive emotions based on true judgements, such as kindness, were acceptable).[79][80][81] After the critiques of reason in the early Enlightenment the appetites were rarely discussed or conflated with the passions.[citation needed] Some Enlightenment camps took after the Stoics to say Reason should oppose Passion rather than order it, while others like the Romantics believed that Passion displaces Reason, as in the maxim "follow your heart".[citation needed]  Reason has been seen as cold, an "enemy of mystery and ambiguity",[82] a slave, or judge, of the passions, notably in the work of David Hume, and more recently of Freud.[citation needed] Reasoning which claims that the object of a desire is demanded by logic alone is called rationalization.[citation needed]  Rousseau first proposed, in his second Discourse, that reason and political life is not natural and possibly harmful to mankind.[83] He asked what really can be said about what is natural to mankind. What, other than reason and civil society, "best suits his constitution"? Rousseau saw "two principles prior to reason" in human nature. First we hold an intense interest in our own well-being. Secondly we object to the suffering or death of any sentient being, especially one like ourselves.[84] These two passions lead us to desire more than we could achieve. We become dependent upon each other, and on relationships of authority and obedience. This effectively puts the human race into slavery. Rousseau says that he almost dares to assert that nature does not destine men to be healthy. According to Velkley, "Rousseau outlines certain programs of rational self-correction, most notably the political legislation of the Contrat Social and the moral education in Émile. All the same, Rousseau understands such corrections to be only ameliorations of an essentially unsatisfactory condition, that of socially and intellectually corrupted humanity."  This quandary presented by Rousseau led to Kant's new way of justifying reason as freedom to create good and evil. These therefore are not to be blamed on nature or God. In various ways, German Idealism after Kant, and major later figures such Nietzsche, Bergson, Husserl, Scheler, and Heidegger, remain preoccupied with problems coming from the metaphysical demands or urges of reason.[85] The influence of Rousseau and these later writers is also large upon art and politics. Many writers (such as Nikos Kazantzakis) extol passion and disparage reason. In politics modern nationalism comes from Rousseau's argument that rationalist cosmopolitanism brings man ever further from his natural state.[86]  Another view on reason and emotion was proposed in the 1994 book titled Descartes' Error by Antonio Damasio. In it, Damasio presents the "Somatic Marker Hypothesis" which states that emotions guide behavior and decision-making. Damasio argues that these somatic markers (known collectively as "gut feelings") are "intuitive signals" that direct our decision making processes in a certain way that cannot be solved with rationality alone. Damasio further argues that rationality requires emotional input in order to function.  Reason versus faith or tradition Main articles: Faith, Religion, and Tradition There are many religious traditions, some of which are explicitly fideist and others of which claim varying degrees of rationalism. Secular critics sometimes accuse all religious adherents of irrationality, since they claim such adherents are guilty of ignoring, suppressing, or forbidding some kinds of reasoning concerning some subjects (such as religious dogmas, moral taboos, etc.).[87] Though the theologies and religions such as classical monotheism typically do not admit to be irrational, there is often a perceived conflict or tension between faith and tradition on the one hand, and reason on the other, as potentially competing sources of wisdom, law and truth.[88][89]  Religious adherents sometimes respond by arguing that faith and reason can be reconciled, or have different non-overlapping domains, or that critics engage in a similar kind of irrationalism:  Reconciliation: Philosopher Alvin Plantinga argues that there is no real conflict between reason and classical theism because classical theism explains (among other things) why the universe is intelligible and why reason can successfully grasp it.[90][91] Non-overlapping magisteria: Evolutionary biologist Stephen Jay Gould argues that there need not be conflict between reason and religious belief because they are each authoritative in their own domain (or "magisterium").[92][93] If so, reason can work on those problems over which it has authority while other sources of knowledge or opinion can have authority on the big questions.[94] Tu quoque: Philosophers Alasdair MacIntyre and Charles Taylor argue that those critics of traditional religion who are adherents of secular liberalism are also sometimes guilty of ignoring, suppressing, and forbidding some kinds of reasoning about subjects.[95][96] Similarly, philosophers of science such as Paul Feyarabend argue that scientists sometimes ignore or suppress evidence contrary to the dominant paradigm. Unification: Theologian Joseph Ratzinger, later Benedict XVI, asserted that "Christianity has understood itself as the religion of the Logos, as the religion according to reason," referring to John 1:Ἐν ἀρχῇ ἦν ὁ λόγος, usually translated as "In the beginning was the Word (Logos)." Thus, he said that the Christian faith is "open to all that is truly rational", and that the rationality of Western Enlightenment "is of Christian origin".[97] Some commentators have claimed that Western civilization can be almost defined by its serious testing of the limits of tension between "unaided" reason and faith in "revealed" truths—figuratively summarized as Athens and Jerusalem, respectively.[98][99] Leo Strauss spoke of a "Greater West" that included all areas under the influence of the tension between Greek rationalism and Abrahamic revelation, including the Muslim lands. He was particularly influenced by the great Muslim philosopher Al-Farabi. To consider to what extent Eastern philosophy might have partaken of these important tensions, Strauss thought it best to consider whether dharma or tao may be equivalent to Nature (by which we mean physis in Greek). According to Strauss the beginning of philosophy involved the "discovery or invention of nature" and the "pre-philosophical equivalent of nature" was supplied by "such notions as 'custom' or 'ways'", which appear to be really universal in all times and places. The philosophical concept of nature or natures as a way of understanding archai (first principles of knowledge) brought about a peculiar tension between reasoning on the one hand, and tradition or faith on the other.[100]  Although there is this special history of debate concerning reason and faith in the Islamic, Christian and Jewish traditions, the pursuit of reason is sometimes argued to be compatible with the other practice of other religions of a different nature, such as Hinduism, because they do not define their tenets in such an absolute way.[101]  Reason in particular fields of study Psychology and cognitive science See also: Psychology of reasoning Scientific research into reasoning is carried out within the fields of psychology and cognitive science. Psychologists attempt to determine whether or not people are capable of rational thought in a number of different circumstances.  Assessing how well someone engages in reasoning is the project of determining the extent to which the person is rational or acts rationally. It is a key research question in the psychology of reasoning and cognitive science of reasoning. Rationality is often divided into its respective theoretical and practical counterparts.  Behavioral experiments on human reasoning Experimental cognitive psychologists carry out research on reasoning behaviour. Such research may focus, for example, on how people perform on tests of reasoning such as intelligence or IQ tests, or on how well people's reasoning matches ideals set by logic (see, for example, the Wason test).[102] Experiments examine how people make inferences from conditionals e.g., If A then B and how they make inferences about alternatives, e.g., A or else B.[103] They test whether people can make valid deductions about spatial and temporal relations, e.g., A is to the left of B, or A happens after B, and about quantified assertions, e.g., All the A are B.[104] Experiments investigate how people make inferences about factual situations, hypothetical possibilities, probabilities, and counterfactual situations.[105]  Developmental studies of children's reasoning Developmental psychologists investigate the development of reasoning from birth to adulthood. Piaget's theory of cognitive development was the first complete theory of reasoning development. Subsequently, several alternative theories were proposed, including the neo-Piagetian theories of cognitive development.[106]  Neuroscience of reasoning The biological functioning of the brain is studied by neurophysiologists, cognitive neuroscientists and neuropsychologists. Research in this area includes research into the structure and function of normally functioning brains, and of damaged or otherwise unusual brains. In addition to carrying out research into reasoning, some psychologists, for example, clinical psychologists and psychotherapists work to alter people's reasoning habits when they are unhelpful.  Computer science Automated reasoning Main articles: Automated reasoning and Computational logic In artificial intelligence and computer science, scientists study and use automated reasoning for diverse applications including automated theorem proving the formal semantics of programming languages, and formal specification in software engineering.  Meta-reasoning See also: Metacognition Meta-reasoning is reasoning about reasoning. In computer science, a system performs meta-reasoning when it is reasoning about its own operation.[107] This requires a programming language capable of reflection, the ability to observe and modify its own structure and behaviour.  Evolution of reason [icon]	 This section needs expansion. You can help by adding to it. (August 2017)  Dan Sperber believes that reasoning in groups is more effective and promotes their evolutionary fitness. A species could benefit greatly from better abilities to reason about, predict and understand the world. French social and cognitive scientists Dan Sperber and Hugo Mercier argue that there could have been other forces driving the evolution of reason. They point out that reasoning is very difficult for humans to do effectively, and that it is hard for individuals to doubt their own beliefs (confirmation bias). Reasoning is most effective when it is done as a collective – as demonstrated by the success of projects like science. They suggest that there are not just individual, but group selection pressures at play. Any group that managed to find ways of reasoning effectively would reap benefits for all its members, increasing their fitness. This could also help explain why humans, according to Sperber, are not optimized to reason effectively alone. Their argumentative theory of reasoning claims that reason may have more to do with winning arguments than with the search for the truth.[108][109]  Reason in political philosophy and ethics Main articles: Political Philosophy, Ethics, and The Good Aristotle famously described reason (with language) as a part of human nature, which means that it is best for humans to live "politically" meaning in communities of about the size and type of a small city state (polis in Greek). For example...  It is clear, then, that a human being is more of a political [politikon = of the polis] animal [zōion] than is any bee or than any of those animals that live in herds. For nature, as we say, makes nothing in vain, and humans are the only animals who possess reasoned speech [logos]. Voice, of course, serves to indicate what is painful and pleasant; that is why it is also found in other animals, because their nature has reached the point where they can perceive what is painful and pleasant and express these to each other. But speech [logos] serves to make plain what is advantageous and harmful and so also what is just and unjust. For it is a peculiarity of humans, in contrast to the other animals, to have perception of good and bad, just and unjust, and the like; and the community in these things makes a household or city [polis]. [...] By nature, then, the drive for such a community exists in everyone, but the first to set one up is responsible for things of very great goodness. For as humans are the best of all animals when perfected, so they are the worst when divorced from law and right. The reason is that injustice is most difficult to deal with when furnished with weapons, and the weapons a human being has are meant by nature to go along with prudence and virtue, but it is only too possible to turn them to contrary uses. Consequently, if a human being lacks virtue, he is the most unholy and savage thing, and when it comes to sex and food, the worst. But justice is something political [to do with the polis], for right is the arrangement of the political community, and right is discrimination of what is just. (Aristotle's Politics 1253a 1.2. Peter Simpson's translation, with Greek terms inserted in square brackets.)  The concept of human nature being fixed in this way, implied, in other words, that we can define what type of community is always best for people. This argument has remained a central argument in all political, ethical and moral thinking since then, and has become especially controversial since firstly Rousseau's Second Discourse, and secondly, the Theory of Evolution. Already in Aristotle there was an awareness that the polis had not always existed and had needed to be invented or developed by humans themselves. The household came first, and the first villages and cities were just extensions of that, with the first cities being run as if they were still families with Kings acting like fathers.[110]  Friendship [philia] seems to prevail [in] man and woman according to nature [kata phusin]; for people are by nature [tēi phusei] pairing [sunduastikon] more than political [politikon = of the polis], in as much as the household [oikos] is prior [proteron = earlier] and more necessary than the polis and making children is more common [koinoteron] with the animals. In the other animals, community [koinōnia] goes no further than this, but people live together [sumoikousin] not only for the sake of making children, but also for the things for life; for from the start the functions [erga] are divided, and are different [for] man and woman. Thus they supply each other, putting their own into the common [eis to koinon]. It is for these [reasons] that both utility [chrēsimon] and pleasure [hēdu] seem to be found in this kind of friendship. (Nicomachean Ethics, VIII.12.1162a. Rough literal translation with Greek terms shown in square brackets.)  Rousseau in his Second Discourse finally took the shocking step of claiming that this traditional account has things in reverse: with reason, language and rationally organized communities all having developed over a long period of time merely as a result of the fact that some habits of cooperation were found to solve certain types of problems, and that once such cooperation became more important, it forced people to develop increasingly complex cooperation—often only to defend themselves from each other.  In other words, according to Rousseau, reason, language and rational community did not arise because of any conscious decision or plan by humans or gods, nor because of any pre-existing human nature. As a result, he claimed, living together in rationally organized communities like modern humans is a development with many negative aspects compared to the original state of man as an ape. If anything is specifically human in this theory, it is the flexibility and adaptability of humans. This view of the animal origins of distinctive human characteristics later received support from Charles Darwin's Theory of Evolution.  The two competing theories concerning the origins of reason are relevant to political and ethical thought because, according to the Aristotelian theory, a best way of living together exists independently of historical circumstances. According to Rousseau, we should even doubt that reason, language and politics are a good thing, as opposed to being simply the best option given the particular course of events that lead to today. Rousseau's theory, that human nature is malleable rather than fixed, is often taken to imply, for example by Karl Marx, a wider range of possible ways of living together than traditionally known.  However, while Rousseau's initial impact encouraged bloody revolutions against traditional politics, including both the French Revolution and the Russian Revolution, his own conclusions about the best forms of community seem to have been remarkably classical, in favor of city-states such as Geneva, and rural living.  See also 	Philosophy portal 	Psychology portal Argument Argumentation theory Confirmation bias Conformity Critical thinking Logic and rationality Outline of thought – topic tree that identifies many types of thoughts/thinking, types of reasoning, aspects of thought, related fields, and more. Outline of human intelligence – topic tree presenting the traits, capacities, models, and research fields of human intelligence, and more. References  Proudfoot, Michael (2010). The Routledge dictionary of philosophy. A. R. Lacey, A. R.. Lacey (4th ed.). London: Routledge. p. 341. ISBN 978-0-203-42846-7. OCLC 503050369. Reason: A general faculty common to all or nearly all humans...this faculty has seemed to be of two sorts, a faculty of intuition by which one 'sees' truths or abstract things ('essences' or universals, etc.), and a faculty of reasoning, i.e. passing from premises to a conclusion (discursive reason). The verb 'reason is confined to this latter sense, which is now anyway the commonest for the noun too  Rescher, Nicholas (2005). The Oxford companion to philosophy. Ted Honderich (2nd ed.). Oxford: Oxford University Press. p. 791. ISBN 978-0-19-153265-8. OCLC 62563098. reason. The general human 'faculty' or capacity for truth-seeking and problem solving  Mercier, Hugo; Sperber, Dan (2017). The Enigma of Reason. Cambridge, MA: Harvard University Press. p. 2. ISBN 9780674368309. OCLC 959650235. Enhanced with reason, cognition can secure better knowledge in all domains and adjust action to novel and ambitious goals, or so the story goes. [...] Understanding why only a few species have echolocation is easy. Understanding why only humans have reason is much more challenging. Compare: MacIntyre, Alasdair (1999). Dependent Rational Animals: Why Human Beings Need the Virtues. The Paul Carus Lectures. 20. Open Court Publishing. ISBN 9780812693973. OCLC 40632451. Retrieved 2014-12-01. [...] the exercise of independent practical reasoning is one essential constituent to full human flourishing. It is not—as I have already insisted—that one cannot flourish at all, if unable to reason. Nonetheless not to be able to reason soundly at the level of practice is a grave disability.  See, for example: Amoretti, Maria Cristina; Vassallo, Nicla, eds. (2013). Reason and Rationality. Philosophische Analyse / Philosophical Analysis. 48. Berlin: De Gruyter. doi:10.1515/9783110325867. ISBN 9783868381634. OCLC 807032616. Audi, Robert (2001). The Architecture of Reason: The Structure and Substance of Rationality. Oxford; New York: Oxford University Press. doi:10.1093/acprof:oso/9780195158427.001.0001. ISBN 0195141121. OCLC 44046914. Eze, Emmanuel Chukwudi (2008). On Reason: Rationality in a World of Cultural Conflict and Racism. Durham, NC: Duke University Press. doi:10.1215/9780822388777. ISBN 9780822341789. OCLC 180989486. Rescher, Nicholas (1988). Rationality: A Philosophical Inquiry into the Nature and the Rationale of Reason. Clarendon Library of Logic and Philosophy. Oxford; New York: Clarendon Press; Oxford University Press. ISBN 0198244355. OCLC 17954516.  Hintikka, J. "Philosophy of logic". Encyclopædia Britannica. Encyclopædia Britannica, Inc. Retrieved 12 November 2013.  "The Internet Classics Archive – Nicomachean Ethics by Aristotle, Book VI, Translated by W. D. Ross". classics.mit.edu. Retrieved 25 May 2020.  Michel Foucault, "What is Enlightenment?" in The Essential Foucault, eds. Paul Rabinow and Nikolas Rose, New York: The New Press, 2003, 43–57. See also Nikolas Kompridis, "The Idea of a New Beginning: A Romantic Source of Normativity and Freedom," in Philosophical Romanticism, New York: Routledge, 2006, 32–59; "So We Need Something Else for Reason to Mean", International Journal of Philosophical Studies 8: 3, 271–295.  Merriam-Webster.com Merriam-Webster Dictionary definition of reason  Rachels, James. The Elements of Moral Philosophy, 4th ed. McGraw Hill, 2002  Liddell, Henry George; Scott, Robert, "logos", A Greek–English Lexicon. For etymology of English "logic" see any dictionary such as the Merriam Webster entry for logic.  Lewis, Charlton; Short, Charles, "ratio", A Latin Dictionary  See Merriam Webster "rational" and Merriam Webster "reasonable".  Habermas, Jürgen (1990). The Philosophical Discourse of Modernity. Cambridge, MA: MIT Press.  Kirk; Raven; Schofield (1983), The Presocratic Philosophers (second ed.), Cambridge University Press. See pp. 204 & 235.  Nicomachean Ethics Book 1.  Davidson, Herbert (1992), Alfarabi, Avicenna, and Averroes, on Intellect, Oxford University Press, p. 3.  Moore, Edward, "Plotinus", Internet Encyclopedia of Philosophy  "Plato", Catholic Encyclopedia  "Catholic Culture", Hellenism  "Reason", Catholic Encyclopedia  "Natural Law", Catholic Encyclopedia  "Religion and Science", Stanford Encyclopaedia of Philosophy  Dreyfus, Hubert. "Telepistemology: Descartes' Last Stand". socrates.berkeley.edu. Retrieved February 23, 2011.  Descartes, "Second Meditation".  Hobbes, Thomas (1839), Molesworth (ed.), De Corpore, London, J. Bohn: "We must not therefore think that computation, that is, ratiocination, has place only in numbers, as if man were distinguished from other living creatures (which is said to have been the opinion of Pythagoras) by nothing but the faculty of numbering; for magnitude, body, motion, time, degrees of quality, action, conception, proportion, speech and names (in which all the kinds of philosophy consist) are capable of addition and substraction [sic]. Now such things as we add or substract, that is, which we put into an account, we are said to consider, in Greek λογίζεσθαι [logizesthai], in which language also συλλογίζεσθι [syllogizesthai] signifies to compute, reason, or reckon."  Hobbes, Thomas, "VII. Of the ends, or resolutions of discourse", The English Works of Thomas Hobbes, 3 (Leviathan) and Hobbes, Thomas, "IX. Of the several subjects of knowledge", The English Works of Thomas Hobbes, 3 (Leviathan)  Locke, John (1824) [1689], "XXVII On Identity and Diversity", An Essay concerning Human Understanding Part 1, The Works of John Locke in Nine Volumes (12th ed.), Rivington  Hume, David, "I.IV.VI. Of Personal Identity", A Treatise of Human Nature  Hume, David, "II.III.III. Of the influencing motives of the will.", A Treatise of Human Nature  Hume, David, "I.III.VII (footnote) Of the Nature of the Idea Or Belief", A Treatise of Human Nature  Hume, David, "I.III.XVI. Of the reason of animals", A Treatise of Human Nature  Immanuel Kant, Critique of Pure Reason; Critique of Practical Reason.  Michael Sandel, Justice: What's the Right Thing to Do?, New York: Farrar, Straus and Giroux, 2009.  Kant, Immanuel; translated by James W. Ellington [1785] (1993). Grounding for the Metaphysics of Morals 3rd ed. Hackett. p. 30. ISBN 978-0-87220-166-8.  See Velkley, Richard (2002), "On Kant's Socratism", Being After Rousseau, University of Chicago Press and Kant's own first preface to The Critique of Pure Reason.  Jürgen Habermas, Moral Consciousness and Communicative Action, Cambridge, MA: MIT Press, 1995.  Jürgen Habermas, The Theory of Communicative Action: Reason and the Rationalization of Society, translated by Thomas McCarthy. Boston: Beacon Press, 1984.  Nikolas Kompridis, Critique and Disclosure: Critical Theory between Past and Future, Cambridge, MA: MIT Press, 2006. See also Nikolas Kompridis, "So We Need Something Else for Reason to Mean", International Journal of Philosophical Studies 8:3, 271–295.  Charles Taylor, Philosophical Arguments (Harvard University Press, 1997), 12; 15.  Michel Foucault, "What is Enlightenment?", The Essential Foucault, New York: The New Press, 2003, 43–57.  Gensler, Harry J. (2010). Introduction to Logic (2nd ed.). New York: Routledge. p. 1. doi:10.4324/9780203855003. ISBN 9780415996501. OCLC 432990013.  Gächter, Simon (2013). "Rationality, social preferences, and strategic decision-making from a behavioral economics perspective". In Wittek, Rafael; Snijders, T. A. B.; Nee, Victor (eds.). The Handbook of Rational Choice Social Research. Stanford, CA: Stanford Social Sciences, an imprint of Stanford University Press. pp. 33–71 (33). doi:10.1515/9780804785501-004. ISBN 9780804784184. OCLC 807769289. The central assumption of the rational choice approach is that decision-makers have logically consistent goals (whatever they are), and, given these goals, choose the best available option.  Hofstadter, Douglas R. (1999) [1979]. Gödel, Escher, Bach: An Eternal Golden Braid (20th anniversary ed.). New York: Basic Books. ISBN 0394756827. OCLC 40724766.  Bickhard, Mark H.; Campbell, Robert L. (July 1996). "Developmental aspects of expertise: rationality and generalization". Journal of Experimental & Theoretical Artificial Intelligence. 8 (3–4): 399–417. doi:10.1080/095281396147393.  Moshman, David (May 2004). "From inference to reasoning: the construction of rationality". Thinking & Reasoning. 10 (2): 221–239. doi:10.1080/13546780442000024.  Ricco, Robert B. (2015). "The development of reasoning". In Lerner, Richard M. (ed.). Handbook of Child Psychology and Developmental Science. 2. Cognitive Processes (7th ed.). Hoboken, NJ: John Wiley & Sons. pp. 519–570 (534). doi:10.1002/9781118963418.childpsy213. ISBN 9781118136850. OCLC 888024689. Moshman's (1990, 1998, 2004, 2013a) theory of the development of deductive reasoning considers changes in metacognition to be the essential story behind the development of deductive (and inductive) reasoning. In his view, reasoning involves explicit conceptual knowledge regarding inference (metalogical knowledge) and metacognitive awareness of, and control over, inference.  Aristotle, Complete Works (2 volumes), Princeton, 1995, ISBN 0-691-09950-2  See this Perseus search, and compare English translations. and see LSJ dictionary entry for λογικός, section II.2.b.  See the Treatise of Human Nature of David Hume, Book I, Part III, Sect. XVI.  Locke, John (1824) [1689], "XVII Of Reason", An Essay concerning Human Understanding Part 2 and Other Writings, The Works of John Locke in Nine Volumes, 2 (12th ed.), Rivington  Terrence Deacon, The Symbolic Species: The Co-Evolution of Language and the Brain, W.W. Norton & Company, 1998, ISBN 0-393-31754-4  Leviathan Chapter IV Archived 2006-06-15 at the Wayback Machine: "The Greeks have but one word, logos, for both speech and reason; not that they thought there was no speech without reason, but no reasoning without speech"  Posterior Analytics II.19.  See for example Ruth M.J. Byrne (2005). The Rational Imagination: How People Create Counterfactual Alternatives to Reality. Cambridge, MA: MIT Press.  De Anima III.i–iii; On Memory and Recollection, On Dreams  Mimesis in modern academic writing, starting with Erich Auerbach, is a technical word, which is not necessarily exactly the same in meaning as the original Greek. See Mimesis.  Origins of the Modern Mind p. 172  Jacob Klein A Commentary on the Meno Ch.5  Jacob Klein A Commentary on the Meno p. 122  Origins of the Modern Mind p. 169  "Introduction" to the translation of Poetics by Davis and Seth Benardete p. xvii, xxviii  Davis is here using "poetic" in an unusual sense, questioning the contrast in Aristotle between action (praxis, the praktikē) and making (poēsis, the poētikē): "Human [peculiarly human] action is imitation of action because thinking is always rethinking. Aristotle can define human beings as at once rational animals, political animals, and imitative animals because in the end the three are the same."  Aristotle On Memory 450a 15–16.  Jacob Klein A Commentary on the Meno p. 109  Aristotle Hist. Anim. I.1.488b.25–26.  Jacob Klein A Commentary on the Meno p. 112  The Origins of the Modern Mind p. 173 see also A Mind So Rare pp. 140–141  Jeffrey, Richard. 1991. Formal logic: its scope and limits, (3rd ed.). New York: McGraw-Hill:1.  Walton, Douglas N. (2014). "Argumentation schemes for argument from analogy". In Ribeiro, Henrique Jales (ed.). Systematic approaches to argument by analogy. Argumentation library. 25. Cham; New York: Springer Verlag. pp. 23–40. doi:10.1007/978-3-319-06334-8_2. ISBN 978-3-319-06333-1. OCLC 884441074.  Vickers, John (2009). "The Problem of Induction". The Stanford Encyclopedia of Philosophy. Metaphysics Research Lab, Stanford University.  Example: Aristotle Metaphysics 981b: τὴν ὀνομαζομένην σοφίαν περὶ τὰ πρῶτα αἴτια καὶ τὰς ἀρχὰς ὑπολαμβάνουσι πάντες: ὥστε, καθάπερ εἴρηται πρότερον, ὁ μὲν ἔμπειρος τῶν ὁποιανοῦν ἐχόντων αἴσθησιν εἶναι δοκεῖ σοφώτερος, ὁ δὲ τεχνίτης τῶν ἐμπείρων, χειροτέχνου δὲ ἀρχιτέκτων, αἱ δὲ θεωρητικαὶ τῶν ποιητικῶν μᾶλλον. English: "...what is called Wisdom is concerned with the primary causes and principles, so that, as has been already stated, the man of experience is held to be wiser than the mere possessors of any power of sensation, the artist than the man of experience, the master craftsman than the artisan; and the speculative sciences to be more learned than the productive."  Metaphysics 1009b ποῖα οὖν τούτων ἀληθῆ ἢ ψευδῆ, ἄδηλον: οὐθὲν γὰρ μᾶλλον τάδε ἢ τάδε ἀληθῆ, ἀλλ᾽ ὁμοίως. διὸ Δημόκριτός γέ φησιν ἤτοι οὐθὲν εἶναι ἀληθὲς ἢ ἡμῖν γ᾽ ἄδηλον. English "Thus it is uncertain which of these impressions are true or false; for one kind is no more true than another, but equally so. And hence Democritus says that either there is no truth or we cannot discover it."  For example Aristotle Metaphysics 983a: ἐπεὶ δὲ φανερὸν ὅτι τῶν ἐξ ἀρχῆς αἰτίων δεῖ λαβεῖν ἐπιστήμην （τότε γὰρ εἰδέναι φαμὲν ἕκαστον, ὅταν τὴν πρώτην αἰτίαν οἰώμεθα γνωρίζειν） English "It is clear that we must obtain knowledge of the primary causes, because it is when we think that we understand its primary cause that we claim to know each particular thing."  Example: Nicomachean Ethics 1139b: ἀμφοτέρων δὴ τῶν νοητικῶν μορίων ἀλήθεια τὸ ἔργον. καθ᾽ ἃς οὖν μάλιστα ἕξεις ἀληθεύσει ἑκάτερον, αὗται ἀρεταὶ ἀμφοῖν. English The attainment of truth is then the function of both the intellectual parts of the soul. Therefore their respective virtues are those dispositions that will best qualify them to attain truth.  Example: Plato Republic 490b: μιγεὶς τῷ ὄντι ὄντως, γεννήσας νοῦν καὶ ἀλήθειαν, γνοίη English: "Consorting with reality really, he would beget intelligence and truth, attain to knowledge"  "This quest for the beginnings proceeds through sense perception, reasoning, and what they call noesis, which is literally translated by "understanding" or intellect," and which we can perhaps translate a little bit more cautiously by "awareness," an awareness of the mind's eye as distinguished from sensible awareness." "Progress or Return" in An Introduction to Political Philosophy: Ten Essays by Leo Strauss. (Expanded version of Political Philosophy: Six Essays by Leo Strauss, 1975.) Ed. Hilail Gilden. Detroit: Wayne State UP, 1989.  However, the empiricism of Aristotle must certainly be doubted. For example in Metaphysics 1009b, cited above, he criticizes people who think knowledge might not be possible because, "They say that the impression given through sense-perception is necessarily true; for it is on these grounds that both Empedocles and Democritus and practically all the rest have become obsessed by such opinions as these."  G.W.F. Hegel The Philosophy of History, p. 9, Dover Publications Inc., ISBN 0-486-20112-0; 1st ed. 1899  Sharples, R. W. (2005). The Oxford companion to philosophy. Ted Honderich (2nd ed.). Oxford: Oxford University Press. p. 896. ISBN 978-0-19-153265-8. OCLC 62563098. Moral virtue is the only good an wickedness the only evil...Emotions are interpreted in intellectual terms; those such as distress, pity (which is a species of distress), and fear which reflect false judgements about what is evil, are to be avoided (as also are those which reflect false judgement about what is good, such as love of honours or riches)...They did however allow the wise man such 'good feelings' as 'watchfulness' or kindness the difference being that these are based on sound (Stoic) reasoning concerning what matters and what does not.  Rufus, Musonius (2000). Concise Routledge encyclopedia of philosophy. Routledge. London: Routledge. p. 863. ISBN 0-203-16994-8. OCLC 49569365. Vice is founded on 'passions': these are at root false value judgements, in which we lose rational control by overvaluing things which are in fact indifferent. Virtue, a set of sciences governing moral choice, is the one thing of intrinsic worth and therefore genuinely 'good'.  Baltzly, Dirk (2019), "Stoicism", in Zalta, Edward N. (ed.), The Stanford Encyclopedia of Philosophy (Spring 2019 ed.), Metaphysics Research Lab, Stanford University, retrieved 2021-03-27  Radford, Benjamin; Frazier, Kendrick (January 2017). "The Edge of Reason: A Rational Skeptic in an Irrational World". Skeptical Inquirer. 41 (1): 60.  Velkley, Richard (2002), "Speech. Imagination, Origins: Rousseau and the Political Animal", Being after Rousseau: Philosophy and Culture in Question, University of Chicago Press  Rousseau (1997), "Preface", in Gourevitch (ed.), Discourse on the Origin and Foundations of Inequality Among Men or Second Discourse, Cambridge University Press  Velkley, Richard (2002), "Freedom, Teleology, and Justification of Reason", Being after Rousseau: Philosophy and Culture in Question, University of Chicago Press  Plattner, Marc (1997), "Rousseau and the Origins of Nationalism", The Legacy of Rousseau, University of Chicago Press  Dawkins, Richard (2008). The God Delusion (Reprint ed.). Mariner Books. ISBN 978-0-618-91824-9. Scientists... see the fight for evolution as only one battle in a larger war: a looming war between supernaturalism on the one side and rationality on the other.  Strauss, Leo, "Progress or Return", An Introduction to Political Philosophy  Locke, John (1824) [1689], "XVIII Of Faith and Reason, and their distinct Provinces.", An Essay concerning Human Understanding Part 2 and Other Writings, The Works of John Locke in Nine Volumes, 2 (12th ed.), Rivington  Plantinga, Alvin (2011). Where the Conflict Really Lies: Science, Religion, and Naturalism (1 ed.). Oxford University Press. ISBN 978-0-19-981209-7.  Natural Signs and Knowledge of God: A New Look at Theistic Arguments (Reprint ed.). Oxford: Oxford University Press. 2012. ISBN 978-0-19-966107-7.  Stephen Jay Gould (1997). "Nonoverlapping Magisteria". www.stephenjaygould.org. Retrieved 2016-04-06. To say it for all my colleagues and for the umpteenth millionth time (from college bull sessions to learned treatises): science simply cannot (by its legitimate methods) adjudicate the issue of God's possible superintendence of nature. We neither affirm nor deny it; we simply can't comment on it as scientists.  Dawkins, Richard (2008). "4". The God Delusion (Reprint ed.). Mariner Books. ISBN 978-0-618-91824-9. This sounds terrific, right up until you give it a moment's thought. You then realize that the presence of a creative deity in the universe is clearly a scientific hypothesis. Indeed, it is hard to imagine a more momentous hypothesis in all of science. A universe with a god would be a completely different kind of universe from one without, and it would be a scientific difference. God could clinch the matter in his favour at any moment by staging a spectacular demonstration of his powers, one that would satisfy the exacting standards of science. Even the infamous Templeton Foundation recognized that God is a scientific hypothesis — by funding double-blind trials to test whether remote prayer would speed the recovery of heart patients. It didn't, of course, although a control group who knew they had been prayed for tended to get worse (how about a class action suit against the Templeton Foundation?) Despite such well-financed efforts, no evidence for God's existence has yet appeared.  "The Meaning of Life as Narrative: A New Proposal for Interpreting Philosophy's 'Primary' Question – Joshua W. Seachris – Philo (Philosophy Documentation Center)". www.pdcnet.org. April 2009. doi:10.5840/philo20091211. Retrieved 2016-04-06.  Three Rival Versions of Moral Enquiry: Encyclopaedia, Genealogy, and Tradition (60067th ed.). University of Notre Dame Press. 1991. ISBN 978-0-268-01877-1.  Taylor, Charles (2007). A Secular Age (1st ed.). The Belknap Press of Harvard University Press. ISBN 978-0-674-02676-6.  "Cardinal Ratzinger on Europe's Crisis of Culture".  When Athens Met Jerusalem: An Introduction to Classical and Christian Thought (58760th ed.). IVP Academic. 2009. ISBN 978-0-8308-2923-1.  Shestov, Lev (1968). "Athens and Jerusalem". Annals of the New York Academy of Sciences. 950 (1): 17. Bibcode:2001NYASA.950...17P. doi:10.1111/j.1749-6632.2001.tb02124.x.  "Progress or Return" in An Introduction to Political Philosophy: Ten Essays by Leo Strauss. (Expanded version of Political Philosophy: Six Essays by Leo Strauss, 1975.) Ed. Hilail Gilden. Detroit: Wayne State UP, 1989.  Bhagavad Gita, Sarvepalli Radhakrishnan: "Hinduism is not just a faith. It is the union of reason and intuition that can not be defined but is only to be experienced."  Manktelow, K.I. 1999. Reasoning and Thinking (Cognitive Psychology: Modular Course.). Hove, Sussex:Psychology Press  Johnson-Laird, P.N. & Byrne, R.M.J. (1991). Deduction. Hillsdale: Erlbaum  Johnson-Laird, P.N. (2006). How we reason. Oxford: Oxford University Press  Byrne, R.M.J. (2005). The Rational Imagination: How People Create Counterfactual Alternatives to Reality. Cambridge, MA: MIT Press  Demetriou, A. (1998). Cognitive development. In A. Demetriou, W. Doise, K.F.M. van Lieshout (Eds.), Life-span developmental psychology (pp. 179–269). London: Wiley.  Costantini, Stefania (2002), "Meta-reasoning: A Survey", Lecture Notes in Computer Science, 2408/2002 (65): 253–288, doi:10.1007/3-540-45632-5_11, ISBN 978-3-540-43960-8  Mercier, Hugo; Sperber, Dan (2011). "Why Do Humans Reason? Arguments for an Argumentative Theory". Behavioral and Brain Sciences. 34 (2): 57–74. doi:10.1017/S0140525X10000968. PMID 21447233. S2CID 5669039.  Mercier, Hugo; Sperber, Dan (2017). The Enigma of Reason. Cambridge: Harvard University Press. ISBN 978-0-674-36830-9.  Politics I.2.1252b15 Further reading 	Look up reason in Wiktionary, the free dictionary. 	Wikiquote has quotations related to: Reason Reason at PhilPapers Beer, Francis A., "Words of Reason", Political Communication 11 (Summer, 1994): 185–201. Gilovich, Thomas (1991), How We Know What Isn't So: The Fallibility of Human Reason in Everyday Life, New York: The Free Press, ISBN 978-0-02-911705-7 Tripurari, Swami, On Faith and Reason, The Harmonist, May 27, 2009. vte Age of Enlightenment vte Human intelligence topics vte Logic vte Philosophical logic Authority control Edit this at Wikidata Categories: ReasoningAge of EnlightenmentCognitionConcepts in epistemologyConcepts in ethicsConcepts in logicConcepts in metaphilosophyConcepts in the philosophy of mindConcepts in the philosophy of scienceCritical thinkingIdealismKnowledgeMetaphysics of mindOntologyPhilosophical logicPhilosophy of logicProblem solving skillsRationalismTruthVirtue Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadEditView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikiquote  Languages Български Dansk Deutsch Français Latina Македонски Shqip Türkçe 中文 71 more Edit links This page was last edited on 5 October 2021, at 21:28 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki   Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more Reason (disambiguation) From Wikipedia, the free encyclopedia Jump to navigationJump to search 	Look up reason in Wiktionary, the free dictionary. 	Wikiquote has quotations related to: Reason Reason is the analytic faculty of the human mind that maintains objectivity unto inspecting and organizing perceptions.  Reason may also refer to:  Rationality, the quality or state of being reasonable, based on facts or reason Reason (argument), a factor which justifies or explains The cause of some thing  Contents 1	Computing 2	Literature 3	Music 4	Other 5	See also Computing Reason (programming language), an alternative OCaml syntax and toolchain created at Facebook Reason (software), a digital music workstation program Literature Reason (magazine), a monthly libertarian magazine published by the Reason Foundation "Reason" (short story), a 1941 science fiction short story by Isaac Asimov Reason: Why Liberals Will Win the Battle for America, a 2010 book by Robert Reich Reason, a fictional weapon system from Neal Stephenson's novel Snow Crash Music Reason (rapper) (born 1990), American hip hop artist Reason (Nami Tamaki song), a 2004 song by Nami Tamaki Reason (Shaman album), a 2005 album by Brazilian power metal band Shamaan Reason (Officium Triste album), a 2004 album by doom metal band Officium Triste Reason (Melanie C album), a 2003 album by singer Melanie C Reason (Violent Apathy album), 1995 Reason (Selah Sue album), 2015 Reason (No Angels song), a 2003 song by German pop band No Angels "Reason", a 2004 song by German dance trio Cascada "Reason", a bonus track on the Cranberries's album Everybody Else Is Doing It, So Why Can't We? Reason (EP), a 2003 EP by The Fray Other The Reason Foundation, a public policy think tank based in Los Angeles, California, U.S. Order of the Reason, a medieval military order native to Spain Reason (surname) See also No Reason (disambiguation) Reasons (disambiguation) The Reason (disambiguation) Disambiguation icon This disambiguation page lists articles associated with the title Reason. If an internal link led you here, you may wish to change the link to point directly to the intended article. Categories: Disambiguation pages Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadEditView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version  Languages Deutsch Español Français 한국어 日本語 Português 中文 5 more Edit links This page was last edited on 13 November 2020, at 16:49 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki   Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more Reason (programming language) From Wikipedia, the free encyclopedia Jump to navigationJump to search Reason Designed by	Jordan Walke First appeared	May 16, 2016; 5 years ago[1] Stable release	 3.6.0 / March 5, 2020 License	MIT License Filename extensions	.re, .rei Website	reasonml.github.io Reason, also known as ReasonML, is a syntax extension and toolchain for OCaml created by Jordan Walke, who also created React, at Facebook.[2] Reason offers a syntax familiar to JavaScript programmers, and transpiles to OCaml.[3] Statically typed Reason (or OCaml) code may be compiled to dynamically typed JavaScript using the ReScript compiler.[4]  The Reason community officially provides ReasonReact as a solution for React based web applications.[5][6]  See also 	Free and open-source software portal Elm: a functional language that uses an abstraction called ports to communicate with JavaScript PureScript: a strongly-typed, purely-functional programming language that compiles to JavaScript References  Simple, fast & type safe code that leverages the JavaScript & OCaml ecosystems: facebook/reason, Facebook, 2019-03-23, retrieved 2019-03-23  "What is ReasonML?". 2ality. Retrieved 2019-03-23.  Gopher, Stupid (2018-11-12). "One week with ReasonML". Medium. Retrieved 2019-03-23.  "Overview | ReScript Documentation". rescript-lang.org. Retrieved 2020-08-10.  "ReasonReact". GitHub.  Wilson, Ian (2019-04-15). "ReasonML with React Hooks Tutorial — Building a Pomodoro Timer". External links 	Wikibooks has a book on the topic of: OCaml Official website ReasonReact Stub icon	 This programming-language-related article is a stub. You can help Wikipedia by expanding it.  vte Programming languages ComparisonTimelineHistory AdaALGOLAPLAssemblyBASICCC++C#COBOLErlangForthFortranGoHaskellJavaJavaScriptKotlinLispLuaMLPascalPerlPHPPrologPythonRRubyRustSQLShellSimulaSmalltalkSwiftmore... Category CategoryList-Class article Lists: AlphabeticalCategoricalGenerationalNon-English-based Categories: Programming language topic stubsCross-platform free softwareExtensible syntax programming languagesFree compilers and interpretersFunctional languagesML programming language familyObject-oriented programming languagesOCaml programming language familyPattern matching programming languagesStatically typed programming languagesProgramming languages created in 2016High-level programming languagesSoftware using the MIT license Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadEditView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version  Languages Français മലയാളം Edit links This page was last edited on 24 December 2020, at 17:05 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki   Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more Syntax (programming languages) From Wikipedia, the free encyclopedia Jump to navigationJump to search  This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed. Find sources: "Syntax" programming languages – news · newspapers · books · scholar · JSTOR (August 2013) (Learn how and when to remove this template message)  Syntax highlighting and indent style are often used to aid programmers in recognizing elements of source code. This Python code uses color coded highlighting. In computer science, the syntax of a computer language is the set of rules that defines the combinations of symbols that are considered to be correctly structured statements or expressions in that language. This applies both to programming languages, where the document represents source code, and to markup languages, where the document represents data.  The syntax of a language defines its surface form.[1] Text-based computer languages are based on sequences of characters, while visual programming languages are based on the spatial layout and connections between symbols (which may be textual or graphical). Documents that are syntactically invalid are said to have a syntax error. When designing the syntax of a language, a designer might start by writing down examples of both legal and illegal strings, before trying to figure out the general rules from these examples.[2]  Syntax therefore refers to the form of the code, and is contrasted with semantics – the meaning. In processing computer languages, semantic processing generally comes after syntactic processing; however, in some cases, semantic processing is necessary for complete syntactic analysis, and these are done together or concurrently. In a compiler, the syntactic analysis comprises the frontend, while the semantic analysis comprises the backend (and middle end, if this phase is distinguished).   Contents 1	Levels of syntax 1.1	Examples of errors 2	Syntax definition 2.1	Example: Lisp S-expressions 2.2	Complex grammars 3	Syntax versus semantics 4	See also 5	References 6	External links Levels of syntax Computer language syntax is generally distinguished into three levels:  Words – the lexical level, determining how characters form tokens; Phrases – the grammar level, narrowly speaking, determining how tokens form phrases; Context – determining what objects or variables names refer to, if types are valid, etc. Distinguishing in this way yields modularity, allowing each level to be described and processed separately and often independently. First, a lexer turns the linear sequence of characters into a linear sequence of tokens; this is known as "lexical analysis" or "lexing". Second, the parser turns the linear sequence of tokens into a hierarchical syntax tree; this is known as "parsing" narrowly speaking. Thirdly, the contextual analysis resolves names and checks types. This modularity is sometimes possible, but in many real-world languages an earlier step depends on a later step – for example, the lexer hack in C is because tokenization depends on context. Even in these cases, syntactical analysis is often seen as approximating this ideal model.  The parsing stage itself can be divided into two parts: the parse tree, or "concrete syntax tree", which is determined by the grammar, but is generally far too detailed for practical use, and the abstract syntax tree (AST), which simplifies this into a usable form. The AST and contextual analysis steps can be considered a form of semantic analysis, as they are adding meaning and interpretation to the syntax, or alternatively as informal, manual implementations of syntactical rules that would be difficult or awkward to describe or implement formally.  The levels generally correspond to levels in the Chomsky hierarchy. Words are in a regular language, specified in the lexical grammar, which is a Type-3 grammar, generally given as regular expressions. Phrases are in a context-free language (CFL), generally a deterministic context-free language (DCFL), specified in a phrase structure grammar, which is a Type-2 grammar, generally given as production rules in Backus–Naur form (BNF). Phrase grammars are often specified in much more constrained grammars than full context-free grammars, in order to make them easier to parse; while the LR parser can parse any DCFL in linear time, the simple LALR parser and even simpler LL parser are more efficient, but can only parse grammars whose production rules are constrained. In principle, contextual structure can be described by a context-sensitive grammar, and automatically analyzed by means such as attribute grammars, though, in general, this step is done manually, via name resolution rules and type checking, and implemented via a symbol table which stores names and types for each scope.  Tools have been written that automatically generate a lexer from a lexical specification written in regular expressions and a parser from the phrase grammar written in BNF: this allows one to use declarative programming, rather than need to have procedural or functional programming. A notable example is the lex-yacc pair. These automatically produce a concrete syntax tree; the parser writer must then manually write code describing how this is converted to an abstract syntax tree. Contextual analysis is also generally implemented manually. Despite the existence of these automatic tools, parsing is often implemented manually, for various reasons – perhaps the phrase structure is not context-free, or an alternative implementation improves performance or error-reporting, or allows the grammar to be changed more easily. Parsers are often written in functional languages, such as Haskell, or in scripting languages, such as Python or Perl, or in C or C++.  Examples of errors Main article: Syntax error As an example, (add 1 1) is a syntactically valid Lisp program (assuming the 'add' function exists, else name resolution fails), adding 1 and 1. However, the following are invalid:  (_ 1 1)    lexical error: '_' is not valid (add 1 1   parsing error: missing closing ')' Note that the lexer is unable to identify the first error – all it knows is that, after producing the token LEFT_PAREN, '(' the remainder of the program is invalid, since no word rule begins with '_'. The second error is detected at the parsing stage: The parser has identified the "list" production rule due to the '(' token (as the only match), and thus can give an error message; in general it may be ambiguous.  Type errors and undeclared variable errors are sometimes considered to be syntax errors when they are detected at compile-time (which is usually the case when compiling strongly-typed languages), though it is common to classify these kinds of error as semantic errors instead.[3][4][5]  As an example, the Python code  'a' + 1 contains a type error because it adds a string literal to an integer literal. Type errors of this kind can be detected at compile-time: They can be detected during parsing (phrase analysis) if the compiler uses separate rules that allow "integerLiteral + integerLiteral" but not "stringLiteral + integerLiteral", though it is more likely that the compiler will use a parsing rule that allows all expressions of the form "LiteralOrIdentifier + LiteralOrIdentifier" and then the error will be detected during contextual analysis (when type checking occurs). In some cases this validation is not done by the compiler, and these errors are only detected at runtime.  In a dynamically typed language, where type can only be determined at runtime, many type errors can only be detected at runtime. For example, the Python code  a + b is syntactically valid at the phrase level, but the correctness of the types of a and b can only be determined at runtime, as variables do not have types in Python, only values do. Whereas there is disagreement about whether a type error detected by the compiler should be called a syntax error (rather than a static semantic error), type errors which can only be detected at program execution time are always regarded as semantic rather than syntax errors.  Syntax definition  Parse tree of Python code with inset tokenization The syntax of textual programming languages is usually defined using a combination of regular expressions (for lexical structure) and Backus–Naur form (for grammatical structure) to inductively specify syntactic categories (nonterminals) and terminal symbols. Syntactic categories are defined by rules called productions, which specify the values that belong to a particular syntactic category.[1] Terminal symbols are the concrete characters or strings of characters (for example keywords such as define, if, let, or void) from which syntactically valid programs are constructed.  A language can have different equivalent grammars, such as equivalent regular expressions (at the lexical levels), or different phrase rules which generate the same language. Using a broader category of grammars, such as LR grammars, can allow shorter or simpler grammars compared with more restricted categories, such as LL grammar, which may require longer grammars with more rules. Different but equivalent phrase grammars yield different parse trees, though the underlying language (set of valid documents) is the same.  Example: Lisp S-expressions Below is a simple grammar, defined using the notation of regular expressions and Extended Backus–Naur form. It describes the syntax of S-expressions, a data syntax of the programming language Lisp, which defines productions for the syntactic categories expression, atom, number, symbol, and list:  expression = atom   | list atom       = number | symbol     number     = [+-]?['0'-'9']+ symbol     = ['A'-'Z']['A'-'Z''0'-'9'].* list       = '(', expression*, ')' This grammar specifies the following:  an expression is either an atom or a list; an atom is either a number or a symbol; a number is an unbroken sequence of one or more decimal digits, optionally preceded by a plus or minus sign; a symbol is a letter followed by zero or more of any characters (excluding whitespace); and a list is a matched pair of parentheses, with zero or more expressions inside it. Here the decimal digits, upper- and lower-case characters, and parentheses are terminal symbols.  The following are examples of well-formed token sequences in this grammar: '12345', '()', '(A B C232 (1))'  Complex grammars The grammar needed to specify a programming language can be classified by its position in the Chomsky hierarchy. The phrase grammar of most programming languages can be specified using a Type-2 grammar, i.e., they are context-free grammars,[6] though the overall syntax is context-sensitive (due to variable declarations and nested scopes), hence Type-1. However, there are exceptions, and for some languages the phrase grammar is Type-0 (Turing-complete).  In some languages like Perl and Lisp the specification (or implementation) of the language allows constructs that execute during the parsing phase. Furthermore, these languages have constructs that allow the programmer to alter the behavior of the parser. This combination effectively blurs the distinction between parsing and execution, and makes syntax analysis an undecidable problem in these languages, meaning that the parsing phase may not finish. For example, in Perl it is possible to execute code during parsing using a BEGIN statement, and Perl function prototypes may alter the syntactic interpretation, and possibly even the syntactic validity of the remaining code.[7] Colloquially this is referred to as "only Perl can parse Perl" (because code must be executed during parsing, and can modify the grammar), or more strongly "even Perl cannot parse Perl" (because it is undecidable). Similarly, Lisp macros introduced by the defmacro syntax also execute during parsing, meaning that a Lisp compiler must have an entire Lisp run-time system present. In contrast, C macros are merely string replacements, and do not require code execution.[8][9]  Syntax versus semantics The syntax of a language describes the form of a valid program, but does not provide any information about the meaning of the program or the results of executing that program. The meaning given to a combination of symbols is handled by semantics (either formal or hard-coded in a reference implementation). Not all syntactically correct programs are semantically correct. Many syntactically correct programs are nonetheless ill-formed, per the language's rules; and may (depending on the language specification and the soundness of the implementation) result in an error on translation or execution. In some cases, such programs may exhibit undefined behavior. Even when a program is well-defined within a language, it may still have a meaning that is not intended by the person who wrote it.  Using natural language as an example, it may not be possible to assign a meaning to a grammatically correct sentence or the sentence may be false:  "Colorless green ideas sleep furiously." is grammatically well formed but has no generally accepted meaning. "John is a married bachelor." is grammatically well formed but expresses a meaning that cannot be true. The following C language fragment is syntactically correct, but performs an operation that is not semantically defined (because p is a null pointer, the operations p->real and p->im have no meaning):   complex *p = NULL;  complex abs_p = sqrt (p->real * p->real + p->im * p->im); As a simpler example,   int x;  printf("%d", x); is syntactically valid, but not semantically defined, as it uses an uninitialized variable. Even though compilers for some programming languages (e.g., Java and C#) would detect uninitialized variable errors of this kind, they should be regarded as semantic errors rather than syntax errors.[5][10]  See also Naming convention (programming) Comparison of programming languages (syntax) To quickly compare syntax of various programming languages, take a look at the list of "Hello, World!" program examples:  Prolog syntax and semantics Perl syntax PHP syntax and semantics C syntax C++ syntax Java syntax JavaScript syntax Python syntax and semantics Lua syntax Haskell syntax References  Friedman, Daniel P.; Mitchell Wand; Christopher T. Haynes (1992). Essentials of Programming Languages (1st ed.). The MIT Press. ISBN 0-262-06145-7.  Smith, Dennis (1999). Designing Maintainable Software. Springer Science & Business Media.  Aho, Alfred V.; Monica S. Lam; Ravi Sethi; Jeffrey D. Ullman (2007). Compilers: Principles, Techniques, and Tools (2nd ed.). Addison Wesley. ISBN 0-321-48681-1.Section 4.1.3: Syntax Error Handling, pp.194–195.  Louden, Kenneth C. (1997). Compiler Construction: Principles and Practice. Brooks/Cole. ISBN 981-243-694-4. Exercise 1.3, pp.27–28.  Semantic Errors in Java  Michael Sipser (1997). Introduction to the Theory of Computation. PWS Publishing. ISBN 0-534-94728-X. Section 2.2: Pushdown Automata, pp.101–114.  The following discussions give examples: Perl and Undecidability LtU comment clarifying that the undecidable problem is membership in the class of Perl programs chromatic's example of Perl code that gives a syntax error depending on the value of random variable  "An Introduction to Common Lisp Macros". Apl.jhu.edu. 1996-02-08. Archived from the original on 2013-08-06. Retrieved 2013-08-17.  "The Common Lisp Cookbook - Macros and Backquote". Cl-cookbook.sourceforge.net. 2007-01-16. Retrieved 2013-08-17.  Issue of syntax or semantics? External links Various syntactic constructs used in computer programming languages Python error “ImportError: No module named” Why? How? Command-Line? [Solved2021] Categories: Programming language syntaxProgramming language topicsSource code Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadEditView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version  Languages العربية Ελληνικά 한국어 Italiano Македонски Nederlands Русский தமிழ் Tiếng Việt 11 more Edit links This page was last edited on 1 October 2021, at 03:32 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki   Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more Visual programming language From Wikipedia, the free encyclopedia   (Redirected from Visual programming languages) Jump to navigationJump to search Not to be confused with Design language.  An implementation of a "Hello, world!" program in the Scratch programming language making the "Cat" sprite "say" the text "Hello World!" In computing, a visual programming language (VPL) is any programming language that lets users create programs by manipulating program elements graphically rather than by specifying them textually.[1][2] A VPL allows programming with visual expressions, spatial arrangements of text and graphic symbols, used either as elements of syntax or secondary notation. For example, many VPLs (known as dataflow or diagrammatic programming)[3][4] are based on the idea of "boxes and arrows", where boxes or other screen objects are treated as entities, connected by arrows, lines or arcs which represent relations.   Contents 1	Definition 2	List of visual languages 2.1	Educational 2.2	Multimedia 2.3	Video games 2.4	Systems / simulation 2.5	Automation 2.6	Data warehousing / business intelligence 2.7	Miscellaneous 2.8	Legacy 3	Visual styles 4	See also 5	References 6	External links Definition VPLs may be further classified, according to the type and extent of visual expression used, into icon-based languages, form-based languages, and diagram languages. Visual programming environments provide graphical or iconic elements which can be manipulated by users in an interactive way according to some specific spatial grammar for program construction.  The general goal of VPLs is to make programming more accessible to novices and to support programmers at three different levels[5]  Syntax: VPLs use icons/blocks, forms and diagrams trying to reduce or even eliminate the potential of syntactic errors helping with the arrangement of programming primitives to create well-formed programs. Semantics: VPLs may provide some mechanisms to disclose the meaning of programming primitives. This could include help functions providing documentation functions built-in to programming languages. Pragmatics: VPLs support the study of what programs mean in particular situations. This level of support allows users to put artifacts created with a VPL into a certain state in order to explore how the program will react to that state. Examples: In AgentSheets or AgentCubes users can set games or simulations into a particular state in order to see how program would react. With the Thymio programming language users can bring a robot into a certain state in order to see how it will react, i.e., which sensors will be activated. Current developments try to integrate the visual programming approach with dataflow programming languages to either have immediate access to the program state, resulting in online debugging, or automatic program generation and documentation. Dataflow languages also allow automatic parallelization, which is likely to become one of the greatest programming challenges of the future.[6]  The Visual Basic, Visual C#, Visual J# etc. languages of the Microsoft Visual Studio IDE are not visual programming languages: the representation of algorithms etc. is textual even though the IDE embellishes the editing and debugging activities with a rich user interface. A similar consideration applies to most other rapid application development environments which typically support a form designer and sometimes also have graphical tools to illustrate (but not define) control flow and data dependencies.  Parsers for visual programming languages can be implemented using graph grammars.[7][8]  List of visual languages This is a dynamic list and may never be able to satisfy particular standards for completeness. You can help by adding missing items with reliable sources. The following contains a list of notable visual programming languages.  Educational AgentCubes, 3D and 2D game design and simulation design computational thinking tools. AgentSheets, game authoring and computational science authoring tool. Alice, an object based language used to program 3D environments. Analytica, for building and analyzing quantitative models for decision and risk analysis. App Inventor for Android, a tool for creating Android applications, based on Blockly and Kawa. Blockly, a client-side library for the programming language JavaScript for creating block-based visual programming languages (VPLs) and editors Bubble, for creating production-ready web applications. Catrobat, block-based visual programming language for animations, games Flowgorithm, creates executable flowcharts which can be converted to several languages. Hopscotch, an iPad app, and visual programming language for creating touchscreen-oriented mobile applications. Kodu, a visual programming tool for Logo. Kojo, a programming language, IDE, and learning environment. mBlock, an extension of Scratch for Arduino hardware interfaces. Developed by Makeblock. Open Roberta, online programming environment from Fraunhofer IAIS, designed for children. Raptor, a product of the USAF, for drawing executable flowcharts. Scratch, a product of MIT, designed for children in K-12 and after-school programs. ScratchJr, another product of MIT, designed for 5-7-year-old children. Snap!, a browser-based reimplementation of BYOB, and extension of Scratch, with first class procedures and lists. Used for teaching at UC Berkeley. Stagecast Creator, a Java-based teaching system. StarLogo, an agent-based simulation language developed by Mitchel Resnick, Eric Klopfer, and others at MIT Media Lab. An extension of the Logo programming language (a dialect of Lisp). ToonTalk, programming system for children. Visual Logic, for creating executable flowcharts. VIPLE Visual IoT/Robotics Programming Language Environment Multimedia AudioMulch, an audio signal flow based sound and music creation environment Bidule, a modular node and patch cord environment for the creation of interactive computer music and multimedia (Windows, MacOS).[9] Blender (software), the open source 3D graphics package, includes node graphs for building shaders,[10] composites[11] and textures,[12]none-destructive geometry.[13][14] Cameleon, graphical functional language Clickteam's The games factory/Multimedia fusion series, environments made for visually developing games Dynamo, a generative modeling interface for Autodesk Revit Filter Forge Node based filter generation for image processing. Houdini (software) vfx, modeling and animation software. GenerativeComponents, a parametric CAD software developed by Bentley Systems Grasshopper 3d, a generative modeling interface for Rhinoceros 3D Kyma (sound design language), a visual programming language for sound design used by musicians, researchers, and sound designers. Mama (software) – a programming language and IDE for building 3D animations and games Max (software), visual programming environment for building interactive, real-time music and multimedia applications Max/MSP Pure Data nato.0+55+3d Nodal, a node-based generative programming software application for music composition Nuke, an object-based visual programming software for visual effects compositing by The Foundry powered by Tcl, Python and Blink-script. OpenMusic, a visual programming language for music composition (based on Common Lisp Object System (CLOS)) applications, and mobile applications Pure Data (Pd) is a visual programming language developed for creating interactive computer music and multimedia works. Quartz Composer, a language for processing and rendering graphical data (macOS) Reaktor, a DSP and MIDI-processing language by Native Instruments Scala Multimedia Authoring suite and complete multimedia system for AmigaOS and Windows Softimage, with ICE Interactive Creative Environment. SynthEdit, a Synthesizer construction tool using a VPL. TouchDesigner, visual programming language for real-time multimedia content Virtools, a middleware used to create interactive 3D experiences vvvv, a general purpose toolkit with a special focus on real-time video synthesis and programming large media environments with physical interfaces, real-time motion graphics, audio and video. WireFusion, visual programming environment for creating interactive 3D web presentations Video games Babylon.js has a node material editor that can be used to build shaders, procedural textures, particle systems and post processing effects.[15] Blender Game Engine (Graphical logic editor) Construct 2 is an HTML5-based 2D game editor, developed by Scirra Ltd. Construct Classic is the previous, DirectX-based open-sourced version of Construct.[16][17] CryEngine has a node-based visual programming language called FlowGraph. GameMaker Studio, has a drag and drop game creation system developed by YoYo Games. GameSalad is a visual game creation tool developed by GameSalad, Inc. GDevelop is a visual game creation tool created by Florian Rival (4ian). Godot, in-house open source MIT Licensed game development software. Human Resource Machine is a visual programming-based puzzle game developed by Tomorrow Corporation. Kodu, a software designed to program games with a 3D Interface developed by Microsoft Research. Pixel Game Maker MV is an interface-based 2D video game development tool. Rec Room includes a game creation system with a node-based visual programming language called Circuits. Snowdrop has a visual scripting system. Stencyl, a video game creation tool. Unity has a visual scripting system as of the ECS release. Unreal Engine 4 has a node-based visual programming language called Blueprints, and also shaders. Clickteam Fusion, a 2D game creation software with event editor system, developed by Clickteam SARL, originally known as Klik n' Play, The Games Factory and Multimedia Fusion 2 Game Builder Garage, a 3D and 2D game creation tool for the Nintendo Switch, developed by Nintendo. Many modern video games make use of behavior trees, which are in principle a family of simple programming languages designed to model behaviors for non-player characters. The behaviors are modeled as trees, and are often edited in graphical editors.  Systems / simulation Analytica, a commercial visual language for decision models based on influence diagrams. BPEL (Business Process Execution Language), currently a Graphical user based Programming Language used to create orchestration logic for data and web services. It is based on XML, but has a graphical interface for faster coding. DRAKON, a graphical algorithmic language EICASLAB, a software suite including a graphical language for supporting the design of control architectures Flowcode is a graphical programming language to program embedded microprocessors Function block diagrams, used in programmable logic controllers GNU Radio, a development toolkit which provides signal-processing blocks to implement software-defined-radios and signal-processing systems KNIME, the Konstanz Information Miner, is an open source data analytics, reporting and integration platform LabVIEW, a graphical language designed for engineers and scientists Ladder logic, a language that simulates relay logic commonly used in programmable logic controllers MeVisLab, cross-platform application framework for medical image processing and scientific visualization Microsoft Visual Programming Language, dataflow language for robotics programming that is a component of Microsoft Robotics Studio MindRover, a robot programming game incorporating a dataflow "wiring" language Minibloq, visual programming language for robotics and Arduino compatible boards MST Workshop, an interactive visual programming language for creating mathematical solutions, rapid prototyping, two-dimensional and three-dimensional graphic applications Node-RED: software system rapid development toolkit NXT-G, a visual programming language for the Lego Mindstorms NXT robotics kit OpenDX scientific data visualization using a visual programming language and data flow model OpenWire - adds visual dataflow programming abilities to Delphi via Visual Component Library (VCL) components and a graphical editor (homonymous binary protocol is unrelated) Orange - An open-source, visual programming tool for data mining, statistical data analysis, and machine learning OutSystems language, a visual modeling language to develop and change all layers of business centric web applications Prograph - an object-oriented programming language that uses iconic symbols to represent actions to be taken on data Ptolemy Project - a project aimed at modeling and designing real-time embedded systems. Qucs graphical interface to set up simulation of electronic circuit signal and noise behavior Reallusion - iClone, a 3D software with Lua language and visual programing design ROBO Pro, a visual programming language for the fischertechnik robotics kit Scicos A graphical language associated with the numerical analysis package ScicosLab (originally SciLab) Sequential function chart, a Petri-net like programming language for programmable logic controllers Simulink, graphical programming environment for modeling, simulating and analyzing multidomain dynamical systems Stateflow, a graphical language that includes  executable state transition diagrams, flow charts, state transition tables, and truth tables STELLA, a VPL for system dynamics modeling Softimage ICE, a node-based system that is used to create and modify 3D models, simulate particles and perform various other tasks VEE VisSim, modeling and simulation language, allows making mathematical models quickly and executing them in real-time Automation Automator CiMPLE, Visual Programming Language by ThinkLABs for teaching robotics Flow a graphical integration language used in the webMethods platform Pipeline Pilot is a scientific visual and dataflow programming language, and the authoring tool for the Accelrys Enterprise Platform. Data warehousing / business intelligence Ab Initio, a tool for ETL processing by creating graphs Alteryx Designer, a tool for data processing and analytics incorporating SQL, R, and Python. Apache Nifi, software project to automate the flow of data between software systems. IBM Cognos Business Intelligence, is an example for front-end programs in Business Intelligence applications, which are used to generate SQL queries to run against RDBMS databases IBM InfoSphere DataStage, an ETL tool Informatica Powercenter is an ETL tool to design mappings graphically for data load in Data Warehouse systems Microsoft SQL Server Integration Services (SSIS), a platform for data integration and workflow applications Pentaho Data Integration (PDI), formerly named Kettle, an open-source ETL tool Miscellaneous Kwikpoint, an isotype visual translator created by Alan Stillman Lava, an experimental object oriented RAD language Limnor, a general purpose programming system. Limnor Studio is an IDE for rapid software development. Morphic (software), makes it easier to build and edit graphical objects by direct manipulation and from within programs; the whole Self (programming language) programming environment is built using Morphic Piet, an esoteric language, the program is an image whose pixels are the language's elements PWCT, Free open source visual programming language for software development StreamBase Systems, StreamBase EventFlow is a visual programming language for processing streaming events WebML, is a visual language for designing complex data-intensive Web applications that can be automatically generated Yahoo! Pipes is a visual data-flow programming system to process web data[18] YAWL, graphical workflow language Legacy AppWare, also known as MicroBrew, icon based programming for classic Mac OS and Microsoft Windows Macromedia Authorware - flowchart based programming language Helix and Double Helix, a pioneering database management system for the Apple Macintosh platform, created in 1983 Illumination Software Creator, a language and IDE for visually creating desktop and mobile software ThingLab Visual styles DRAKON (Dragon), a SDL- and AADL-influenced visual 2D programming language designed for developing the on-board hard real-time software system for automatic flight and landing of the Soviet/Russian Buran (Snowstorm) orbiting spacecraft Executable UML, a profile of the Universal Modeling Language specification defining executable semantics for a subset of UML Flowchart Subtext See also Argument map Cognitive dimensions of notations - Notation assessment for visual and non-visual languages Concept map Dataflow programming Deutsch limit, an aphorism about the information density of language primitives in a visual notation Domain-specific modeling Drag and drop Flow-based programming Graph drawing Low-code development platform No-code development platform Programming game Unified Modeling Language Visual language Visual thinking References  Jost, Beate; Ketterl, Markus; Budde, Reinhard; Leimbach, Thorsten (2014). "Graphical Programming Environments for Educational Robots: Open Roberta - Yet Another One?". 2014 IEEE International Symposium on Multimedia. pp. 381–386. doi:10.1109/ISM.2014.24. ISBN 978-1-4799-4311-1.  The Maturity of Visual Programming  Bragg, S.D.; Driskill, C.G. (1994). "Diagrammatic-graphical programming languages and DoD-STD-2167A". Proceedings of AUTOTESTCON '94. pp. 211–220. doi:10.1109/AUTEST.1994.381508. ISBN 0-7803-1910-9.  Kuhail, M. A.; Farooq, S.; Hammad, R.; Bahja, M. (2021). "Characterizing Visual Programming Approaches for End-User Developers: A Systematic Review". IEEE Access. 9: 14181–14202. doi:10.1109/ACCESS.2021.3051043.  Repenning, Alexander (2017). "Moving Beyond Syntax: Lessons from 20 Years of Blocks Programing in AgentSheets". Journal of Visual Languages and Sentient Systems. 3: 68–91. doi:10.18293/vlss2017-010.  Johnston, W.M.; Hanna, J.R.P.; Millar, R.J. (2004). "Advances in dataflow programming languages" (PDF). ACM Computing Surveys. 36 (1): 1–34. doi:10.1145/1013208.1013209. Retrieved 2011-02-16.  Rekers, J.; Schürr, A. (1997). "Defining and parsing visual languages with layered graph grammars". Journal of Visual Languages & Computing. 8 (1): 27–55. doi:10.1006/jvlc.1996.0027.  Zhang, D.-Q. (2001). "A context-sensitive graph grammar formalism for the specification of visual languages". The Computer Journal. 44 (3): 186–200. doi:10.1093/comjnl/44.3.186.  http://www.computermusicjournal.org/reviews/31-* * * 2/regan-bidule.html  "Shader Editor — Blender Manual". docs.blender.org. Retrieved 2021-01-22.  "Compositing — Blender Manual". docs.blender.org. Retrieved 2021-01-22.  "Texture Editing — Blender Manual". docs.blender.org. Retrieved 2021-01-22.  "Reference/Release Notes/2.92/Geometry Nodes - Blender Developer Wiki". wiki.blender.org. Retrieved 2021-01-22.  "Geometry Nodes — Blender Manual". docs.blender.org. Retrieved 2021-10-02.  "Babylon.js Node Material Editor". nme.babylonjs.com. Retrieved 2021-01-22.  Construct Classic home page  Construct Classic page on SourceForge  "Yahoo! pipes". Archived from the original on 2015-01-03. Retrieved 2015-01-03. This article was originally based on material from the Free On-line Dictionary of Computing, used with permission. Update as needed. External links Visual programming languages at Curlie Visual Programming Languages - Snapshots vte Types of programming languages Authority control Edit this at Wikidata Categories: Programming language classificationVisual programming languages Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadEditView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons  Languages العربية Deutsch Ελληνικά Español Français 한국어 日本語 Русский 中文 13 more Edit links This page was last edited on 5 October 2021, at 04:03 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki   Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more Computer program From Wikipedia, the free encyclopedia Jump to navigationJump to search For the TV program, see The Computer Programme. Program execution General concepts Code Translation Compiler Compile-time Optimizing compiler Intermediate representation (IR) Execution Runtime system Runtime Executable Interpreter Virtual machine Types of code Source code Object code Bytecode Machine code Microcode Compilation strategies Just-in-time (JIT) Tracing just-in-time Ahead-of-time (AOT) Transcompilation Recompilation Notable runtimes Android Runtime (ART) Common Language Runtime (CLR) and Mono crt0 Java virtual machine (JVM) Objective-C and Swift V8 and Node.js CPython and PyPy Zend Engine (PHP) Notable compilers & toolchains GNU Compiler Collection (GCC) LLVM and Clang vte A computer program is a collection of instructions[1] that can be executed by a computer to perform a specific task.  A computer program is usually written by a computer programmer in a programming language. From the program in its human-readable form of source code, a compiler or assembler can derive machine code—a form consisting of instructions that the computer can directly execute. Alternatively, a computer program may be executed with the aid of an interpreter.  A collection of computer programs, libraries, and related data are referred to as software. Computer programs may be categorized along functional lines, such as applications software and system software. The underlying method used for some calculation or manipulation is known as an algorithm. The way data is organized is referred to data structures.   Contents 1	History 1.1	Early programmable machines 1.2	Analytical Engine 1.3	Universal Turing machine 1.4	Early programmable computers 1.5	Later computers 2	Computer programming 2.1	Programming languages 2.1.1	Imperative languages 2.1.2	Declarative languages 2.2	Compilation and interpretation 3	Storage and execution 3.1	Simultaneous execution 3.2	Self-modifying programs 4	Functional categories 4.1	Application software 4.2	Utility programs 4.3	Operating system 4.4	Boot program 4.5	Embedded programs 4.6	Microcode programs 5	See also 6	References 7	Further reading History See also: Computer programming § History, Programmer § History, History of computing, History of programming languages, and History of software Code-breaking algorithms have existed for centuries. In the 9th century, the Arab mathematician Al-Kindi described a cryptographic algorithm for deciphering encrypted code, in A Manuscript On Deciphering Cryptographic Messages. He gave the first description of cryptanalysis by frequency analysis, the earliest code-breaking algorithm.[2]  Early programmable machines The earliest programmable machines preceded the invention of the digital computer. As early as the 9th century, a programmable music sequencer was invented by the Persian Banu Musa brothers, who described an automated mechanical flute player in the Book of Ingenious Devices.[3][4] In 1206, the Arab engineer Al-Jazari invented a programmable drum machine where musical mechanical automata could be made to play different rhythms and drum patterns.[5] In 1801, Joseph-Marie Jacquard devised a loom that would weave a pattern by following a series of perforated cards. Patterns could be woven and repeated by arranging the cards.[6]  Analytical Engine  Lovelace's diagram from Note G, the first published computer algorithm In 1837, Charles Babbage was inspired by Jacquard's loom to attempt to build the Analytical Engine.[6] The names of the components of the calculating device were borrowed from the textile industry. In the textile industry, yarn was brought from the store to be milled. The device would have had a "store"—memory to hold 1,000 numbers of 40 decimal digits each. Numbers from the "store" would then have then been transferred to the "mill" (analogous to the CPU of a modern machine), for processing. A "thread" is the execution of programmed instructions by the device. It was programmed using two sets of perforated cards—one to direct the operation and the other for the input variables.[6] [7] However, after more than 17,000 pounds of the British government's money, the thousands of cogged wheels and gears never fully worked together.[8]  During a nine-month period in 1842–43, Ada Lovelace translated the memoir of Italian mathematician Luigi Menabrea. The memoir covered the Analytical Engine. The translation contained Note G which completely detailed a method for calculating Bernoulli numbers using the Analytical Engine. This note is recognized by some historians as the world's first written computer program.[9]  Universal Turing machine In 1936, Alan Turing introduced the Universal Turing machine—a theoretical device that can model every computation that can be performed on a Turing complete computing machine.[10] It is a finite-state machine that has an infinitely long read/write tape. The machine can move the tape back and forth, changing its contents as it performs an algorithm. The machine starts in the initial state, goes through a sequence of steps, and halts when it encounters the halt state.[11] This machine is considered by some to be the origin of the stored-program computer—used by John von Neumann (1946) for the "Electronic Computing Instrument" that now bears the von Neumann architecture name.[12]  Early programmable computers The Z3 computer, invented by Konrad Zuse (1941) in Germany, was a digital and programmable computer.[13] A digital computer uses electricity as the calculating component. The Z3 contained 2,400 relays to create the circuits. The circuits provided a binary, floating-point, nine-instruction computer. Programming the Z3 was through a specially designed keyboard and punched tape.  The Electronic Numerical Integrator And Computer (Fall 1945) was a Turing complete, general-purpose computer that used 17,468 vacuum tubes to create the circuits. At its core, it was a series of Pascalines wired together.[14] Its 40 units weighed 30 tons, occupied 1,800 square feet (167 m2), and consumed $650 per hour (in 1940s currency) in electricity when idle.[14] It had 20 base-10 accumulators. Programming the ENIAC took up to two months.[14] Three function tables were on wheels and needed to be rolled to fixed function panels. Function tables were connected to function panels using heavy black cables. Each function table had 728 rotating knobs. Programming the ENIAC also involved setting some of the 3,000 switches. Debugging a program took a week.[14] The programmers of the ENIAC were women who were known collectively as the "ENIAC girls"[15] and included Jean Jennings Bartik, Betty Holberton, Marlyn Wescoff, Kathleen McNulty, Ruth Teitelbaum, and Frances Spence. [16] The ENIAC featured parallel operations. Different sets of accumulators could simultaneously work on different algorithms. It used punched card machines for input and output, and it was controlled with a clock signal. It ran for eight years, calculating hydrogen bomb parameters, predicting weather patterns, and producing firing tables to aim artillery guns.  The Manchester Baby (June 1948) was a stored-program computer.[17] Programming transitioned away from moving cables and setting dials; instead, a computer program was stored in memory as numbers. Only three bits of memory were available to store each instruction, so it was limited to eight instructions. 32 switches were available for programming.  Later computers  Switches for manual input on a Data General Nova 3, manufactured in the mid-1970s Computers manufactured until the 1970s had front-panel switches for programming. The computer program was written on paper for reference. An instruction was represented by a configuration of on/off settings. After setting the configuration, an execute button was pressed. This process was then repeated. Computer programs also were manually input via paper tape or punched cards. After the medium was loaded, the starting address was set via switches, and the execute button was pressed.[18]  In 1961, the Burroughs B5000 was built specifically to be programmed in the ALGOL 60 language. The hardware featured circuits to ease the compile phase.[19]  In 1964, the IBM System/360 was a line of six computers each having the same instruction set architecture. The Model 30 was the smallest and least expensive. Customers could upgrade and retain the same application software.[20] Each System/360 model featured multiprogramming. With operating system support, multiple programs could be in memory at once. When one was waiting for input/output, another could compute. Each model also could emulate other computers. Customers could upgrade to the System/360 and retain their IBM 7094 or IBM 1401 application software.[20]  Computer programming Main article: Computer programming  "hello, world" computer program by Brian Kernighan (1978) Computer programming is the process of writing or editing source code. Editing source code involves testing, analyzing, refining, and sometimes coordinating with other programmers on a jointly developed program. A person who practices this skill is referred to as a computer programmer, software developer, and sometimes coder.  The sometimes lengthy process of computer programming is usually referred to as software development. The term software engineering is becoming popular as the process is seen as an engineering discipline.  Programming languages Main article: Programming language  A computer program written in the imperative programming style Computer programs can be categorized by the programming language paradigm used to produce them. Two of the main paradigms are imperative and declarative.  Imperative languages Imperative programming languages specify a sequential algorithm using declarations, expressions, and statements:[21]  A declaration couples a variable name to a datatype – for example: var x: integer; An expression yields a value – for example: 2 + 2 yields 4 A statement might assign an expression to a variable or use the value of a variable to alter the program's control flow – for example: x := 2 + 2; if x = 4 then do_something(); One criticism of imperative languages is the side effect of an assignment statement on a class of variables called non-local variables.[22]  Declarative languages Declarative programming languages describe what computation should be performed and not how to compute it. Declarative programs omit the control flow and are considered sets of instructions. Two broad categories of declarative languages are functional languages and logical languages. The principle behind functional languages (like Haskell) is to not allow side effects, which makes it easier to reason about programs like mathematical functions.[22] The principle behind logical languages (like Prolog) is to define the problem to be solved – the goal – and leave the detailed solution to the Prolog system itself.[23] The goal is defined by providing a list of subgoals. Then each subgoal is defined by further providing a list of its subgoals, etc. If a path of subgoals fails to find a solution, then that subgoal is backtracked and another path is systematically attempted.  Compilation and interpretation A computer program in the form of a human-readable, computer programming language is called source code. Source code may be converted into an executable image by a compiler or assembler, or executed immediately with the aid of an interpreter.  Compilers are used to translate source code from a programming language into either object code or machine code.[24] Object code needs further processing to become machine code, and machine code consists of the central processing unit's native instructions, ready for execution. Compiled computer programs are commonly referred to as executables, binary images, or simply as binaries – a reference to the binary file format used to store the executable code.  Some compiled and assembled object programs need to be combined as modules with a linker utility in order to produce an executable program.  Interpreters are used to execute source code from a programming language line-by-line. The interpreter decodes each statement and performs its behavior. One advantage of interpreters is that they can easily be extended to an interactive session. The programmer is presented with a prompt, and individual lines of code are typed in and performed immediately.  The main disadvantage of interpreters is computer programs run slower than when compiled. Interpreting code is slower because the interpreter must decode each statement and then perform it. However, software development may be faster using an interpreter because testing is immediate when the compiling step is omitted. Another disadvantage of interpreters is an interpreter must be present on the executing computer. By contrast, compiled computer programs need no compiler present during execution.  Just in time compilers pre-compile computer programs just before execution. For example, the Java virtual machine Hotspot contains a Just In Time Compiler which selectively compiles Java bytecode into machine code – but only code which Hotspot predicts is likely to be used many times.  Either compiled or interpreted programs might be executed in a batch process without human interaction.  Scripting languages are often used to create batch processes. One common scripting language is Unix shell, and its executing environment is called the command-line interface.  No properties of a programming language require it to be exclusively compiled or exclusively interpreted. The categorization usually reflects the most popular method of language execution. For example, Java is thought of as an interpreted language and C a compiled language, despite the existence of Java compilers and C interpreters.  Storage and execution  In the 1950s, computer programs were stored on perforated paper tape Typically, computer programs are stored in non-volatile memory until requested either directly or indirectly to be executed by the computer user. Upon such a request, the program is loaded into random-access memory, by a computer program called an operating system, where it can be accessed directly by the central processor. The central processor then executes ("runs") the program, instruction by instruction, until termination. A program in execution is called a process.[25] Termination is either by normal self-termination, by user intervention, or by error – software or hardware error.  Simultaneous execution See also: Process (computing) and Multiprocessing Many operating systems support multitasking which enables many computer programs to appear to run simultaneously on one computer. Operating systems may run multiple programs through process scheduling – a software mechanism to switch the CPU among processes often so users can interact with each program while it runs.[26] Within hardware, modern day multiprocessor computers or computers with multicore processors may run multiple programs.[27]  Self-modifying programs Main article: Self-modifying code A computer program in execution is normally treated as being different from the data the program operates on. However, in some cases, this distinction is blurred when a computer program modifies itself. The modified computer program is subsequently executed as part of the same program. Self-modifying code is possible for programs written in machine code, assembly language, Lisp, C, COBOL, PL/1, and Prolog.  Functional categories Computer programs may be categorized along functional lines. The main functional categories are application software and system software. System software includes the operating system which couples computer hardware with application software.[28] The purpose of the operating system is to provide an environment in which application software executes in a convenient and efficient manner.[28] In addition to the operating system, system software includes embedded programs, boot programs, and micro programs. Application software designed for end users have a user interface. Application software not designed for the end user includes middleware, which couples one application with another. Application software also includes utility programs. The distinction between system software and application software is under debate.  Application software Main article: Application software  Example of an app: GCalctool, a software calculator There are many types of application software:  The word app came to being in 21st century. It is a clipping of the word "application". They have been designed for many platforms, but the word was first used for smaller mobile apps. Desktop apps are traditional computer programs that run on desktop computers. Mobile apps run on mobile devices. Web apps run inside a web browser. Both mobile and desktop apps may be downloaded from the developers' website or purchased from app stores such as Microsoft Store, Apple App Store, Mac App Store, Google Play or Intel AppUp. An application suite consists of multiple applications bundled together. Examples include Microsoft Office, LibreOffice, and iWork. They bundle a word processor, spreadsheet, and other applications. Enterprise applications bundle accounting, personnel, customer, and vendor applications. Examples include enterprise resource planning, customer relationship management, and supply chain management software. Enterprise infrastructure software supports the enterprise's software systems. Examples include databases, email servers, and network servers. Information worker software are designed for workers at the departmental level. Examples include time management, resource management, analytical, collaborative and documentation tools. Word processors, spreadsheets, email and blog clients, personal information system, and individual media editors may aid in multiple information worker tasks. Media development software generates print and electronic media for others to consume, most often in a commercial or educational setting. These produce graphics, publications, animations, and videos. Product engineering software is used to help develop large machines and other application software. Examples includes computer-aided design (CAD), computer-aided engineering (CAE), and integrated development environments. Entertainment Software can refer to video games, movie recorders and players, and music recorders and players. Utility programs Utility programs are application programs designed to aid system administrators and computer programmers.  Operating system See also: Operating system An operating system is the low-level software that supports a computer's basic functions, such as scheduling tasks and controlling peripherals. [28]  In the 1950s, the programmer, who was also the operator, would write a program and run it. After the program finished executing, the output may have been printed, or it may have been punched onto paper tape or cards for later processing.[18] More often than not the program did not work. The programmer then looked at the console lights and fiddled with the console switches. If less fortunate, a memory printout was made for further study. In the 1960s, programmers reduced the amount of wasted time by automating the operator's job. A program called an operating system was kept in the computer at all times.[29]  Originally, operating systems were programmed in assembly; however, modern operating systems are typically written in C.  Boot program A stored-program computer requires an initial computer program stored in its read-only memory to boot. The boot process is to identify and initialize all aspects of the system, from processor registers to device controllers to memory contents.[30] Following the initialization process, this initial computer program loads the operating system and sets the program counter to begin normal operations.  Embedded programs  The microcontroller on the right of this USB flash drive is controlled with embedded firmware. Independent of the host computer, a hardware device might have embedded firmware to control its operation. Firmware is used when the computer program is rarely or never expected to change, or when the program must not be lost when the power is off.[29]  Microcode programs Main article: Microcode Microcode programs control some central processing units and some other hardware. This code moves data between the registers, buses, arithmetic logic units, and other functional units in the CPU. Unlike conventional programs, microcode is not usually written by, or even visible to, the end users of systems, and is usually provided by the manufacturer, and is considered internal to the device.  See also Artificial intelligence Automatic programming Computer virus Firmware Killer application Program lifecycle phase Software Software bug Toy program References  Rochkind, Marc J. (2004). Advanced Unix Programming, Second Edition. Addison-Wesley. p. 1.1.2.  Dooley, John F. (2013). A Brief History of Cryptology and Cryptographic Algorithms. Springer Science & Business Media. pp. 12–3. ISBN 9783319016283.  Koetsier, Teun (2001), "On the prehistory of programmable machines: musical automata, looms, calculators", Mechanism and Machine Theory, Elsevier, 36 (5): 589–603, doi:10.1016/S0094-114X(01)00005-2.  Kapur, Ajay; Carnegie, Dale; Murphy, Jim; Long, Jason (2017). "Loudspeakers Optional: A history of non-loudspeaker-based electroacoustic music". Organised Sound. Cambridge University Press. 22 (2): 195–205. doi:10.1017/S1355771817000103. ISSN 1355-7718.  Noel Sharkey (2007), A 13th Century Programmable Robot, University of Sheffield  McCartney, Scott (1999). ENIAC – The Triumphs and Tragedies of the World's First Computer. Walker and Company. p. 16. ISBN 978-0-8027-1348-3.  Bromley, Allan G. (1998). "Charles Babbage's Analytical Engine, 1838" (PDF). IEEE Annals of the History of Computing. 20 (4): 29–45. doi:10.1109/85.728228. S2CID 2285332.  Tanenbaum, Andrew S. (1990). Structured Computer Organization, Third Edition. Prentice Hall. p. 15. ISBN 978-0-13-854662-5.  J. Fuegi; J. Francis (October–December 2003), "Lovelace & Babbage and the creation of the 1843 'notes'", Annals of the History of Computing, 25 (4): 16, 19, 25, doi:10.1109/MAHC.2003.1253887  Rosen, Kenneth H. (1991). Discrete Mathematics and Its Applications. McGraw-Hill, Inc. p. 654. ISBN 978-0-07-053744-6.  Linz, Peter (1990). An Introduction to Formal Languages and Automata. D. C. Heath and Company. p. 234. ISBN 978-0-669-17342-0.  Davis, Martin (2000), Engines of Logic: Mathematicians and the origin of the Computer (1st ed.), New York NY: W. W. Norton & Company, ISBN 978-0-393-32229-3, (pb.)  "History of Computing".  McCartney, Scott (1999). ENIAC – The Triumphs and Tragedies of the World's First Computer. Walker and Company. p. 102. ISBN 978-0-8027-1348-3.  Frink, Brenda D. (1 June 2011). "Researcher reveals how "Computer Geeks" replaced "Computer Girls"". Gender News. Stanford University. Archived from the original on 12 March 2015. Retrieved 22 October 2018.  Bartik, Jean Jennings (2013). Rickman, Jon; Todd, Kim D. (eds.). Pioneer programmer: Jean Jennings Bartik and the computer that changed the world. Truman State University Press.  Enticknap, Nicholas (Summer 1998), "Computing's Golden Jubilee", Resurrection (20), ISSN 0958-7403, archived from the original on 9 January 2012, retrieved 19 April 2008  Silberschatz, Abraham (1994). Operating System Concepts, Fourth Edition. Addison-Wesley. p. 6. ISBN 978-0-201-50480-4.  Tanenbaum, Andrew S. (1990). Structured Computer Organization, Third Edition. Prentice Hall. p. 20. ISBN 978-0-13-854662-5.  Tanenbaum, Andrew S. (1990). Structured Computer Organization, Third Edition. Prentice Hall. p. 21. ISBN 978-0-13-854662-5.  Wilson, Leslie B. (1993). Comparative Programming Languages, Second Edition. Addison-Wesley. p. 75. ISBN 978-0-201-56885-1.  Wilson, Leslie B. (1993). Comparative Programming Languages, Second Edition. Addison-Wesley. p. 213. ISBN 978-0-201-56885-1.  Wilson, Leslie B. (1993). Comparative Programming Languages, Second Edition. Addison-Wesley. p. 244. ISBN 978-0-201-56885-1.  "What is a Compiler?". Retrieved 2012-01-10.  Silberschatz, Abraham (1994). Operating System Concepts, Fourth Edition. Addison-Wesley. p. 97. ISBN 978-0-201-50480-4.  Silberschatz, Abraham (1994). Operating System Concepts, Fourth Edition. Addison-Wesley. p. 100. ISBN 978-0-201-50480-4.  Akhter, Shameem (2006). Multi-Core Programming. Richard Bowles (Intel Press). pp. 11–13. ISBN 978-0-9764832-4-3.  Silberschatz, Abraham (1994). Operating System Concepts, Fourth Edition. Addison-Wesley. p. 1. ISBN 978-0-201-50480-4.  Tanenbaum, Andrew S. (1990). Structured Computer Organization, Third Edition. Prentice Hall. p. 11. ISBN 978-0-13-854662-5.  Silberschatz, Abraham (1994). Operating System Concepts, Fourth Edition. Addison-Wesley. p. 30. ISBN 978-0-201-50480-4. Further reading Knuth, Donald E. (1997). The Art of Computer Programming, Volume 1, 3rd Edition. Boston: Addison-Wesley. ISBN 978-0-201-89683-1. Knuth, Donald E. (1997). The Art of Computer Programming, Volume 2, 3rd Edition. Boston: Addison-Wesley. ISBN 978-0-201-89684-8. Knuth, Donald E. (1997). The Art of Computer Programming, Volume 3, 3rd Edition. Boston: Addison-Wesley. ISBN 978-0-201-89685-5. Authority control Edit this at Wikidata General	 Integrated Authority File (Germany) National libraries	 SpainUnited States Other	 Microsoft AcademicNational Archives (US) Categories: Computer programmingSoftwareMathematical and quantitative methods (economics) Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadEditView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons  Languages Български Deutsch Ελληνικά Français हिन्दी Македонски Shqip Türkçe 中文 88 more Edit links This page was last edited on 9 October 2021, at 07:16 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki   Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more Page semi-protected Computer From Wikipedia, the free encyclopedia Jump to navigationJump to search For other uses, see Computer (disambiguation). Man replacing one vacuum tube out of hundreds in early computer Computer room with multiple computer cabinets and operating panel Smartphone with rainbow-like display held in a hand Black desktop computer with monitor on top and keyboard in front Purple video game console with attached controller Rows of large, dark computer cabinets in warehouse-like room Computers and computing devices from different eras – clockwise from top left: Early vacuum tube computer (ENIAC) Mainframe computer (IBM System 360) Desktop computer (IBM ThinkCentre S50 with monitor) Supercomputer (IBM Summit) Video game console (Nintendo GameCube) Smartphone (LYF Water 2) A computer is a machine that can be programmed to carry out sequences of arithmetic or logical operations automatically. Modern computers can perform generic sets of operations known as programs. These programs enable computers to perform a wide range of tasks. A computer system is a "complete" computer that includes the hardware, operating system (main software), and peripheral equipment needed and used for "full" operation. This term may also refer to a group of computers that are linked and function together, such as a computer network or computer cluster.  A broad range of industrial and consumer products use computers as control systems. Simple special-purpose devices like microwave ovens and remote controls are included, as are factory devices like industrial robots and computer-aided design, as well as general-purpose devices like personal computers and mobile devices like smartphones. Computers power the Internet, which links hundreds of millions of other computers and users.  Early computers were meant to be used only for calculations. Simple manual instruments like the abacus have aided people in doing calculations since ancient times. Early in the Industrial Revolution, some mechanical devices were built to automate long tedious tasks, such as guiding patterns for looms. More sophisticated electrical machines did specialized analog calculations in the early 20th century. The first digital electronic calculating machines were developed during World War II. The first semiconductor transistors in the late 1940s were followed by the silicon-based MOSFET (MOS transistor) and monolithic integrated circuit (IC) chip technologies in the late 1950s, leading to the microprocessor and the microcomputer revolution in the 1970s. The speed, power and versatility of computers have been increasing dramatically ever since then, with transistor counts increasing at a rapid pace (as predicted by Moore's law), leading to the Digital Revolution during the late 20th to early 21st centuries.  Conventionally, a modern computer consists of at least one processing element, typically a central processing unit (CPU) in the form of a microprocessor, along with some type of computer memory, typically semiconductor memory chips. The processing element carries out arithmetic and logical operations, and a sequencing and control unit can change the order of operations in response to stored information. Peripheral devices include input devices (keyboards, mice, joystick, etc.), output devices (monitor screens, printers, etc.), and input/output devices that perform both functions (e.g., the 2000s-era touchscreen). Peripheral devices allow information to be retrieved from an external source and they enable the result of operations to be saved and retrieved.   Contents 1	Etymology 2	History 2.1	Pre-20th century 2.2	First computer 2.3	Analog computers 2.4	Digital computers 2.5	Modern computers 2.6	Mobile computers 3	Types 3.1	By architecture 3.2	By size, form-factor and purpose 4	Hardware 4.1	History of computing hardware 4.2	Other hardware topics 4.3	Input devices 4.4	Output devices 4.5	Control unit 4.6	Central processing unit (CPU) 4.7	Arithmetic logic unit (ALU) 4.8	Memory 4.9	Input/output (I/O) 4.10	Multitasking 4.11	Multiprocessing 5	Software 5.1	Languages 5.2	Programs 6	Networking and the Internet 7	Unconventional computers 8	Future 8.1	Computer architecture paradigms 8.2	Artificial intelligence 9	Professions and organizations 10	See also 11	References 12	Notes 13	External links Etymology A human computer. A human computer, with microscope and calculator, 1952 According to the Oxford English Dictionary, the first known use of computer was in a 1613 book called The Yong Mans Gleanings by the English writer Richard Braithwait: "I haue [sic] read the truest computer of Times, and the best Arithmetician that euer [sic] breathed, and he reduceth thy dayes into a short number." This usage of the term referred to a human computer, a person who carried out calculations or computations. The word continued with the same meaning until the middle of the 20th century. During the latter part of this period women were often hired as computers because they could be paid less than their male counterparts.[1] By 1943, most human computers were women.[2]  The Online Etymology Dictionary gives the first attested use of computer in the 1640s, meaning 'one who calculates'; this is an "agent noun from compute (v.)". The Online Etymology Dictionary states that the use of the term to mean "'calculating machine' (of any type) is from 1897." The Online Etymology Dictionary indicates that the "modern use" of the term, to mean 'programmable digital electronic computer' dates from "1945 under this name; [in a] theoretical [sense] from 1937, as Turing machine".[3]  History Main articles: History of computing hardware and History of computing Pre-20th century  The Ishango bone, a bone tool dating back to prehistoric Africa. Devices have been used to aid computation for thousands of years, mostly using one-to-one correspondence with fingers. The earliest counting device was probably a form of tally stick. Later record keeping aids throughout the Fertile Crescent included calculi (clay spheres, cones, etc.) which represented counts of items, probably livestock or grains, sealed in hollow unbaked clay containers.[4][5] The use of counting rods is one example.   The Chinese suanpan (算盘). The number represented on this abacus is 6,302,715,408. The abacus was initially used for arithmetic tasks. The Roman abacus was developed from devices used in Babylonia as early as 2400 BC. Since then, many other forms of reckoning boards or tables have been invented. In a medieval European counting house, a checkered cloth would be placed on a table, and markers moved around on it according to certain rules, as an aid to calculating sums of money.[6]   The Antikythera mechanism, dating back to ancient Greece circa 150–100 BC, is an early analog computing device. The Antikythera mechanism is believed to be the earliest mechanical analog computer, according to Derek J. de Solla Price.[7] It was designed to calculate astronomical positions. It was discovered in 1901 in the Antikythera wreck off the Greek island of Antikythera, between Kythera and Crete, and has been dated to c. 100 BC. Devices of a level of complexity comparable to that of the Antikythera mechanism would not reappear until a thousand years later.  Many mechanical aids to calculation and measurement were constructed for astronomical and navigation use. The planisphere was a star chart invented by Abū Rayhān al-Bīrūnī in the early 11th century.[8] The astrolabe was invented in the Hellenistic world in either the 1st or 2nd centuries BC and is often attributed to Hipparchus. A combination of the planisphere and dioptra, the astrolabe was effectively an analog computer capable of working out several different kinds of problems in spherical astronomy. An astrolabe incorporating a mechanical calendar computer[9][10] and gear-wheels was invented by Abi Bakr of Isfahan, Persia in 1235.[11] Abū Rayhān al-Bīrūnī invented the first mechanical geared lunisolar calendar astrolabe,[12] an early fixed-wired knowledge processing machine[13] with a gear train and gear-wheels,[14] c. 1000 AD.  The sector, a calculating instrument used for solving problems in proportion, trigonometry, multiplication and division, and for various functions, such as squares and cube roots, was developed in the late 16th century and found application in gunnery, surveying and navigation.  The planimeter was a manual instrument to calculate the area of a closed figure by tracing over it with a mechanical linkage.   A slide rule. The slide rule was invented around 1620–1630 by the English clergyman William Oughtred, shortly after the publication of the concept of the logarithm. It is a hand-operated analog computer for doing multiplication and division. As slide rule development progressed, added scales provided reciprocals, squares and square roots, cubes and cube roots, as well as transcendental functions such as logarithms and exponentials, circular and hyperbolic trigonometry and other functions. Slide rules with special scales are still used for quick performance of routine calculations, such as the E6B circular slide rule used for time and distance calculations on light aircraft.  In the 1770s, Pierre Jaquet-Droz, a Swiss watchmaker, built a mechanical doll (automaton) that could write holding a quill pen. By switching the number and order of its internal wheels different letters, and hence different messages, could be produced. In effect, it could be mechanically "programmed" to read instructions. Along with two other complex machines, the doll is at the Musée d'Art et d'Histoire of Neuchâtel, Switzerland, and still operates.[15]  In 1831–1835, mathematician and engineer Giovanni Plana devised a Perpetual Calendar machine, which, though a system of pulleys and cylinders and over, could predict the perpetual calendar for every year from AD 0 (that is, 1 BC) to AD 4000, keeping track of leap years and varying day length. The tide-predicting machine invented by the Scottish scientist Sir William Thomson in 1872 was of great utility to navigation in shallow waters. It used a system of pulleys and wires to automatically calculate predicted tide levels for a set period at a particular location.  The differential analyser, a mechanical analog computer designed to solve differential equations by integration, used wheel-and-disc mechanisms to perform the integration. In 1876, Sir William Thomson had already discussed the possible construction of such calculators, but he had been stymied by the limited output torque of the ball-and-disk integrators.[16] In a differential analyzer, the output of one integrator drove the input of the next integrator, or a graphing output. The torque amplifier was the advance that allowed these machines to work. Starting in the 1920s, Vannevar Bush and others developed mechanical differential analyzers.  First computer  A portion of Babbage's Difference engine. Charles Babbage, an English mechanical engineer and polymath, originated the concept of a programmable computer. Considered the "father of the computer",[17] he conceptualized and invented the first mechanical computer in the early 19th century. After working on his revolutionary difference engine, designed to aid in navigational calculations, in 1833 he realized that a much more general design, an Analytical Engine, was possible. The input of programs and data was to be provided to the machine via punched cards, a method being used at the time to direct mechanical looms such as the Jacquard loom. For output, the machine would have a printer, a curve plotter and a bell. The machine would also be able to punch numbers onto cards to be read in later. The Engine incorporated an arithmetic logic unit, control flow in the form of conditional branching and loops, and integrated memory, making it the first design for a general-purpose computer that could be described in modern terms as Turing-complete.[18][19]  The machine was about a century ahead of its time. All the parts for his machine had to be made by hand – this was a major problem for a device with thousands of parts. Eventually, the project was dissolved with the decision of the British Government to cease funding. Babbage's failure to complete the analytical engine can be chiefly attributed to political and financial difficulties as well as his desire to develop an increasingly sophisticated computer and to move ahead faster than anyone else could follow. Nevertheless, his son, Henry Babbage, completed a simplified version of the analytical engine's computing unit (the mill) in 1888. He gave a successful demonstration of its use in computing tables in 1906.  Analog computers Main article: Analog computer  Sir William Thomson's third tide-predicting machine design, 1879–81 During the first half of the 20th century, many scientific computing needs were met by increasingly sophisticated analog computers, which used a direct mechanical or electrical model of the problem as a basis for computation. However, these were not programmable and generally lacked the versatility and accuracy of modern digital computers.[20] The first modern analog computer was a tide-predicting machine, invented by Sir William Thomson (later to become Lord Kelvin) in 1872. The differential analyser, a mechanical analog computer designed to solve differential equations by integration using wheel-and-disc mechanisms, was conceptualized in 1876 by James Thomson, the elder brother of the more famous Sir William Thomson.[16]  The art of mechanical analog computing reached its zenith with the differential analyzer, built by H. L. Hazen and Vannevar Bush at MIT starting in 1927. This built on the mechanical integrators of James Thomson and the torque amplifiers invented by H. W. Nieman. A dozen of these devices were built before their obsolescence became obvious. By the 1950s, the success of digital electronic computers had spelled the end for most analog computing machines, but analog computers remained in use during the 1950s in some specialized applications such as education (slide rule) and aircraft (control systems).  Digital computers Electromechanical By 1938, the United States Navy had developed an electromechanical analog computer small enough to use aboard a submarine. This was the Torpedo Data Computer, which used trigonometry to solve the problem of firing a torpedo at a moving target. During World War II similar devices were developed in other countries as well.   Replica of Zuse's Z3, the first fully automatic, digital (electromechanical) computer. Early digital computers were electromechanical; electric switches drove mechanical relays to perform the calculation. These devices had a low operating speed and were eventually superseded by much faster all-electric computers, originally using vacuum tubes. The Z2, created by German engineer Konrad Zuse in 1939, was one of the earliest examples of an electromechanical relay computer.[21]  In 1941, Zuse followed his earlier machine up with the Z3, the world's first working electromechanical programmable, fully automatic digital computer.[22][23] The Z3 was built with 2000 relays, implementing a 22 bit word length that operated at a clock frequency of about 5–10 Hz.[24] Program code was supplied on punched film while data could be stored in 64 words of memory or supplied from the keyboard. It was quite similar to modern machines in some respects, pioneering numerous advances such as floating point numbers. Rather than the harder-to-implement decimal system (used in Charles Babbage's earlier design), using a binary system meant that Zuse's machines were easier to build and potentially more reliable, given the technologies available at that time.[25] The Z3 was not itself a universal computer but could be extended to be Turing complete.[26][27]  Vacuum tubes and digital electronic circuits Purely electronic circuit elements soon replaced their mechanical and electromechanical equivalents, at the same time that digital calculation replaced analog. The engineer Tommy Flowers, working at the Post Office Research Station in London in the 1930s, began to explore the possible use of electronics for the telephone exchange. Experimental equipment that he built in 1934 went into operation five years later, converting a portion of the telephone exchange network into an electronic data processing system, using thousands of vacuum tubes.[20] In the US, John Vincent Atanasoff and Clifford E. Berry of Iowa State University developed and tested the Atanasoff–Berry Computer (ABC) in 1942,[28] the first "automatic electronic digital computer".[29] This design was also all-electronic and used about 300 vacuum tubes, with capacitors fixed in a mechanically rotating drum for memory.[30]  Two women are seen by the Colossus computer. Colossus, the first electronic digital programmable computing device, was used to break German ciphers during World War II. It is seen here in use at Bletchley Park in 1943. During World War II, the British code-breakers at Bletchley Park achieved a number of successes at breaking encrypted German military communications. The German encryption machine, Enigma, was first attacked with the help of the electro-mechanical bombes which were often run by women.[31][32] To crack the more sophisticated German Lorenz SZ 40/42 machine, used for high-level Army communications, Max Newman and his colleagues commissioned Flowers to build the Colossus.[30] He spent eleven months from early February 1943 designing and building the first Colossus.[33] After a functional test in December 1943, Colossus was shipped to Bletchley Park, where it was delivered on 18 January 1944[34] and attacked its first message on 5 February.[30]  Colossus was the world's first electronic digital programmable computer.[20] It used a large number of valves (vacuum tubes). It had paper-tape input and was capable of being configured to perform a variety of boolean logical operations on its data, but it was not Turing-complete. Nine Mk II Colossi were built (The Mk I was converted to a Mk II making ten machines in total). Colossus Mark I contained 1,500 thermionic valves (tubes), but Mark II with 2,400 valves, was both 5 times faster and simpler to operate than Mark I, greatly speeding the decoding process.[35][36]   ENIAC was the first electronic, Turing-complete device, and performed ballistics trajectory calculations for the United States Army. The ENIAC[37] (Electronic Numerical Integrator and Computer) was the first electronic programmable computer built in the U.S. Although the ENIAC was similar to the Colossus, it was much faster, more flexible, and it was Turing-complete. Like the Colossus, a "program" on the ENIAC was defined by the states of its patch cables and switches, a far cry from the stored program electronic machines that came later. Once a program was written, it had to be mechanically set into the machine with manual resetting of plugs and switches. The programmers of the ENIAC were six women, often known collectively as the "ENIAC girls".[38][39]  It combined the high speed of electronics with the ability to be programmed for many complex problems. It could add or subtract 5000 times a second, a thousand times faster than any other machine. It also had modules to multiply, divide, and square root. High speed memory was limited to 20 words (about 80 bytes). Built under the direction of John Mauchly and J. Presper Eckert at the University of Pennsylvania, ENIAC's development and construction lasted from 1943 to full operation at the end of 1945. The machine was huge, weighing 30 tons, using 200 kilowatts of electric power and contained over 18,000 vacuum tubes, 1,500 relays, and hundreds of thousands of resistors, capacitors, and inductors.[40]  Modern computers Concept of modern computer The principle of the modern computer was proposed by Alan Turing in his seminal 1936 paper,[41] On Computable Numbers. Turing proposed a simple device that he called "Universal Computing machine" and that is now known as a universal Turing machine. He proved that such a machine is capable of computing anything that is computable by executing instructions (program) stored on tape, allowing the machine to be programmable. The fundamental concept of Turing's design is the stored program, where all the instructions for computing are stored in memory. Von Neumann acknowledged that the central concept of the modern computer was due to this paper.[42] Turing machines are to this day a central object of study in theory of computation. Except for the limitations imposed by their finite memory stores, modern computers are said to be Turing-complete, which is to say, they have algorithm execution capability equivalent to a universal Turing machine.  Stored programs Main article: Stored-program computer Three tall racks containing electronic circuit boards A section of the Manchester Baby, the first electronic stored-program computer Early computing machines had fixed programs. Changing its function required the re-wiring and re-structuring of the machine.[30] With the proposal of the stored-program computer this changed. A stored-program computer includes by design an instruction set and can store in memory a set of instructions (a program) that details the computation. The theoretical basis for the stored-program computer was laid by Alan Turing in his 1936 paper. In 1945, Turing joined the National Physical Laboratory and began work on developing an electronic stored-program digital computer. His 1945 report "Proposed Electronic Calculator" was the first specification for such a device. John von Neumann at the University of Pennsylvania also circulated his First Draft of a Report on the EDVAC in 1945.[20]  The Manchester Baby was the world's first stored-program computer. It was built at the University of Manchester in England by Frederic C. Williams, Tom Kilburn and Geoff Tootill, and ran its first program on 21 June 1948.[43] It was designed as a testbed for the Williams tube, the first random-access digital storage device.[44] Although the computer was considered "small and primitive" by the standards of its time, it was the first working machine to contain all of the elements essential to a modern electronic computer.[45] As soon as the Baby had demonstrated the feasibility of its design, a project was initiated at the university to develop it into a more usable computer, the Manchester Mark 1. Grace Hopper was the first person to develop a compiler for programming language.[2]  The Mark 1 in turn quickly became the prototype for the Ferranti Mark 1, the world's first commercially available general-purpose computer.[46] Built by Ferranti, it was delivered to the University of Manchester in February 1951. At least seven of these later machines were delivered between 1953 and 1957, one of them to Shell labs in Amsterdam.[47] In October 1947, the directors of British catering company J. Lyons & Company decided to take an active role in promoting the commercial development of computers. The LEO I computer became operational in April 1951[48] and ran the world's first regular routine office computer job.  Transistors Main articles: Transistor and History of the transistor Further information: Transistor computer and MOSFET  Bipolar junction transistor (BJT) The concept of a field-effect transistor was proposed by Julius Edgar Lilienfeld in 1925. John Bardeen and Walter Brattain, while working under William Shockley at Bell Labs, built the first working transistor, the point-contact transistor, in 1947, which was followed by Shockley's bipolar junction transistor in 1948.[49][50] From 1955 onwards, transistors replaced vacuum tubes in computer designs, giving rise to the "second generation" of computers. Compared to vacuum tubes, transistors have many advantages: they are smaller, and require less power than vacuum tubes, so give off less heat. Junction transistors were much more reliable than vacuum tubes and had longer, indefinite, service life. Transistorized computers could contain tens of thousands of binary logic circuits in a relatively compact space. However, early junction transistors were relatively bulky devices that were difficult to manufacture on a mass-production basis, which limited them to a number of specialised applications.[51]  At the University of Manchester, a team under the leadership of Tom Kilburn designed and built a machine using the newly developed transistors instead of valves.[52] Their first transistorised computer and the first in the world, was operational by 1953, and a second version was completed there in April 1955. However, the machine did make use of valves to generate its 125 kHz clock waveforms and in the circuitry to read and write on its magnetic drum memory, so it was not the first completely transistorized computer. That distinction goes to the Harwell CADET of 1955,[53] built by the electronics division of the Atomic Energy Research Establishment at Harwell.[53][54]   MOSFET (MOS transistor), showing gate (G), body (B), source (S) and drain (D) terminals. The gate is separated from the body by an insulating layer (pink). The metal–oxide–silicon field-effect transistor (MOSFET), also known as the MOS transistor, was invented by Mohamed M. Atalla and Dawon Kahng at Bell Labs in 1959.[55] It was the first truly compact transistor that could be miniaturised and mass-produced for a wide range of uses.[51] With its high scalability,[56] and much lower power consumption and higher density than bipolar junction transistors,[57] the MOSFET made it possible to build high-density integrated circuits.[58][59] In addition to data processing, it also enabled the practical use of MOS transistors as memory cell storage elements, leading to the development of MOS semiconductor memory, which replaced earlier magnetic-core memory in computers. The MOSFET led to the microcomputer revolution,[60] and became the driving force behind the computer revolution.[61][62] The MOSFET is the most widely used transistor in computers,[63][64] and is the fundamental building block of digital electronics.[65]  Integrated circuits Main articles: Integrated circuit and Invention of the integrated circuit Further information: Planar process and Microprocessor The next great advance in computing power came with the advent of the integrated circuit (IC). The idea of the integrated circuit was first conceived by a radar scientist working for the Royal Radar Establishment of the Ministry of Defence, Geoffrey W.A. Dummer. Dummer presented the first public description of an integrated circuit at the Symposium on Progress in Quality Electronic Components in Washington, D.C. on 7 May 1952.[66]  The first working ICs were invented by Jack Kilby at Texas Instruments and Robert Noyce at Fairchild Semiconductor.[67] Kilby recorded his initial ideas concerning the integrated circuit in July 1958, successfully demonstrating the first working integrated example on 12 September 1958.[68] In his patent application of 6 February 1959, Kilby described his new device as "a body of semiconductor material ... wherein all the components of the electronic circuit are completely integrated".[69][70] However, Kilby's invention was a hybrid integrated circuit (hybrid IC), rather than a monolithic integrated circuit (IC) chip.[71] Kilby's IC had external wire connections, which made it difficult to mass-produce.[72]  Noyce also came up with his own idea of an integrated circuit half a year later than Kilby.[73] Noyce's invention was the first true monolithic IC chip.[74][72] His chip solved many practical problems that Kilby's had not. Produced at Fairchild Semiconductor, it was made of silicon, whereas Kilby's chip was made of germanium. Noyce's monolithic IC was fabricated using the planar process, developed by his colleague Jean Hoerni in early 1959. In turn, the planar process was based on Mohamed M. Atalla's work on semiconductor surface passivation by silicon dioxide in the late 1950s.[75][76][77]  Modern monolithic ICs are predominantly MOS (metal-oxide-semiconductor) integrated circuits, built from MOSFETs (MOS transistors).[78] The earliest experimental MOS IC to be fabricated was a 16-transistor chip built by Fred Heiman and Steven Hofstein at RCA in 1962.[79] General Microelectronics later introduced the first commercial MOS IC in 1964,[80] developed by Robert Norman.[79] Following the development of the self-aligned gate (silicon-gate) MOS transistor by Robert Kerwin, Donald Klein and John Sarace at Bell Labs in 1967, the first silicon-gate MOS IC with self-aligned gates was developed by Federico Faggin at Fairchild Semiconductor in 1968.[81] The MOSFET has since become the most critical device component in modern ICs.[82]  The development of the MOS integrated circuit led to the invention of the microprocessor,[83][84] and heralded an explosion in the commercial and personal use of computers. While the subject of exactly which device was the first microprocessor is contentious, partly due to lack of agreement on the exact definition of the term "microprocessor", it is largely undisputed that the first single-chip microprocessor was the Intel 4004,[85] designed and realized by Federico Faggin with his silicon-gate MOS IC technology,[83] along with Ted Hoff, Masatoshi Shima and Stanley Mazor at Intel.[86][87] In the early 1970s, MOS IC technology enabled the integration of more than 10,000 transistors on a single chip.[59]  System on a Chip (SoCs) are complete computers on a microchip (or chip) the size of a coin.[88] They may or may not have integrated RAM and flash memory. If not integrated, the RAM is usually placed directly above (known as Package on package) or below (on the opposite side of the circuit board) the SoC, and the flash memory is usually placed right next to the SoC, this all done to improve data transfer speeds, as the data signals don't have to travel long distances. Since ENIAC in 1945, computers have advanced enormously, with modern SoCs (Such as the Snapdragon 865) being the size of a coin while also being hundreds of thousands of times more powerful than ENIAC, integrating billions of transistors, and consuming only a few watts of power.  Mobile computers The first mobile computers were heavy and ran from mains power. The 50lb IBM 5100 was an early example. Later portables such as the Osborne 1 and Compaq Portable were considerably lighter but still needed to be plugged in. The first laptops, such as the Grid Compass, removed this requirement by incorporating batteries – and with the continued miniaturization of computing resources and advancements in portable battery life, portable computers grew in popularity in the 2000s.[89] The same developments allowed manufacturers to integrate computing resources into cellular mobile phones by the early 2000s.  These smartphones and tablets run on a variety of operating systems and recently became the dominant computing device on the market.[90] These are powered by System on a Chip (SoCs), which are complete computers on a microchip the size of a coin.[88]  Types See also: Classes of computers Computers can be classified in a number of different ways, including:  By architecture Analog computer Digital computer Hybrid computer Harvard architecture Von Neumann architecture Complex instruction set computer Reduced instruction set computer By size, form-factor and purpose Supercomputer Mainframe computer Minicomputer (term no longer used) Server Rackmount server Blade server Tower server Personal computer Workstation Microcomputer (term no longer used) Home computer Desktop computer Tower desktop Slimline desktop Multimedia computer (non-linear editing system computers, video editing PCs and the like) Gaming computer All-in-one PC Nettop (Small form factor PCs, Mini PCs) Home theater PC Keyboard computer Portable computer Thin client Internet appliance Laptop Desktop replacement computer Gaming laptop Rugged laptop 2-in-1 PC Ultrabook Chromebook Subnotebook Netbook Mobile computers: Tablet computer Smartphone Ultra-mobile PC Pocket PC Palmtop PC Handheld PC Wearable computer Smartwatch Smartglasses Single-board computer Plug computer Stick PC Programmable logic controller Computer-on-module System on module System in a package System-on-chip (Also known as an Application Processor or AP if it lacks circuitry such as radio circuitry) Microcontroller Hardware Main articles: Computer hardware, Personal computer hardware, Central processing unit, and Microprocessor File:Computer Components.webm Video demonstrating the standard components of a "slimline" computer The term hardware covers all of those parts of a computer that are tangible physical objects. Circuits, computer chips, graphic cards, sound cards, memory (RAM), motherboard, displays, power supplies, cables, keyboards, printers and "mice" input devices are all hardware.  History of computing hardware Main article: History of computing hardware First generation (mechanical/electromechanical)	Calculators	Pascal's calculator, Arithmometer, Difference engine, Quevedo's analytical machines Programmable devices	Jacquard loom, Analytical engine, IBM ASCC/Harvard Mark I, Harvard Mark II, IBM SSEC, Z1, Z2, Z3 Second generation (vacuum tubes)	Calculators	Atanasoff–Berry Computer, IBM 604, UNIVAC 60, UNIVAC 120 Programmable devices	Colossus, ENIAC, Manchester Baby, EDSAC, Manchester Mark 1, Ferranti Pegasus, Ferranti Mercury, CSIRAC, EDVAC, UNIVAC I, IBM 701, IBM 702, IBM 650, Z22 Third generation (discrete transistors and SSI, MSI, LSI integrated circuits)	Mainframes	IBM 7090, IBM 7080, IBM System/360, BUNCH Minicomputer	HP 2116A, IBM System/32, IBM System/36, LINC, PDP-8, PDP-11 Desktop Computer	HP 9100 Fourth generation (VLSI integrated circuits)	Minicomputer	VAX, IBM AS/400 4-bit microcomputer	Intel 4004, Intel 4040 8-bit microcomputer	Intel 8008, Intel 8080, Motorola 6800, Motorola 6809, MOS Technology 6502, Zilog Z80 16-bit microcomputer	Intel 8088, Zilog Z8000, WDC 65816/65802 32-bit microcomputer	Intel 80386, Pentium, Motorola 68000, ARM 64-bit microcomputer[91]	Alpha, MIPS, PA-RISC, PowerPC, SPARC, x86-64, ARMv8-A Embedded computer	Intel 8048, Intel 8051 Personal computer	Desktop computer, Home computer, Laptop computer, Personal digital assistant (PDA), Portable computer, Tablet PC, Wearable computer Theoretical/experimental	Quantum computer, Chemical computer, DNA computing, Optical computer, Spintronics-based computer, Wetware/Organic computer	 Other hardware topics Peripheral device (input/output)	Input	Mouse, keyboard, joystick, image scanner, webcam, graphics tablet, microphone Output	Monitor, printer, loudspeaker Both	Floppy disk drive, hard disk drive, optical disc drive, teleprinter Computer buses	Short range	RS-232, SCSI, PCI, USB Long range (computer networking)	Ethernet, ATM, FDDI A general-purpose computer has four main components: the arithmetic logic unit (ALU), the control unit, the memory, and the input and output devices (collectively termed I/O). These parts are interconnected by buses, often made of groups of wires. Inside each of these parts are thousands to trillions of small electrical circuits which can be turned off or on by means of an electronic switch. Each circuit represents a bit (binary digit) of information so that when the circuit is on it represents a "1", and when off it represents a "0" (in positive logic representation). The circuits are arranged in logic gates so that one or more of the circuits may control the state of one or more of the other circuits.  Input devices When unprocessed data is sent to the computer with the help of input devices, the data is processed and sent to output devices. The input devices may be hand-operated or automated. The act of processing is mainly regulated by the CPU. Some examples of input devices are:  Computer keyboard Digital camera Digital video Graphics tablet Image scanner Joystick Microphone Mouse Overlay keyboard Real-time clock Trackball Touchscreen Light pen Output devices The means through which computer gives output are known as output devices. Some examples of output devices are:  Computer monitor Printer PC speaker Projector Sound card Video card Control unit Main articles: CPU design and Control unit  Diagram showing how a particular MIPS architecture instruction would be decoded by the control system The control unit (often called a control system or central controller) manages the computer's various components; it reads and interprets (decodes) the program instructions, transforming them into control signals that activate other parts of the computer.[92] Control systems in advanced computers may change the order of execution of some instructions to improve performance.  A key component common to all CPUs is the program counter, a special memory cell (a register) that keeps track of which location in memory the next instruction is to be read from.[93]  The control system's function is as follows— this is a simplified description, and some of these steps may be performed concurrently or in a different order depending on the type of CPU:  Read the code for the next instruction from the cell indicated by the program counter. Decode the numerical code for the instruction into a set of commands or signals for each of the other systems. Increment the program counter so it points to the next instruction. Read whatever data the instruction requires from cells in memory (or perhaps from an input device). The location of this required data is typically stored within the instruction code. Provide the necessary data to an ALU or register. If the instruction requires an ALU or specialized hardware to complete, instruct the hardware to perform the requested operation. Write the result from the ALU back to a memory location or to a register or perhaps an output device. Jump back to step (1). Since the program counter is (conceptually) just another set of memory cells, it can be changed by calculations done in the ALU. Adding 100 to the program counter would cause the next instruction to be read from a place 100 locations further down the program. Instructions that modify the program counter are often known as "jumps" and allow for loops (instructions that are repeated by the computer) and often conditional instruction execution (both examples of control flow).  The sequence of operations that the control unit goes through to process an instruction is in itself like a short computer program, and indeed, in some more complex CPU designs, there is another yet smaller computer called a microsequencer, which runs a microcode program that causes all of these events to happen.  Central processing unit (CPU) Main articles: Central processing unit and Microprocessor The control unit, ALU, and registers are collectively known as a central processing unit (CPU). Early CPUs were composed of many separate components. Since the 1970s, CPUs have typically been constructed on a single MOS integrated circuit chip called a microprocessor.  Arithmetic logic unit (ALU) Main article: Arithmetic logic unit The ALU is capable of performing two classes of operations: arithmetic and logic.[94] The set of arithmetic operations that a particular ALU supports may be limited to addition and subtraction, or might include multiplication, division, trigonometry functions such as sine, cosine, etc., and square roots. Some can operate only on whole numbers (integers) while others use floating point to represent real numbers, albeit with limited precision. However, any computer that is capable of performing just the simplest operations can be programmed to break down the more complex operations into simple steps that it can perform. Therefore, any computer can be programmed to perform any arithmetic operation—although it will take more time to do so if its ALU does not directly support the operation. An ALU may also compare numbers and return boolean truth values (true or false) depending on whether one is equal to, greater than or less than the other ("is 64 greater than 65?"). Logic operations involve Boolean logic: AND, OR, XOR, and NOT. These can be useful for creating complicated conditional statements and processing boolean logic.  Superscalar computers may contain multiple ALUs, allowing them to process several instructions simultaneously.[95] Graphics processors and computers with SIMD and MIMD features often contain ALUs that can perform arithmetic on vectors and matrices.  Memory Main articles: Computer memory and Computer data storage  Magnetic-core memory (using magnetic cores) was the computer memory of choice in the 1960s, until it was replaced by semiconductor memory (using MOS memory cells). A computer's memory can be viewed as a list of cells into which numbers can be placed or read. Each cell has a numbered "address" and can store a single number. The computer can be instructed to "put the number 123 into the cell numbered 1357" or to "add the number that is in cell 1357 to the number that is in cell 2468 and put the answer into cell 1595." The information stored in memory may represent practically anything. Letters, numbers, even computer instructions can be placed into memory with equal ease. Since the CPU does not differentiate between different types of information, it is the software's responsibility to give significance to what the memory sees as nothing but a series of numbers.  In almost all modern computers, each memory cell is set up to store binary numbers in groups of eight bits (called a byte). Each byte is able to represent 256 different numbers (28 = 256); either from 0 to 255 or −128 to +127. To store larger numbers, several consecutive bytes may be used (typically, two, four or eight). When negative numbers are required, they are usually stored in two's complement notation. Other arrangements are possible, but are usually not seen outside of specialized applications or historical contexts. A computer can store any kind of information in memory if it can be represented numerically. Modern computers have billions or even trillions of bytes of memory.  The CPU contains a special set of memory cells called registers that can be read and written to much more rapidly than the main memory area. There are typically between two and one hundred registers depending on the type of CPU. Registers are used for the most frequently needed data items to avoid having to access main memory every time data is needed. As data is constantly being worked on, reducing the need to access main memory (which is often slow compared to the ALU and control units) greatly increases the computer's speed.  Computer main memory comes in two principal varieties:  random-access memory or RAM read-only memory or ROM RAM can be read and written to anytime the CPU commands it, but ROM is preloaded with data and software that never changes, therefore the CPU can only read from it. ROM is typically used to store the computer's initial start-up instructions. In general, the contents of RAM are erased when the power to the computer is turned off, but ROM retains its data indefinitely. In a PC, the ROM contains a specialized program called the BIOS that orchestrates loading the computer's operating system from the hard disk drive into RAM whenever the computer is turned on or reset. In embedded computers, which frequently do not have disk drives, all of the required software may be stored in ROM. Software stored in ROM is often called firmware, because it is notionally more like hardware than software. Flash memory blurs the distinction between ROM and RAM, as it retains its data when turned off but is also rewritable. It is typically much slower than conventional ROM and RAM however, so its use is restricted to applications where high speed is unnecessary.[96]  In more sophisticated computers there may be one or more RAM cache memories, which are slower than registers but faster than main memory. Generally computers with this sort of cache are designed to move frequently needed data into the cache automatically, often without the need for any intervention on the programmer's part.  Input/output (I/O) Main article: Input/output  Hard disk drives are common storage devices used with computers. I/O is the means by which a computer exchanges information with the outside world.[97] Devices that provide input or output to the computer are called peripherals.[98] On a typical personal computer, peripherals include input devices like the keyboard and mouse, and output devices such as the display and printer. Hard disk drives, floppy disk drives and optical disc drives serve as both input and output devices. Computer networking is another form of I/O. I/O devices are often complex computers in their own right, with their own CPU and memory. A graphics processing unit might contain fifty or more tiny computers that perform the calculations necessary to display 3D graphics.[citation needed] Modern desktop computers contain many smaller computers that assist the main CPU in performing I/O. A 2016-era flat screen display contains its own computer circuitry.  Multitasking Main article: Computer multitasking While a computer may be viewed as running one gigantic program stored in its main memory, in some systems it is necessary to give the appearance of running several programs simultaneously. This is achieved by multitasking i.e. having the computer switch rapidly between running each program in turn.[99] One means by which this is done is with a special signal called an interrupt, which can periodically cause the computer to stop executing instructions where it was and do something else instead. By remembering where it was executing prior to the interrupt, the computer can return to that task later. If several programs are running "at the same time". then the interrupt generator might be causing several hundred interrupts per second, causing a program switch each time. Since modern computers typically execute instructions several orders of magnitude faster than human perception, it may appear that many programs are running at the same time even though only one is ever executing in any given instant. This method of multitasking is sometimes termed "time-sharing" since each program is allocated a "slice" of time in turn.[100]  Before the era of inexpensive computers, the principal use for multitasking was to allow many people to share the same computer. Seemingly, multitasking would cause a computer that is switching between several programs to run more slowly, in direct proportion to the number of programs it is running, but most programs spend much of their time waiting for slow input/output devices to complete their tasks. If a program is waiting for the user to click on the mouse or press a key on the keyboard, then it will not take a "time slice" until the event it is waiting for has occurred. This frees up time for other programs to execute so that many programs may be run simultaneously without unacceptable speed loss.  Multiprocessing Main article: Multiprocessing  Cray designed many supercomputers that used multiprocessing heavily. Some computers are designed to distribute their work across several CPUs in a multiprocessing configuration, a technique once employed in only large and powerful machines such as supercomputers, mainframe computers and servers. Multiprocessor and multi-core (multiple CPUs on a single integrated circuit) personal and laptop computers are now widely available, and are being increasingly used in lower-end markets as a result.  Supercomputers in particular often have highly unique architectures that differ significantly from the basic stored-program architecture and from general-purpose computers.[101] They often feature thousands of CPUs, customized high-speed interconnects, and specialized computing hardware. Such designs tend to be useful for only specialized tasks due to the large scale of program organization required to successfully utilize most of the available resources at once. Supercomputers usually see usage in large-scale simulation, graphics rendering, and cryptography applications, as well as with other so-called "embarrassingly parallel" tasks.  Software Main article: Computer software Software refers to parts of the computer which do not have a material form, such as programs, data, protocols, etc. Software is that part of a computer system that consists of encoded information or computer instructions, in contrast to the physical hardware from which the system is built. Computer software includes computer programs, libraries and related non-executable data, such as online documentation or digital media. It is often divided into system software and application software Computer hardware and software require each other and neither can be realistically used on its own. When software is stored in hardware that cannot easily be modified, such as with BIOS ROM in an IBM PC compatible computer, it is sometimes called "firmware".  Operating system /System Software	Unix and BSD	UNIX System V, IBM AIX, HP-UX, Solaris (SunOS), IRIX, List of BSD operating systems Linux	List of Linux distributions, Comparison of Linux distributions Microsoft Windows	Windows 95, Windows 98, Windows NT, Windows 2000, Windows ME, Windows XP, Windows Vista, Windows 7, Windows 8, Windows 8.1, Windows 10 DOS	86-DOS (QDOS), IBM PC DOS, MS-DOS, DR-DOS, FreeDOS Macintosh operating systems	Classic Mac OS, macOS (previously OS X and Mac OS X) Embedded and real-time	List of embedded operating systems Experimental	Amoeba, Oberon–AOS, Bluebottle, A2, Plan 9 from Bell Labs Library	Multimedia	DirectX, OpenGL, OpenAL, Vulkan (API) Programming library	C standard library, Standard Template Library Data	Protocol	TCP/IP, Kermit, FTP, HTTP, SMTP File format	HTML, XML, JPEG, MPEG, PNG User interface	Graphical user interface (WIMP)	Microsoft Windows, GNOME, KDE, QNX Photon, CDE, GEM, Aqua Text-based user interface	Command-line interface, Text user interface Application Software	Office suite	Word processing, Desktop publishing, Presentation program, Database management system, Scheduling & Time management, Spreadsheet, Accounting software Internet Access	Browser, Email client, Web server, Mail transfer agent, Instant messaging Design and manufacturing	Computer-aided design, Computer-aided manufacturing, Plant management, Robotic manufacturing, Supply chain management Graphics	Raster graphics editor, Vector graphics editor, 3D modeler, Animation editor, 3D computer graphics, Video editing, Image processing Audio	Digital audio editor, Audio playback, Mixing, Audio synthesis, Computer music Software engineering	Compiler, Assembler, Interpreter, Debugger, Text editor, Integrated development environment, Software performance analysis, Revision control, Software configuration management Educational	Edutainment, Educational game, Serious game, Flight simulator Games	Strategy, Arcade, Puzzle, Simulation, First-person shooter, Platform, Massively multiplayer, Interactive fiction Misc	Artificial intelligence, Antivirus software, Malware scanner, Installer/Package management systems, File manager Languages There are thousands of different programming languages—some intended for general purpose, others useful for only highly specialized applications.  Programming languages Lists of programming languages	Timeline of programming languages, List of programming languages by category, Generational list of programming languages, List of programming languages, Non-English-based programming languages Commonly used assembly languages	ARM, MIPS, x86 Commonly used high-level programming languages	Ada, BASIC, C, C++, C#, COBOL, Fortran, PL/I, REXX, Java, Lisp, Pascal, Object Pascal Commonly used scripting languages	Bourne script, JavaScript, Python, Ruby, PHP, Perl Programs The defining feature of modern computers which distinguishes them from all other machines is that they can be programmed. That is to say that some type of instructions (the program) can be given to the computer, and it will process them. Modern computers based on the von Neumann architecture often have machine code in the form of an imperative programming language. In practical terms, a computer program may be just a few instructions or extend to many millions of instructions, as do the programs for word processors and web browsers for example. A typical modern computer can execute billions of instructions per second (gigaflops) and rarely makes a mistake over many years of operation. Large computer programs consisting of several million instructions may take teams of programmers years to write, and due to the complexity of the task almost certainly contain errors.  Stored program architecture Main articles: Computer program and Computer programming  Replica of the Manchester Baby, the world's first electronic stored-program computer, at the Museum of Science and Industry in Manchester, England This section applies to most common RAM machine–based computers.  In most cases, computer instructions are simple: add one number to another, move some data from one location to another, send a message to some external device, etc. These instructions are read from the computer's memory and are generally carried out (executed) in the order they were given. However, there are usually specialized instructions to tell the computer to jump ahead or backwards to some other place in the program and to carry on executing from there. These are called "jump" instructions (or branches). Furthermore, jump instructions may be made to happen conditionally so that different sequences of instructions may be used depending on the result of some previous calculation or some external event. Many computers directly support subroutines by providing a type of jump that "remembers" the location it jumped from and another instruction to return to the instruction following that jump instruction.  Program execution might be likened to reading a book. While a person will normally read each word and line in sequence, they may at times jump back to an earlier place in the text or skip sections that are not of interest. Similarly, a computer may sometimes go back and repeat the instructions in some section of the program over and over again until some internal condition is met. This is called the flow of control within the program and it is what allows the computer to perform tasks repeatedly without human intervention.  Comparatively, a person using a pocket calculator can perform a basic arithmetic operation such as adding two numbers with just a few button presses. But to add together all of the numbers from 1 to 1,000 would take thousands of button presses and a lot of time, with a near certainty of making a mistake. On the other hand, a computer may be programmed to do this with just a few simple instructions. The following example is written in the MIPS assembly language:    begin:   addi $8, $0, 0           # initialize sum to 0   addi $9, $0, 1           # set first number to add = 1   loop:   slti $10, $9, 1000       # check if the number is less than 1000   beq $10, $0, finish      # if odd number is greater than n then exit   add $8, $8, $9           # update sum   addi $9, $9, 1           # get next number   j loop                   # repeat the summing process   finish:   add $2, $8, $0           # put sum in output register Once told to run this program, the computer will perform the repetitive addition task without further human intervention. It will almost never make a mistake and a modern PC can complete the task in a fraction of a second.  Machine code In most computers, individual instructions are stored as machine code with each instruction being given a unique number (its operation code or opcode for short). The command to add two numbers together would have one opcode; the command to multiply them would have a different opcode, and so on. The simplest computers are able to perform any of a handful of different instructions; the more complex computers have several hundred to choose from, each with a unique numerical code. Since the computer's memory is able to store numbers, it can also store the instruction codes. This leads to the important fact that entire programs (which are just lists of these instructions) can be represented as lists of numbers and can themselves be manipulated inside the computer in the same way as numeric data. The fundamental concept of storing programs in the computer's memory alongside the data they operate on is the crux of the von Neumann, or stored program[citation needed], architecture. In some cases, a computer might store some or all of its program in memory that is kept separate from the data it operates on. This is called the Harvard architecture after the Harvard Mark I computer. Modern von Neumann computers display some traits of the Harvard architecture in their designs, such as in CPU caches.  While it is possible to write computer programs as long lists of numbers (machine language) and while this technique was used with many early computers,[102] it is extremely tedious and potentially error-prone to do so in practice, especially for complicated programs. Instead, each basic instruction can be given a short name that is indicative of its function and easy to remember – a mnemonic such as ADD, SUB, MULT or JUMP. These mnemonics are collectively known as a computer's assembly language. Converting programs written in assembly language into something the computer can actually understand (machine language) is usually done by a computer program called an assembler.   A 1970s punched card containing one line from a Fortran program. The card reads: "Z(1) = Y + W(1)" and is labeled "PROJ039" for identification purposes. Programming language Main article: Programming language Programming languages provide various ways of specifying programs for computers to run. Unlike natural languages, programming languages are designed to permit no ambiguity and to be concise. They are purely written languages and are often difficult to read aloud. They are generally either translated into machine code by a compiler or an assembler before being run, or translated directly at run time by an interpreter. Sometimes programs are executed by a hybrid method of the two techniques.  Low-level languages Main article: Low-level programming language Machine languages and the assembly languages that represent them (collectively termed low-level programming languages) are generally unique to the particular architecture of a computer's central processing unit (CPU). For instance, an ARM architecture CPU (such as may be found in a smartphone or a hand-held videogame) cannot understand the machine language of an x86 CPU that might be in a PC.[103] Historically a significant number of other cpu architectures were created and saw extensive use, notably including the MOS Technology 6502 and 6510 in addition to the Zilog Z80.  High-level languages Main article: High-level programming language Although considerably easier than in machine language, writing long programs in assembly language is often difficult and is also error prone. Therefore, most practical programs are written in more abstract high-level programming languages that are able to express the needs of the programmer more conveniently (and thereby help reduce programmer error). High level languages are usually "compiled" into machine language (or sometimes into assembly language and then into machine language) using another computer program called a compiler.[104] High level languages are less related to the workings of the target computer than assembly language, and more related to the language and structure of the problem(s) to be solved by the final program. It is therefore often possible to use different compilers to translate the same high level language program into the machine language of many different types of computer. This is part of the means by which software like video games may be made available for different computer architectures such as personal computers and various video game consoles.  Program design  This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (July 2012) (Learn how and when to remove this template message) Program design of small programs is relatively simple and involves the analysis of the problem, collection of inputs, using the programming constructs within languages, devising or using established procedures and algorithms, providing data for output devices and solutions to the problem as applicable. As problems become larger and more complex, features such as subprograms, modules, formal documentation, and new paradigms such as object-oriented programming are encountered. Large programs involving thousands of line of code and more require formal software methodologies. The task of developing large software systems presents a significant intellectual challenge. Producing software with an acceptably high reliability within a predictable schedule and budget has historically been difficult; the academic and professional discipline of software engineering concentrates specifically on this challenge.  Bugs Main article: Software bug  The actual first computer bug, a moth found trapped on a relay of the Harvard Mark II computer Errors in computer programs are called "bugs". They may be benign and not affect the usefulness of the program, or have only subtle effects. But in some cases, they may cause the program or the entire system to "hang", becoming unresponsive to input such as mouse clicks or keystrokes, to completely fail, or to crash. Otherwise benign bugs may sometimes be harnessed for malicious intent by an unscrupulous user writing an exploit, code designed to take advantage of a bug and disrupt a computer's proper execution. Bugs are usually not the fault of the computer. Since computers merely execute the instructions they are given, bugs are nearly always the result of programmer error or an oversight made in the program's design.[105] Admiral Grace Hopper, an American computer scientist and developer of the first compiler, is credited for having first used the term "bugs" in computing after a dead moth was found shorting a relay in the Harvard Mark II computer in September 1947.[106]  Networking and the Internet Main articles: Computer networking and Internet  Visualization of a portion of the routes on the Internet Computers have been used to coordinate information between multiple locations since the 1950s. The U.S. military's SAGE system was the first large-scale example of such a system, which led to a number of special-purpose commercial systems such as Sabre.[107] In the 1970s, computer engineers at research institutions throughout the United States began to link their computers together using telecommunications technology. The effort was funded by ARPA (now DARPA), and the computer network that resulted was called the ARPANET.[108] The technologies that made the Arpanet possible spread and evolved.  In time, the network spread beyond academic and military institutions and became known as the Internet. The emergence of networking involved a redefinition of the nature and boundaries of the computer. Computer operating systems and applications were modified to include the ability to define and access the resources of other computers on the network, such as peripheral devices, stored information, and the like, as extensions of the resources of an individual computer. Initially these facilities were available primarily to people working in high-tech environments, but in the 1990s the spread of applications like e-mail and the World Wide Web, combined with the development of cheap, fast networking technologies like Ethernet and ADSL saw computer networking become almost ubiquitous. In fact, the number of computers that are networked is growing phenomenally. A very large proportion of personal computers regularly connect to the Internet to communicate and receive information. "Wireless" networking, often utilizing mobile phone networks, has meant networking is becoming increasingly ubiquitous even in mobile computing environments.  Unconventional computers Main article: Human computer See also: Harvard Computers A computer does not need to be electronic, nor even have a processor, nor RAM, nor even a hard disk. While popular usage of the word "computer" is synonymous with a personal electronic computer, the modern[109] definition of a computer is literally: "A device that computes, especially a programmable [usually] electronic machine that performs high-speed mathematical or logical operations or that assembles, stores, correlates, or otherwise processes information."[110] Any device which processes information qualifies as a computer, especially if the processing is purposeful.[citation needed]  Future There is active research to make computers out of many promising new types of technology, such as optical computers, DNA computers, neural computers, and quantum computers. Most computers are universal, and are able to calculate any computable function, and are limited only by their memory capacity and operating speed. However different designs of computers can give very different performance for particular problems; for example quantum computers can potentially break some modern encryption algorithms (by quantum factoring) very quickly.  Computer architecture paradigms There are many types of computer architectures:  Quantum computer vs. Chemical computer Scalar processor vs. Vector processor Non-Uniform Memory Access (NUMA) computers Register machine vs. Stack machine Harvard architecture vs. von Neumann architecture Cellular architecture Of all these abstract machines, a quantum computer holds the most promise for revolutionizing computing.[111] Logic gates are a common abstraction which can apply to most of the above digital or analog paradigms. The ability to store and execute lists of instructions called programs makes computers extremely versatile, distinguishing them from calculators. The Church–Turing thesis is a mathematical statement of this versatility: any computer with a minimum capability (being Turing-complete) is, in principle, capable of performing the same tasks that any other computer can perform. Therefore, any type of computer (netbook, supercomputer, cellular automaton, etc.) is able to perform the same computational tasks, given enough time and storage capacity.  Artificial intelligence A computer will solve problems in exactly the way it is programmed to, without regard to efficiency, alternative solutions, possible shortcuts, or possible errors in the code. Computer programs that learn and adapt are part of the emerging field of artificial intelligence and machine learning. Artificial intelligence based products generally fall into two major categories: rule based systems and pattern recognition systems. Rule based systems attempt to represent the rules used by human experts and tend to be expensive to develop. Pattern based systems use data about a problem to generate conclusions. Examples of pattern based systems include voice recognition, font recognition, translation and the emerging field of on-line marketing.  Professions and organizations As the use of computers has spread throughout society, there are an increasing number of careers involving computers.  Computer-related professions Hardware-related	Electrical engineering, Electronic engineering, Computer engineering, Telecommunications engineering, Optical engineering, Nanoengineering Software-related	Computer science, Computer engineering, Desktop publishing, Human–computer interaction, Information technology, Information systems, Computational science, Software engineering, Video game industry, Web design The need for computers to work well together and to be able to exchange information has spawned the need for many standards organizations, clubs and societies of both a formal and informal nature.  Organizations Standards groups	ANSI, IEC, IEEE, IETF, ISO, W3C Professional societies	ACM, AIS, IET, IFIP, BCS Free/open source software groups	Free Software Foundation, Mozilla Foundation, Apache Software Foundation See also Glossary of computers Computability theory Computer insecurity Computer security Glossary of computer hardware terms History of computer science List of computer term etymologies List of fictional computers List of pioneers in computer science Pulse computation TOP500 (list of most powerful computers) Unconventional computing References  Evans 2018, p. 23.  Smith 2013, p. 6.  "computer (n.)". Online Etymology Dictionary.  According to Schmandt-Besserat 1981, these clay containers contained tokens, the total of which were the count of objects being transferred. The containers thus served as something of a bill of lading or an accounts book. In order to avoid breaking open the containers, first, clay impressions of the tokens were placed on the outside of the containers, for the count; the shapes of the impressions were abstracted into stylized marks; finally, the abstract marks were systematically used as numerals; these numerals were finally formalized as numbers. Eventually (Schmandt-Besserat estimates it took 4000 years Archived 30 January 2012 at the Wayback Machine ) the marks on the outside of the containers were all that were needed to convey the count, and the clay containers evolved into clay tablets with marks for the count.  Robson, Eleanor (2008), Mathematics in Ancient Iraq, ISBN 978-0-691-09182-2. p. 5: calculi were in use in Iraq for primitive accounting systems as early as 3200–3000 BCE, with commodity-specific counting representation systems. Balanced accounting was in use by 3000–2350 BCE, and a sexagesimal number system was in use 2350–2000 BCE.  Numbers through the ages. Flegg, Graham. Houndmills, Basingstoke, Hampshire: Macmillan Education. 1989. ISBN 0-333-49130-0. OCLC 24660570.  The Antikythera Mechanism Research Project Archived 28 April 2008 at the Wayback Machine, The Antikythera Mechanism Research Project. Retrieved 1 July 2007.  G. Wiet, V. Elisseeff, P. Wolff, J. Naudu (1975). History of Mankind, Vol 3: The Great medieval Civilisations, p. 649. George Allen & Unwin Ltd, UNESCO.  Fuat Sezgin "Catalogue of the Exhibition of the Institute for the History of Arabic-Islamic Science (at the Johann Wolfgang Goethe University", Frankfurt, Germany) Frankfurt Book Fair 2004, pp. 35 & 38.  Charette, François (2006). "Archaeology: High tech from Ancient Greece". Nature. 444 (7119): 551–552. Bibcode:2006Natur.444..551C. doi:10.1038/444551a. PMID 17136077. S2CID 33513516.  Bedini, Silvio A.; Maddison, Francis R. (1966). "Mechanical Universe: The Astrarium of Giovanni de' Dondi". Transactions of the American Philosophical Society. 56 (5): 1–69. doi:10.2307/1006002. JSTOR 1006002.  Price, Derek de S. (1984). "A History of Calculating Machines". IEEE Micro. 4 (1): 22–52. doi:10.1109/MM.1984.291305.  Őren, Tuncer (2001). "Advances in Computer and Information Sciences: From Abacus to Holonic Agents" (PDF). Turk J Elec Engin. 9 (1): 63–70.  Donald Routledge Hill (1985). "Al-Biruni's mechanical calendar", Annals of Science 42, pp. 139–163.  "The Writer Automaton, Switzerland". chonday.com. 11 July 2013.  Ray Girvan, "The revealed grace of the mechanism: computing after Babbage" Archived 3 November 2012 at the Wayback Machine, Scientific Computing World, May/June 2003  Halacy, Daniel Stephen (1970). Charles Babbage, Father of the Computer. Crowell-Collier Press. ISBN 978-0-02-741370-0.  "Babbage". Online stuff. Science Museum. 19 January 2007. Retrieved 1 August 2012.  "Let's build Babbage's ultimate mechanical computer". opinion. New Scientist. 23 December 2010. Retrieved 1 August 2012.  The Modern History of Computing. Stanford Encyclopedia of Philosophy. 2017.  Zuse, Horst. "Part 4: Konrad Zuse's Z1 and Z3 Computers". The Life and Work of Konrad Zuse. EPE Online. Archived from the original on 1 June 2008. Retrieved 17 June 2008.  Zuse, Konrad (2010) [1984], The Computer – My Life Translated by McKenna, Patricia and Ross, J. Andrew from: Der Computer, mein Lebenswerk (1984), Berlin/Heidelberg: Springer-Verlag, ISBN 978-3-642-08151-4  Salz Trautman, Peggy (20 April 1994). "A Computer Pioneer Rediscovered, 50 Years On". The New York Times.  Zuse, Konrad (1993). Der Computer. Mein Lebenswerk (in German) (3rd ed.). Berlin: Springer-Verlag. p. 55. ISBN 978-3-540-56292-4.  "Crash! The Story of IT: Zuse". Archived from the original on 18 September 2016. Retrieved 1 June 2016.  Rojas, R. (1998). "How to make Zuse's Z3 a universal computer". IEEE Annals of the History of Computing. 20 (3): 51–54. doi:10.1109/85.707574. S2CID 14606587.  Rojas, Raúl. "How to Make Zuse's Z3 a Universal Computer" (PDF).  15 January 1941 notice in the Des Moines Register,  Arthur W. Burks (1989). The First Electronic Computer. ISBN 0472081047.  Copeland, Jack (2006), Colossus: The Secrets of Bletchley Park's Codebreaking Computers, Oxford: Oxford University Press, pp. 101–115, ISBN 978-0-19-284055-4  Miller, Joe (10 November 2014). "The woman who cracked Enigma cyphers". BBC News. Retrieved 14 October 2018.  Bearne, Suzanne (24 July 2018). "Meet the female codebreakers of Bletchley Park". The Guardian. Retrieved 14 October 2018.  "Bletchley's code-cracking Colossus", BBC News, 2 February 2010, retrieved 19 October 2012  "Colossus – The Rebuild Story". The National Museum of Computing. Archived from the original on 18 April 2015. Retrieved 7 January 2014.  Randell, Brian; Fensom, Harry; Milne, Frank A. (15 March 1995), "Obituary: Allen Coombs", The Independent, retrieved 18 October 2012  Fensom, Jim (8 November 2010), "Harry Fensom obituary", The Guardian, retrieved 17 October 2012  John Presper Eckert Jr. and John W. Mauchly, Electronic Numerical Integrator and Computer, United States Patent Office, US Patent 3,120,606, filed 26 June 1947, issued 4 February 1964, and invalidated 19 October 1973 after court ruling on Honeywell v. Sperry Rand.  Evans 2018, p. 39.  Light 1999, p. 459.  "Generations of Computer". techiwarehouse.com. Archived from the original on 2 July 2015. Retrieved 7 January 2014.  Turing, A. M. (1937). "On Computable Numbers, with an Application to the Entscheidungsproblem". Proceedings of the London Mathematical Society. 2. 42 (1): 230–265. doi:10.1112/plms/s2-42.1.230.  "von Neumann ... firmly emphasized to me, and to others I am sure, that the fundamental conception is owing to Turing—insofar as not anticipated by Babbage, Lovelace and others." Letter by Stanley Frankel to Brian Randell, 1972, quoted in Jack Copeland (2004) The Essential Turing, p22.  Enticknap, Nicholas (Summer 1998), "Computing's Golden Jubilee", Resurrection (20), ISSN 0958-7403, archived from the original on 9 January 2012, retrieved 19 April 2008  "Early computers at Manchester University", Resurrection, 1 (4), Summer 1992, ISSN 0958-7403, archived from the original on 28 August 2017, retrieved 7 July 2010  Early Electronic Computers (1946–51), University of Manchester, archived from the original on 5 January 2009, retrieved 16 November 2008  Napper, R. B. E., Introduction to the Mark 1, The University of Manchester, archived from the original on 26 October 2008, retrieved 4 November 2008  Computer Conservation Society, Our Computer Heritage Pilot Study: Deliveries of Ferranti Mark I and Mark I Star computers, archived from the original on 11 December 2016, retrieved 9 January 2010  Lavington, Simon. "A brief history of British computers: the first 25 years (1948–1973)". British Computer Society. Retrieved 10 January 2010.  Lee, Thomas H. (2003). The Design of CMOS Radio-Frequency Integrated Circuits (PDF). Cambridge University Press. ISBN 9781139643771.  Puers, Robert; Baldi, Livio; Voorde, Marcel Van de; Nooten, Sebastiaan E. van (2017). Nanoelectronics: Materials, Devices, Applications, 2 Volumes. John Wiley & Sons. p. 14. ISBN 9783527340538.  Moskowitz, Sanford L. (2016). Advanced Materials Innovation: Managing Global Technology in the 21st century. John Wiley & Sons. pp. 165–167. ISBN 9780470508923.  Lavington, Simon (1998), A History of Manchester Computers (2 ed.), Swindon: The British Computer Society, pp. 34–35  Cooke-Yarborough, E. H. (June 1998), "Some early transistor applications in the UK", Engineering Science & Education Journal, 7 (3): 100–106, doi:10.1049/esej:19980301, ISSN 0963-7346, retrieved 7 June 2009 (subscription required)  Cooke-Yarborough, E.H. (1957). Introduction to Transistor Circuits. Edinburgh: Oliver and Boyd. p. 139.  "1960: Metal Oxide Semiconductor (MOS) Transistor Demonstrated". The Silicon Engine: A Timeline of Semiconductors in Computers. Computer History Museum. Retrieved 31 August 2019.  Motoyoshi, M. (2009). "Through-Silicon Via (TSV)". Proceedings of the IEEE. 97 (1): 43–48. doi:10.1109/JPROC.2008.2007462. ISSN 0018-9219. S2CID 29105721.  "Transistors Keep Moore's Law Alive". EETimes. 12 December 2018. Retrieved 18 July 2019.  "Who Invented the Transistor?". Computer History Museum. 4 December 2013. Retrieved 20 July 2019.  Hittinger, William C. (1973). "Metal-Oxide-Semiconductor Technology". Scientific American. 229 (2): 48–59. Bibcode:1973SciAm.229b..48H. doi:10.1038/scientificamerican0873-48. ISSN 0036-8733. JSTOR 24923169.  Malmstadt, Howard V.; Enke, Christie G.; Crouch, Stanley R. (1994). Making the Right Connections: Microcomputers and Electronic Instrumentation. American Chemical Society. p. 389. ISBN 9780841228610. The relative simplicity and low power requirements of MOSFETs have fostered today's microcomputer revolution.  Fossum, Jerry G.; Trivedi, Vishal P. (2013). Fundamentals of Ultra-Thin-Body MOSFETs and FinFETs. Cambridge University Press. p. vii. ISBN 9781107434493.  "Remarks by Director Iancu at the 2019 International Intellectual Property Conference". United States Patent and Trademark Office. 10 June 2019. Archived from the original on 17 December 2019. Retrieved 20 July 2019.  "Dawon Kahng". National Inventors Hall of Fame. Retrieved 27 June 2019.  "Martin Atalla in Inventors Hall of Fame, 2009". Retrieved 21 June 2013.  "Triumph of the MOS Transistor". YouTube. Computer History Museum. 6 August 2010. Archived from the original on 18 August 2021. Retrieved 21 July 2019.  "The Hapless Tale of Geoffrey Dummer" Archived 11 May 2013 at the Wayback Machine, (n.d.), (HTML), Electronic Product News, accessed 8 July 2008.  Kilby, Jack (2000), Nobel lecture (PDF), Stockholm: Nobel Foundation, retrieved 15 May 2008  The Chip that Jack Built, (c. 2008), (HTML), Texas Instruments, Retrieved 29 May 2008.  Jack S. Kilby, Miniaturized Electronic Circuits, United States Patent Office, US Patent 3,138,743, filed 6 February 1959, issued 23 June 1964.  Winston, Brian (1998). Media Technology and Society: A History : From the Telegraph to the Internet. Routledge. p. 221. ISBN 978-0-415-14230-4.  Saxena, Arjun N. (2009). Invention of Integrated Circuits: Untold Important Facts. World Scientific. p. 140. ISBN 9789812814456.  "Integrated circuits". NASA. Retrieved 13 August 2019.  Robert Noyce's Unitary circuit, US patent 2981877, "Semiconductor device-and-lead structure", issued 1961-04-25, assigned to Fairchild Semiconductor Corporation  "1959: Practical Monolithic Integrated Circuit Concept Patented". Computer History Museum. Retrieved 13 August 2019.  Lojek, Bo (2007). History of Semiconductor Engineering. Springer Science & Business Media. p. 120. ISBN 9783540342588.  Bassett, Ross Knox (2007). To the Digital Age: Research Labs, Start-up Companies, and the Rise of MOS Technology. Johns Hopkins University Press. p. 46. ISBN 9780801886393.  Huff, Howard R.; Tsuya, H.; Gösele, U. (1998). Silicon Materials Science and Technology: Proceedings of the Eighth International Symposium on Silicon Materials Science and Technology. Electrochemical Society. pp. 181–182. ISBN 9781566771931.  Kuo, Yue (1 January 2013). "Thin Film Transistor Technology—Past, Present, and Future" (PDF). The Electrochemical Society Interface. 22 (1): 55–61. Bibcode:2013ECSIn..22a..55K. doi:10.1149/2.F06131if. ISSN 1064-8208.  "Tortoise of Transistors Wins the Race - CHM Revolution". Computer History Museum. Retrieved 22 July 2019.  "1964 – First Commercial MOS IC Introduced". Computer History Museum.  "1968: Silicon Gate Technology Developed for ICs". Computer History Museum. Retrieved 22 July 2019.  Kuo, Yue (1 January 2013). "Thin Film Transistor Technology—Past, Present, and Future" (PDF). The Electrochemical Society Interface. 22 (1): 55–61. Bibcode:2013ECSIn..22a..55K. doi:10.1149/2.F06131if. ISSN 1064-8208.  "1971: Microprocessor Integrates CPU Function onto a Single Chip". Computer History Museum. Retrieved 22 July 2019.  Colinge, Jean-Pierre; Greer, James C. (2016). Nanowire Transistors: Physics of Devices and Materials in One Dimension. Cambridge University Press. p. 2. ISBN 9781107052406.  Intel's First Microprocessor—the Intel 4004, Intel Corp., November 1971, archived from the original on 13 May 2008, retrieved 17 May 2008  The Intel 4004 (1971) die was 12 mm2, composed of 2300 transistors; by comparison, the Pentium Pro was 306 mm2, composed of 5.5 million transistors, according to Patterson, David; Hennessy, John (1998), Computer Organization and Design, San Francisco: Morgan Kaufmann, pp. 27–39, ISBN 978-1-55860-428-5  Federico Faggin, The Making of the First Microprocessor, IEEE Solid-State Circuits Magazine, Winter 2009, IEEE Xplore  "7 dazzling smartphone improvements with Qualcomm's Snapdragon 835 chip". 3 January 2017.  Chartier, David (23 December 2008). "Global notebook shipments finally overtake desktops". Ars Technica.  IDC (25 July 2013). "Growth Accelerates in the Worldwide Mobile Phone and Smartphone Markets in the Second Quarter, According to IDC". Archived from the original on 26 June 2014.  Most major 64-bit instruction set architectures are extensions of earlier designs. All of the architectures listed in this table, except for Alpha, existed in 32-bit forms before their 64-bit incarnations were introduced.  The control unit's role in interpreting instructions has varied somewhat in the past. Although the control unit is solely responsible for instruction interpretation in most modern computers, this is not always the case. Some computers have instructions that are partially interpreted by the control unit with further interpretation performed by another device. For example, EDVAC, one of the earliest stored-program computers, used a central control unit that interpreted only four instructions. All of the arithmetic-related instructions were passed on to its arithmetic unit and further decoded there.  Instructions often occupy more than one memory address, therefore the program counter usually increases by the number of memory locations required to store one instruction.  David J. Eck (2000). The Most Complex Machine: A Survey of Computers and Computing. A K Peters, Ltd. p. 54. ISBN 978-1-56881-128-4.  Erricos John Kontoghiorghes (2006). Handbook of Parallel Computing and Statistics. CRC Press. p. 45. ISBN 978-0-8247-4067-2.  Flash memory also may only be rewritten a limited number of times before wearing out, making it less useful for heavy random access usage. (Verma & Mielke 1988)  Donald Eadie (1968). Introduction to the Basic Computer. Prentice-Hall. p. 12.  Arpad Barna; Dan I. Porat (1976). Introduction to Microcomputers and the Microprocessors. Wiley. p. 85. ISBN 978-0-471-05051-3.  Jerry Peek; Grace Todino; John Strang (2002). Learning the UNIX Operating System: A Concise Guide for the New User. O'Reilly. p. 130. ISBN 978-0-596-00261-9.  Gillian M. Davis (2002). Noise Reduction in Speech Applications. CRC Press. p. 111. ISBN 978-0-8493-0949-6.  However, it is also very common to construct supercomputers out of many pieces of cheap commodity hardware; usually individual computers connected by networks. These so-called computer clusters can often provide supercomputer performance at a much lower cost than customized designs. While custom architectures are still used for most of the most powerful supercomputers, there has been a proliferation of cluster computers in recent years. (TOP500 2006)  Even some later computers were commonly programmed directly in machine code. Some minicomputers like the DEC PDP-8 could be programmed directly from a panel of switches. However, this method was usually used only as part of the booting process. Most modern computers boot entirely automatically by reading a boot program from some non-volatile memory.  However, there is sometimes some form of machine language compatibility between different computers. An x86-64 compatible microprocessor like the AMD Athlon 64 is able to run most of the same programs that an Intel Core 2 microprocessor can, as well as programs designed for earlier microprocessors like the Intel Pentiums and Intel 80486. This contrasts with very early commercial computers, which were often one-of-a-kind and totally incompatible with other computers.  High level languages are also often interpreted rather than compiled. Interpreted languages are translated into machine code on the fly, while running, by another program called an interpreter.  It is not universally true that bugs are solely due to programmer oversight. Computer hardware may fail or may itself have a fundamental problem that produces unexpected results in certain situations. For instance, the Pentium FDIV bug caused some Intel microprocessors in the early 1990s to produce inaccurate results for certain floating point division operations. This was caused by a flaw in the microprocessor design and resulted in a partial recall of the affected devices.  Taylor, Alexander L., III (16 April 1984). "The Wizard Inside the Machine". TIME. Archived from the original on 16 March 2007. Retrieved 17 February 2007. (subscription required)  Agatha C. Hughes (2000). Systems, Experts, and Computers. MIT Press. p. 161. ISBN 978-0-262-08285-3. The experience of SAGE helped make possible the first truly large-scale commercial real-time network: the SABRE computerized airline reservations system ...  Leiner, Barry M.; Cerf, Vinton G.; Clark, David D.; Kahn, Robert E.; Kleinrock, Leonard; Lynch, Daniel C.; Postel, Jon; Roberts, Larry G.; Wolf, Stephen (1999). "A Brief History of the Internet". Internet Society. arXiv:cs/9901011. Bibcode:1999cs........1011L. Retrieved 20 September 2008.  According to the Shorter Oxford English Dictionary (6th ed, 2007), the word computer dates back to the mid 17th century, when it referred to "A person who makes calculations; specifically a person employed for this in an observatory etc."  "Definition of computer". Thefreedictionary.com. Retrieved 29 January 2012.  II, Joseph D. Dumas (2005). Computer Architecture: Fundamentals and Principles of Computer Design. CRC Press. p. 340. ISBN 9780849327490. Notes Evans, Claire L. (2018). Broad Band: The Untold Story of the Women Who Made the Internet. New York: Portfolio/Penguin. ISBN 9780735211759. Fuegi, J.; Francis, J. (2003). "Lovelace & Babbage and the creation of the 1843 'notes'". IEEE Annals of the History of Computing. 25 (4): 16. doi:10.1109/MAHC.2003.1253887. S2CID 40077111. a Kempf, Karl (1961). "Historical Monograph: Electronic Computers Within the Ordnance Corps". Aberdeen Proving Ground (United States Army). a Phillips, Tony (2000). "The Antikythera Mechanism I". American Mathematical Society. Retrieved 5 April 2006. a Shannon, Claude Elwood (1940). A symbolic analysis of relay and switching circuits (Thesis). Massachusetts Institute of Technology. hdl:1721.1/11173. Digital Equipment Corporation (1972). PDP-11/40 Processor Handbook (PDF). Maynard, MA: Digital Equipment Corporation. Verma, G.; Mielke, N. (1988). "Reliability performance of ETOX based flash memories". IEEE International Reliability Physics Symposium. Swade, Doron D. (February 1993). "Redeeming Charles Babbage's Mechanical Computer". Scientific American. 268 (2): 86–91. Bibcode:1993SciAm.268b..86S. doi:10.1038/scientificamerican0293-86. JSTOR 24941379. Meuer, Hans; Strohmaier, Erich; Simon, Horst; Dongarra, Jack (13 November 2006). "Architectures Share Over Time". TOP500. Archived from the original on 20 February 2007. Retrieved 27 November 2006. Lavington, Simon (1998). A History of Manchester Computers (2 ed.). Swindon: The British Computer Society. ISBN 978-0-902505-01-8. Light, Jennifer S. (1999). "When Computers Were Women". Technology and Culture. 40 (3): 455–483. doi:10.1353/tech.1999.0128. JSTOR 25147356. S2CID 108407884. Stokes, Jon (2007). Inside the Machine: An Illustrated Introduction to Microprocessors and Computer Architecture. San Francisco: No Starch Press. ISBN 978-1-59327-104-6. Zuse, Konrad (1993). The Computer – My life. Berlin: Pringler-Verlag. ISBN 978-0-387-56453-1. Felt, Dorr E. (1916). Mechanical arithmetic, or The history of the counting machine. Chicago: Washington Institute. Ifrah, Georges (2001). The Universal History of Computing: From the Abacus to the Quantum Computer. New York: John Wiley & Sons. ISBN 978-0-471-39671-0. Berkeley, Edmund (1949). Giant Brains, or Machines That Think. John Wiley & Sons. Cohen, Bernard (2000). Howard Aiken, Portrait of a computer pioneer. Physics Today. 53. Cambridge, Massachusetts: The MIT Press. pp. 74–75. Bibcode:2000PhT....53c..74C. doi:10.1063/1.883007. ISBN 978-0-262-53179-5. Ligonnière, Robert (1987). Préhistoire et Histoire des ordinateurs. Paris: Robert Laffont. ISBN 978-2-221-05261-7. Couffignal, Louis (1933). Les machines à calculer; leurs principes, leur évolution. Paris: Gauthier-Villars. Essinger, James (2004). Jacquard's Web, How a hand loom led to the birth of the information age. Oxford University Press. ISBN 978-0-19-280577-5. Hyman, Anthony (1985). Charles Babbage: Pioneer of the Computer. Princeton University Press. ISBN 978-0-691-02377-9. Bowden, B. V. (1953). Faster than thought. New York, Toronto, London: Pitman publishing corporation. Moseley, Maboth (1964). Irascible Genius, Charles Babbage, inventor. London: Hutchinson. Collier, Bruce (1970). The little engine that could've: The calculating machines of Charles Babbage. Garland Publishing Inc. ISBN 978-0-8240-0043-1. Randell, Brian (1982). "From Analytical Engine to Electronic Digital Computer: The Contributions of Ludgate, Torres, and Bush" (PDF). Archived from the original (PDF) on 21 September 2013. Retrieved 29 October 2013. Smith, Erika E. (2013). "Recognizing a Collective Inheritance through the History of Women in Computing". CLCWeb: Comparative Literature and Culture. 15 (1): 1–9. doi:10.7771/1481-4374.1972. External links  Media related to Computers at Wikimedia Commons  Wikiversity has a quiz on this article Warhol & The Computer vte Basic computer components vte Digital electronics vte Electronics Authority control Edit this at Wikidata Categories: ComputersConsumer electronicsElectronics industry Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadView sourceView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikiquote  Languages Български Bosanski Deutsch Ελληνικά Français Македонски Ποντιακά Shqip Türkçe 217 more Edit links This page was last edited on 19 September 2021, at 20:05 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki  This is a good article. Click here for more information. Page semi-protected World War II From Wikipedia, the free encyclopedia Jump to navigationJump to search "The Second World War" and "WWII" redirect here. For other uses, see The Second World War (disambiguation), WWII (disambiguation), and World War II (disambiguation). World War II   in the    Clockwise from top left: Chinese forces in the Battle of ChangdeAustralian 25-pounder guns during the First Battle of El AlameinGerman Stuka dive bombers on the Eastern Front in December 1943US naval force in the Lingayen GulfWilhelm Keitel signing the German Instrument of SurrenderSoviet troops in the Battle of Stalingrad Date	 1 September 1939 – 2 September 1945[a] (6 years and 1 day) Location	 Europe, Pacific, Atlantic, Indian Ocean, South-East Asia, China, Japan, Middle East, Mediterranean, North Africa, Horn of Africa, Central Africa, Australia, briefly North and South America Result	 Allied victory Fall of Nazi Germany, Fascist Italy and Imperial Japan Allied military occupations of Germany, Japan, Austria and foundation of the Italian Republic in place of the Kingdom of Italy Beginning of the Nuclear Age Dissolution of the League of Nations and creation of the United Nations Emergence of the United States and the Soviet Union as rival superpowers and beginning of the Cold War (See Aftermath of World War II) Participants Allies	Axis Commanders and leaders Main Allied leaders: Soviet Union Joseph Stalin United States Franklin D. Roosevelt United Kingdom Winston Churchill Republic of China (1912–1949) Chiang Kai-shek Main Axis leaders: Nazi Germany Adolf Hitler Empire of Japan Emperor Hirohito Fascist Italy (1922–1943) Benito Mussolini Casualties and losses Military dead: Over 16,000,000 Civilian dead: Over 45,000,000 Total dead: Over 61,000,000 (1937–1945) ...further details Military dead: Over 8,000,000 Civilian dead: Over 4,000,000 Total dead: Over 12,000,000 (1937–1945) ...further details vte Campaigns of World War II World War II Alphabetical indices A B C D E F G H I J K L M N O P Q R S T U V W X Y Z 0–9 Navigation CampaignsCountriesEquipment TimelineOutlineListsHistoriography PortalCategoryBibliography vte World War II or the Second World War, often abbreviated as WWII or WW2, was a global war that lasted from 1939 to 1945. It involved the vast majority of the world's countries—including all of the great powers—forming two opposing military alliances: the Allies and the Axis powers. In a total war directly involving more than 100 million personnel from more than 30 countries, the major participants threw their entire economic, industrial, and scientific capabilities behind the war effort, blurring the distinction between civilian and military resources. Aircraft played a major role in the conflict, enabling the strategic bombing of population centres and the only two uses of nuclear weapons in war to this day. World War II was by far the deadliest conflict in human history; it resulted in 70 to 85 million fatalities, a majority being civilians. Tens of millions of people died due to genocides (including the Holocaust), starvation, massacres, and disease. In the wake of the Axis defeat, Germany and Japan were occupied, and war crimes tribunals were conducted against German and Japanese leaders.  World War II is generally considered to have begun on 1 September 1939, when Nazi Germany, under Adolf Hitler, invaded Poland. The United Kingdom and France subsequently declared war on Germany on 3 September. Under the Molotov–Ribbentrop Pact of August 1939, Germany and the Soviet Union had partitioned Poland and marked out their "spheres of influence" across Finland, Romania and the Baltic states. From late 1939 to early 1941, in a series of campaigns and treaties, Germany conquered or controlled much of continental Europe, and formed the Axis alliance with Italy and Japan (along with other countries later on). Following the onset of campaigns in North Africa and East Africa, and the fall of France in mid-1940, the war continued primarily between the European Axis powers and the British Empire, with war in the Balkans, the aerial Battle of Britain, the Blitz of the UK, and the Battle of the Atlantic. On 22 June 1941, Germany led the European Axis powers in an invasion of the Soviet Union, opening the Eastern Front, the largest land theatre of war in history and trapping the Axis powers, crucially the German Wehrmacht, in a war of attrition.  Japan, which aimed to dominate Asia and the Pacific, was at war with the Republic of China by 1937. In December 1941, Japan attacked American and British territories with near-simultaneous offensives against Southeast Asia and the Central Pacific, including an attack on the US fleet at Pearl Harbor which forced the US to declare war against Japan; the European Axis powers declared war on the US in solidarity. Japan soon captured much of the western Pacific, but its advances were halted in 1942 after losing the critical Battle of Midway; later, Germany and Italy were defeated in North Africa and at Stalingrad in the Soviet Union. Key setbacks in 1943—including a series of German defeats on the Eastern Front, the Allied invasions of Sicily and the Italian mainland, and Allied offensives in the Pacific—cost the Axis powers their initiative and forced it into strategic retreat on all fronts. In 1944, the Western Allies invaded German-occupied France, while the Soviet Union regained its territorial losses and turned towards Germany and its allies. During 1944 and 1945, Japan suffered reversals in mainland Asia, while the Allies crippled the Japanese Navy and captured key western Pacific islands.  The war in Europe concluded with the liberation of German-occupied territories, and the invasion of Germany by the Western Allies and the Soviet Union, culminating in the fall of Berlin to Soviet troops, Hitler's suicide and the German unconditional surrender on 8 May 1945. Following the Potsdam Declaration by the Allies on 26 July 1945 and the refusal of Japan to surrender on its terms, the United States dropped the first atomic bombs on the Japanese cities of Hiroshima, on 6 August, and Nagasaki, on 9 August. Faced with an imminent invasion of the Japanese archipelago, the possibility of additional atomic bombings, and the Soviet entry into the war against Japan and its invasion of Manchuria, Japan announced its intention to surrender on 15 August, then signed the surrender document on 2 September 1945, cementing total victory in Asia for the Allies.  World War II changed the political alignment and social structure of the globe. The United Nations (UN) was established to foster international co-operation and prevent future conflicts, and the victorious great powers—China, France, the Soviet Union, the United Kingdom, and the United States—became the permanent members of its Security Council. The Soviet Union and the United States emerged as rival superpowers, setting the stage for the nearly half-century-long Cold War. In the wake of European devastation, the influence of its great powers waned, triggering the decolonisation of Africa and Asia. Most countries whose industries had been damaged moved towards economic recovery and expansion. Political integration, especially in Europe, began as an effort to forestall future hostilities, end pre-war enmities and forge a sense of common identity.   Contents 1	Start and end dates 2	Background 2.1	Europe 2.2	Asia 3	Pre-war events 3.1	Italian invasion of Ethiopia (1935) 3.2	Spanish Civil War (1936–1939) 3.3	Japanese invasion of China (1937) 3.4	Soviet–Japanese border conflicts 3.5	European occupations and agreements 4	Course of the war 4.1	War breaks out in Europe (1939–40) 4.2	Western Europe (1940–41) 4.3	Mediterranean (1940–41) 4.4	Axis attack on the Soviet Union (1941) 4.5	War breaks out in the Pacific (1941) 4.6	Axis advance stalls (1942–43) 4.7	Allies gain momentum (1943–44) 4.8	Allies close in (1944) 4.9	Axis collapse, Allied victory (1944–45) 5	Aftermath 6	Impact 6.1	Casualties and war crimes 6.2	Genocide, concentration camps, and slave labour 6.3	Occupation 6.4	Home fronts and production 6.5	Advances in technology and warfare 7	See also 8	Notes 9	Citations 10	References 11	External links Start and end dates See also: Timeline of World War II Timelines of World War II Chronological Prelude (in Asiain Europe) 1939194019411942 194319441945 onwards By topic Diplomacy Declarations of war EngagementsOperations Battle of Europe air operations Eastern FrontManhattan Project United Kingdom home front Surrender of the Axis armies vte It is generally considered that in Europe World War II started on 1 September 1939,[1][2] beginning with the German invasion of Poland and the United Kingdom and France's declaration of war on Germany two days later. The dates for the beginning of the war in the Pacific include the start of the Second Sino-Japanese War on 7 July 1937,[3][4] or the earlier Japanese invasion of Manchuria, on 19 September 1931.[5][6][7] Others follow the British historian A. J. P. Taylor, who held that the Sino-Japanese War and war in Europe and its colonies occurred simultaneously, and the two wars became World War II in 1941. Other starting dates sometimes used for World War II include the Italian invasion of Abyssinia on 3 October 1935.[8] The British historian Antony Beevor views the beginning of World War II as the Battles of Khalkhin Gol fought between Japan and the forces of Mongolia and the Soviet Union from May to September 1939.[9] Others view the Spanish Civil War as the start or prelude to World War II.[10][11]  The exact date of the war's end is also not universally agreed upon. It was generally accepted at the time that the war ended with the armistice of 14 August 1945 (V-J Day), rather than with the formal surrender of Japan on 2 September 1945, which officially ended the war in Asia. A peace treaty between Japan and the Allies was signed in 1951.[12] A 1990 treaty regarding Germany's future allowed the reunification of East and West Germany to take place and resolved most post-World War II issues.[13] No formal peace treaty between Japan and the Soviet Union was ever signed,[14] although the state of war between the two countries was terminated by the Soviet–Japanese Joint Declaration of 1956, which also restored full diplomatic relations between them.[15]  Background Main article: Causes of World War II Europe World War I had radically altered the political European map, with the defeat of the Central Powers—including Austria-Hungary, Germany, Bulgaria and the Ottoman Empire—and the 1917 Bolshevik seizure of power in Russia, which led to the founding of the Soviet Union. Meanwhile, the victorious Allies of World War I, such as France, Belgium, Italy, Romania, and Greece, gained territory, and new nation-states were created out of the collapse of Austria-Hungary and the Ottoman and Russian Empires.   The League of Nations assembly, held in Geneva, Switzerland, 1930 To prevent a future world war, the League of Nations was created during the 1919 Paris Peace Conference. The organisation's primary goals were to prevent armed conflict through collective security, military and naval disarmament, and settling international disputes through peaceful negotiations and arbitration.  Despite strong pacifist sentiment after World War I,[16] irredentist and revanchist nationalism emerged in several European states in the same period. These sentiments were especially marked in Germany because of the significant territorial, colonial, and financial losses imposed by the Treaty of Versailles. Under the treaty, Germany lost around 13 percent of its home territory and all its overseas possessions, while German annexation of other states was prohibited, reparations were imposed, and limits were placed on the size and capability of the country's armed forces.[17]  The German Empire was dissolved in the German Revolution of 1918–1919, and a democratic government, later known as the Weimar Republic, was created. The interwar period saw strife between supporters of the new republic and hardline opponents on both the right and left. Italy, as an Entente ally, had made some post-war territorial gains; however, Italian nationalists were angered that the promises made by the United Kingdom and France to secure Italian entrance into the war were not fulfilled in the peace settlement. From 1922 to 1925, the Fascist movement led by Benito Mussolini seized power in Italy with a nationalist, totalitarian, and class collaborationist agenda that abolished representative democracy, repressed socialist, left-wing and liberal forces, and pursued an aggressive expansionist foreign policy aimed at making Italy a world power, and promising the creation of a "New Roman Empire".[18]   Adolf Hitler at a German Nazi political rally in Nuremberg, August 1933 Adolf Hitler, after an unsuccessful attempt to overthrow the German government in 1923, eventually became the Chancellor of Germany in 1933 when Paul Von Hindenburg and the Reichstag appointed him. He abolished democracy, espousing a radical, racially motivated revision of the world order, and soon began a massive rearmament campaign.[19] Meanwhile, France, to secure its alliance, allowed Italy a free hand in Ethiopia, which Italy desired as a colonial possession. The situation was aggravated in early 1935 when the Territory of the Saar Basin was legally reunited with Germany, and Hitler repudiated the Treaty of Versailles, accelerated his rearmament programme, and introduced conscription.[20]  The United Kingdom, France and Italy formed the Stresa Front in April 1935 in order to contain Germany, a key step towards military globalisation; however, that June, the United Kingdom made an independent naval agreement with Germany, easing prior restrictions. The Soviet Union, concerned by Germany's goals of capturing vast areas of Eastern Europe, drafted a treaty of mutual assistance with France. Before taking effect, though, the Franco-Soviet pact was required to go through the bureaucracy of the League of Nations, which rendered it essentially toothless.[21] The United States, concerned with events in Europe and Asia, passed the Neutrality Act in August of the same year.[22]  Hitler defied the Versailles and Locarno treaties by remilitarising the Rhineland in March 1936, encountering little opposition due to the policy of appeasement.[23] In October 1936, Germany and Italy formed the Rome–Berlin Axis. A month later, Germany and Japan signed the Anti-Comintern Pact, which Italy joined the following year.[24]  Asia The Kuomintang (KMT) party in China launched a unification campaign against regional warlords and nominally unified China in the mid-1920s, but was soon embroiled in a civil war against its former Chinese Communist Party allies[25] and new regional warlords. In 1931, an increasingly militaristic Empire of Japan, which had long sought influence in China[26] as the first step of what its government saw as the country's right to rule Asia, staged the Mukden Incident as a pretext to invade Manchuria and establish the puppet state of Manchukuo.[27]  China appealed to the League of Nations to stop the Japanese invasion of Manchuria. Japan withdrew from the League of Nations after being condemned for its incursion into Manchuria. The two nations then fought several battles, in Shanghai, Rehe and Hebei, until the Tanggu Truce was signed in 1933. Thereafter, Chinese volunteer forces continued the resistance to Japanese aggression in Manchuria, and Chahar and Suiyuan.[28] After the 1936 Xi'an Incident, the Kuomintang and communist forces agreed on a ceasefire to present a united front to oppose Japan.[29]  Pre-war events Italian invasion of Ethiopia (1935)  Benito Mussolini inspecting troops during the Italo-Ethiopian War, 1935 Main article: Second Italo-Ethiopian War The Second Italo-Ethiopian War was a brief colonial war that began in October 1935 and ended in May 1936. The war began with the invasion of the Ethiopian Empire (also known as Abyssinia) by the armed forces of the Kingdom of Italy (Regno d'Italia), which was launched from Italian Somaliland and Eritrea.[30] The war resulted in the military occupation of Ethiopia and its annexation into the newly created colony of Italian East Africa (Africa Orientale Italiana, or AOI); in addition it exposed the weakness of the League of Nations as a force to preserve peace. Both Italy and Ethiopia were member nations, but the League did little when the former clearly violated Article X of the League's Covenant.[31] The United Kingdom and France supported imposing sanctions on Italy for the invasion, but the sanctions were not fully enforced and failed to end the Italian invasion.[32] Italy subsequently dropped its objections to Germany's goal of absorbing Austria.[33]  Spanish Civil War (1936–1939) Main article: Spanish Civil War  The bombing of Guernica in 1937, during the Spanish Civil War, sparked fears abroad in Europe that the next war would be based on bombing of cities with very high civilian casualties. When civil war broke out in Spain, Hitler and Mussolini lent military support to the Nationalist rebels, led by General Francisco Franco. Italy supported the Nationalists to a greater extent than the Nazis did: altogether Mussolini sent to Spain more than 70,000 ground troops and 6,000 aviation personnel, as well as about 720 aircraft.[34] The Soviet Union supported the existing government of the Spanish Republic. More than 30,000 foreign volunteers, known as the International Brigades, also fought against the Nationalists. Both Germany and the Soviet Union used this proxy war as an opportunity to test in combat their most advanced weapons and tactics. The Nationalists won the civil war in April 1939; Franco, now dictator, remained officially neutral during World War II but generally favoured the Axis.[35] His greatest collaboration with Germany was the sending of volunteers to fight on the Eastern Front.[36]  Japanese invasion of China (1937) Main article: Second Sino-Japanese War  Japanese Imperial Army soldiers during the Battle of Shanghai, 1937 In July 1937, Japan captured the former Chinese imperial capital of Peking after instigating the Marco Polo Bridge Incident, which culminated in the Japanese campaign to invade all of China.[37] The Soviets quickly signed a non-aggression pact with China to lend materiel support, effectively ending China's prior co-operation with Germany. From September to November, the Japanese attacked Taiyuan, engaged the Kuomintang Army around Xinkou,[38] and fought Communist forces in Pingxingguan.[39][40] Generalissimo Chiang Kai-shek deployed his best army to defend Shanghai, but after three months of fighting, Shanghai fell. The Japanese continued to push the Chinese forces back, capturing the capital Nanking in December 1937. After the fall of Nanking, tens or hundreds of thousands of Chinese civilians and disarmed combatants were murdered by the Japanese.[41][42]  In March 1938, Nationalist Chinese forces won their first major victory at Taierzhuang, but then the city of Xuzhou was taken by the Japanese in May.[43] In June 1938, Chinese forces stalled the Japanese advance by flooding the Yellow River; this manoeuvre bought time for the Chinese to prepare their defences at Wuhan, but the city was taken by October.[44] Japanese military victories did not bring about the collapse of Chinese resistance that Japan had hoped to achieve; instead, the Chinese government relocated inland to Chongqing and continued the war.[45][46]  Soviet–Japanese border conflicts Main article: Soviet–Japanese border conflicts  Red Army artillery unit during the Battle of Lake Khasan, 1938 In the mid-to-late 1930s, Japanese forces in Manchukuo had sporadic border clashes with the Soviet Union and Mongolia. The Japanese doctrine of Hokushin-ron, which emphasised Japan's expansion northward, was favoured by the Imperial Army during this time. With the Japanese defeat at Khalkin Gol in 1939, the ongoing Second Sino-Japanese War[47] and ally Nazi Germany pursuing neutrality with the Soviets, this policy would prove difficult to maintain. Japan and the Soviet Union eventually signed a Neutrality Pact in April 1941, and Japan adopted the doctrine of Nanshin-ron, promoted by the Navy, which took its focus southward, eventually leading to its war with the United States and the Western Allies.[48][49]  European occupations and agreements  Chamberlain, Daladier, Hitler, Mussolini, and Ciano pictured just before signing the Munich Agreement, 29 September 1938 In Europe, Germany and Italy were becoming more aggressive. In March 1938, Germany annexed Austria, again provoking little response from other European powers.[50] Encouraged, Hitler began pressing German claims on the Sudetenland, an area of Czechoslovakia with a predominantly ethnic German population. Soon the United Kingdom and France followed the appeasement policy of British Prime Minister Neville Chamberlain and conceded this territory to Germany in the Munich Agreement, which was made against the wishes of the Czechoslovak government, in exchange for a promise of no further territorial demands.[51] Soon afterwards, Germany and Italy forced Czechoslovakia to cede additional territory to Hungary, and Poland annexed Czechoslovakia's Zaolzie region.[52]  Although all of Germany's stated demands had been satisfied by the agreement, privately Hitler was furious that British interference had prevented him from seizing all of Czechoslovakia in one operation. In subsequent speeches Hitler attacked British and Jewish "war-mongers" and in January 1939 secretly ordered a major build-up of the German navy to challenge British naval supremacy. In March 1939, Germany invaded the remainder of Czechoslovakia and subsequently split it into the German Protectorate of Bohemia and Moravia and a pro-German client state, the Slovak Republic.[53] Hitler also delivered an ultimatum to Lithuania on 20 March 1939, forcing the concession of the Klaipėda Region, formerly the German Memelland.[54]   German Foreign Minister Joachim von Ribbentrop (right) and the Soviet leader Joseph Stalin, after signing the Molotov–Ribbentrop Pact, 23 August 1939 Greatly alarmed and with Hitler making further demands on the Free City of Danzig, the United Kingdom and France guaranteed their support for Polish independence; when Italy conquered Albania in April 1939, the same guarantee was extended to the Kingdoms of Romania and Greece.[55] Shortly after the Franco-British pledge to Poland, Germany and Italy formalised their own alliance with the Pact of Steel.[56] Hitler accused the United Kingdom and Poland of trying to "encircle" Germany and renounced the Anglo-German Naval Agreement and the German–Polish Non-Aggression Pact.[57]  The situation reached a general crisis in late August as German troops continued to mobilise against the Polish border. On 23 August, when tripartite negotiations about a military alliance between France, the United Kingdom and Soviet Union stalled,[58] the Soviet Union signed a non-aggression pact with Germany.[59] This pact had a secret protocol that defined German and Soviet "spheres of influence" (western Poland and Lithuania for Germany; eastern Poland, Finland, Estonia, Latvia and Bessarabia for the Soviet Union), and raised the question of continuing Polish independence.[60] The pact neutralised the possibility of Soviet opposition to a campaign against Poland and assured that Germany would not have to face the prospect of a two-front war, as it had in World War I. Immediately after that, Hitler ordered the attack to proceed on 26 August, but upon hearing that the United Kingdom had concluded a formal mutual assistance pact with Poland and that Italy would maintain neutrality, he decided to delay it.[61]  In response to British requests for direct negotiations to avoid war, Germany made demands on Poland, which only served as a pretext to worsen relations.[62] On 29 August, Hitler demanded that a Polish plenipotentiary immediately travel to Berlin to negotiate the handover of Danzig, and to allow a plebiscite in the Polish Corridor in which the German minority would vote on secession.[62] The Poles refused to comply with the German demands, and on the night of 30–31 August in a stormy meeting with the British ambassador Nevile Henderson, Ribbentrop declared that Germany considered its claims rejected.[63]  Course of the war Further information: Diplomatic history of World War II War breaks out in Europe (1939–40) Main article: European theatre of World War II  Soldiers of the German Wehrmacht tearing down the border crossing into Poland, 1 September 1939 On 1 September 1939, Germany invaded Poland after having staged several false flag border incidents as a pretext to initiate the invasion.[64] The first German attack of the war came against the Polish defenses at Westerplatte.[65] The United Kingdom responded with an ultimatum to Germany to cease military operations, and on 3 September, after the ultimatum was ignored, Britain and France declared war on Germany,[66] followed by Australia, New Zealand, South Africa and Canada. The alliance provided no direct military support to Poland, outside of a cautious French probe into the Saarland.[67] The Western Allies also began a naval blockade of Germany, which aimed to damage the country's economy and the war effort.[68] Germany responded by ordering U-boat warfare against Allied merchant and warships, which would later escalate into the Battle of the Atlantic.[69]   Soldiers of the Polish Army during the defence of Poland, September 1939 On 8 September, German troops reached the suburbs of Warsaw. The Polish counter offensive to the west halted the German advance for several days, but it was outflanked and encircled by the Wehrmacht. Remnants of the Polish army broke through to besieged Warsaw. On 17 September 1939, after signing a cease-fire with Japan, the Soviet Union invaded Eastern Poland[70] under a pretext that the Polish state had ostensibly ceased to exist.[71] On 27 September, the Warsaw garrison surrendered to the Germans, and the last large operational unit of the Polish Army surrendered on 6 October. Despite the military defeat, Poland never surrendered; instead, it formed the Polish government-in-exile and a clandestine state apparatus remained in occupied Poland.[72] A significant part of Polish military personnel evacuated to Romania and the Baltic countries; many of them later fought against the Axis in other theatres of the war.[73]  Germany annexed the western and occupied the central part of Poland, and the Soviet Union annexed its eastern part; small shares of Polish territory were transferred to Lithuania and Slovakia. On 6 October, Hitler made a public peace overture to the United Kingdom and France but said that the future of Poland was to be determined exclusively by Germany and the Soviet Union. The proposal was rejected,[63] and Hitler ordered an immediate offensive against France,[74] which was postponed until the spring of 1940 due to bad weather.[75][76][77]   Finnish machine gun nest aimed at Soviet Red Army positions during the Winter War, February 1940 The Soviet Union forced the Baltic countries—Estonia, Latvia and Lithuania, which were in the Soviet "sphere of influence" under the Molotov-Ribbentrop pact—to sign "mutual assistance pacts" that stipulated stationing Soviet troops in these countries. Soon after, significant Soviet military contingents were moved there.[78][79][80] Finland refused to sign a similar pact and rejected ceding part of its territory to the Soviet Union. The Soviet Union invaded Finland in November 1939,[81] and the Soviet Union was expelled from the League of Nations.[82] Despite overwhelming numerical superiority, Soviet military success was modest, but the Finno-Soviet war ended in March 1940 with fairly significant Finnish concessions.[83]  In June 1940, the Soviet Union forcibly annexed Estonia, Latvia and Lithuania,[79] and the Romanian regions of Bessarabia, Northern Bukovina and the Hertsa region. Meanwhile, Nazi-Soviet political rapprochement and economic co-operation[84][85] gradually stalled,[86][87] and both states began preparations for war.[88]  Western Europe (1940–41) Main article: Western Front (World War II)  German advance into Belgium and Northern France, 10 May-4 June 1940, swept past the Maginot Line (shown in dark red) In April 1940, Germany invaded Denmark and Norway to protect shipments of iron ore from Sweden, which the Allies were attempting to cut off.[89] Denmark capitulated after a few hours, and Norway was conquered within two months[90] despite Allied support. British discontent over the Norwegian campaign led to the appointment of Winston Churchill as Prime Minister on 10 May 1940.[91]  On the same day, Germany launched an offensive against France. To circumvent the strong Maginot Line fortifications on the Franco-German border, Germany directed its attack at the neutral nations of Belgium, the Netherlands, and Luxembourg.[92] The Germans carried out a flanking manoeuvre through the Ardennes region,[93] which was mistakenly perceived by Allies as an impenetrable natural barrier against armoured vehicles.[94][95] By successfully implementing new blitzkrieg tactics, the Wehrmacht rapidly advanced to the Channel and cut off the Allied forces in Belgium, trapping the bulk of the Allied armies in a cauldron on the Franco-Belgian border near Lille. The United Kingdom was able to evacuate a significant number of Allied troops from the continent by early June, although abandoning almost all their equipment.[96]  On 10 June, Italy invaded France, declaring war on both France and the United Kingdom.[97] The Germans turned south against the weakened French army, and Paris fell to them on 14 June. Eight days later France signed an armistice with Germany; it was divided into German and Italian occupation zones,[98] and an unoccupied rump state under the Vichy Regime, which, though officially neutral, was generally aligned with Germany. France kept its fleet, which the United Kingdom attacked on 3 July in an attempt to prevent its seizure by Germany.[99]   London seen from St. Paul's Cathedral after the German Blitz, 29 December 1940 The air Battle of Britain[100] began in early July with Luftwaffe attacks on shipping and harbours.[101] The United Kingdom rejected Hitler's peace offer,[102] and the German air superiority campaign started in August but failed to defeat RAF Fighter Command, forcing the indefinite postponement of the proposed German invasion of Britain. The German strategic bombing offensive intensified with night attacks on London and other cities in the Blitz, but failed to significantly disrupt the British war effort[101] and largely ended in May 1941.[103]  Using newly captured French ports, the German Navy enjoyed success against an over-extended Royal Navy, using U-boats against British shipping in the Atlantic.[104] The British Home Fleet scored a significant victory on 27 May 1941 by sinking the German battleship Bismarck.[105]  In November 1939, the United States was taking measures to assist China and the Western Allies and amended the Neutrality Act to allow "cash and carry" purchases by the Allies.[106] In 1940, following the German capture of Paris, the size of the United States Navy was significantly increased. In September the United States further agreed to a trade of American destroyers for British bases.[107] Still, a large majority of the American public continued to oppose any direct military intervention in the conflict well into 1941.[108] In December 1940 Roosevelt accused Hitler of planning world conquest and ruled out any negotiations as useless, calling for the United States to become an "arsenal of democracy" and promoting Lend-Lease programmes of aid to support the British war effort.[102] The United States started strategic planning to prepare for a full-scale offensive against Germany.[109]  At the end of September 1940, the Tripartite Pact formally united Japan, Italy, and Germany as the Axis powers. The Tripartite Pact stipulated that any country, with the exception of the Soviet Union, which attacked any Axis Power would be forced to go to war against all three.[110] The Axis expanded in November 1940 when Hungary, Slovakia and Romania joined.[111] Romania and Hungary later made major contributions to the Axis war against the Soviet Union, in Romania's case partially to recapture territory ceded to the Soviet Union.[112]  Mediterranean (1940–41) Main article: Mediterranean and Middle East theatre of World War II  Soldiers of the British Commonwealth forces from the Australian Army's 9th Division during the Siege of Tobruk; North African Campaign, August 1941 In early June 1940, the Italian Regia Aeronautica attacked and besieged Malta, a British possession. From late summer to early autumn, Italy conquered British Somaliland and made an incursion into British-held Egypt. In October, Italy attacked Greece, but the attack was repulsed with heavy Italian casualties; the campaign ended within months with minor territorial changes.[113] Germany started preparation for an invasion of the Balkans to assist Italy, to prevent the British from gaining a foothold there, which would be a potential threat for Romanian oil fields, and to strike against the British dominance of the Mediterranean.[114]  In December 1940, British Empire forces began counter-offensives against Italian forces in Egypt and Italian East Africa.[115] The offensives were highly successful; by early February 1941, Italy had lost control of eastern Libya, and large numbers of Italian troops had been taken prisoner. The Italian Navy also suffered significant defeats, with the Royal Navy putting three Italian battleships out of commission by means of a carrier attack at Taranto, and neutralising several more warships at the Battle of Cape Matapan.[116]   German Panzer III of the Afrika Korps advancing across the North African desert, 1941 Italian defeats prompted Germany to deploy an expeditionary force to North Africa and at the end of March 1941, Rommel's Afrika Korps launched an offensive which drove back the Commonwealth forces.[117] In under a month, Axis forces advanced to western Egypt and besieged the port of Tobruk.[118]  By late March 1941, Bulgaria and Yugoslavia signed the Tripartite Pact; however, the Yugoslav government was overthrown two days later by pro-British nationalists. Germany responded with simultaneous invasions of both Yugoslavia and Greece, commencing on 6 April 1941; both nations were forced to surrender within the month.[119] The airborne invasion of the Greek island of Crete at the end of May completed the German conquest of the Balkans.[120] Although the Axis victory was swift, bitter and large-scale partisan warfare subsequently broke out against the Axis occupation of Yugoslavia, which continued until the end of the war.[121]  In the Middle East in May, Commonwealth forces quashed an uprising in Iraq which had been supported by German aircraft from bases within Vichy-controlled Syria.[122] Between June and July, they invaded and occupied the French possessions Syria and Lebanon, with the assistance of the Free French.[123]  Axis attack on the Soviet Union (1941) Main article: Eastern Front (World War II)  European theatre of World War II animation map, 1939–1945 – Red: Western Allies and the Soviet Union after 1941; Green: Soviet Union before 1941; Blue: Axis powers With the situation in Europe and Asia relatively stable, Germany, Japan, and the Soviet Union made preparations. With the Soviets wary of mounting tensions with Germany and the Japanese planning to take advantage of the European War by seizing resource-rich European possessions in Southeast Asia, the two powers signed the Soviet–Japanese Neutrality Pact in April 1941.[124] By contrast, the Germans were steadily making preparations for an attack on the Soviet Union, massing forces on the Soviet border.[125]  Hitler believed that the United Kingdom's refusal to end the war was based on the hope that the United States and the Soviet Union would enter the war against Germany sooner or later.[126] He, therefore, decided to try to strengthen Germany's relations with the Soviets or failing that to attack and eliminate them as a factor. In November 1940, negotiations took place to determine if the Soviet Union would join the Tripartite Pact. The Soviets showed some interest but asked for concessions from Finland, Bulgaria, Turkey, and Japan that Germany considered unacceptable. On 18 December 1940, Hitler issued the directive to prepare for an invasion of the Soviet Union.[127]   German soldiers during the invasion of the Soviet Union by the Axis powers, 1941 On 22 June 1941, Germany, supported by Italy and Romania, invaded the Soviet Union in Operation Barbarossa, with Germany accusing the Soviets of plotting against them. They were joined shortly by Finland and Hungary.[128] The primary targets of this surprise offensive[129] were the Baltic region, Moscow and Ukraine, with the ultimate goal of ending the 1941 campaign near the Arkhangelsk-Astrakhan line, from the Caspian to the White Seas. Hitler's objectives were to eliminate the Soviet Union as a military power, exterminate Communism, generate Lebensraum ("living space")[130] by dispossessing the native population[131] and guarantee access to the strategic resources needed to defeat Germany's remaining rivals.[132]  Although the Red Army was preparing for strategic counter-offensives before the war,[133] Barbarossa forced the Soviet supreme command to adopt a strategic defence. During the summer, the Axis made significant gains into Soviet territory, inflicting immense losses in both personnel and materiel. By mid-August, however, the German Army High Command decided to suspend the offensive of a considerably depleted Army Group Centre, and to divert the 2nd Panzer Group to reinforce troops advancing towards central Ukraine and Leningrad.[134] The Kiev offensive was overwhelmingly successful, resulting in encirclement and elimination of four Soviet armies, and made possible further advance into Crimea and industrially developed Eastern Ukraine (the First Battle of Kharkov).[135]   Soviet civilians leaving destroyed houses after a German bombardment during the Battle of Leningrad, 10 December 1942 The diversion of three quarters of the Axis troops and the majority of their air forces from France and the central Mediterranean to the Eastern Front[136] prompted the United Kingdom to reconsider its grand strategy.[137] In July, the UK and the Soviet Union formed a military alliance against Germany[138] and in August, the United Kingdom and the United States jointly issued the Atlantic Charter, which outlined British and American goals for the postwar world.[139] In late August the British and Soviets invaded neutral Iran to secure the Persian Corridor, Iran's oil fields, and preempt any Axis advances through Iran toward the Baku oil fields or British India.[140]  By October Axis operational objectives in Ukraine and the Baltic region were achieved, with only the sieges of Leningrad[141] and Sevastopol continuing.[142] A major offensive against Moscow was renewed; after two months of fierce battles in increasingly harsh weather, the German army almost reached the outer suburbs of Moscow, where the exhausted troops[143] were forced to suspend their offensive.[144] Large territorial gains were made by Axis forces, but their campaign had failed to achieve its main objectives: two key cities remained in Soviet hands, the Soviet capability to resist was not broken, and the Soviet Union retained a considerable part of its military potential. The blitzkrieg phase of the war in Europe had ended.[145]  By early December, freshly mobilised reserves[146] allowed the Soviets to achieve numerical parity with Axis troops.[147] This, as well as intelligence data which established that a minimal number of Soviet troops in the East would be sufficient to deter any attack by the Japanese Kwantung Army,[148] allowed the Soviets to begin a massive counter-offensive that started on 5 December all along the front and pushed German troops 100–250 kilometres (62–155 mi) west.[149]  War breaks out in the Pacific (1941) Main article: Pacific War Following the Japanese false flag Mukden Incident in 1931, the Japanese shelling of the American gunboat USS Panay in 1937, and the 1937-38 Nanjing Massacre, Japanese-American relations deteriorated. In 1939, the United States notified Japan that it would not be extending its trade treaty and American public opinion opposing Japanese expansionism led to a series of economic sanctions, the Export Control Acts, which banned U.S. exports of chemicals, minerals and military parts to Japan and increased economic pressure on the Japanese regime.[102][150][151] During 1939 Japan launched its first attack against Changsha, a strategically important Chinese city, but was repulsed by late September.[152] Despite several offensives by both sides, the war between China and Japan was stalemated by 1940. To increase pressure on China by blocking supply routes, and to better position Japanese forces in the event of a war with the Western powers, Japan invaded and occupied northern Indochina in September 1940.[153]   Japanese soldiers entering Hong Kong, 8 December 1941 Chinese nationalist forces launched a large-scale counter-offensive in early 1940. In August, Chinese communists launched an offensive in Central China; in retaliation, Japan instituted harsh measures in occupied areas to reduce human and material resources for the communists.[154] The continued antipathy between Chinese communist and nationalist forces culminated in armed clashes in January 1941, effectively ending their co-operation.[155] In March, the Japanese 11th army attacked the headquarters of the Chinese 19th army but was repulsed during Battle of Shanggao.[156] In September, Japan attempted to take the city of Changsha again and clashed with Chinese nationalist forces.[157]  German successes in Europe encouraged Japan to increase pressure on European governments in Southeast Asia. The Dutch government agreed to provide Japan with some oil supplies from the Dutch East Indies, but negotiations for additional access to their resources ended in failure in June 1941.[158] In July 1941 Japan sent troops to southern Indochina, thus threatening British and Dutch possessions in the Far East. The United States, the United Kingdom, and other Western governments reacted to this move with a freeze on Japanese assets and a total oil embargo.[159][160] At the same time, Japan was planning an invasion of the Soviet Far East, intending to capitalise off the German invasion in the west, but abandoned the operation after the sanctions.[161]  Since early 1941 the United States and Japan had been engaged in negotiations in an attempt to improve their strained relations and end the war in China. During these negotiations, Japan advanced a number of proposals which were dismissed by the Americans as inadequate.[162] At the same time the United States, the United Kingdom, and the Netherlands engaged in secret discussions for the joint defence of their territories, in the event of a Japanese attack against any of them.[163] Roosevelt reinforced the Philippines (an American protectorate scheduled for independence in 1946) and warned Japan that the United States would react to Japanese attacks against any "neighboring countries".[163]   The USS Arizona was a total loss in the Japanese surprise air attack on the American Pacific Fleet at Pearl Harbor, Sunday 7 December 1941. Frustrated at the lack of progress and feeling the pinch of the American–British–Dutch sanctions, Japan prepared for war. On 20 November, a new government under Hideki Tojo presented an interim proposal as its final offer. It called for the end of American aid to China and for lifting the embargo on the supply of oil and other resources to Japan. In exchange, Japan promised not to launch any attacks in Southeast Asia and to withdraw its forces from southern Indochina.[162] The American counter-proposal of 26 November required that Japan evacuate all of China without conditions and conclude non-aggression pacts with all Pacific powers.[164] That meant Japan was essentially forced to choose between abandoning its ambitions in China, or seizing the natural resources it needed in the Dutch East Indies by force;[165][166] the Japanese military did not consider the former an option, and many officers considered the oil embargo an unspoken declaration of war.[167]  Japan planned to rapidly seize European colonies in Asia to create a large defensive perimeter stretching into the Central Pacific. The Japanese would then be free to exploit the resources of Southeast Asia while exhausting the over-stretched Allies by fighting a defensive war.[168][169] To prevent American intervention while securing the perimeter, it was further planned to neutralise the United States Pacific Fleet and the American military presence in the Philippines from the outset.[170] On 7 December 1941 (8 December in Asian time zones), Japan attacked British and American holdings with near-simultaneous offensives against Southeast Asia and the Central Pacific.[171] These included an attack on the American fleets at Pearl Harbor and the Philippines, Guam, Wake Island, landings in Malaya,[171] Thailand and the Battle of Hong Kong.[172]  The Japanese invasion of Thailand led to Thailand's decision to ally itself with Japan and the other Japanese attacks led the United States, United Kingdom, China, Australia, and several other states to formally declare war on Japan, whereas the Soviet Union, being heavily involved in large-scale hostilities with European Axis countries, maintained its neutrality agreement with Japan.[173] Germany, followed by the other Axis states, declared war on the United States[174] in solidarity with Japan, citing as justification the American attacks on German war vessels that had been ordered by Roosevelt.[128][175]  Axis advance stalls (1942–43)  US President Franklin D. Roosevelt and British PM Winston Churchill seated at the Casablanca Conference, January 1943 On 1 January 1942, the Allied Big Four[176]—the Soviet Union, China, the United Kingdom and the United States—and 22 smaller or exiled governments issued the Declaration by United Nations, thereby affirming the Atlantic Charter,[177] and agreeing not to sign a separate peace with the Axis powers.[178]  During 1942, Allied officials debated on the appropriate grand strategy to pursue. All agreed that defeating Germany was the primary objective. The Americans favoured a straightforward, large-scale attack on Germany through France. The Soviets were also demanding a second front. The British, on the other hand, argued that military operations should target peripheral areas to wear out German strength, leading to increasing demoralisation, and bolster resistance forces. Germany itself would be subject to a heavy bombing campaign. An offensive against Germany would then be launched primarily by Allied armour without using large-scale armies.[179] Eventually, the British persuaded the Americans that a landing in France was infeasible in 1942 and they should instead focus on driving the Axis out of North Africa.[180]  At the Casablanca Conference in early 1943, the Allies reiterated the statements issued in the 1942 Declaration and demanded the unconditional surrender of their enemies. The British and Americans agreed to continue to press the initiative in the Mediterranean by invading Sicily to fully secure the Mediterranean supply routes.[181] Although the British argued for further operations in the Balkans to bring Turkey into the war, in May 1943, the Americans extracted a British commitment to limit Allied operations in the Mediterranean to an invasion of the Italian mainland and to invade France in 1944.[182]  Pacific (1942–43)  Map of Japanese military advances through mid-1942 By the end of April 1942, Japan and its ally Thailand had almost fully conquered Burma, Malaya, the Dutch East Indies, Singapore, and Rabaul, inflicting severe losses on Allied troops and taking a large number of prisoners.[183] Despite stubborn resistance by Filipino and US forces, the Philippine Commonwealth was eventually captured in May 1942, forcing its government into exile.[184] On 16 April, in Burma, 7,000 British soldiers were encircled by the Japanese 33rd Division during the Battle of Yenangyaung and rescued by the Chinese 38th Division.[185] Japanese forces also achieved naval victories in the South China Sea, Java Sea and Indian Ocean,[186] and bombed the Allied naval base at Darwin, Australia. In January 1942, the only Allied success against Japan was a Chinese victory at Changsha.[187] These easy victories over the unprepared US and European opponents left Japan overconfident, as well as overextended.[188]  In early May 1942, Japan initiated operations to capture Port Moresby by amphibious assault and thus sever communications and supply lines between the United States and Australia. The planned invasion was thwarted when an Allied task force, centred on two American fleet carriers, fought Japanese naval forces to a draw in the Battle of the Coral Sea.[189] Japan's next plan, motivated by the earlier Doolittle Raid, was to seize Midway Atoll and lure American carriers into battle to be eliminated; as a diversion, Japan would also send forces to occupy the Aleutian Islands in Alaska.[190] In mid-May, Japan started the Zhejiang-Jiangxi campaign in China, with the goal of inflicting retribution on the Chinese who aided the surviving American airmen in the Doolittle Raid by destroying Chinese air bases and fighting against the Chinese 23rd and 32nd Army Groups.[191][192] In early June, Japan put its operations into action, but the Americans, having broken Japanese naval codes in late May, were fully aware of the plans and order of battle, and used this knowledge to achieve a decisive victory at Midway over the Imperial Japanese Navy.[193]   US Marines during the Guadalcanal Campaign, in the Pacific theatre, 1942 With its capacity for aggressive action greatly diminished as a result of the Midway battle, Japan chose to focus on a belated attempt to capture Port Moresby by an overland campaign in the Territory of Papua.[194] The Americans planned a counter-attack against Japanese positions in the southern Solomon Islands, primarily Guadalcanal, as a first step towards capturing Rabaul, the main Japanese base in Southeast Asia.[195]  Both plans started in July, but by mid-September, the Battle for Guadalcanal took priority for the Japanese, and troops in New Guinea were ordered to withdraw from the Port Moresby area to the northern part of the island, where they faced Australian and United States troops in the Battle of Buna–Gona.[196] Guadalcanal soon became a focal point for both sides with heavy commitments of troops and ships in the battle for Guadalcanal. By the start of 1943, the Japanese were defeated on the island and withdrew their troops.[197] In Burma, Commonwealth forces mounted two operations. The first, an offensive into the Arakan region in late 1942, went disastrously, forcing a retreat back to India by May 1943.[198] The second was the insertion of irregular forces behind Japanese front-lines in February which, by the end of April, had achieved mixed results.[199]  Eastern Front (1942–43)  Red Army soldiers on the counterattack during the Battle of Stalingrad, February 1943 Despite considerable losses, in early 1942 Germany and its allies stopped a major Soviet offensive in central and southern Russia, keeping most territorial gains they had achieved during the previous year.[200] In May the Germans defeated Soviet offensives in the Kerch Peninsula and at Kharkov,[201] and then launched their main summer offensive against southern Russia in June 1942, to seize the oil fields of the Caucasus and occupy the Kuban steppe, while maintaining positions on the northern and central areas of the front. The Germans split Army Group South into two groups: Army Group A advanced to the lower Don River and struck south-east to the Caucasus, while Army Group B headed towards the Volga River. The Soviets decided to make their stand at Stalingrad on the Volga.[202]  By mid-November, the Germans had nearly taken Stalingrad in bitter street fighting. The Soviets began their second winter counter-offensive, starting with an encirclement of German forces at Stalingrad,[203] and an assault on the Rzhev salient near Moscow, though the latter failed disastrously.[204] By early February 1943, the German Army had taken tremendous losses; German troops at Stalingrad had been defeated,[205] and the front-line had been pushed back beyond its position before the summer offensive. In mid-February, after the Soviet push had tapered off, the Germans launched another attack on Kharkov, creating a salient in their front line around the Soviet city of Kursk.[206]  Western Europe/Atlantic and Mediterranean (1942–43)  American 8th Air Force Boeing B-17 Flying Fortress bombing raid on the Focke-Wulf factory in Germany, 9 October 1943 Exploiting poor American naval command decisions, the German navy ravaged Allied shipping off the American Atlantic coast.[207] By November 1941, Commonwealth forces had launched a counter-offensive, Operation Crusader, in North Africa, and reclaimed all the gains the Germans and Italians had made.[208] In North Africa, the Germans launched an offensive in January, pushing the British back to positions at the Gazala line by early February,[209] followed by a temporary lull in combat which Germany used to prepare for their upcoming offensives.[210] Concerns the Japanese might use bases in Vichy-held Madagascar caused the British to invade the island in early May 1942.[211] An Axis offensive in Libya forced an Allied retreat deep inside Egypt until Axis forces were stopped at El Alamein.[212] On the Continent, raids of Allied commandos on strategic targets, culminating in the disastrous Dieppe Raid,[213] demonstrated the Western Allies' inability to launch an invasion of continental Europe without much better preparation, equipment, and operational security.[214][page needed]  In August 1942, the Allies succeeded in repelling a second attack against El Alamein[215] and, at a high cost, managed to deliver desperately needed supplies to the besieged Malta.[216] A few months later, the Allies commenced an attack of their own in Egypt, dislodging the Axis forces and beginning a drive west across Libya.[217] This attack was followed up shortly after by Anglo-American landings in French North Africa, which resulted in the region joining the Allies.[218] Hitler responded to the French colony's defection by ordering the occupation of Vichy France;[218] although Vichy forces did not resist this violation of the armistice, they managed to scuttle their fleet to prevent its capture by German forces.[218][219] The Axis forces in Africa withdrew into Tunisia, which was conquered by the Allies in May 1943.[218][220]  In June 1943 the British and Americans began a strategic bombing campaign against Germany with a goal to disrupt the war economy, reduce morale, and "de-house" the civilian population.[221] The firebombing of Hamburg was among the first attacks in this campaign, inflicting significant casualties and considerable losses on infrastructure of this important industrial centre.[222]  Allies gain momentum (1943–44)  U.S. Navy SBD-5 scout plane flying patrol over USS Washington and USS Lexington during the Gilbert and Marshall Islands campaign, 1943 After the Guadalcanal Campaign, the Allies initiated several operations against Japan in the Pacific. In May 1943, Canadian and US forces were sent to eliminate Japanese forces from the Aleutians.[223] Soon after, the United States, with support from Australia, New Zealand and Pacific Islander forces, began major ground, sea and air operations to isolate Rabaul by capturing surrounding islands, and breach the Japanese Central Pacific perimeter at the Gilbert and Marshall Islands.[224] By the end of March 1944, the Allies had completed both of these objectives and had also neutralised the major Japanese base at Truk in the Caroline Islands. In April, the Allies launched an operation to retake Western New Guinea.[225]  In the Soviet Union, both the Germans and the Soviets spent the spring and early summer of 1943 preparing for large offensives in central Russia. On 4 July 1943, Germany attacked Soviet forces around the Kursk Bulge. Within a week, German forces had exhausted themselves against the Soviets' deeply echeloned and well-constructed defences,[226] and for the first time in the war Hitler cancelled the operation before it had achieved tactical or operational success.[227] This decision was partially affected by the Western Allies' invasion of Sicily launched on 9 July, which, combined with previous Italian failures, resulted in the ousting and arrest of Mussolini later that month.[228]   Red Army troops in a counter-offensive on German positions at the Battle of Kursk, July 1943 On 12 July 1943, the Soviets launched their own counter-offensives, thereby dispelling any chance of German victory or even stalemate in the east. The Soviet victory at Kursk marked the end of German superiority,[229] giving the Soviet Union the initiative on the Eastern Front.[230][231] The Germans tried to stabilise their eastern front along the hastily fortified Panther–Wotan line, but the Soviets broke through it at Smolensk and by the Lower Dnieper Offensive.[232]  On 3 September 1943, the Western Allies invaded the Italian mainland, following Italy's armistice with the Allies.[233] Germany with the help of fascists responded by disarming Italian forces that were in many places without superior orders, seizing military control of Italian areas,[234] and creating a series of defensive lines.[235] German special forces then rescued Mussolini, who then soon established a new client state in German-occupied Italy named the Italian Social Republic,[236] causing an Italian civil war. The Western Allies fought through several lines until reaching the main German defensive line in mid-November.[237]  German operations in the Atlantic also suffered. By May 1943, as Allied counter-measures became increasingly effective, the resulting sizeable German submarine losses forced a temporary halt of the German Atlantic naval campaign.[238] In November 1943, Franklin D. Roosevelt and Winston Churchill met with Chiang Kai-shek in Cairo and then with Joseph Stalin in Tehran.[239] The former conference determined the post-war return of Japanese territory[240] and the military planning for the Burma campaign,[241] while the latter included agreement that the Western Allies would invade Europe in 1944 and that the Soviet Union would declare war on Japan within three months of Germany's defeat.[242]   Ruins of the Benedictine monastery, during the Battle of Monte Cassino, Italian Campaign, May 1944 From November 1943, during the seven-week Battle of Changde, the Chinese forced Japan to fight a costly war of attrition, while awaiting Allied relief.[243][244][245] In January 1944, the Allies launched a series of attacks in Italy against the line at Monte Cassino and tried to outflank it with landings at Anzio.[246]  On 27 January 1944, Soviet troops launched a major offensive that expelled German forces from the Leningrad region, thereby ending the most lethal siege in history.[247] The following Soviet offensive was halted on the pre-war Estonian border by the German Army Group North aided by Estonians hoping to re-establish national independence. This delay slowed subsequent Soviet operations in the Baltic Sea region.[248] By late May 1944, the Soviets had liberated Crimea, largely expelled Axis forces from Ukraine, and made incursions into Romania, which were repulsed by the Axis troops.[249] The Allied offensives in Italy had succeeded and, at the expense of allowing several German divisions to retreat, on 4 June Rome was captured.[250]  The Allies had mixed success in mainland Asia. In March 1944, the Japanese launched the first of two invasions, an operation against British positions in Assam, India,[251] and soon besieged Commonwealth positions at Imphal and Kohima.[252] In May 1944, British forces mounted a counter-offensive that drove Japanese troops back to Burma by July,[252] and Chinese forces that had invaded northern Burma in late 1943 besieged Japanese troops in Myitkyina.[253] The second Japanese invasion of China aimed to destroy China's main fighting forces, secure railways between Japanese-held territory and capture Allied airfields.[254] By June, the Japanese had conquered the province of Henan and begun a new attack on Changsha.[255]  Allies close in (1944)  American troops approaching Omaha Beach during the invasion of Normandy on D-Day, 6 June 1944 On 6 June 1944 (known as D-Day), after three years of Soviet pressure,[256] the Western Allies invaded northern France. After reassigning several Allied divisions from Italy, they also attacked southern France.[257] These landings were successful and led to the defeat of the German Army units in France. Paris was liberated on 25 August by the local resistance assisted by the Free French Forces, both led by General Charles de Gaulle,[258] and the Western Allies continued to push back German forces in western Europe during the latter part of the year. An attempt to advance into northern Germany spearheaded by a major airborne operation in the Netherlands failed.[259] After that, the Western Allies slowly pushed into Germany, but failed to cross the Rur river in a large offensive. In Italy, Allied advance also slowed due to the last major German defensive line.[260]   German SS soldiers from the Dirlewanger Brigade, tasked with suppressing the Warsaw Uprising against Nazi occupation, August 1944 On 22 June, the Soviets launched a strategic offensive in Belarus ("Operation Bagration") that almost completely destroyed the German Army Group Centre.[261] Soon after that, another Soviet strategic offensive forced German troops from Western Ukraine and Eastern Poland. The Soviets formed the Polish Committee of National Liberation to control territory in Poland and combat the Polish Armia Krajowa; The Soviet Red Army remained in the Praga district on the other side of the Vistula and watched passively as the Germans quelled the Warsaw Uprising initiated by the Armia Krajowa.[262] The national uprising in Slovakia was also quelled by the Germans.[263] The Soviet Red Army's strategic offensive in eastern Romania cut off and destroyed the considerable German troops there and triggered a successful coup d'état in Romania and in Bulgaria, followed by those countries' shift to the Allied side.[264]  In September 1944, Soviet troops advanced into Yugoslavia and forced the rapid withdrawal of German Army Groups E and F in Greece, Albania and Yugoslavia to rescue them from being cut off.[265] By this point, the Communist-led Partisans under Marshal Josip Broz Tito, who had led an increasingly successful guerrilla campaign against the occupation since 1941, controlled much of the territory of Yugoslavia and engaged in delaying efforts against German forces further south. In northern Serbia, the Soviet Red Army, with limited support from Bulgarian forces, assisted the Partisans in a joint liberation of the capital city of Belgrade on 20 October. A few days later, the Soviets launched a massive assault against German-occupied Hungary that lasted until the fall of Budapest in February 1945.[266] Unlike impressive Soviet victories in the Balkans, bitter Finnish resistance to the Soviet offensive in the Karelian Isthmus denied the Soviets occupation of Finland and led to a Soviet-Finnish armistice on relatively mild conditions,[267] although Finland was forced to fight their former ally Germany.[268]   General Douglas MacArthur returns to the Philippines during the Battle of Leyte, 20 October 1944 By the start of July 1944, Commonwealth forces in Southeast Asia had repelled the Japanese sieges in Assam, pushing the Japanese back to the Chindwin River[269] while the Chinese captured Myitkyina. In September 1944, Chinese forces captured Mount Song and reopened the Burma Road.[270] In China, the Japanese had more successes, having finally captured Changsha in mid-June and the city of Hengyang by early August.[271] Soon after, they invaded the province of Guangxi, winning major engagements against Chinese forces at Guilin and Liuzhou by the end of November[272] and successfully linking up their forces in China and Indochina by mid-December.[273]  In the Pacific, US forces continued to press back the Japanese perimeter. In mid-June 1944, they began their offensive against the Mariana and Palau islands and decisively defeated Japanese forces in the Battle of the Philippine Sea. These defeats led to the resignation of the Japanese Prime Minister, Hideki Tojo, and provided the United States with air bases to launch intensive heavy bomber attacks on the Japanese home islands. In late October, American forces invaded the Filipino island of Leyte; soon after, Allied naval forces scored another large victory in the Battle of Leyte Gulf, one of the largest naval battles in history.[274]  Axis collapse, Allied victory (1944–45)  Yalta Conference held in February 1945, with Winston Churchill, Franklin D. Roosevelt and Joseph Stalin On 16 December 1944, Germany made a last attempt on the Western Front by using most of its remaining reserves to launch a massive counter-offensive in the Ardennes and along with the French-German border to split the Western Allies, encircle large portions of Western Allied troops and capture their primary supply port at Antwerp to prompt a political settlement.[275] By January, the offensive had been repulsed with no strategic objectives fulfilled.[275] In Italy, the Western Allies remained stalemated at the German defensive line. In mid-January 1945, the Soviets and Poles attacked in Poland, pushing from the Vistula to the Oder river in Germany, and overran East Prussia.[276] On 4 February Soviet, British, and US leaders met for the Yalta Conference. They agreed on the occupation of post-war Germany, and on when the Soviet Union would join the war against Japan.[277]  In February, the Soviets entered Silesia and Pomerania, while Western Allies entered western Germany and closed to the Rhine river. By March, the Western Allies crossed the Rhine north and south of the Ruhr, encircling the German Army Group B.[278] In early March, in an attempt to protect its last oil reserves in Hungary and to retake Budapest, Germany launched its last major offensive against Soviet troops near Lake Balaton. In two weeks, the offensive had been repulsed, the Soviets advanced to Vienna, and captured the city. In early April, Soviet troops captured Königsberg, while the Western Allies finally pushed forward in Italy and swept across western Germany capturing Hamburg and Nuremberg. American and Soviet forces met at the Elbe river on 25 April, leaving several unoccupied pockets in southern Germany and around Berlin.   The German Reichstag after its capture by the Allied forces, 3 June 1945. Soviet and Polish forces stormed and captured Berlin in late April. In Italy, German forces surrendered on 29 April. On 30 April, the Reichstag was captured, signalling the military defeat of Nazi Germany,[279] Berlin garrison surrendered on 2 May.  Several changes in leadership occurred during this period. On 12 April, President Roosevelt died and was succeeded by Harry S. Truman. Benito Mussolini was killed by Italian partisans on 28 April.[280] Two days later, Hitler committed suicide in besieged Berlin, and he was succeeded by Grand Admiral Karl Dönitz.[281] Total and unconditional surrender in Europe was signed on 7 and 8 May, to be effective by the end of 8 May.[282] German Army Group Centre resisted in Prague until 11 May.[283]  In the Pacific theatre, American forces accompanied by the forces of the Philippine Commonwealth advanced in the Philippines, clearing Leyte by the end of April 1945. They landed on Luzon in January 1945 and recaptured Manila in March. Fighting continued on Luzon, Mindanao, and other islands of the Philippines until the end of the war.[284] Meanwhile, the United States Army Air Forces launched a massive firebombing campaign of strategic cities in Japan in an effort to destroy Japanese war industry and civilian morale. A devastating bombing raid on Tokyo of 9–10 March was the deadliest conventional bombing raid in history.[285]   Atomic bombing of Nagasaki on 9 August 1945. In May 1945, Australian troops landed in Borneo, overrunning the oilfields there. British, American, and Chinese forces defeated the Japanese in northern Burma in March, and the British pushed on to reach Rangoon by 3 May.[286] Chinese forces started a counterattack in the Battle of West Hunan that occurred between 6 April and 7 June 1945. American naval and amphibious forces also moved towards Japan, taking Iwo Jima by March, and Okinawa by the end of June.[287] At the same time, American submarines cut off Japanese imports, drastically reducing Japan's ability to supply its overseas forces.[288]  On 11 July, Allied leaders met in Potsdam, Germany. They confirmed earlier agreements about Germany,[289] and the American, British and Chinese governments reiterated the demand for unconditional surrender of Japan, specifically stating that "the alternative for Japan is prompt and utter destruction".[290] During this conference, the United Kingdom held its general election, and Clement Attlee replaced Churchill as Prime Minister.[291]  The call for unconditional surrender was rejected by the Japanese government, which believed it would be capable of negotiating for more favourable surrender terms.[292] In early August, the United States dropped atomic bombs on the Japanese cities of Hiroshima and Nagasaki. Between the two bombings, the Soviets, pursuant to the Yalta agreement, invaded Japanese-held Manchuria and quickly defeated the Kwantung Army, which was the largest Japanese fighting force.[293] These two events persuaded previously adamant Imperial Army leaders to accept surrender terms.[294] The Red Army also captured the southern part of Sakhalin Island and the Kuril Islands. On 15 August 1945, Japan surrendered, with the surrender documents finally signed at Tokyo Bay on the deck of the American battleship USS Missouri on 2 September 1945, ending the war.[295]  Aftermath Main articles: Aftermath of World War II and Consequences of Nazism  Ruins of Warsaw in January 1945, after the deliberate destruction of the city by the occupying German forces The Allies established occupation administrations in Austria and Germany. The former became a neutral state, non-aligned with any political bloc. The latter was divided into western and eastern occupation zones controlled by the Western Allies and the Soviet Union. A denazification programme in Germany led to the prosecution of Nazi war criminals in the Nuremberg trials and the removal of ex-Nazis from power, although this policy moved towards amnesty and re-integration of ex-Nazis into West German society.[296]  Germany lost a quarter of its pre-war (1937) territory. Among the eastern territories, Silesia, Neumark and most of Pomerania were taken over by Poland,[297] and East Prussia was divided between Poland and the Soviet Union, followed by the expulsion to Germany of the nine million Germans from these provinces,[298][299] as well as three million Germans from the Sudetenland in Czechoslovakia. By the 1950s, one-fifth of West Germans were refugees from the east. The Soviet Union also took over the Polish provinces east of the Curzon line,[300] from which 2 million Poles were expelled;[299][301] north-east Romania,[302][303] parts of eastern Finland,[304] and the three Baltic states were incorporated into the Soviet Union.[305][306]   Defendants at the Nuremberg trials, where the Allied forces prosecuted prominent members of the political, military, judicial and economic leadership of Nazi Germany for crimes against humanity In an effort to maintain world peace,[307] the Allies formed the United Nations, which officially came into existence on 24 October 1945,[308] and adopted the Universal Declaration of Human Rights in 1948 as a common standard for all member nations.[309] The great powers that were the victors of the war—France, China, the United Kingdom, the Soviet Union and the United States—became the permanent members of the UN's Security Council.[310] The five permanent members remain so to the present, although there have been two seat changes, between the Republic of China and the People's Republic of China in 1971, and between the Soviet Union and its successor state, the Russian Federation, following the dissolution of the Soviet Union in 1991. The alliance between the Western Allies and the Soviet Union had begun to deteriorate even before the war was over.[311]   Post-war border changes in Central Europe and creation of the Communist Eastern Bloc Germany had been de facto divided, and two independent states, the Federal Republic of Germany (West Germany) and the German Democratic Republic (East Germany),[312] were created within the borders of Allied and Soviet occupation zones. The rest of Europe was also divided into Western and Soviet spheres of influence.[313] Most eastern and central European countries fell into the Soviet sphere, which led to establishment of Communist-led regimes, with full or partial support of the Soviet occupation authorities. As a result, East Germany,[314] Poland, Hungary, Romania, Czechoslovakia, and Albania[315] became Soviet satellite states. Communist Yugoslavia conducted a fully independent policy, causing tension with the Soviet Union.[316]  Post-war division of the world was formalised by two international military alliances, the United States-led NATO and the Soviet-led Warsaw Pact.[317] The long period of political tensions and military competition between them, the Cold War, would be accompanied by an unprecedented arms race and number of proxy wars throughout the world.[318]  In Asia, the United States led the occupation of Japan and administered Japan's former islands in the Western Pacific, while the Soviets annexed South Sakhalin and the Kuril Islands.[319] Korea, formerly under Japanese rule, was divided and occupied by the Soviet Union in the North and the United States in the South between 1945 and 1948. Separate republics emerged on both sides of the 38th parallel in 1948, each claiming to be the legitimate government for all of Korea, which led ultimately to the Korean War.[320]   David Ben-Gurion proclaiming the Israeli Declaration of Independence at the Independence Hall, 14 May 1948 In China, nationalist and communist forces resumed the civil war in June 1946. Communist forces were victorious and established the People's Republic of China on the mainland, while nationalist forces retreated to Taiwan in 1949.[321] In the Middle East, the Arab rejection of the United Nations Partition Plan for Palestine and the creation of Israel marked the escalation of the Arab–Israeli conflict. While European powers attempted to retain some or all of their colonial empires, their losses of prestige and resources during the war rendered this unsuccessful, leading to decolonisation.[322][323]  The global economy suffered heavily from the war, although participating nations were affected differently. The United States emerged much richer than any other nation, leading to a baby boom, and by 1950 its gross domestic product per person was much higher than that of any of the other powers, and it dominated the world economy.[324] The UK and US pursued a policy of industrial disarmament in Western Germany in the years 1945–1948.[325] Because of international trade interdependencies this led to European economic stagnation and delayed European recovery for several years.[326][327]  Recovery began with the mid-1948 currency reform in Western Germany, and was sped up by the liberalisation of European economic policy that the Marshall Plan (1948–1951) both directly and indirectly caused.[328][329] The post-1948 West German recovery has been called the German economic miracle.[330] Italy also experienced an economic boom[331] and the French economy rebounded.[332] By contrast, the United Kingdom was in a state of economic ruin,[333] and although receiving a quarter of the total Marshall Plan assistance, more than any other European country,[334] it continued in relative economic decline for decades.[335]  The Soviet Union, despite enormous human and material losses, also experienced rapid increase in production in the immediate post-war era.[336] Japan recovered much later.[337] China returned to its pre-war industrial production by 1952.[338]  Impact Main article: Historiography of World War II Casualties and war crimes Main articles: World War II casualties and List of war crimes committed during World War II  World War II deaths Estimates for the total number of casualties in the war vary, because many deaths went unrecorded.[339] Most suggest that some 60 million people died in the war, including about 20 million military personnel and 40 million civilians.[340][341][342] Many of the civilians died because of deliberate genocide, massacres, mass bombings, disease, and starvation.  The Soviet Union alone lost around 27 million people during the war,[343] including 8.7 million military and 19 million civilian deaths.[344] A quarter of the total people in the Soviet Union were wounded or killed.[345] Germany sustained 5.3 million military losses, mostly on the Eastern Front and during the final battles in Germany.[346]  An estimated 11[347] to 17 million[348] civilians died as a direct or as an indirect result of Hitler's racist policies, including mass killing of around 6 million Jews, along with Roma, homosexuals, at least 1.9 million ethnic Poles[349][350] and millions of other Slavs (including Russians, Ukrainians and Belarusians), and other ethnic and minority groups.[351][348] Between 1941 and 1945, more than 200,000 ethnic Serbs, along with gypsies and Jews, were persecuted and murdered by the Axis-aligned Croatian Ustaše in Yugoslavia.[352] Concurrently, Muslims and Croats were persecuted and killed by Serb nationalist Chetniks,[353] with an estimated 50,000-68,000 victims (of which 41,000 were civilians).[354] Also, more than 100,000 Poles were massacred by the Ukrainian Insurgent Army in the Volhynia massacres, between 1943 and 1945.[355] At the same time, about 10,000–15,000 Ukrainians were killed by the Polish Home Army and other Polish units, in reprisal attacks.[356]   Chinese civilians being buried alive by soldiers of the Imperial Japanese Army, during the Nanking Massacre, December 1937 In Asia and the Pacific, between 3 million and more than 10 million civilians, mostly Chinese (estimated at 7.5 million[357]), were killed by the Japanese occupation forces.[358] The most infamous Japanese atrocity was the Nanking Massacre, in which fifty to three hundred thousand Chinese civilians were raped and murdered.[359] Mitsuyoshi Himeta reported that 2.7 million casualties occurred during the Sankō Sakusen. General Yasuji Okamura implemented the policy in Heipei and Shantung.[360]  Axis forces employed biological and chemical weapons. The Imperial Japanese Army used a variety of such weapons during its invasion and occupation of China (see Unit 731)[361][362] and in early conflicts against the Soviets.[363] Both the Germans and the Japanese tested such weapons against civilians,[364] and sometimes on prisoners of war.[365]  The Soviet Union was responsible for the Katyn massacre of 22,000 Polish officers,[366] and the imprisonment or execution of thousands of political prisoners by the NKVD, along with mass civilian deportations to Siberia, in the Baltic states and eastern Poland annexed by the Red Army.[367]  The mass bombing of cities in Europe and Asia has often been called a war crime, although no positive or specific customary international humanitarian law with respect to aerial warfare existed before or during World War II.[368] The USAAF firebombed a total of 67 Japanese cities, killing 393,000 civilians and destroying 65% of built-up areas.[369]  Genocide, concentration camps, and slave labour Main articles: Genocide, The Holocaust, Nazi concentration camps, Extermination camp, Forced labour under German rule during World War II, Kidnapping of children by Nazi Germany, and Nazi human experimentation  Schutzstaffel (SS) female camp guards removing prisoners' bodies from lorries and carrying them to a mass grave, inside the German Bergen-Belsen concentration camp, 1945 Nazi Germany, under the dictatorship of Adolf Hitler, was responsible for the Holocaust (which killed approximately 6 million Jews) as well as for killing 2.7 million ethnic Poles[370] and 4 million others who were deemed "unworthy of life" (including the disabled and mentally ill, Soviet prisoners of war, Romani, homosexuals, Freemasons, and Jehovah's Witnesses) as part of a programme of deliberate extermination, in effect becoming a "genocidal state".[371] Soviet POWs were kept in especially unbearable conditions, and 3.6 million Soviet POWs out of 5.7 million died in Nazi camps during the war.[372][373] In addition to concentration camps, death camps were created in Nazi Germany to exterminate people on an industrial scale. Nazi Germany extensively used forced labourers; about 12 million Europeans from German-occupied countries were abducted and used as a slave work force in German industry, agriculture and war economy.[374]  The Soviet Gulag became a de facto system of deadly camps during 1942–43, when wartime privation and hunger caused numerous deaths of inmates,[375] including foreign citizens of Poland and other countries occupied in 1939–40 by the Soviet Union, as well as Axis POWs.[376] By the end of the war, most Soviet POWs liberated from Nazi camps and many repatriated civilians were detained in special filtration camps where they were subjected to NKVD evaluation, and 226,127 were sent to the Gulag as real or perceived Nazi collaborators.[377]   Prisoner identity photograph taken by the German SS of a Polish girl deported to Auschwitz. Approximately 230,000 children were held prisoner and used in forced labour and medical experiments. Japanese prisoner-of-war camps, many of which were used as labour camps, also had high death rates. The International Military Tribunal for the Far East found the death rate of Western prisoners was 27 per cent (for American POWs, 37 per cent),[378] seven times that of POWs under the Germans and Italians.[379] While 37,583 prisoners from the UK, 28,500 from the Netherlands, and 14,473 from the United States were released after the surrender of Japan, the number of Chinese released was only 56.[380]  At least five million Chinese civilians from northern China and Manchukuo were enslaved between 1935 and 1941 by the East Asia Development Board, or Kōain, for work in mines and war industries. After 1942, the number reached 10 million.[381] In Java, between 4 and 10 million rōmusha (Japanese: "manual labourers"), were forced to work by the Japanese military. About 270,000 of these Javanese labourers were sent to other Japanese-held areas in South East Asia, and only 52,000 were repatriated to Java.[382]  Occupation Main articles: German-occupied Europe, Resistance during World War II, Collaboration with the Axis Powers, and Nazi plunder  Polish civilians wearing blindfolds photographed just before their execution by German soldiers in Palmiry forest, 1940 In Europe, occupation came under two forms. In Western, Northern, and Central Europe (France, Norway, Denmark, the Low Countries, and the annexed portions of Czechoslovakia) Germany established economic policies through which it collected roughly 69.5 billion reichsmarks (27.8 billion US dollars) by the end of the war; this figure does not include the sizeable plunder of industrial products, military equipment, raw materials and other goods.[383] Thus, the income from occupied nations was over 40 percent of the income Germany collected from taxation, a figure which increased to nearly 40 percent of total German income as the war went on.[384]   Soviet partisans hanged by the German army. The Russian Academy of Sciences reported in 1995 civilian victims in the Soviet Union at German hands totalled 13.7 million dead, twenty percent of the 68 million persons in the occupied Soviet Union. In the East, the intended gains of Lebensraum were never attained as fluctuating front-lines and Soviet scorched earth policies denied resources to the German invaders.[385] Unlike in the West, the Nazi racial policy encouraged extreme brutality against what it considered to be the "inferior people" of Slavic descent; most German advances were thus followed by mass executions.[386] Although resistance groups formed in most occupied territories, they did not significantly hamper German operations in either the East[387] or the West[388] until late 1943.  In Asia, Japan termed nations under its occupation as being part of the Greater East Asia Co-Prosperity Sphere, essentially a Japanese hegemony which it claimed was for purposes of liberating colonised peoples.[389] Although Japanese forces were sometimes welcomed as liberators from European domination, Japanese war crimes frequently turned local public opinion against them.[390] During Japan's initial conquest, it captured 4,000,000 barrels (640,000 m3) of oil (~5.5×105 tonnes) left behind by retreating Allied forces; and by 1943, was able to get production in the Dutch East Indies up to 50 million barrels (~6.8×106 t), 76 per cent of its 1940 output rate.[390]  Home fronts and production Main articles: Military production during World War II and Home front during World War II Allies to Axis GDP ratio between 1938 and 1945 In Europe, before the outbreak of the war, the Allies had significant advantages in both population and economics. In 1938, the Western Allies (United Kingdom, France, Poland and the British Dominions) had a 30 percent larger population and a 30 percent higher gross domestic product than the European Axis powers (Germany and Italy); if colonies are included, the Allies had more than a 5:1 advantage in population and a nearly 2:1 advantage in GDP.[391] In Asia at the same time, China had roughly six times the population of Japan but only an 89 percent higher GDP; this is reduced to three times the population and only a 38 percent higher GDP if Japanese colonies are included.[391]  The United States produced about two-thirds of all the munitions used by the Allies in WWII, including warships, transports, warplanes, artillery, tanks, trucks, and ammunition.[392] Though the Allies' economic and population advantages were largely mitigated during the initial rapid blitzkrieg attacks of Germany and Japan, they became the decisive factor by 1942, after the United States and Soviet Union joined the Allies, as the war largely settled into one of attrition.[393] While the Allies' ability to out-produce the Axis is often attributed[by whom?] to the Allies having more access to natural resources, other factors, such as Germany and Japan's reluctance to employ women in the labour force,[394] Allied strategic bombing,[395] and Germany's late shift to a war economy[396] contributed significantly. Additionally, neither Germany nor Japan planned to fight a protracted war, and had not equipped themselves to do so.[397] To improve their production, Germany and Japan used millions of slave labourers;[398] Germany used about 12 million people, mostly from Eastern Europe,[374] while Japan used more than 18 million people in Far East Asia.[381][382]  Advances in technology and warfare Main article: Technology during World War II  B-29 Superfortress strategic bombers on the Boeing assembly line in Wichita, Kansas, 1944 Aircraft were used for reconnaissance, as fighters, bombers, and ground-support, and each role was advanced considerably. Innovation included airlift (the capability to quickly move limited high-priority supplies, equipment, and personnel);[399] and of strategic bombing (the bombing of enemy industrial and population centres to destroy the enemy's ability to wage war).[400] Anti-aircraft weaponry also advanced, including defences such as radar and surface-to-air artillery. The use of the jet aircraft was pioneered and, though late introduction meant it had little impact, it led to jets becoming standard in air forces worldwide.[401] Although guided missiles were being developed, they were not advanced enough to reliably target aircraft until some years after the war.  Advances were made in nearly every aspect of naval warfare, most notably with aircraft carriers and submarines. Although aeronautical warfare had relatively little success at the start of the war, actions at Taranto, Pearl Harbor, and the Coral Sea established the carrier as the dominant capital ship in place of the battleship.[402][403][404] In the Atlantic, escort carriers proved to be a vital part of Allied convoys, increasing the effective protection radius and helping to close the Mid-Atlantic gap.[405] Carriers were also more economical than battleships because of the relatively low cost of aircraft[406] and their not requiring to be as heavily armoured.[407] Submarines, which had proved to be an effective weapon during the First World War,[408] were anticipated by all sides to be important in the second. The British focused development on anti-submarine weaponry and tactics, such as sonar and convoys, while Germany focused on improving its offensive capability, with designs such as the Type VII submarine and wolfpack tactics.[409][better source needed] Gradually, improving Allied technologies such as the Leigh light, hedgehog, squid, and homing torpedoes proved victorious over the German submarines.[410]   A V-2 rocket launched from a fixed site in Peenemünde, 21 June 1943 Land warfare changed from the static front lines of trench warfare of World War I, which had relied on improved artillery that outmatched the speed of both infantry and cavalry, to increased mobility and combined arms. The tank, which had been used predominantly for infantry support in the First World War, had evolved into the primary weapon.[411] In the late 1930s, tank design was considerably more advanced than it had been during World War I,[412] and advances continued throughout the war with increases in speed, armour and firepower.[citation needed] At the start of the war, most commanders thought enemy tanks should be met by tanks with superior specifications.[413] This idea was challenged by the poor performance of the relatively light early tank guns against armour, and German doctrine of avoiding tank-versus-tank combat. This, along with Germany's use of combined arms, were among the key elements of their highly successful blitzkrieg tactics across Poland and France.[411] Many means of destroying tanks, including indirect artillery, anti-tank guns (both towed and self-propelled), mines, short-ranged infantry antitank weapons, and other tanks were used.[413] Even with large-scale mechanisation, infantry remained the backbone of all forces,[414] and throughout the war, most infantry were equipped similarly to World War I.[415] The portable machine gun spread, a notable example being the German MG34, and various submachine guns which were suited to close combat in urban and jungle settings.[415] The assault rifle, a late war development incorporating many features of the rifle and submachine gun, became the standard postwar infantry weapon for most armed forces.[416]   Nuclear Gadget being raised to the top of the detonation "shot tower", at Alamogordo Bombing Range; Trinity nuclear test, New Mexico, July 1945 Most major belligerents attempted to solve the problems of complexity and security involved in using large codebooks for cryptography by designing ciphering machines, the most well known being the German Enigma machine.[417] Development of SIGINT (signals intelligence) and cryptanalysis enabled the countering process of decryption. Notable examples were the Allied decryption of Japanese naval codes[418] and British Ultra, a pioneering method for decoding Enigma benefiting from information given to the United Kingdom by the Polish Cipher Bureau, which had been decoding early versions of Enigma before the war.[419] Another aspect of military intelligence was the use of deception, which the Allies used to great effect, such as in operations Mincemeat and Bodyguard.[418][420]  Other technological and engineering feats achieved during, or as a result of, the war include the world's first programmable computers (Z3, Colossus, and ENIAC), guided missiles and modern rockets, the Manhattan Project's development of nuclear weapons, operations research and the development of artificial harbours and oil pipelines under the English Channel.[citation needed] Penicillin was first mass-produced and used during the war (see Stabilization and mass production of penicillin).[421]  See also 	World War II portal 	War portal Index of World War II articles Lists of World War II topics Outline of World War II Notes  While various other dates have been proposed as the date on which World War II began or ended, this is the time span most frequently cited. Citations  Weinberg 2005, p. 6.  Wells, Anne Sharp (2014) Historical Dictionary of World War II: The War against Germany and Italy. Rowman & Littlefield Publishing. p. 7.  Ferris, John; Mawdsley, Evan (2015). The Cambridge History of the Second World War, Volume I: Fighting the War. Cambridge: Cambridge University Press.  Förster & Gessler 2005, p. 64.  Ghuhl, Wernar (2007) Imperial Japan's World War Two Transaction Publishers pp. 7, 30  Polmar, Norman; Thomas B. Allen (1991) World War II: America at war, 1941–1945 ISBN 978-0-394-58530-7  Seagrave, Sterling (5 February 2007). "post Feb 5 2007, 03:15 PM". The Education Forum. Archived from the original on 13 June 2008. Retrieved 13 June 2008. Americans think of WW2 in Asia as having begun with Pearl Harbor, the British with the fall of Singapore, and so forth. The Chinese would correct this by identifying the Marco Polo Bridge incident as the start, or the Japanese seizure of Manchuria earlier.  Ben-Horin 1943, p. 169; Taylor 1979, p. 124; Yisreelit, Hevrah Mizrahit (1965). Asian and African Studies, p. 191. For 1941 see Taylor 1961, p. vii; Kellogg, William O (2003). American History the Easy Way. Barron's Educational Series. p. 236 ISBN 0-7641-1973-7. There is also the viewpoint that both World War I and World War II are part of the same "European Civil War" or "Second Thirty Years War": Canfora 2006, p. 155; Prins 2002, p. 11.  Beevor 2012, p. 10.  "In Many Ways, Author Says, Spanish Civil War Was 'The First Battle Of WWII'". NPR.org.  Frank, Willard C. (1987). "The Spanish Civil War and the Coming of the Second World War". The International History Review. 9 (3): 368–409. doi:10.1080/07075332.1987.9640449. JSTOR 40105814 – via JSTOR.  Masaya 1990, p. 4.  "History of German-American Relations » 1989–1994 – Reunification » "Two-plus-Four-Treaty": Treaty on the Final Settlement with Respect to Germany, September 12, 1990". usa.usembassy.de. Archived from the original on 7 May 2012. Retrieved 6 May 2012.  Why Japan and Russia never signed a WWII peace treaty Archived 4 June 2018 at the Wayback Machine. Asia Times.  Texts of Soviet–Japanese Statements; Peace Declaration Trade Protocol. New York Times, page 2, October 20, 1956. Subtitle: "Moscow, October 19. (UP) – Following are the texts of a Soviet–Japanese peace declaration and of a trade protocol between the two countries, signed here today, in unofficial translation from the Russian". Quote: "The state of war between the U.S.S.R. and Japan ends on the day the present declaration enters into force [...]"  Ingram 2006, pp. 76–78.  Kantowicz 1999, p. 149.  Shaw 2000, p. 35.  Brody 1999, p. 4.  Zalampas 1989, p. 62.  Mandelbaum 1988, p. 96; Record 2005, p. 50.  Schmitz 2000, p. 124.  Adamthwaite 1992, p. 52.  Shirer 1990, pp. 298–99.  Preston 1998, p. 104.  Myers & Peattie 1987, p. 458.  Smith & Steadman 2004, p. 28.  Coogan 1993: "Although some Chinese troops in the Northeast managed to retreat south, others were trapped by the advancing Japanese Army and were faced with the choice of resistance in defiance of orders, or surrender. A few commanders submitted, receiving high office in the puppet government, but others took up arms against the invader. The forces they commanded were the first of the volunteer armies."  Busky 2002, p. 10.  Andrea L. Stanton; Edward Ramsamy; Peter J. Seybolt (2012). Cultural Sociology of the Middle East, Asia, and Africa: An Encyclopedia. p. 308. ISBN 978-1-4129-8176-7. Archived from the original on 18 August 2018. Retrieved 6 April 2014.  Barker 1971, pp. 131–32.  Shirer 1990, p. 289.  Kitson 2001, p. 231.  Neulen 2000, p. 25.  Payne 2008, p. 271.  Payne 2008, p. 146.  Eastman 1986, pp. 547–51.  Hsu & Chang 1971, pp. 195–200.  Tucker, Spencer C. (2009). A Global Chronology of Conflict: From the Ancient World to the Modern Middle East [6 volumes]: From the Ancient World to the Modern Middle East. ABC-CLIO. ISBN 978-1-85109-672-5. Archived from the original on 18 August 2018. Retrieved 27 August 2017 – via Google Books.  Yang Kuisong, "On the reconstruction of the facts of the Battle of Pingxingguan"  Levene, Mark and Roberts, Penny. The Massacre in History. 1999, pp. 223–24  Totten, Samuel. Dictionary of Genocide. 2008, 298–99.  Hsu & Chang 1971, pp. 221–30.  Eastman 1986, p. 566.  Taylor 2009, pp. 150–52.  Sella 1983, pp. 651–87.  Beevor 2012, p. 342.  Goldman, Stuart D. (28 August 2012). "The Forgotten Soviet-Japanese War of 1939". The Diplomat. Archived from the original on 29 June 2015. Retrieved 26 June 2015.  Timothy Neeno. "Nomonhan: The Second Russo-Japanese War". MilitaryHistoryOnline.com. Archived from the original on 24 November 2005. Retrieved 26 June 2015.  Collier & Pedley 2000, p. 144.  Kershaw 2001, pp. 121–22.  Kershaw 2001, p. 157.  Davies 2006, pp. 143–44 (2008 ed.).  Shirer 1990, pp. 461–62.  Lowe & Marzari 2002, p. 330.  Dear & Foot 2001, p. 234.  Shirer 1990, p. 471.  Watson, Derek (2000). "Molotov's Apprenticeship in Foreign Policy: The Triple Alliance Negotiations in 1939". Europe-Asia Studies. 52 (4): 695–722. doi:10.1080/713663077. JSTOR 153322. S2CID 144385167.  Shore 2003, p. 108.  Dear & Foot 2001, p. 608.  "The German Campaign In Poland (1939)". Archived from the original on 24 May 2014. Retrieved 29 October 2014.  "The Danzig Crisis". ww2db.com. Archived from the original on 5 May 2016. Retrieved 29 April 2016.  "Major international events of 1939, with explanation". Ibiblio.org. Archived from the original on 10 March 2013. Retrieved 9 May 2013.  Evans 2008, pp. 1–2.  David T. Zabecki (1 May 2015). World War II in Europe: An Encyclopedia. Routledge. p. 1663. ISBN 978-1-135-81242-3. The earliest fighting started at 0445 hours when marines from the battleship Schleswig-Holstein attempted to storm a small Polish fort in Danzig, the Westerplate  The UK declared war on Germany at 11 AM. France followed 6 hours later at 5 PM.  Keegan 1997, p. 35. Cienciala 2010, p. 128, observes that, while it is true that Poland was far away, making it difficult for the French and British to provide support, "[f]ew Western historians of World War II ... know that the British had committed to bomb Germany if it attacked Poland, but did not do so except for one raid on the base of Wilhelmshaven. The French, who committed to attacking Germany in the west, had no intention of doing so."  Beevor 2012, p. 32; Dear & Foot 2001, pp. 248–49; Roskill 1954, p. 64.  James Bjorkman, New Hope for Allied Shipping Archived 18 December 2018 at the Wayback Machine, Retrieved 17 December 2018.  Zaloga 2002, pp. 80, 83.  Ginsburgs, George (1958). "A Case Study in the Soviet Use of International Law: Eastern Poland in 1939". The American Journal of International Law. 52 (1): 69–84. doi:10.2307/2195670. JSTOR 2195670.  Hempel 2005, p. 24.  Zaloga 2002, pp. 88–89.  Nuremberg Documents C-62/GB86, a directive from Hitler in October 1939 which concludes: "The attack [on France] is to be launched this Autumn if conditions are at all possible."  Liddell Hart 1977, pp. 39–40.  Bullock 1990, pp. 563–64, 566, 568–69, 574–75 (1983 ed.).  Blitzkrieg: From the Rise of Hitler to the Fall of Dunkirk, L Deighton, Jonathan Cape, 1993, pp. 186–87. Deighton states that "the offensive was postponed twenty-nine times before it finally took place."  Smith et al. 2002, p. 24.  Bilinsky 1999, p. 9.  Murray & Millett 2001, pp. 55–56.  Spring 1986, pp. 207–26.  Carl van Dyke. The Soviet Invasion of Finland. Frank Cass Publishers, Portland, OR. ISBN 0-7146-4753-5, p. 71.  Hanhimäki 1997, p. 12.  Ferguson 2006, pp. 367, 376, 379, 417.  Snyder 2010, p. 118ff.  Koch 1983, pp. 912–14, 917–20.  Roberts 2006, p. 56.  Roberts 2006, p. 59.  Murray & Millett 2001, pp. 57–63.  Commager 2004, p. 9.  Reynolds 2006, p. 76.  Evans 2008, pp. 122–23.  Keegan 1997, pp. 59–60.  Regan 2004, p. 152.  Liddell Hart 1977, p. 48.  Keegan 1997, pp. 66–67.  Overy & Wheatcroft 1999, p. 207.  Umbreit 1991, p. 311.  Brown 2004, p. 198.  Keegan 1997, p. 72.  Murray 1983, The Battle of Britain.  "Major international events of 1940, with explanation". Ibiblio.org. Archived from the original on 25 May 2013.  Dear & Foot 2001, pp. 108–09.  Goldstein 2004, p. 35  Steury 1987, p. 209; Zetterling & Tamelander 2009, p. 282.  Overy & Wheatcroft 1999, pp. 328–30.  Maingot 1994, p. 52.  Cantril 1940, p. 390.  Skinner Watson, Mark. "Coordination With Britain". US Army in WWII – Chief of Staff: Prewar Plans and Operations. Archived from the original on 30 April 2013. Retrieved 13 May 2013.  Bilhartz & Elliott 2007, p. 179.  Dear & Foot 2001, p. 877.  Dear & Foot 2001, pp. 745–46.  Clogg 2002, p. 118.  Evans 2008, pp. 146, 152; US Army 1986, pp. 4–6  Jowett 2001, pp. 9–10.  Jackson 2006, p. 106.  Laurier 2001, pp. 7–8.  Murray & Millett 2001, pp. 263–76.  Gilbert 1989, pp. 174–75.  Gilbert 1989, pp. 184–87.  Gilbert 1989, pp. 208, 575, 604.  Watson 2003, p. 80.  Morrisey, Will (24 January 2019), "What Churchill and De Gaulle learned from the Great War", Winston Churchill, Routledge, pp. 119–126, doi:10.4324/9780429027642-6, ISBN 978-0-429-02764-2  Garver 1988, p. 114.  Weinberg 2005, p. 195.  Murray 1983, p. 69.  Shirer 1990, pp. 810–12.  Klooz, Marle; Wiley, Evelyn (1944), Events leading up to World War II – Chronological History, 78th Congress, 2d Session – House Document N. 541, Director: Humphrey, Richard A., Washington: US Government Printing Office, pp. 267–312 (1941), archived from the original on 14 December 2013, retrieved 9 May 2013.  Sella 1978.  Kershaw 2007, pp. 66–69.  Steinberg 1995.  Hauner 1978.  Roberts 1995.  Wilt 1981.  Erickson 2003, pp. 114–37.  Glantz 2001, p. 9.  Farrell 1993.  Keeble 1990, p. 29.  Beevor 2012, p. 220.  Bueno de Mesquita et al. 2003, p. 425.  Kleinfeld 1983.  Jukes 2001, p. 113.  Glantz 2001, p. 26: "By 1 November [the Wehrmacht] had lost fully 20% of its committed strength (686,000 men), up to 2/3 of its ½-million motor vehicles, and 65 percent of its tanks. The German Army High Command (OKH) rated its 136 divisions as equivalent to 83 full-strength divisions."  Reinhardt 1992, p. 227.  Milward 1964.  Rotundo 1986.  Glantz 2001, p. 26.  Deighton, Len (1993). Blood, Tears and Folly. London: Pimlico. p. 479. ISBN 978-0-7126-6226-0.  Beevor 1998, pp. 41–42; Evans 2008, pp. 213–14, notes that "Zhukov had pushed the Germans back where they had launched Operation Typhoon two months before. ... Only Stalin's decision to attack all along the front instead of concentrating his forces in an all-out assault against the retreating German Army Group Centre prevented the disaster from being even worse."  "Peace and War: United States Foreign Policy, 1931-1941". U.S. Department of State Publication (1983): 87–97. 1983.  Maechling, Charles. Pearl Harbor: The First Energy War. History Today. December 2000  Jowett & Andrew 2002, p. 14.  Overy & Wheatcroft 1999, p. 289.  Joes 2004, p. 224.  Fairbank & Goldman 2006, p. 320.  Hsu & Chang 1971, p. 30.  Hsu & Chang 1971, p. 33.  "Japanese Policy and Strategy 1931 – July 1941". US Army in WWII – Strategy and Command: The First Two Years. pp. 45–66. Archived from the original on 6 January 2013. Retrieved 15 May 2013.  Anderson 1975, p. 201.  Evans & Peattie 2012, p. 456.  Coox, Alvin (1985). Nomonhan: Japan against Russia, 1939. Stanford, CA: Stanford University Press. pp. 1046–49. ISBN 978-0-8047-1835-6.  "The decision for War". US Army in WWII – Strategy, and Command: The First Two Years. pp. 113–27. Archived from the original on 25 May 2013. Retrieved 15 May 2013.  "The Showdown With Japan Aug–Dec 1941". US Army in WWII – Strategic Planning for Coalition Warfare. pp. 63–96. Archived from the original on 9 November 2012. Retrieved 15 May 2013.  The United States Replies Archived 29 April 2013 at the Wayback Machine. Investigation of the Pearl Harbor attack.  Painter 2012, p. 26: "The United States cut off oil exports to Japan in the summer of 1941, forcing Japanese leaders to choose between going to war to seize the oil fields of the Netherlands East Indies or giving in to U.S. pressure."  Wood 2007, p. 9, listing various military and diplomatic developments, observes that "the threat to Japan was not purely economic."  Lightbody 2004, p. 125.  Weinberg 2005, p. 310  Dower 1986, p. 5, calls attention to the fact that "the Allied struggle against Japan exposed the racist underpinnings of the European and American colonial structure. Japan did not invade independent countries in southern Asia. It invaded colonial outposts which the Westerners had dominated for generations, taking absolutely for granted their racial and cultural superiority over their Asian subjects." Dower goes on to note that, before the horrors of Japanese occupation made themselves felt, many Asians responded favourably to the victories of the Imperial Japanese forces.  Wood 2007, pp. 11–12.  Wohlstetter 1962, pp. 341–43.  Keegan, John (1989) The Second World War. New York: Viking. pp. 256-57. ISBN 978-0399504341  Dunn 1998, p. 157. According to May 1955, p. 155, Churchill stated: "Russian declaration of war on Japan would be greatly to our advantage, provided, but only provided, that Russians are confident that will not impair their Western Front."  Adolf Hitler's Declaration of War against the United States in Wikisource.  Klooz, Marle; Wiley, Evelyn (1944), Events leading up to World War II – Chronological History, 78th Congress, 2d Session – House Document N. 541, Director: Humphrey, Richard A., Washington: US Government Printing Office, p. 310 (1941), archived from the original on 14 December 2013, retrieved 9 May 2013.  Bosworth & Maiolo 2015, pp. 313–14.  Mingst & Karns 2007, p. 22.  Shirer 1990, p. 904.  "The First Full Dress Debate over Strategic Deployment. Dec 1941 – Jan 1942". US Army in WWII – Strategic Planning for Coalition Warfare. pp. 97–119. Archived from the original on 9 November 2012. Retrieved 16 May 2013.  "The Elimination of the Alternatives. Jul–Aug 1942". US Army in WWII – Strategic Planning for Coalition Warfare. pp. 266–92. Archived from the original on 30 April 2013. Retrieved 16 May 2013.  "Casablanca – Beginning of an Era: January 1943". US Army in WWII – Strategic Planning for Coalition Warfare. pp. 18–42. Archived from the original on 25 May 2013. Retrieved 16 May 2013.  "The Trident Conference – New Patterns: May 1943". US Army in WWII – Strategic Planning for Coalition Warfare. pp. 126–45. Archived from the original on 25 May 2013. Retrieved 16 May 2013.  Beevor 2012, pp. 247–67, 345.  Lewis 1953, p. 529 (Table 11).  Slim 1956, pp. 71–74.  Grove 1995, p. 362.  Ch'i 1992, p. 158.  Perez 1998, p. 145.  Maddox 1992, pp. 111–12.  Salecker 2001, p. 186.  Schoppa 2011, p. 28.  Chevrier & Chomiczewski & Garrigue 2004 Archived 18 August 2018 at the Wayback Machine, p. 19.  Ropp 2000, p. 368.  Weinberg 2005, p. 339.  Gilbert, Adrian (2003). The Encyclopedia of Warfare: From Earliest Times to the Present Day. Globe Pequot. p. 259. ISBN 978-1-59228-027-8. Archived from the original on 19 July 2019. Retrieved 26 June 2019.  Swain 2001, p. 197.  Hane 2001, p. 340.  Marston 2005, p. 111.  Brayley 2002, p. 9.  Glantz 2001, p. 31.  Read 2004, p. 764.  Davies 2006, p. 100 (2008 ed.).  Beevor 1998, pp. 239–65.  Black 2003, p. 119.  Beevor 1998, pp. 383–91.  Erickson 2001, p. 142.  Milner 1990, p. 52.  Beevor 2012, pp. 224–28.  Molinari 2007, p. 91.  Mitcham 2007, p. 31.  Beevor 2012, pp. 380–81.  Rich 1992, p. 178.  Gordon 2004, p. 129.  Neillands 2005.  Keegan 1997, p. 277.  Smith 2002.  Thomas & Andrew 1998, p. 8.  Ross 1997, p. 38.  Bonner & Bonner 2001, p. 24.  Collier 2003, p. 11.  "The Civilians" Archived 5 November 2013 at the Wayback Machine the United States Strategic Bombing Survey Summary Report (European War)  Overy 1995, pp. 119–20.  Thompson & Randall 2008, p. 164.  Kennedy 2001, p. 610.  Rottman 2002, p. 228.  Glantz 1986; Glantz 1989, pp. 149–59.  Kershaw 2001, p. 592.  O'Reilly 2001, p. 32.  Bellamy 2007, p. 595.  O'Reilly 2001, p. 35.  Healy 1992, p. 90.  Glantz 2001, pp. 50–55.  Kolko 1990, p. 45  Mazower 2008, p. 362.  Hart, Hart & Hughes 2000, p. 151.  Blinkhorn 2006, p. 52.  Read & Fisher 2002, p. 129.  Padfield 1998, pp. 335–36.  Kolko 1990, pp. 211, 235, 267–68.  Iriye 1981, p. 154.  Mitter 2014, p. 286.  Polley 2000, p. 148.  Beevor 2012, pp. 268–74.  Ch'i 1992, p. 161.  Hsu & Chang 1971, pp. 412–16, Map 38  Weinberg 2005, pp. 660–61.  Glantz 2002, pp. 327–66.  Glantz 2002, pp. 367–414.  Chubarov 2001, p. 122.  Holland 2008, pp. 169–84; Beevor 2012, pp. 568–73. The weeks after the fall of Rome saw a dramatic upswing in German atrocities in Italy (Mazower 2008, pp. 500–02). The period featured massacres with victims in the hundreds at Civitella (de Grazia & Paggi 1991; Belco 2010), Fosse Ardeatine (Portelli 2003), and Sant'Anna di Stazzema (Gordon 2012, pp. 10–11), and is capped with the Marzabotto massacre.  Lightbody 2004, p. 224.  Zeiler 2004, p. 60.  Beevor 2012, pp. 555–60.  Ch'i 1992, p. 163.  Coble 2003, p. 85.  Rees 2008, pp. 406–07: "Stalin always believed that Britain and America were delaying the second front so that the Soviet Union would bear the brunt of the war."  Weinberg 2005, p. 695.  Badsey 1990, p. 91.  Dear & Foot 2001, p. 562.  Forrest, Evans & Gibbons 2012, p. 191  Zaloga 1996, p. 7: "It was the most calamitous defeat of all the German armed forces in World War II."  Berend 1996, p. 8.  "Slovak National Uprising 1944". Museum of the Slovak National Uprising. Ministry of Foreign and European Affairs of the Slovak Republic. Retrieved 27 April 2020.  "Armistice Negotiations and Soviet Occupation". US Library of Congress. Archived from the original on 30 April 2011. Retrieved 14 November 2009. The coup speeded the Red Army's advance, and the Soviet Union later awarded Michael the Order of Victory for his personal courage in overthrowing Antonescu and putting an end to Romania's war against the Allies. Western historians uniformly point out that the Communists played only a supporting role in the coup; postwar Romanian historians, however, ascribe to the Communists the decisive role in Antonescu's overthrow  Evans 2008, p. 653.  Wiest & Barbier 2002, pp. 65–66.  Wiktor, Christian L (1998). Multilateral Treaty Calendar – 1648–1995. Kluwer Law International. p. 426. ISBN 978-90-411-0584-4.  Shirer 1990, p. 1085.  Marston 2005, p. 120.  全面抗战，战犯前仆后继见阎王 [The war criminals tries to be the first to see their ancestors]. Archived from the original on 3 March 2016. Retrieved 16 March 2013.  Jowett & Andrew 2002, p. 8.  Howard 2004, p. 140.  Drea 2003, p. 54.  Cook & Bewes 1997, p. 305.  Parker 2004, pp. xiii–xiv, 6–8, 68–70, 329–30  Glantz 2001, p. 85.  Beevor 2012, pp. 709–22.  Buchanan 2006, p. 21.  Shepardson 1998.  O'Reilly 2001, p. 244.  Kershaw 2001, p. 823.  Evans 2008, p. 737.  Glantz 1998, p. 24.  Chant, Christopher (1986). The Encyclopedia of Codenames of World War II. Routledge & Kegan Paul. p. 118. ISBN 978-0-7102-0718-0.  Long, Tony (9 March 2011). "March 9, 1945: Burning the Heart Out of the Enemy". Wired. Wired Magazine. Archived from the original on 23 March 2017. Retrieved 22 June 2018. 1945: In the single deadliest air raid of World War II, 330 American B-29s rain incendiary bombs on Tokyo, touching off a firestorm that kills upwards of 100,000 people, burns a quarter of the city to the ground, and leaves a million homeless.  Drea 2003, p. 57.  Jowett & Andrew 2002, p. 6.  Poirier, Michel Thomas (20 October 1999). "Results of the German and American Submarine Campaigns of World War II". U.S. Navy. Archived from the original on 9 April 2008. Retrieved 13 April 2008.  Williams 2006, p. 90.  Miscamble 2007, p. 201.  Miscamble 2007, pp. 203–04.  Ward Wilson. "The Winning Weapon? Rethinking Nuclear Weapons in Light of Hiroshima". International Security, Vol. 31, No. 4 (Spring 2007), pp. 162–79.  Glantz 2005.  Pape 1993 " The principal cause of Japan's surrender was the ability of the United States to increase the military vulnerability of Japan's home islands, persuading Japanese leaders that defense of the homeland was highly unlikely to succeed. The key military factor causing this effect was the sea blockade, which crippled Japan's ability to produce and equip the forces necessary to execute its strategy. The most important factor accounting for the timing of surrender was the Soviet attack against Manchuria, largely because it persuaded previously adamant Army leaders that the homeland could not be defended.".  Beevor 2012, p. 776.  Frei 2002, pp. 41–66.  Eberhardt, Piotr (2015). "The Oder-Neisse Line as Poland's western border: As postulated and made a reality". Geographia Polonica. 88 (1): 77–105. doi:10.7163/GPol.0007. Archived from the original on 3 May 2018. Retrieved 3 May 2018.  Eberhardt, Piotr (2006). Political Migrations in Poland 1939–1948 (PDF). Warsaw: Didactica. ISBN 978-1-5361-1035-7. Archived from the original (PDF) on 26 June 2015.  Eberhardt, Piotr (2011). Political Migrations On Polish Territories (1939-1950) (PDF). Warsaw: Polish Academy of Sciences. ISBN 978-83-61590-46-0. Archived (PDF) from the original on 20 May 2014. Retrieved 3 May 2018.  Eberhardt, Piotr (2012). "The Curzon line as the eastern boundary of Poland. The origins and the political background". Geographia Polonica. 85 (1): 5–21. doi:10.7163/GPol.2012.1.1. Archived from the original on 3 May 2018. Retrieved 3 May 2018.  Roberts 2006, p. 43.  Roberts 2006, p. 55.  Shirer 1990, p. 794.  Kennedy-Pipe 1995.  Wettig 2008, pp. 20–21.  Senn 2007, p. ?.  Yoder 1997, p. 39.  "History of the UN". United Nations. Archived from the original on 18 February 2010. Retrieved 25 January 2010.  Waltz 2002. The UDHR is viewable here [1] Archived 3 July 2017 at the Wayback Machine.  The UN Security Council, archived from the original on 20 June 2012, retrieved 15 May 2012  Kantowicz 2000, p. 6.  Wettig 2008, pp. 96–100.  Trachtenberg 1999, p. 33.  Applebaum 2012.  Naimark 2010.  Swain 1992.  Borstelmann 2005, p. 318.  Leffler & Westad 2010.  Weinberg 2005, p. 911.  Stueck 2010, p. 71.  Lynch 2010, pp. 12–13.  Roberts 1997, p. 589.  Darwin 2007, pp. 441–43, 464–68.  Dear & Foot 2001, p. 1006; Harrison 1998, pp. 34–55.  Balabkins 1964, p. 207.  Petrov 1967, p. 263.  Balabkins 1964, pp. 208, 209.  DeLong & Eichengreen 1993, pp. 190, 191  Balabkins 1964, p. 212.  Wolf 1993, pp. 29, 30, 32  Bull & Newell 2005, pp. 20, 21  Ritchie 1992, p. 23.  Minford 1993, p. 117.  Schain 2001.  Emadi-Coffin 2002, p. 64.  Smith 1993, p. 32.  Neary 1992, p. 49.  Genzberger, Christine (1994). China Business: The Portable Encyclopedia for Doing Business with China. Petaluma, CA: World Trade Press. p. 4. ISBN 978-0-9631864-3-0.  Quick Reference Handbook Set, Basic Knowledge and Modern Technology (revised) by Edward H. Litchfield, Ph.D 1984 page 195  O'Brien, Prof. Joseph V. "World War II: Combatants and Casualties (1937–1945)". Obee's History Page. John Jay College of Criminal Justice. Archived from the original on 25 December 2010. Retrieved 28 December 2013.  White, Matthew. "Source List and Detailed Death Tolls for the Twentieth Century Hemoclysm". Historical Atlas of the Twentieth Century. Matthew White's Homepage. Archived from the original on 7 March 2011. Retrieved 20 April 2007.  "World War II Fatalities". secondworldwar.co.uk. Archived from the original on 22 September 2008. Retrieved 20 April 2007.  Hosking 2006, p. 242  Ellman & Maksudov 1994.  Smith 1994, p. 204.  Herf 2003.  Florida Center for Instructional Technology (2005). "Victims". A Teacher's Guide to the Holocaust. University of South Florida. Archived from the original on 16 May 2016. Retrieved 2 February 2008.  Niewyk & Nicosia 2000, pp. 45–52.  Snyder, Timothy (16 July 2009). "Holocaust: The Ignored Reality". The New York Review of Books. Archived from the original on 10 October 2017. Retrieved 27 August 2017.  "Polish Victims". www.ushmm.org. Archived from the original on 7 May 2016. Retrieved 27 August 2017.  "Non-Jewish Holocaust Victims : The 5,000,000 others". BBC. April 2006. Archived from the original on 3 March 2013. Retrieved 4 August 2013.  Evans 2008, pp. 158–60, 234–36.  Redžić, Enver (2005). Bosnia and Herzegovina in the Second World War. New York: Tylor and Francis. p. 155. ISBN 978-0714656250.  Geiger, Vladimir (2012). "Human Losses of the Croats in World War II and the Immediate Post-War Period Caused by the Chetniks (Yugoslav Army in the Fatherand) and the Partisans (People's Liberation Army and the Partisan Detachments of Yugoslavia/Yugoslav Army) and the Communist Authorities: Numerical Indicators". Review of Croatian History. Croatian Institute of History. VIII (1): 117. Archived from the original on 17 November 2015. Retrieved 25 October 2015..  Massacre, Volhynia. "The Effects of the Volhynian Massacres". Volhynia Massacre. Archived from the original on 21 June 2018. Retrieved 9 July 2018.  "Od rzezi wołyńskiej do akcji Wisła. Konflikt polsko-ukraiński 1943–1947". dzieje.pl (in Polish). Archived from the original on 24 June 2018. Retrieved 10 March 2018.  Dear & Foot 2001, p. 290.  Rummell, R.J. "Statistics". Freedom, Democide, War. The University of Hawaii System. Archived from the original on 23 March 2010. Retrieved 25 January 2010.  Chang 1997, p. 102.  Bix 2000, p. ?.  Gold, Hal (1996). Unit 731 testimony. Tuttle. pp. 75–77. ISBN 978-0-8048-3565-7.  Tucker & Roberts 2004, p. 320.  Harris 2002, p. 74.  Lee 2002, p. 69.  "Japan tested chemical weapons on Aussie POW: new evidence". The Japan Times Online. 27 July 2004. Archived from the original on 29 May 2012. Retrieved 25 January 2010.  Kużniar-Plota, Małgorzata (30 November 2004). "Decision to commence investigation into Katyn Massacre". Departmental Commission for the Prosecution of Crimes against the Polish Nation. Retrieved 4 August 2011.  Robert Gellately (2007). Lenin, Stalin, and Hitler: The Age of Social Catastrophe. Knopf, ISBN 1-4000-4005-1 p. 391  Terror from the Sky: The Bombing of German Cities in World War II. Berghahn Books. 2010. p. 167. ISBN 978-1-84545-844-7.  John Dower (2007). "Lessons from Iwo Jima". Perspectives. 45 (6): 54–56. Archived from the original on 17 January 2011. Retrieved 12 January 2014.  Institute of National Remembrance, Polska 1939–1945 Straty osobowe i ofiary represji pod dwiema okupacjami. Materski and Szarota. page 9 "Total Polish population losses under German occupation are currently calculated at about 2 770 000".  (2006). The World Must Know: The History of the Holocaust as Told in the United States Holocaust Memorial Museum (2nd ed.). Washington, DC: United States Holocaust Memorial Museum. ISBN 978-0-8018-8358-3.  Herbert 1994, p. 222  Overy 2004, pp. 568–69.  Marek, Michael (27 October 2005). "Final Compensation Pending for Former Nazi Forced Laborers". dw-world.de. Deutsche Welle. Archived from the original on 2 May 2006. Retrieved 19 January 2010.  J. Arch Getty, Gábor T. Rittersporn and Viktor N. Zemskov. Victims of the Soviet Penal System in the Pre-War Years: A First Approach on the Basisof Archival Evidence. The American Historical Review, Vol. 98, No. 4 (Oct. 1993), pp. 1017–49  Applebaum 2003, pp. 389–96.  Zemskov V.N. On repatriation of Soviet citizens. Istoriya SSSR., 1990, No. 4, (in Russian). See also [2] Archived 14 October 2011 at the Wayback Machine (online version), and Bacon 1992; Ellman 2002.  "Japanese Atrocities in the Philippines". American Experience: the Bataan Rescue. PBS Online. Archived from the original on 27 July 2003. Retrieved 18 January 2010.  Tanaka 1996, pp. 2–3.  Bix 2000, p. 360.  Ju, Zhifen (June 2002). "Japan's atrocities of conscripting and abusing north China draughtees after the outbreak of the Pacific war". Joint Study of the Sino-Japanese War: Minutes of the June 2002 Conference. Harvard University Faculty of Arts and Sciences. Archived from the original on 21 May 2012. Retrieved 28 December 2013.  "Indonesia: World War II and the Struggle For Independence, 1942–50; The Japanese Occupation, 1942–45". Library of Congress. 1992. Archived from the original on 30 October 2004. Retrieved 9 February 2007.  Liberman 1996, p. 42.  Milward 1992, p. 138.  Milward 1992, p. 148.  Barber & Harrison 2006, p. 232.  Hill 2005, p. 5.  Christofferson & Christofferson 2006, p. 156  Radtke 1997, p. 107.  Rahn 2001, p. 266.  Harrison 1998, p. 3.  Compare: Wilson, Mark R. (2016). Destructive Creation: American Business and the Winning of World War II. American Business, Politics, and Society (reprint ed.). Philadelphia: University of Pennsylvania Press. p. 2. ISBN 978-0-8122-9354-8. Retrieved 19 December 2019. By producing nearly two thirds of the munitions used by Allied forces - including huge numbers of aircraft, ships, tanks, trucks, rifles, artillery shells , and bombs - American industry became what President Franklin D. Roosevelt once called 'the arsenal of democracy' [...].  Harrison 1998, p. 2.  Bernstein 1991, p. 267.  Griffith, Charles (1999). The Quest: Haywood Hansell and American Strategic Bombing in World War II. Diane Publishing. p. 203. ISBN 978-1-58566-069-8.  Overy 1994, p. 26.  BBSU 1998, p. 84; Lindberg & Todd 2001, p. 126..  Unidas, Naciones (2005). World Economic And Social Survey 2004: International Migration. United Nations Pubns. p. 23. ISBN 978-92-1-109147-2.  Tucker & Roberts 2004, p. 76.  Levine 1992, p. 227.  Klavans, Di Benedetto & Prudom 1997; Ward 2010, pp. 247–51.  Tucker & Roberts 2004, p. 163.  Bishop, Chris; Chant, Chris (2004). Aircraft Carriers: The World's Greatest Naval Vessels and Their Aircraft. Wigston, Leics: Silverdale Books. p. 7. ISBN 978-1-84509-079-1.  Chenoweth, H. Avery; Nihart, Brooke (2005). Semper Fi: The Definitive Illustrated History of the U.S. Marines. New York: Main Street. p. 180. ISBN 978-1-4027-3099-3.  Sumner & Baker 2001, p. 25.  Hearn 2007, p. 14.  Gardiner & Brown 2004, p. 52.  Burcher & Rydill 1995, p. 15.  Burcher & Rydill 1995, p. 16.  Burns, R.W.: 'Impact of technology on the defeat of the U-boat September 1939-May 1943', IEE Proceedings - Science, Measurement and Technology, 1994, 141, (5), p. 343-355, DOI: 10.1049/ip-smt:19949918 IET Digital Library, https://digital-library.theiet.org/content/journals/10.1049/ip-smt_19949918  Tucker & Roberts 2004, p. 125.  Dupuy, Trevor Nevitt (1982). The Evolution of Weapons and Warfare. Jane's Information Group. p. 231. ISBN 978-0-7106-0123-0.  Tucker & Roberts 2004, p. 108.  Tucker & Roberts 2004, p. 734.  Cowley & Parker 2001, p. 221.  Sprague, Oliver; Griffiths, Hugh (2006). "The AK-47: the worlds favourite killing machine" (PDF). controlarms.org. p. 1. Archived from the original on 28 December 2018. Retrieved 14 November 2009.  Ratcliff 2006, p. 11.  Schoenherr, Steven (2007). "Code Breaking in World War II". History Department at the University of San Diego. Archived from the original on 9 May 2008. Retrieved 15 November 2009.  Macintyre, Ben (10 December 2010). "Bravery of thousands of Poles was vital in securing victory". The Times. London. p. 27.  Rowe, Neil C.; Rothstein, Hy. "Deception for Defense of Information Systems: Analogies from Conventional Warfare". Departments of Computer Science and Defense Analysis U.S. Naval Postgraduate School. Air University. Archived from the original on 23 November 2010. Retrieved 15 November 2009.  "Discovery and Development of Penicillin: International Historic Chemical Landmark". Washington, D.C.: American Chemical Society. Archived from the original on 28 June 2019. Retrieved 15 July 2019. References See also: Bibliography of World War II Adamthwaite, Anthony P. (1992). The Making of the Second World War. New York: Routledge. ISBN 978-0-415-90716-3. Anderson, Irvine H., Jr. (1975). "The 1941 De Facto Embargo on Oil to Japan: A Bureaucratic Reflex". The Pacific Historical Review. 44 (2): 201–31. doi:10.2307/3638003. JSTOR 3638003. Applebaum, Anne (2003). Gulag: A History of the Soviet Camps. London: Allen Lane. ISBN 978-0-7139-9322-6. ——— (2012). Iron Curtain: The Crushing of Eastern Europe 1944–56. London: Allen Lane. ISBN 978-0-7139-9868-9. Bacon, Edwin (1992). "Glasnost' and the Gulag: New Information on Soviet Forced Labour around World War II". Soviet Studies. 44 (6): 1069–86. doi:10.1080/09668139208412066. JSTOR 152330. Badsey, Stephen (1990). Normandy 1944: Allied Landings and Breakout. Oxford: Osprey Publishing. ISBN 978-0-85045-921-0. Balabkins, Nicholas (1964). Germany Under Direct Controls: Economic Aspects of Industrial Disarmament 1945–1948. New Brunswick, NJ: Rutgers University Press. ISBN 978-0-8135-0449-0. Barber, John; Harrison, Mark (2006). "Patriotic War, 1941–1945". In Ronald Grigor Suny (ed.). The Cambridge History of Russia. III: The Twentieth Century. Cambridge: Cambridge University Press. pp. 217–42. ISBN 978-0-521-81144-6. Barker, A.J. (1971). The Rape of Ethiopia 1936. New York: Ballantine Books. ISBN 978-0-345-02462-6. Beevor, Antony (1998). Stalingrad. New York: Viking. ISBN 978-0-670-87095-0. ——— (2012). The Second World War. London: Weidenfeld & Nicolson. ISBN 978-0-297-84497-6. Belco, Victoria (2010). War, Massacre, and Recovery in Central Italy: 1943–1948. Toronto: University of Toronto Press. ISBN 978-0-8020-9314-1. Bellamy, Chris T. (2007). Absolute War: Soviet Russia in the Second World War. New York: Alfred A. Knopf. ISBN 978-0-375-41086-4. Ben-Horin, Eliahu (1943). The Middle East: Crossroads of History. New York: W.W. Norton. Berend, Ivan T. (1996). Central and Eastern Europe, 1944–1993: Detour from the Periphery to the Periphery. Cambridge: Cambridge University Press. ISBN 978-0-521-55066-6. Bernstein, Gail Lee (1991). Recreating Japanese Women, 1600–1945. Berkeley & Los Angeles: University of California Press. ISBN 978-0-520-07017-2. Bilhartz, Terry D.; Elliott, Alan C. (2007). Currents in American History: A Brief History of the United States. Armonk, NY: M.E. Sharpe. ISBN 978-0-7656-1821-4. Bilinsky, Yaroslav (1999). Endgame in NATO's Enlargement: The Baltic States and Ukraine. Westport, CT: Greenwood Publishing Group. ISBN 978-0-275-96363-7. Bix, Herbert P. (2000). Hirohito and the Making of Modern Japan. New York: HarperCollins. ISBN 978-0-06-019314-0. Black, Jeremy (2003). World War Two: A Military History. Abingdon & New York: Routledge. ISBN 978-0-415-30534-1. Blinkhorn, Martin (2006) [1984]. Mussolini and Fascist Italy (3rd ed.). Abingdon & New York: Routledge. ISBN 978-0-415-26206-4. Bonner, Kit; Bonner, Carolyn (2001). Warship Boneyards. Osceola, WI: MBI Publishing Company. ISBN 978-0-7603-0870-7. Borstelmann, Thomas (2005). "The United States, the Cold War, and the colour line". In Melvyn P. Leffler; David S. Painter (eds.). Origins of the Cold War: An International History (2nd ed.). Abingdon & New York: Routledge. pp. 317–32. ISBN 978-0-415-34109-7. Bosworth, Richard; Maiolo, Joseph (2015). The Cambridge History of the Second World War Volume 2: Politics and Ideology. The Cambridge History of the Second World War (3 vol). Cambridge: Cambridge University Press. pp. 313–14. Brayley, Martin J. (2002). The British Army 1939–45, Volume 3: The Far East. Oxford: Osprey Publishing. ISBN 978-1-84176-238-8. British Bombing Survey Unit (1998). The Strategic Air War Against Germany, 1939–1945. London & Portland, OR: Frank Cass Publishers. ISBN 978-0-7146-4722-7. Brody, J. Kenneth (1999). The Avoidable War: Pierre Laval and the Politics of Reality, 1935–1936. New Brunswick, NJ: Transaction Publishers. ISBN 978-0-7658-0622-2. Brown, David (2004). The Road to Oran: Anglo-French Naval Relations, September 1939 – July 1940. London & New York: Frank Cass. ISBN 978-0-7146-5461-4. Buchanan, Tom (2006). Europe's Troubled Peace, 1945–2000. Oxford & Malden, MA: Blackwell Publishing. ISBN 978-0-631-22162-3. Bueno de Mesquita, Bruce; Smith, Alastair; Siverson, Randolph M.; Morrow, James D. (2003). The Logic of Political Survival. Cambridge, MA: MIT Press. ISBN 978-0-262-02546-1. Bull, Martin J.; Newell, James L. (2005). Italian Politics: Adjustment Under Duress. Polity. ISBN 978-0-7456-1298-0. Bullock, Alan (1990). Hitler: A Study in Tyranny. London: Penguin Books. ISBN 978-0-14-013564-0. Burcher, Roy; Rydill, Louis (1995). Concepts in Submarine Design. Journal of Applied Mechanics. 62. Cambridge: Cambridge University Press. p. 268. Bibcode:1995JAM....62R.268B. doi:10.1115/1.2895927. ISBN 978-0-521-55926-3. Busky, Donald F. (2002). Communism in History and Theory: Asia, Africa, and the Americas. Westport, CT: Praeger Publishers. ISBN 978-0-275-97733-7. Canfora, Luciano (2006) [2004]. Democracy in Europe: A History. Oxford & Malden MA: Blackwell Publishing. ISBN 978-1-4051-1131-7. Cantril, Hadley (1940). "America Faces the War: A Study in Public Opinion". Public Opinion Quarterly. 4 (3): 387–407. doi:10.1086/265420. JSTOR 2745078. Chang, Iris (1997). The Rape of Nanking: The Forgotten Holocaust of World War II. New York: Basic Books. ISBN 978-0-465-06835-7. Christofferson, Thomas R.; Christofferson, Michael S. (2006). France During World War II: From Defeat to Liberation. New York: Fordham University Press. ISBN 978-0-8232-2562-0. Chubarov, Alexander (2001). Russia's Bitter Path to Modernity: A History of the Soviet and Post-Soviet Eras. London & New York: Continuum. ISBN 978-0-8264-1350-5. Ch'i, Hsi-Sheng (1992). "The Military Dimension, 1942–1945". In James C. Hsiung; Steven I. Levine (eds.). China's Bitter Victory: War with Japan, 1937–45. Armonk, NY: M.E. Sharpe. pp. 157–84. ISBN 978-1-56324-246-5. Cienciala, Anna M. (2010). "Another look at the Poles and Poland during World War II". The Polish Review. 55 (1): 123–43. JSTOR 25779864. Clogg, Richard (2002). A Concise History of Greece (2nd ed.). Cambridge: Cambridge University Press. ISBN 978-0-521-80872-9. Coble, Parks M. (2003). Chinese Capitalists in Japan's New Order: The Occupied Lower Yangzi, 1937–1945. Berkeley & Los Angeles: University of California Press. ISBN 978-0-520-23268-6. Collier, Paul (2003). The Second World War (4): The Mediterranean 1940–1945. Oxford: Osprey Publishing. ISBN 978-1-84176-539-6. Collier, Martin; Pedley, Philip (2000). Germany 1919–45. Oxford: Heinemann. ISBN 978-0-435-32721-7. Commager, Henry Steele (2004). The Story of the Second World War. Brassey's. ISBN 978-1-57488-741-9. Coogan, Anthony (1993). "The Volunteer Armies of Northeast China". History Today. 43. Retrieved 6 May 2012. Cook, Chris; Bewes, Diccon (1997). What Happened Where: A Guide to Places and Events in Twentieth-Century History. London: UCL Press. ISBN 978-1-85728-532-1. Cowley, Robert; Parker, Geoffrey, eds. (2001). The Reader's Companion to Military History. Boston: Houghton Mifflin Company. ISBN 978-0-618-12742-9. Darwin, John (2007). After Tamerlane: The Rise & Fall of Global Empires 1400–2000. London: Penguin Books. ISBN 978-0-14-101022-9. Davies, Norman (2006). Europe at War 1939–1945: No Simple Victory. London: Macmillan. ix+544 pages. ISBN 978-0-333-69285-1. OCLC 70401618. Dear, I.C.B.; Foot, M.R.D., eds. (2001) [1995]. The Oxford Companion to World War II. Oxford: Oxford University Press. ISBN 978-0-19-860446-4. DeLong, J. Bradford; Eichengreen, Barry (1993). "The Marshall Plan: History's Most Successful Structural Adjustment Program". In Rudiger Dornbusch; Wilhelm Nölling; Richard Layard (eds.). Postwar Economic Reconstruction and Lessons for the East Today. Cambridge, MA: MIT Press. pp. 189–230. ISBN 978-0-262-04136-2. Dower, John W. (1986). War Without Mercy: Race and Power in the Pacific War. New York: Pantheon Books. ISBN 978-0-394-50030-0. Drea, Edward J. (2003). In the Service of the Emperor: Essays on the Imperial Japanese Army. Lincoln, NE: University of Nebraska Press. ISBN 978-0-8032-6638-4. de Grazia, Victoria; Paggi, Leonardo (Autumn 1991). "Story of an Ordinary Massacre: Civitella della Chiana, 29 June, 1944". Cardozo Studies in Law and Literature. 3 (2): 153–69. doi:10.1525/lal.1991.3.2.02a00030. JSTOR 743479. Dunn, Dennis J. (1998). Caught Between Roosevelt & Stalin: America's Ambassadors to Moscow. Lexington, KY: University Press of Kentucky. ISBN 978-0-8131-2023-2. Eastman, Lloyd E. (1986). "Nationalist China during the Sino-Japanese War 1937–1945". In John K. Fairbank; Denis Twitchett (eds.). The Cambridge History of China. 13: Republican China 1912–1949, Part 2. Cambridge: Cambridge University Press. ISBN 978-0-521-24338-4. Ellman, Michael (2002). "Soviet Repression Statistics: Some Comments" (PDF). Europe-Asia Studies. 54 (7): 1151–1172. doi:10.1080/0966813022000017177. JSTOR 826310. S2CID 43510161. Archived from the original (PDF) on 22 November 2012. Copy ———; Maksudov, S. (1994). "Soviet Deaths in the Great Patriotic War: A Note" (PDF). Europe-Asia Studies. 46 (4): 671–80. doi:10.1080/09668139408412190. JSTOR 152934. PMID 12288331. Emadi-Coffin, Barbara (2002). Rethinking International Organization: Deregulation and Global Governance. London & New York: Routledge. ISBN 978-0-415-19540-9. Erickson, John (2001). "Moskalenko". In Shukman, Harold (ed.). Stalin's Generals. London: Phoenix Press. pp. 137–54. ISBN 978-1-84212-513-7. ——— (2003). The Road to Stalingrad. London: Cassell Military. ISBN 978-0-304-36541-8. Evans, David C.; Peattie, Mark R. (2012) [1997]. Kaigun: Strategy, Tactics, and Technology in the Imperial Japanese Navy. Annapolis, MD: Naval Institute Press. ISBN 978-1-59114-244-7. Evans, Richard J. (2008). The Third Reich at War. London: Allen Lane. ISBN 978-0-7139-9742-2. Fairbank, John King; Goldman, Merle (2006) [1994]. China: A New History (2nd ed.). Cambridge: Harvard University Press. ISBN 978-0-674-01828-0. Farrell, Brian P. (1993). "Yes, Prime Minister: Barbarossa, Whipcord, and the Basis of British Grand Strategy, Autumn 1941". Journal of Military History. 57 (4): 599–625. doi:10.2307/2944096. JSTOR 2944096. Ferguson, Niall (2006). The War of the World: Twentieth-Century Conflict and the Descent of the West. Penguin. ISBN 978-0-14-311239-6. Forrest, Glen; Evans, Anthony; Gibbons, David (2012). The Illustrated Timeline of Military History. New York: The Rosen Publishing Group. ISBN 978-1-4488-4794-5. Förster, Stig; Gessler, Myriam (2005). "The Ultimate Horror: Reflections on Total War and Genocide". In Roger Chickering; Stig Förster; Bernd Greiner (eds.). A World at Total War: Global Conflict and the Politics of Destruction, 1937–1945. Cambridge: Cambridge University Press. pp. 53–68. ISBN 978-0-521-83432-2. Frei, Norbert (2002). Adenauer's Germany and the Nazi Past: The Politics of Amnesty and Integration. New York: Columbia University Press. ISBN 978-0-231-11882-8. Gardiner, Robert; Brown, David K., eds. (2004). The Eclipse of the Big Gun: The Warship 1906–1945. London: Conway Maritime Press. ISBN 978-0-85177-953-9. Garver, John W. (1988). Chinese-Soviet Relations, 1937–1945: The Diplomacy of Chinese Nationalism. New York: Oxford University Press. ISBN 978-0-19-505432-3. Gilbert, Martin (1989). Second World War. London: Weidenfeld and Nicolson. ISBN 978-0-297-79616-9. Glantz, David M. (1986). "Soviet Defensive Tactics at Kursk, July 1943". Combined Arms Research Library. CSI Report No. 11. Command and General Staff College. OCLC 278029256. Archived from the original on 6 March 2008. Retrieved 15 July 2013. ——— (1989). Soviet Military Deception in the Second World War. Abingdon & New York: Frank Cass. ISBN 978-0-7146-3347-3. ——— (1998). When Titans Clashed: How the Red Army Stopped Hitler. Lawrence, KS: University Press of Kansas. ISBN 978-0-7006-0899-7. ——— (2001). "The Soviet-German War 1941–45 Myths and Realities: A Survey Essay" (PDF). Archived from the original (PDF) on 9 July 2011. ——— (2002). The Battle for Leningrad: 1941–1944. Lawrence, KS: University Press of Kansas. ISBN 978-0-7006-1208-6. ——— (2005). "August Storm: The Soviet Strategic Offensive in Manchuria". Combined Arms Research Library. Leavenworth Papers. Command and General Staff College. OCLC 78918907. Archived from the original on 2 March 2008. Retrieved 15 July 2013. Goldstein, Margaret J. (2004). World War II: Europe. Minneapolis: Lerner Publications. ISBN 978-0-8225-0139-8. Gordon, Andrew (2004). "The greatest military armada ever launched". In Jane Penrose (ed.). The D-Day Companion. Oxford: Osprey Publishing. pp. 127–144. ISBN 978-1-84176-779-6. Gordon, Robert S.C. (2012). The Holocaust in Italian Culture, 1944–2010. Stanford, CA: Stanford University Press. ISBN 978-0-8047-6346-2. Grove, Eric J. (1995). "A Service Vindicated, 1939–1946". In J.R. Hill (ed.). The Oxford Illustrated History of the Royal Navy. Oxford: Oxford University Press. pp. 348–80. ISBN 978-0-19-211675-8. Hane, Mikiso (2001). Modern Japan: A Historical Survey (3rd ed.). Boulder, CO: Westview Press. ISBN 978-0-8133-3756-2. Hanhimäki, Jussi M. (1997). Containing Coexistence: America, Russia, and the "Finnish Solution". Kent, OH: Kent State University Press. ISBN 978-0-87338-558-9. Harris, Sheldon H. (2002). Factories of Death: Japanese Biological Warfare, 1932–1945, and the American Cover-up (2nd ed.). London & New York: Routledge. ISBN 978-0-415-93214-1. Harrison, Mark (1998). "The economics of World War II: an overview". In Mark Harrison (ed.). The Economics of World War II: Six Great Powers in International Comparison. Cambridge: Cambridge University Press. pp. 1–42. ISBN 978-0-521-62046-8. Hart, Stephen; Hart, Russell; Hughes, Matthew (2000). The German Soldier in World War II. Osceola, WI: MBI Publishing Company. ISBN 978-1-86227-073-2. Hauner, Milan (1978). "Did Hitler Want a World Dominion?". Journal of Contemporary History. 13 (1): 15–32. doi:10.1177/002200947801300102. JSTOR 260090. S2CID 154865385. Healy, Mark (1992). Kursk 1943: The Tide Turns in the East. Oxford: Osprey Publishing. ISBN 978-1-85532-211-0. Hearn, Chester G. (2007). Carriers in Combat: The Air War at Sea. Mechanicsburg, PA: Stackpole Books. ISBN 978-0-8117-3398-4. Hempel, Andrew (2005). Poland in World War II: An Illustrated Military History. New York: Hippocrene Books. ISBN 978-0-7818-1004-3. Herbert, Ulrich (1994). "Labor as spoils of conquest, 1933–1945". In David F. Crew (ed.). Nazism and German Society, 1933–1945. London & New York: Routledge. pp. 219–73. ISBN 978-0-415-08239-6. Herf, Jeffrey (2003). "The Nazi Extermination Camps and the Ally to the East. Could the Red Army and Air Force Have Stopped or Slowed the Final Solution?". Kritika: Explorations in Russian and Eurasian History. 4 (4): 913–30. doi:10.1353/kri.2003.0059. S2CID 159958616. Hill, Alexander (2005). The War Behind The Eastern Front: The Soviet Partisan Movement In North-West Russia 1941–1944. London & New York: Frank Cass. ISBN 978-0-7146-5711-0. Holland, James (2008). Italy's Sorrow: A Year of War 1944–45. London: HarperPress. ISBN 978-0-00-717645-8. Hosking, Geoffrey A. (2006). Rulers and Victims: The Russians in the Soviet Union. Cambridge: Harvard University Press. ISBN 978-0-674-02178-5. Howard, Joshua H. (2004). Workers at War: Labor in China's Arsenals, 1937–1953. Stanford, CA: Stanford University Press. ISBN 978-0-8047-4896-4. Hsu, Long-hsuen; Chang, Ming-kai (1971). History of The Sino-Japanese War (1937–1945) (2nd ed.). Chung Wu Publishers. ASIN B00005W210. Ingram, Norman (2006). "Pacifism". In Lawrence D. Kritzman; Brian J. Reilly (eds.). The Columbia History Of Twentieth-Century French Thought. New York: Columbia University Press. pp. 76–78. ISBN 978-0-231-10791-4. Iriye, Akira (1981). Power and Culture: The Japanese-American War, 1941–1945. Cambridge, MA: Harvard University Press. ISBN 978-0-674-69580-1. Jackson, Ashley (2006). The British Empire and the Second World War. London & New York: Hambledon Continuum. ISBN 978-1-85285-417-1. Joes, Anthony James (2004). Resisting Rebellion: The History And Politics of Counterinsurgency. Lexington: University Press of Kentucky. ISBN 978-0-8131-2339-4. Jowett, Philip S. (2001). The Italian Army 1940–45, Volume 2: Africa 1940–43. Oxford: Osprey Publishing. ISBN 978-1-85532-865-5. ———; Andrew, Stephen (2002). The Japanese Army, 1931–45. Oxford: Osprey Publishing. ISBN 978-1-84176-353-8. Jukes, Geoffrey (2001). "Kuznetzov". In Harold Shukman (ed.). Stalin's Generals. London: Phoenix Press. pp. 109–16. ISBN 978-1-84212-513-7. Kantowicz, Edward R. (1999). The Rage of Nations. Grand Rapids, MI: William B. Eerdmans Publishing Company. ISBN 978-0-8028-4455-2. ——— (2000). Coming Apart, Coming Together. Grand Rapids, MI: William B. Eerdmans Publishing Company. ISBN 978-0-8028-4456-9. Keeble, Curtis (1990). "The historical perspective". In Alex Pravda; Peter J. Duncan (eds.). Soviet-British Relations Since the 1970s. Cambridge: Cambridge University Press. ISBN 978-0-521-37494-1. Keegan, John (1997). The Second World War. London: Pimlico. ISBN 978-0-7126-7348-8. Kennedy, David M. (2001). Freedom from Fear: The American People in Depression and War, 1929–1945. Oxford University Press. ISBN 978-0-19-514403-1. Kennedy-Pipe, Caroline (1995). Stalin's Cold War: Soviet Strategies in Europe, 1943–56. Manchester: Manchester University Press. ISBN 978-0-7190-4201-0. Kershaw, Ian (2001). Hitler, 1936–1945: Nemesis. New York: W.W. Norton. ISBN 978-0-393-04994-7. ——— (2007). Fateful Choices: Ten Decisions That Changed the World, 1940–1941. London: Allen Lane. ISBN 978-0-7139-9712-5. Kitson, Alison (2001). Germany 1858–1990: Hope, Terror, and Revival. Oxford: Oxford University Press. ISBN 978-0-19-913417-5. Klavans, Richard A.; Di Benedetto, C. Anthony; Prudom, Melanie J. (1997). "Understanding Competitive Interactions: The U.S. Commercial Aircraft Market". Journal of Managerial Issues. 9 (1): 13–361. JSTOR 40604127. Kleinfeld, Gerald R. (1983). "Hitler's Strike for Tikhvin". Military Affairs. 47 (3): 122–128. doi:10.2307/1988082. JSTOR 1988082. Koch, H.W. (1983). "Hitler's 'Programme' and the Genesis of Operation 'Barbarossa'". The Historical Journal. 26 (4): 891–920. doi:10.1017/S0018246X00012747. JSTOR 2639289. Kolko, Gabriel (1990) [1968]. The Politics of War: The World and United States Foreign Policy, 1943–1945. New York: Random House. ISBN 978-0-679-72757-6. Laurier, Jim (2001). Tobruk 1941: Rommel's Opening Move. Oxford: Osprey Publishing. ISBN 978-1-84176-092-6. Lee, En-han (2002). "The Nanking Massacre Reassessed: A Study of the Sino-Japanese Controversy over the Factual Number of Massacred Victims". In Robert Sabella; Fei Fei Li; David Liu (eds.). Nanking 1937: Memory and Healing. Armonk, NY: M.E. Sharpe. pp. 47–74. ISBN 978-0-7656-0816-1. Leffler, Melvyn P.; Westad, Odd Arne, eds. (2010). The Cambridge History of the Cold War. Cambridge: Cambridge University Press. ISBN 978-0-521-83938-9, in 3 volumes. Levine, Alan J. (1992). The Strategic Bombing of Germany, 1940–1945. Westport, CT: Praeger. ISBN 978-0-275-94319-6. Lewis, Morton (1953). "Japanese Plans and American Defenses". In Greenfield, Kent Roberts (ed.). The Fall of the Philippines. Washington, DC: US Government Printing Office. LCCN 53-63678. Liberman, Peter (1996). Does Conquest Pay?: The Exploitation of Occupied Industrial Societies. Princeton, NJ: Princeton University Press. ISBN 978-0-691-02986-3. Liddell Hart, Basil (1977). History of the Second World War (4th ed.). London: Pan. ISBN 978-0-330-23770-3. Lightbody, Bradley (2004). The Second World War: Ambitions to Nemesis. London & New York: Routledge. ISBN 978-0-415-22404-8. Lindberg, Michael; Todd, Daniel (2001). Brown-, Green- and Blue-Water Fleets: the Influence of Geography on Naval Warfare, 1861 to the Present. Westport, CT: Praeger. ISBN 978-0-275-96486-3. Lowe, C.J.; Marzari, F. (2002). Italian Foreign Policy 1870–1940. London: Routledge. ISBN 978-0-415-26681-9. Lynch, Michael (2010). The Chinese Civil War 1945–49. Oxford: Osprey Publishing. ISBN 978-1-84176-671-3. Maddox, Robert James (1992). The United States and World War II. Boulder, CO: Westview Press. ISBN 978-0-8133-0437-3. Maingot, Anthony P. (1994). The United States and the Caribbean: Challenges of an Asymmetrical Relationship. Boulder, CO: Westview Press. ISBN 978-0-8133-2241-4. Mandelbaum, Michael (1988). The Fate of Nations: The Search for National Security in the Nineteenth and Twentieth Centuries. Cambridge University Press. p. 96. ISBN 978-0-521-35790-6. Marston, Daniel (2005). The Pacific War Companion: From Pearl Harbor to Hiroshima. Oxford: Osprey Publishing. ISBN 978-1-84176-882-3. Masaya, Shiraishi (1990). Japanese Relations with Vietnam, 1951–1987. Ithaca, NY: SEAP Publications. ISBN 978-0-87727-122-2. May, Ernest R. (1955). "The United States, the Soviet Union, and the Far Eastern War, 1941–1945". Pacific Historical Review. 24 (2): 153–74. doi:10.2307/3634575. JSTOR 3634575. Mazower, Mark (2008). Hitler's Empire: Nazi Rule in Occupied Europe. London: Allen Lane. ISBN 978-1-59420-188-2. Milner, Marc (1990). "The Battle of the Atlantic". In Gooch, John (ed.). Decisive Campaigns of the Second World War. Abingdon: Frank Cass. pp. 45–66. ISBN 978-0-7146-3369-5. Milward, A.S. (1964). "The End of the Blitzkrieg". The Economic History Review. 16 (3): 499–518. JSTOR 2592851. ——— (1992) [1977]. War, Economy, and Society, 1939–1945. Berkeley, CA: University of California Press. ISBN 978-0-520-03942-1. Minford, Patrick (1993). "Reconstruction and the UK Postwar Welfare State: False Start and New Beginning". In Rudiger Dornbusch; Wilhelm Nölling; Richard Layard (eds.). Postwar Economic Reconstruction and Lessons for the East Today. Cambridge, MA: MIT Press. pp. 115–38. ISBN 978-0-262-04136-2. Mingst, Karen A.; Karns, Margaret P. (2007). United Nations in the Twenty-First Century (3rd ed.). Boulder, CO: Westview Press. ISBN 978-0-8133-4346-4. Miscamble, Wilson D. (2007). From Roosevelt to Truman: Potsdam, Hiroshima, and the Cold War. New York: Cambridge University Press. ISBN 978-0-521-86244-8. Mitcham, Samuel W. (2007) [1982]. Rommel's Desert War: The Life and Death of the Afrika Korps. Mechanicsburg, PA: Stackpole Books. ISBN 978-0-8117-3413-4. Mitter, Rana (2014). Forgotten Ally: China's World War II, 1937–1945. Mariner Books. ISBN 978-0-544-33450-2. Molinari, Andrea (2007). Desert Raiders: Axis and Allied Special Forces 1940–43. Oxford: Osprey Publishing. ISBN 978-1-84603-006-2. Murray, Williamson (1983). Strategy for Defeat: The Luftwaffe, 1933–1945. Maxwell Air Force Base, AL: Air University Press. ISBN 978-1-4294-9235-5. ———; Millett, Allan Reed (2001). A War to Be Won: Fighting the Second World War. Cambridge, MA: Harvard University Press. ISBN 978-0-674-00680-5. Myers, Ramon; Peattie, Mark (1987). The Japanese Colonial Empire, 1895–1945. Princeton, NJ: Princeton University Press. ISBN 978-0-691-10222-1. Naimark, Norman (2010). "The Sovietization of Eastern Europe, 1944–1953". In Melvyn P. Leffler; Odd Arne Westad (eds.). The Cambridge History of the Cold War. I: Origins. Cambridge: Cambridge University Press. pp. 175–97. ISBN 978-0-521-83719-4. Neary, Ian (1992). "Japan". In Martin Harrop (ed.). Power and Policy in Liberal Democracies. Cambridge: Cambridge University Press. pp. 49–70. ISBN 978-0-521-34579-8. Neillands, Robin (2005). The Dieppe Raid: The Story of the Disastrous 1942 Expedition. Bloomington, IN: Indiana University Press. ISBN 978-0-253-34781-7. Neulen, Hans Werner (2000). In the skies of Europe – Air Forces allied to the Luftwaffe 1939–1945. Ramsbury, Marlborough, UK: The Crowood Press. ISBN 1-86126-799-1. Niewyk, Donald L.; Nicosia, Francis (2000). The Columbia Guide to the Holocaust. New York: Columbia University Press. ISBN 978-0-231-11200-0. Overy, Richard (1994). War and Economy in the Third Reich. New York: Clarendon Press. ISBN 978-0-19-820290-5. ——— (1995). Why the Allies Won. London: Pimlico. ISBN 978-0-7126-7453-9. ——— (2004). The Dictators: Hitler's Germany, Stalin's Russia. New York: W.W. Norton. ISBN 978-0-393-02030-4. ———; Wheatcroft, Andrew (1999). The Road to War (2nd ed.). London: Penguin Books. ISBN 978-0-14-028530-7. O'Reilly, Charles T. (2001). Forgotten Battles: Italy's War of Liberation, 1943–1945. Lanham, MD: Lexington Books. ISBN 978-0-7391-0195-7. Painter, David S. (2012). "Oil and the American Century". The Journal of American History. 99 (1): 24–39. doi:10.1093/jahist/jas073. Padfield, Peter (1998). War Beneath the Sea: Submarine Conflict During World War II. New York: John Wiley. ISBN 978-0-471-24945-0. Pape, Robert A. (1993). "Why Japan Surrendered". International Security. 18 (2): 154–201. doi:10.2307/2539100. JSTOR 2539100. S2CID 153741180. Parker, Danny S. (2004). Battle of the Bulge: Hitler's Ardennes Offensive, 1944–1945 (New ed.). Cambridge, MA: Da Capo Press. ISBN 978-0-306-81391-7. Payne, Stanley G. (2008). Franco and Hitler: Spain, Germany, and World War II. New Haven, CT: Yale University Press. ISBN 978-0-300-12282-4. Perez, Louis G. (1998). The History of Japan. Westport, CT: Greenwood Publishing Group. ISBN 978-0-313-30296-1. Petrov, Vladimir (1967). Money and Conquest: Allied Occupation Currencies in World War II. Baltimore, MD: Johns Hopkins University Press. ISBN 978-0-8018-0530-1. Polley, Martin (2000). An A–Z of Modern Europe Since 1789. London & New York: Routledge. ISBN 978-0-415-18597-4. Portelli, Alessandro (2003). The Order Has Been Carried Out: History, Memory, and Meaning of a Nazi Massacre in Rome. Basingstoke & New York: Palgrave Macmillan. ISBN 978-1-4039-8008-3. Preston, P. W. (1998). Pacific Asia in the Global System: An Introduction. Oxford & Malden, MA: Blackwell Publishers. ISBN 978-0-631-20238-7. Prins, Gwyn (2002). The Heart of War: On Power, Conflict and Obligation in the Twenty-First Century. London & New York: Routledge. ISBN 978-0-415-36960-2. Radtke, K.W. (1997). "'Strategic' concepts underlying the so-called Hirota foreign policy, 1933–7". In Aiko Ikeo (ed.). Economic Development in Twentieth Century East Asia: The International Context. London & New York: Routledge. pp. 100–20. ISBN 978-0-415-14900-6. Rahn, Werner (2001). "The War in the Pacific". In Horst Boog; Werner Rahn; Reinhard Stumpf; Bernd Wegner (eds.). Germany and the Second World War. VI: The Global War. Oxford: Clarendon Press. pp. 191–298. ISBN 978-0-19-822888-2. Ratcliff, R.A. (2006). Delusions of Intelligence: Enigma, Ultra, and the End of Secure Ciphers. New York: Cambridge University Press. ISBN 978-0-521-85522-8. Read, Anthony (2004). The Devil's Disciples: Hitler's Inner Circle. New York: W.W. Norton. ISBN 978-0-393-04800-1. Read, Anthony; Fisher, David (2002) [1992]. The Fall Of Berlin. London: Pimlico. ISBN 978-0-7126-0695-0. Record, Jeffery (2005). Appeasement Reconsidered: Investigating the Mythology of the 1930s (PDF). Diane Publishing. p. 50. ISBN 978-1-58487-216-0. Retrieved 15 November 2009. Rees, Laurence (2008). World War II Behind Closed Doors: Stalin, the Nazis and the West. London: BBC Books. ISBN 978-0-563-49335-8. Regan, Geoffrey (2004). The Brassey's Book of Military Blunders. Brassey's. ISBN 978-1-57488-252-0. Reinhardt, Klaus (1992). Moscow – The Turning Point: The Failure of Hitler's Strategy in the Winter of 1941–42. Oxford: Berg. ISBN 978-0-85496-695-0. Reynolds, David (2006). From World War to Cold War: Churchill, Roosevelt, and the International History of the 1940s. Oxford University Press. ISBN 978-0-19-928411-5. Rich, Norman (1992) [1973]. Hitler's War Aims, Volume I: Ideology, the Nazi State, and the Course of Expansion. New York: W.W. Norton. ISBN 978-0-393-00802-9. Ritchie, Ella (1992). "France". In Martin Harrop (ed.). Power and Policy in Liberal Democracies. Cambridge: Cambridge University Press. pp. 23–48. ISBN 978-0-521-34579-8. Roberts, Cynthia A. (1995). "Planning for War: The Red Army and the Catastrophe of 1941". Europe-Asia Studies. 47 (8): 1293–1326. doi:10.1080/09668139508412322. JSTOR 153299. Roberts, Geoffrey (2006). Stalin's Wars: From World War to Cold War, 1939–1953. New Haven, CT: Yale University Press. ISBN 978-0-300-11204-7. Roberts, J.M. (1997). The Penguin History of Europe. London: Penguin Books. ISBN 978-0-14-026561-3. Ropp, Theodore (2000). War in the Modern World (Revised ed.). Baltimore, MD: Johns Hopkins University Press. ISBN 978-0-8018-6445-2. Roskill, S.W. (1954). The War at Sea 1939–1945, Volume 1: The Defensive. History of the Second World War. United Kingdom Military Series. London: HMSO. Ross, Steven T. (1997). American War Plans, 1941–1945: The Test of Battle. Abingdon & New York: Routledge. ISBN 978-0-7146-4634-3. Rottman, Gordon L. (2002). World War II Pacific Island Guide: A Geo-Military Study. Westport, CT: Greenwood Press. ISBN 978-0-313-31395-0. Rotundo, Louis (1986). "The Creation of Soviet Reserves and the 1941 Campaign". Military Affairs. 50 (1): 21–28. doi:10.2307/1988530. JSTOR 1988530. Salecker, Gene Eric (2001). Fortress Against the Sun: The B-17 Flying Fortress in the Pacific. Conshohocken, PA: Combined Publishing. ISBN 978-1-58097-049-5. Schain, Martin A., ed. (2001). The Marshall Plan Fifty Years Later. London: Palgrave Macmillan. ISBN 978-0-333-92983-4. Schmitz, David F. (2000). Henry L. Stimson: The First Wise Man. Lanham, MD: Rowman & Littlefield. ISBN 978-0-8420-2632-1. Schoppa, R. Keith (2011). In a Sea of Bitterness, Refugees during the Sino-Japanese War. Harvard University Press. ISBN 978-0-674-05988-7. Sella, Amnon (1978). ""Barbarossa": Surprise Attack and Communication". Journal of Contemporary History. 13 (3): 555–83. doi:10.1177/002200947801300308. JSTOR 260209. S2CID 220880174. ——— (1983). "Khalkhin-Gol: The Forgotten War". Journal of Contemporary History. 18 (4): 651–87. JSTOR 260307. Senn, Alfred Erich (2007). Lithuania 1940: Revolution from Above. Amsterdam & New York: Rodopi. ISBN 978-90-420-2225-6. Shaw, Anthony (2000). World War II: Day by Day. Osceola, WI: MBI Publishing Company. ISBN 978-0-7603-0939-1. Shepardson, Donald E. (1998). "The Fall of Berlin and the Rise of a Myth". Journal of Military History. 62 (1): 135–54. doi:10.2307/120398. JSTOR 120398. Shirer, William L. (1990) [1960]. The Rise and Fall of the Third Reich: A History of Nazi Germany. New York: Simon & Schuster. ISBN 978-0-671-72868-7. Shore, Zachary (2003). What Hitler Knew: The Battle for Information in Nazi Foreign Policy. New York: Oxford University Press. ISBN 978-0-19-518261-3. Slim, William (1956). Defeat into Victory. London: Cassell. ISBN 978-0-304-29114-4. Smith, Alan (1993). Russia and the World Economy: Problems of Integration. London: Routledge. ISBN 978-0-415-08924-1. Smith, J.W. (1994). The World's Wasted Wealth 2: Save Our Wealth, Save Our Environment. Institute for Economic Democracy. ISBN 978-0-9624423-2-2. Smith, Peter C. (2002) [1970]. Pedestal: The Convoy That Saved Malta (5th ed.). Manchester: Goodall. ISBN 978-0-907579-19-9. Smith, David J.; Pabriks, Artis; Purs, Aldis; Lane, Thomas (2002). The Baltic States: Estonia, Latvia and Lithuania. London: Routledge. ISBN 978-0-415-28580-3. Smith, Winston; Steadman, Ralph (2004). All Riot on the Western Front, Volume 3. Last Gasp. ISBN 978-0-86719-616-0. Snyder, Timothy (2010). Bloodlands: Europe Between Hitler and Stalin. London: The Bodley Head. ISBN 978-0-224-08141-2. Spring, D. W. (1986). "The Soviet Decision for War against Finland, 30 November 1939". Soviet Studies. 38 (2): 207–26. doi:10.1080/09668138608411636. JSTOR 151203. S2CID 154270850. Steinberg, Jonathan (1995). "The Third Reich Reflected: German Civil Administration in the Occupied Soviet Union, 1941–4". The English Historical Review. 110 (437): 620–51. doi:10.1093/ehr/cx.437.620. JSTOR 578338. Steury, Donald P. (1987). "Naval Intelligence, the Atlantic Campaign and the Sinking of the Bismarck: A Study in the Integration of Intelligence into the Conduct of Naval Warfare". Journal of Contemporary History. 22 (2): 209–33. doi:10.1177/002200948702200202. JSTOR 260931. S2CID 159943895. Stueck, William (2010). "The Korean War". In Melvyn P. Leffler; Odd Arne Westad (eds.). The Cambridge History of the Cold War. I: Origins. Cambridge: Cambridge University Press. pp. 266–87. ISBN 978-0-521-83719-4. Sumner, Ian; Baker, Alix (2001). The Royal Navy 1939–45. Oxford: Osprey Publishing. ISBN 978-1-84176-195-4. Swain, Bruce (2001). A Chronology of Australian Armed Forces at War 1939–45. Crows Nest: Allen & Unwin. ISBN 978-1-86508-352-0. Swain, Geoffrey (1992). "The Cominform: Tito's International?". The Historical Journal. 35 (3): 641–63. doi:10.1017/S0018246X00026017. Tanaka, Yuki (1996). Hidden Horrors: Japanese War Crimes in World War II. Boulder, CO: Westview Press. ISBN 978-0-8133-2717-4. Taylor, A.J.P. (1961). The Origins of the Second World War. London: Hamish Hamilton. ——— (1979). How Wars Begin. London: Hamish Hamilton. ISBN 978-0-241-10017-2. Taylor, Jay (2009). The Generalissimo: Chiang Kai-shek and the Struggle for Modern China. Cambridge, MA: Harvard University Press. ISBN 978-0-674-03338-2. Thomas, Nigel; Andrew, Stephen (1998). German Army 1939–1945 (2): North Africa & Balkans. Oxford: Osprey Publishing. ISBN 978-1-85532-640-8. Thompson, John Herd; Randall, Stephen J. (2008). Canada and the United States: Ambivalent Allies (4th ed.). Athens, GA: University of Georgia Press. ISBN 978-0-8203-3113-3. Trachtenberg, Marc (1999). A Constructed Peace: The Making of the European Settlement, 1945–1963. Princeton, NJ: Princeton University Press. ISBN 978-0-691-00273-6. Tucker, Spencer C.; Roberts, Priscilla Mary (2004). Encyclopedia of World War II: A Political, Social, and Military History. ABC-CIO. ISBN 978-1-57607-999-7. Umbreit, Hans (1991). "The Battle for Hegemony in Western Europe". In P. S. Falla (ed.). Germany and the Second World War. 2: Germany's Initial Conquests in Europe. Oxford: Oxford University Press. pp. 227–326. ISBN 978-0-19-822885-1. United States Army (1986) [1953]. The German Campaigns in the Balkans (Spring 1941). Washington, DC: Department of the Army. Waltz, Susan (2002). "Reclaiming and Rebuilding the History of the Universal Declaration of Human Rights". Third World Quarterly. 23 (3): 437–48. doi:10.1080/01436590220138378. JSTOR 3993535. S2CID 145398136. Ward, Thomas A. (2010). Aerospace Propulsion Systems. Singapore: John Wiley & Sons. ISBN 978-0-470-82497-9. Watson, William E. (2003). Tricolor and Crescent: France and the Islamic World. Westport, CT: Praeger. ISBN 978-0-275-97470-1. Weinberg, Gerhard L. (2005). A World at Arms: A Global History of World War II (2nd ed.). Cambridge: Cambridge University Press. ISBN 978-0-521-85316-3.; comprehensive overview with emphasis on diplomacy Wettig, Gerhard (2008). Stalin and the Cold War in Europe: The Emergence and Development of East-West Conflict, 1939–1953. Lanham, MD: Rowman & Littlefield. ISBN 978-0-7425-5542-6. Wiest, Andrew; Barbier, M.K. (2002). Strategy and Tactics: Infantry Warfare. St Paul, MN: MBI Publishing Company. ISBN 978-0-7603-1401-2. Williams, Andrew (2006). Liberalism and War: The Victors and the Vanquished. Abingdon & New York: Routledge. ISBN 978-0-415-35980-1. Wilt, Alan F. (1981). "Hitler's Late Summer Pause in 1941". Military Affairs. 45 (4): 187–91. doi:10.2307/1987464. JSTOR 1987464. Wohlstetter, Roberta (1962). Pearl Harbor: Warning and Decision. Palo Alto, CA: Stanford University Press. ISBN 978-0-8047-0597-4. Wolf, Holger C. (1993). "The Lucky Miracle: Germany 1945–1951". In Rudiger Dornbusch; Wilhelm Nölling; Richard Layard (eds.). Postwar Economic Reconstruction and Lessons for the East Today. Cambridge: MIT Press. pp. 29–56. ISBN 978-0-262-04136-2. Wood, James B. (2007). Japanese Military Strategy in the Pacific War: Was Defeat Inevitable?. Lanham, MD: Rowman & Littlefield. ISBN 978-0-7425-5339-2. Yoder, Amos (1997). The Evolution of the United Nations System (3rd ed.). London & Washington, DC: Taylor & Francis. ISBN 978-1-56032-546-8. Zalampas, Michael (1989). Adolf Hitler and the Third Reich in American magazines, 1923–1939. Bowling Green University Popular Press. ISBN 978-0-87972-462-7. Zaloga, Steven J. (1996). Bagration 1944: The Destruction of Army Group Centre. Oxford: Osprey Publishing. ISBN 978-1-85532-478-7. ——— (2002). Poland 1939: The Birth of Blitzkrieg. Oxford: Osprey Publishing. ISBN 978-1-84176-408-5. Zeiler, Thomas W. (2004). Unconditional Defeat: Japan, America, and the End of World War II. Wilmington, DE: Scholarly Resources. ISBN 978-0-8420-2991-9. Zetterling, Niklas; Tamelander, Michael (2009). Bismarck: The Final Days of Germany's Greatest Battleship. Drexel Hill, PA: Casemate. ISBN 978-1-935149-04-0. External links World War II at Wikipedia's sister projects West Point Maps of the European War West Point Maps of the Asian-Pacific War Atlas of the World Battle Fronts (July 1943 to August 1945) Records of World War II propaganda posters are held by Simon Fraser University's Special Collections and Rare Books Archived 2 February 2017 at the Wayback Machine Maps of World War II in Europe at Omniatlas vte World War II vte History of World War II by region and country Authority control Edit this at Wikidata Categories: World War IIWorld WarsConflicts in 1939Conflicts in 1940Conflicts in 1941Conflicts in 1942Conflicts in 1943Conflicts in 1944Conflicts in 1945Global conflictsLate modern EuropeNuclear warfareWarWars involving AlbaniaWars involving AustraliaWars involving AustriaWars involving BelgiumWars involving BoliviaWars involving BrazilWars involving British IndiaWars involving BulgariaWars involving MyanmarWars involving CambodiaWars involving CanadaWars involving ChileWars involving ColombiaWars involving Costa RicaWars involving CroatiaWars involving CubaWars involving CzechoslovakiaWars involving DenmarkWars involving EcuadorWars involving EgyptWars involving El SalvadorWars involving EstoniaWars involving EthiopiaWars involving FinlandWars involving FranceWars involving GermanyWars involving GreeceWars involving GuatemalaWars involving HaitiWars involving HondurasWars involving HungaryWars involving IcelandWars involving IndonesiaWars involving ItalyWars involving IranWars involving IraqWars involving JapanWars involving LaosWars involving LatviaWars involving LebanonWars involving LiberiaWars involving LithuaniaWars involving LuxembourgWars involving MexicoWars involving MongoliaWars involving MontenegroWars involving NepalWars involving NorwayWars involving NicaraguaWars involving PanamaWars involving ParaguayWars involving PeruWars involving PolandWars involving RhodesiaWars involving RomaniaWars involving Saudi ArabiaWars involving SerbiaWars involving SlovakiaWars involving SloveniaWars involving South AfricaWars involving Sri LankaWars involving SyriaWars involving ThailandWars involving the Dominican RepublicWars involving the NetherlandsWars involving the PhilippinesWars involving the Republic of ChinaWars involving the Soviet UnionWars involving the United KingdomWars involving the United StatesWars involving UruguayWars involving VenezuelaWars involving VietnamWars involving YugoslaviaWars involving India Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadView sourceView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikinews Wikiquote Wikiversity Wikivoyage  Languages Afrikaans Български Deutsch Ελληνικά Français Македонски Shqip Türkçe 中文 205 more Edit links This page was last edited on 8 October 2021, at 13:04 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki   Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more Republic of China (1912–1949) From Wikipedia, the free encyclopedia Jump to navigationJump to search For the Republic of China from 1949, see Taiwan. Republic of China 中華民國 Chunghwa Minkuo Jonghwa Min'gwo Zhōnghuá Mínguó 1912–1949 Flag of China Flag of the Republic of China.svg Top: Flag (1912–1928) Bottom: Flag (1928–1949) Twelve Symbols national emblem of China.svg National Emblem of the Republic of China.svg Top: Emblem (1913–1928) Bottom: Emblem (1928–1949) Anthem:  《五族共和歌》 "Song of Five Races Under One Union" (1912–1913) 《卿雲歌》 "Song to the Auspicious Cloud" (1913–1915; 1921–1928)[a] 《中華雄立宇宙間》 "China Heroically Stands in the Universe" (1915–1921) 《中華民國國歌》 "National Anthem of the Republic of China" (1930–1949) Flag anthem: 《中華民國國旗歌》 "National Flag Anthem of the Republic of China" (1937–1949) National seal 中華民國之璽 中華民國之璽.svg (1929–1949) Republic of China (orthographic projection, historical).svg Location and maximum extent of territory claimed by the Republic of China (1945)   Territory controlled by ROC   Territory claimed but not controlled by ROC[b] Capital	Peking (1912–1928) Nanking[c] (1927–1937, 1946–1949) Chungking[d] (1937–1946) Largest city	Shanghai Official languages	Standard Chinese Recognised national languages	Tibetan Chagatai/Uighur Manchu Mongolian and other languages Official script	 Traditional Chinese Manchu alphabet Mongolian script Tibetan alphabet Uyghur alphabets Formosan Latin alphabet (from 1945) Religion	See Religion in China Demonym(s)	Chinese[1] Government	 Provisional government (1912) Beiyang government (1912–1928) Nationalist government (1928–1948) ROC government (1948–1949) President	  • 1912 Sun Yat-sen (first, provisional) • 1949–1950 Li Zongren (last in Chinese mainland, acting) Premier	  • 1912 Tang Shaoyi (first) • 1949 He Yingqin (last in Chinese mainland) Legislature	Parliament • Electoral college •Upper house National Assembly Control Yuan[2] • Lower house Legislative Yuan History	  • Xinhai Revolution 10 October 1911[e]–12 February 1912[f] • Republic of China proclaimed 1 January 1912 1912 • Beiyang government in Beijing 1912–1928 • Joined the League of Nations 10 January 1920 • Northern Expedition 1926–1928 • Nationalist government in Nanjing 1927–1948 • Chinese Civil War 1927–1936, 1946–1950[g] • Second Sino-Japanese War 7 July 1937[h]–2 September 1945[i] • Admitted to the United Nations 24 October 1945 • Constitution adopted 25 December 1947 • Proclamation of the People's Republic of China 1 October 1949 • Government moved to Taipei 7 December 1949 Currency	 Customs gold unit (1912–1949 in Chinese mainland) Old Taiwan dollar (1946–1949 in Taiwan) Time zone	UTC+5:30 to +8:30 (Kunlun to Changpai Standard Times) Driving side	right[j] ISO 3166 code	CN Preceded by	Succeeded by 	Qing dynasty People's Republic of China	 Republic of China on Taiwan	   Populations from http://www.populstat.info/Asia/chinac.htm China, officially known as the Republic of China (ROC) was a country in East Asia based in mainland China from 1912 to 1949, prior to the relocation of its government to Taiwan as a result of the Chinese Civil War. At a population of 541 million in 1949, it was the world's most populous country. Covering 11.4 million square kilometres (4.4 million square miles),[3] it consisted of 35 provinces, 1 special administrative region, 2 regions, 12 special municipalities, 14 leagues, and 4 special banners. This period is often referred to as the Republican Era in mainland China[4] or the Mainland Period in Taiwan.[5]  The Republic was declared on 1 January 1912 after the Xinhai Revolution, which overthrew the Qing dynasty, the last imperial dynasty of China. On 12 February 1912, regent Empress Dowager Longyu signed the abdication decree on behalf of the Xuantong Emperor, ending several millennia of Chinese monarchical rule.[6] Sun Yat-sen, the founder and its provisional president, served only briefly before handing over the presidency to Yuan Shikai, the leader of the Beiyang Army. Sun's party, the Kuomintang (KMT), then led by Song Jiaoren, won the parliamentary election held in December 1912. However, Song was assassinated on Yuan's orders shortly after and the Beiyang Army, led by Yuan, maintained full control of the Beiyang government, who then proclaimed the Empire of China in 1915 before abolishing the short-lived monarchy as a result of popular unrest. After Yuan's death in 1916, the authority of the Beiyang government was further weakened by a brief restoration of the Qing dynasty. The mostly powerless government led to a fracturing of the country as cliques in the Beiyang Army claimed individual autonomy and clashed with each other. So began the Warlord Era: a decade of decentralized power struggles and prolonged armed conflict.  The KMT, under the leadership of Sun, attempted multiple times to establish a national government in Canton. After taking Canton for a third time in 1923, the KMT successfully established a rival government in preparation for a campaign to unify China. In 1924 the KMT would enter into an alliance with the fledgling Communist Party of China (CPC) as a requirement for Soviet support. General Chiang Kai-shek, who became the Chairman of the Kuomintang after Sun's death and subsequent power struggle in 1925, began the Northern Expedition in 1926 to overthrow the Beiyang government. In 1927, Chiang moved the nationalist government to Nanking and purged the CPC, beginning with the Shanghai massacre. The latter event forced the CPC and KMT's left-wing into armed rebellion, marking the beginning of the Chinese Civil War and the establishment of a rival nationalist government in Wuhan under Wang Jingwei. However, this rival government soon purged the communists as well and reconciled with Chiang's KMT. After the Northern Expedition resulted in nominal unification under Chiang in 1928, disgruntled warlords formed an anti-Chiang coalition. These warlords would fight Chiang and his allies in the Central Plains War from 1929 to 1930, ultimately losing in the largest conflict of the Warlord Era.  China experienced some industrialization during the 1930s but suffered setbacks from conflicts between the Nationalist government in Nanjing, the CPC, remaining warlords, and the Empire of Japan after the Japanese invasion of Manchuria. Nation-building efforts yielded to fight the Second Sino-Japanese War in 1937 when a skirmish between the National Revolutionary Army and Imperial Japanese Army culminated in a full-scale invasion by Japan. Hostilities between the KMT and CPC partially subsided when, shortly before the war, they formed the Second United Front to resist Japanese aggression until the alliance broke down in 1941. The war lasted until the surrender of Japan at the end of World War II in 1945; China then regained control of the island of Taiwan and the Pescadores.  Shortly after, the Chinese Civil War between the KMT and CPC resumed with full-scale fighting, leading to the 1946 Constitution of the Republic of China replacing the 1928 Organic Law[7] as the Republic's fundamental law. Three years later, in 1949, nearing the end of the civil war, the CPC established the People's Republic of China in Beijing, with the KMT-led ROC moving its capital several times from Nanjing to Guangzhou, followed by Chongqing, then Chengdu and lastly, Taipei. The CPC emerged victorious and expelled the KMT and ROC government from the Chinese mainland. The ROC later lost control of Hainan in 1950, and the Dachen Islands in Zhejiang in 1955. It has maintained control over Taiwan and other smaller islands.  The ROC was a founding member of the League of Nations and later the United Nations (including its Security Council seat) where it maintained until 1971, when the People's Republic of China took over its membership. It was also a member of the Universal Postal Union and the International Olympic Committee.   Contents 1	Names 2	History 2.1	Overview 2.2	Founding 2.3	Nanjing decade 2.4	Second Sino-Japanese War (1937–1945) 2.5	Post-World War II 3	Government 3.1	Foreign relations 3.2	Administrative divisions 3.3	Nobility 4	Military 5	Economy 6	See also 7	Notes 8	References 8.1	Citations 8.2	Sources 9	External links Names See also: Names of China The official name of the state on the mainland was the "Republic of China", but it has been known under various names throughout its existence. Shortly after the ROC's establishment in 1912, the government used the short form "China" (Zhōngguó or Jung-hwa (中國)) to refer to itself, "China" being derived from zhōng ("central" or "middle") and guó ("state, nation-state"),[k] a term that developed under the Zhou dynasty in reference to its royal demesne,[l] and the name was then applied to the area around Luoyi (present-day Luoyang) during the Eastern Zhou and then to China's Central Plain before being used as an occasional synonym for the state during the Qing era.[9]  "Republican China" and "Republican Era" refer to the "Beiyang government" (from 1912 to 1928), and "Nationalist government" (from 1928 to 1949).[11]  History Main article: History of the Republic of China Further information: Timeline of Republic of China history See also: History of China Overview  Sun Yat-sen, the founding father of Republic of China, the oldest republic in Asia. A republic was formally established on 1 January 1912 following the Xinhai Revolution, which itself began with the Wuchang uprising on 10 October 1911, successfully overthrowing the Qing dynasty and ending over two thousand years of imperial rule in China.[12] From its founding until 1949, the republic was based on mainland China. Central authority waxed and waned in response to warlordism (1915–28), a Japanese invasion (1937–45), and a full-scale civil war (1927–49), with central authority strongest during the Nanjing Decade (1927–37), when most of China came under the control of the authoritarian, one-party military dictatorship of the Kuomintang (KMT).[13]  In 1945, at the end of World War II, the Empire of Japan surrendered control of Taiwan and its island groups to the Allies; and Taiwan was placed under the Republic of China's administrative control. The communist takeover of mainland China in 1949, after the Chinese Civil War, left the ruling Kuomintang with control over only Taiwan, Penghu, Kinmen, Matsu, and other minor islands. With the loss of the mainland, the ROC government retreated to Taiwan and the KMT declared Taipei the provisional capital.[14] Meanwhile, the Communist Party of China took over all of mainland China[15][16] and founded the People's Republic of China (PRC) in Beijing.  Founding Main article: Wuchang Uprising Further information: Beiyang government, Warlord era, and China during World War I See also: First United Front, Northern Expedition, Shanghai massacre of 1927, and Nanchang Uprising A drawing depicting two lions looking up in front of two flags. The flag on the left is red and blue with a white sun; while the one on the right is made of five vertical stripes (black, white, blue, yellow and red). Two circular pictures of two Chinese men stand in front of each flag. Yuan Shikai (left) and Sun Yat-sen (right) with flags representing the early republic In 1912, after over two thousand years of imperial rule, a republic was established to replace the monarchy.[12] The Qing dynasty that preceded the republic had experienced instability throughout the 19th century and suffered from both internal rebellion and foreign imperialism.[17] A program of institutional reform proved too little and too late. Only the lack of an alternative regime prolonged the monarchy's existence until 1912.[18][19]  The Chinese Republic grew out of the Wuchang Uprising against the Qing government, on 10 October 1911, which is now celebrated annually as the ROC's national day, also known as "Double Ten Day". Sun Yat-sen had been actively promoting revolution from his bases in exile. He now returned and on 29 December 1911, Sun Yat-sen was elected president by the Nanjing assembly, which consisted of representatives from seventeen provinces. On 1 January 1912, he was officially inaugurated and pledged "to overthrow the despotic government led by the Manchu, consolidate the Republic of China and plan for the welfare of the people".[20] Sun's new government lacked military strength. As a compromise, he negotiated with Yuan Shikai the commander of the Beiyang Army, promising Yuan the presidency of the republic if he were to remove the Qing emperor by force. Yuan agreed to the deal, and the last emperor of the Qing Dynasty, Puyi, was forced to abdicate in 1912. Song Jiaoren led the Kuomintang Party to electoral victories by fashioning his party's program to appeal to the gentry, landowners, and merchants. Song was assassinated on 20 March 1913, at the behest of Yuan Shikai.[21]  Yuan was elected president of the ROC in 1913.[17][22] He ruled by military power and ignored the republican institutions established by his predecessor, threatening to execute Senate members who disagreed with his decisions. He soon dissolved the ruling Kuomintang (KMT) party, banned "secret organizations" (which implicitly included the KMT), and ignored the provisional constitution. An attempt at a democratic election in 1912 ended with the assassination of the elected candidate by a man recruited by Yuan. Ultimately, Yuan declared himself Emperor of China in 1915.[23] The new ruler of China tried to increase centralization by abolishing the provincial system; however, this move angered the gentry along with the provincial governors, who were usually military men. Many provinces declared independence and became warlord states. Increasingly unpopular and deserted by his supporters, Yuan abdicated in 1916 and died of natural causes shortly thereafter.[24][25] China then declined into a period of warlordism. Sun, having been forced into exile, returned to Guangdong in the south in 1917 and 1922, with the help of warlords, and set up successive rival governments to the Beiyang government in Beijing, having re-established the KMT in October 1919. Sun's dream was to unify China by launching an expedition against the north. However, he lacked the military support and funding to turn it into a reality.[26]  Meanwhile, the Beiyang government struggled to hold onto power, and an open and wide-ranging debate evolved regarding how China should confront the West. In 1919, a student protest against the government's weak response to the Treaty of Versailles, considered unfair by Chinese intellectuals, led to the May Fourth movement, whose demonstrations were against the danger of spreading Western influence replacing Chinese culture. It was in this intellectual climate that the influence of Marxism spread and became popular, leading to the founding of the Communist Party of China in 1921.[27]  Nanjing decade Main article: Nanjing decade Further information: Nationalist government See also: Northeast Flag Replacement, Central Plains War, Encirclement Campaigns, Mukden Incident, and Xi'an Incident  Major Chinese warlord coalitions during the "Nanjing Decade".  With help from Germany, Chinese industry and its military were improved just prior to the war against Imperial Japan. After Sun's death in March 1925, Chiang Kai-shek became the leader of the Kuomintang. In 1926, Chiang led the Northern Expedition with the intention of defeating the Beiyang warlords and unifying the country. Chiang received the help of the Soviet Union and the Communist Party of China. However, he soon dismissed his Soviet advisers, being convinced that they wanted to get rid of the KMT and take control.[28] Chiang decided to purge the Communists, killing thousands of them. At the same time, other violent conflicts were taking place in China: in the South, where the Communists had superior numbers, Nationalist supporters were being massacred. Such events eventually led to the Chinese Civil War between the Nationalists and Communists. Chiang Kai-shek pushed the Communists into the interior and established a government, with Nanking as its capital, in 1927.[29] By 1928, Chiang's army overthrew the Beiyang government and unified the entire nation, at least nominally, beginning the so-called Nanjing Decade.[citation needed]  According to Sun Yat-sen's theory, the KMT was to rebuild China in three phases: a phase of military rule during which the KMT would take over power and reunite China by force; a phase of political tutelage; and finally a constitutional, democratic phase.[30] In 1930, the Nationalists, having taken power militarily and reunifying China, started the second phase, promulgating a provisional constitution and beginning the period of so-called "tutelage".[31] Criticized for instituting authoritarianism, the KMT claimed it was attempting to establish a modern democratic society. Among other things, it created the Academia Sinica, the Central Bank of China, and other agencies. In 1932, China for the first time sent a team to the Olympic Games. Campaigns were mounted and laws passed to promote the rights of women. The ease and speed of communication facilitated focusing on social problems, especially those of remote villages. The Rural Reconstruction Movement was one of many that took advantage of the new freedom to raise social consciousness.[citation needed] The Nationalist government published a draft constitution on 5 May 1936.[32]  During this time a series of wars took place in western China, including the Kumul Rebellion, the Sino-Tibetan War, and the Soviet Invasion of Xinjiang. Although the central government was nominally in control of the entire country during this period, large areas of China remained under the semi-autonomous rule of local warlords such as Feng Yuxiang and Yan Xishan, provincial military leaders, or warlord coalitions. Nationalist rule was strongest in the eastern regions around the capital Nanjing. The Central Plains War in 1930, the Japanese aggression in 1931, and the Red Army's Long March in 1934 led to more power for the central government, but there continued to be foot-dragging and even outright defiance, as in the Fujian Rebellion of 1933–34.[citation needed]  Historians such as Edmund Fung argue that establishing a democracy in China at that time was not possible. The nation was at war and divided between Communists and Nationalists. Corruption and lack of direction within the government prevented any significant reforms from taking place. Chiang realized the lack of real work being done within his administration and told the State Council: "Our organization becomes worse and worse... many staff members just sit at their desks and gaze into space, others read newspapers and still others sleep."[33]  Second Sino-Japanese War (1937–1945) Main article: Second Sino-Japanese War See also: Marco Polo Bridge Incident, Second United Front, New Fourth Army incident, and Burma Campaign  China had been resisting the Japanese aggression since 1931. Few Chinese had any illusions about Japanese desires on China. Hungry for raw materials and pressed by a growing population, Japan initiated the seizure of Manchuria in September 1931 and established the ex-Qing emperor Puyi as head of the puppet state of Manchukuo in 1932. The loss of Manchuria, and its potential for industrial development and war industries, was a blow to the Kuomintang economy. The League of Nations, established at the end of World War I, was unable to act in the face of Japanese defiance.  The Japanese began to push south of the Great Wall into northern China and the coastal provinces. Chinese fury against Japan was predictable, but anger was also directed against Chiang and the Nanking government, which at the time was more preoccupied with anti-Communist extermination campaigns than with resisting the Japanese invaders. The importance of "internal unity before external danger" was forcefully brought home in December 1936, when Chiang Kai-shek, in an event now known as the Xi'an Incident, was kidnapped by Zhang Xueliang and forced to ally with the Communists against the Japanese in the Second Kuomintang-CPC United Front.  Chinese resistance stiffened after 7 July 1937, when a clash occurred between Chinese and Japanese troops outside Beiping (Later Beijing) near the Marco Polo Bridge. This skirmish led to open, although undeclared, warfare between China and Japan. Shanghai fell after a three-month battle during which Japan suffered extensive casualties in both its army and navy. The capital, Nanking, fell in December 1937, which was followed by mass murders and rapes known as the Nanking Massacre. The national capital was briefly at Wuhan, then removed in an epic retreat to Chongqing, the seat of government until 1945. In 1940, the Japanese set up the collaborationist Wang Jingwei regime, with its capital in Nanking, which proclaimed itself the legitimate "Republic of China" in opposition to Chiang Kai-shek's government, although its claims were significantly hampered due to its being a puppet state controlling limited amounts of territory.   Chinese Nationalist Army soldiers during the 1938 Yellow River flood The United Front between the Kuomintang and the CPC had salutary effects for the beleaguered CPC, despite Japan's steady territorial gains in northern China, the coastal regions and the rich Yangtze River Valley in central China. After 1940, conflicts between the Kuomintang and Communists became more frequent in the areas not under Japanese control. The Communists expanded their influence wherever opportunities presented themselves through mass organizations, administrative reforms and the land- and tax-reform measures favoring the peasants and, the spread of their organizational network, while the Kuomintang attempted to neutralize the spread of Communist influence. Meanwhile, northern China was infiltrated politically by Japanese politicians in Manchukuo using facilities such as the Wei Huang Gong.  After its entry into the Pacific War during World War II, the United States became increasingly involved in Chinese affairs. As an ally, it embarked in late 1941 on a program of massive military and financial aid to the hard-pressed Nationalist Government. In January 1943, both the United States and the United Kingdom led the way in revising their unequal treaties with China from the past.[34][35] Within a few months a new agreement was signed between the United States and the Republic of China for the stationing of American troops in China as part of the common war effort against Japan. The United States sought unsuccessfully to reconcile the rival Kuomintang and Communists, to make for a more effective anti-Japanese war effort. In December 1943, the Chinese Exclusion Acts of the 1880s, and subsequent laws, enacted by the United States Congress to restrict Chinese immigration into the United States were repealed. The wartime policy of the United States was meant to help China become a strong ally and a stabilizing force in postwar East Asia. During the war, China was one of the Big Four Allies of World War II and later one of the Four Policemen, which was a precursor to China having a permanent seat on the United Nations Security Council.[36]  In August 1945, with American help, Nationalist troops moved to take the Japanese surrender in North China. The Soviet Union—encouraged to invade Manchuria to hasten the end of the war and allowed a Soviet sphere of influence there as agreed to at the Yalta Conference in February 1945—dismantled and removed more than half the industrial equipment left there by the Japanese. Although the Chinese had not been present at Yalta, they had been consulted and had agreed to have the Soviets enter the war, in the belief that the Soviet Union would deal only with the Kuomintang government. However, the Soviet presence in northeast China enabled the Communists to arm themselves with equipment surrendered by the withdrawing Japanese army.  Post-World War II Further information: Chinese Civil War, Proclamation of the People's Republic of China, Republic of China retreat to Taiwan, First Taiwan Strait Crisis, and Cross-Strait Relations See also: Political status of Taiwan and One-China policy In 1945, after the end of the war, the Nationalist Government moved back to Nanjing. The Republic of China emerged from the war nominally a great military power but actually a nation economically prostrate and on the verge of all-out civil war. The problems of rehabilitating the formerly Japanese-occupied areas and of reconstructing the nation from the ravages of a protracted war were staggering. The economy deteriorated, sapped by the military demands of foreign war and internal strife, by spiraling inflation, and by Nationalist profiteering, speculation, and hoarding. Starvation came in the wake of the war, and millions were rendered homeless by floods and unsettled conditions in many parts of the country.  On 25 October 1945, following the Surrender of Japan, the administration of Taiwan and Penghu Islands were handed over from Japan to China.[37] After the end of the war, United States Marines were used to hold Beiping (Beijing) and Tianjin against a possible Soviet incursion, and logistic support was given to Kuomintang forces in north and northeast China. To further this end, on 30 September 1945 the 1st Marine Division, charged with maintaining security in the areas of the Shandong Peninsula and the eastern Hebei, arrived in China.[38]  In January 1946, through the mediation of the United States, a military truce between the Kuomintang and the Communists was arranged, but battles soon resumed. Public opinion of the administrative incompetence of the Nationalist government was incited by the Communists during the nationwide student protest against the mishandling of the Shen Chong rape case in early 1947 and during another national protest against monetary reforms later that year. The United States—realizing that no American efforts short of large-scale armed intervention could stop the coming war—withdrew Gen. George Marshall's American mission. Thereafter, the Chinese Civil War became more widespread; battles raged not only for territories but also for the allegiance of sections of the population. The United States aided the Nationalists with massive economic loans and weapons but no combat support.   The Nationalists' retreat to Taipei: after the Nationalists lost Nanjing (Nanking) they next moved to Guangzhou (Canton), then to Chongqing (Chungking), Chengdu (Chengtu) and Xichang (Sichang) before arriving in Taipei. Belatedly, the Republic of China government sought to enlist popular support through internal reforms. However, the effort was in vain, because of rampant government corruption and the accompanying political and economic chaos. By late 1948 the Kuomintang position was bleak. The demoralized and undisciplined National Revolutionary Army proved to be no match for the Communists' motivated and disciplined People's Liberation Army. The Communists were well established in the north and northeast. Although the Kuomintang had an advantage in numbers of men and weapons, controlled a much larger territory and population than their adversaries, and enjoyed considerable international support, they were exhausted by the long war with Japan and in-fighting among various generals. They were also losing the propaganda war to the Communists, with a population weary of Kuomintang corruption and yearning for peace.  In January 1949, Beiping was taken by the Communists without a fight, and its name changed back to Beijing. Following the capture of Nanjing on 23 April, major cities passed from Kuomintang to Communist control with minimal resistance, through November. In most cases the surrounding countryside and small towns had come under Communist influence long before the cities. Finally, on 1 October 1949, Communists led by Mao Zedong founded the People's Republic of China. Chiang Kai-shek declared martial law in May 1949, whilst a few hundred thousand Nationalist troops and two million refugees, predominantly from the government and business community, fled from mainland China to Taiwan. There remained in China itself only isolated pockets of resistance. On 7 December 1949, Chiang proclaimed Taipei, Taiwan, the temporary capital of the Republic of China.  During the Chinese Civil War both the Nationalists and Communists carried out mass atrocities, with millions of non-combatants killed by both sides.[39] Benjamin Valentino has estimated atrocities in the civil war resulted in the death of between 1.8 million and 3.5 million people between 1927 and 1949, including deaths from forced conscription and massacres.[40]  For the history of Republic of China after 1949, see History of Taiwan (1945–present). Government Main article: Government of the Republic of China See also: Provisional Government of the Republic of China (1912), Beiyang government, Warlord era, Nationalist government, and Reorganized National Government of the Republic of China The first Republic of China national government was established on 1 January 1912, in Nanjing, and was founded on the Constitution of the ROC and its Three Principles of the People, which state that "[the ROC] shall be a democratic republic of the people, to be governed by the people and for the people."[41]  Sun Yat-sen was the provisional president. Delegates from the provinces sent to confirm the government's authority formed the first parliament in 1913. The power of this government was limited, with generals controlling both the central and northern provinces of China, and short-lived. The number of acts passed by the government was few and included the formal abdication of the Qing dynasty and some economic initiatives. The parliament's authority soon became nominal: violations of the Constitution by Yuan were met with half-hearted motions of censure. Kuomintang members of parliament who gave up their membership in the KMT were offered 1,000 pounds. Yuan maintained power locally by sending generals to be provincial governors or by obtaining the allegiance of those already in power.  When Yuan died, the parliament of 1913 was reconvened to give legitimacy to a new government. However, the real power passed to military leaders, leading to the warlord period. The impotent government still had its use; when World War I began, several Western powers and Japan wanted China to declare war on Germany, to liquidate German holdings in China.  In February 1928, the Fourth Plenary Session of the 2nd Kuomintang National Congress, held in Nanjing, passed the Reorganization of the Nationalist Government Act. This act stipulated that the Nationalist Government was to be directed and regulated under the Central Executive Committee of the Kuomintang, with the Committee of the Nationalist Government being elected by the KMT Central Committee. Under the Nationalist Government were seven ministries – Interior, Foreign Affairs, Finance, Transport, Justice, Agriculture and Mines, and Commerce, in addition to institutions such as the Supreme Court, Control Yuan, and the General Academy.   Nationalist government of Nanking – nominally ruling over entire China during 1930s With the promulgation of the Organic Law of the Nationalist Government in October 1928, the government was reorganized into five different branches, or yuan, namely the Executive Yuan, Legislative Yuan, Judicial Yuan, Examination Yuan as well as the Control Yuan. The Chairman of the National Government was to be the head-of-state and commander-in-chief of the National Revolutionary Army. Chiang Kai-shek was appointed as the first chairman, a position he would retain until 1931. The Organic Law also stipulated that the Kuomintang, through its National Congress and Central Executive Committee, would exercise sovereign power during the period of "political tutelage", that the KMT's Political Council would guide and superintend the Nationalist Government in the execution of important national affairs, and that the Political Council has the power to interpret or amend the Organic Law.[42]  Shortly after the Second Sino-Japanese War, a long-delayed constitutional convention was summoned to meet in Nanking in May 1946. Amidst heated debate, this convention adopted many constitutional amendments demanded by several parties, including the KMT and the Communist Party, into the Constitution. This Constitution was promulgated on 25 December 1946 and came into effect on 25 December 1947. Under it, the Central Government was divided into the presidency and the five yuans, each responsible for a part of the government. None was responsible to the other except for certain obligations such as the president appointing the head of the Executive Yuan. Ultimately, the president and the yuans reported to the National Assembly, which represented the will of the citizens.  Under the new constitution the first elections for the National Assembly occurred in January 1948, and the Assembly was summoned to meet in March 1948. It elected the President of the Republic on 21 March 1948, formally bringing an end to the KMT party rule started in 1928, although the President was a member of the KMT. These elections, though praised by at least one US observer, were poorly received by the Communist Party, which would soon start an open, armed insurrection.  Foreign relations See also: Foreign relations of China and Foreign relations of Taiwan Before the Nationalist government was ousted from the mainland, the Republic of China had diplomatic relations with 59 countries, such as Australia, Canada, Cuba, Czechoslovakia, Estonia, France, Germany, Guatemala, Honduras, Italy, Japan, Latvia, Lithuania, Norway, Panama, Siam, Soviet Union, Spain, the United Kingdom, the United States, and Vatican City. Most of these relations continued at least until the 1970s, and the Republic of China remained a member of the United Nations until 1971.  Administrative divisions Main article: History of the administrative divisions of China (1912–49)  Rand McNally map of the Republic of China in 1914, after Mongolia declared its independence     Map of the first-level administrative divisions of the Republic of China in law (1945)  Provinces and Equivalents of the Republic of China (1945)[43] Period Name (Current Name)	Traditional Chinese	Pinyin	Abbreviation	Capital	Chinese	Modern equivalent (if applicable) Provinces Antung (Andong)	安東	Āndōng	安 ān	Tunghwa (Tonghua)	通化	[note 1] Anhwei (Anhui)	安徽	Ānhuī	皖 wǎn	Hofei (Hefei)	合肥	 Chahar (Chahar)	察哈爾	Cháhār	察 chá	Changyuan (Zhangjiakou)	張垣(張家口)	[note 2] Chekiang (Zhejiang)	浙江	Zhèjiāng	浙 zhè	Hangchow (Hangzhou)	杭州	 Fukien (Fujian)	福建	Fújiàn	閩 mǐn	Foochow (Fuzhou)	福州	 Hopeh (Hebei)	河北	Héběi	冀 jì	Tsingyuan (Baoding)	清苑(保定)	 Heilungkiang (Heilongjiang)	黑龍江	Hēilóngjiāng	黑 hēi	Peian (Bei'an)	北安	 Hokiang (Hejiang)	合江	Héjiāng	合 hé	Chiamussu (Jiamusi)	佳木斯	[note 3] Honan (Henan)	河南	Hénán	豫 yù	Kaifeng (Kaifeng)	開封	 Hupeh (Hubei)	湖北	Húběi	鄂 è	Wuchang (Wuchang)	武昌	 Hunan (Hunan)	湖南	Húnán	湘 xiāng	Changsha (Changsha)	長沙	 Hsingan (Xing'an)	興安	Xīng'ān	興 xīng	Hailar (Hulunbuir)	海拉爾(呼倫貝爾)	[note 4] Jehol (Rehe)	熱河	Rèhé	熱 rè	Chengteh (Chengde)	承德	[note 5] Kansu (Gansu)	甘肅	Gānsù	隴 lǒng	Lanchow (Lanzhou)	蘭州	 Kiangsu (Jiangsu)	江蘇	Jiāngsū	蘇 sū	Chingkiang (Zhenjiang)	鎮江	 Kiangsi (Jiangxi)	江西	Jiāngxī	贛 gàn	Nanchang (Nanchang)	南昌	 Kirin (Jilin)	吉林	Jílín	吉 jí	Kirin (Jilin)	吉林	 Kwangtung (Guangdong)	廣東	Guǎngdōng	粵 yuè	Canton (Guangzhou)	廣州	 Kwangsi (Guangxi)	廣西	Guǎngxī	桂 guì	Kweilin (Guilin)	桂林	 Kweichow (Guizhou)	貴州	Guìzhōu	黔 qián	Kweiyang (Guiyang)	貴陽	 Liaopeh (Liaobei)	遼北	Liáoběi	洮 táo	Liaoyuan (Liaoyuan)	遼源	[note 6] Liaoning (Liaoning)	遼寧	Liáoníng	遼 liáo	Shenyang (Shenyang)	瀋陽	 Ningsia (Ningxia)	寧夏	Níngxià	寧 níng	Yinchuan (Yinchuan)	銀川	 Nunkiang (Nenjiang)	嫩江	Nènjiāng	嫩 nèn	Tsitsihar (Qiqihar)	齊齊哈爾	[note 7] Shansi (Shanxi)	山西	Shānxī	晉 jìn	Taiyuan (Taiyuan)	太原	 Shantung (Shandong)	山東	Shāndōng	魯 lǔ	Tsinan (Jinan)	濟南	 Shensi (Shaanxi)	陝西	Shǎnxī	陝 shǎn	Sian (Xi'an)	西安	 Sikang (Xikang)	西康	Xīkāng	康 kāng	Kangting (Kangding)	康定	[note 8] Sinkiang (Xinjiang)	新疆	Xīnjiāng	新 xīn	Tihwa (Ürümqi)	迪化(烏魯木齊)	 Suiyuan (Suiyuan)	綏遠	Suīyuǎn	綏 suī	Kweisui (Hohhot)	歸綏(呼和浩特)	[note 9] Sungkiang (Songjiang)	松江	Sōngjiāng	松 sōng	Mutankiang (Mudanjiang)	牡丹江	[note 10] Szechwan (Sichuan)	四川	Sìchuān	蜀 shǔ	Chengtu (Chengdu)	成都	 Taiwan (Taiwan)	臺灣	Táiwān	臺 tái	Taipei	臺北	 Tsinghai (Qinghai)	青海	Qīnghǎi	青 qīng	Sining (Xining)	西寧	 Yunnan (Yunnan)	雲南	Yúnnán	滇 diān	Kunming (Kunming)	昆明	 Special Administrative Region Hainan (Hainan)	海南	Hǎinán	瓊 qióng	Haikow (Haikou)	海口	 Regions Mongolia Area (Outer Mongolia)	蒙古	Ménggǔ	蒙 méng	Kulun (now Ulaanbaatar)	庫倫	[note 11] Tibet Area (Tibet)	西藏	Xīzàng	藏 zàng	Lhasa	拉薩	 Special Municipalities Nanking (Nanjing)	南京	Nánjīng	京 jīng	(Chinhuai District)	秦淮區	 Shanghai (Shanghai)	上海	Shànghǎi	滬 hù	(Huangpu District)	黄浦區	 Harbin (Harbin)	哈爾濱	Hā'ěrbīn	哈 hā	(Nangang District)	南崗區	 Mukden (Shenyang)	瀋陽	Shěnyáng	瀋 shěn	(Shenhe District)	瀋河區	 Dairen (Dalian)	大連	Dàlián	連 lián	(Xigang District)	西崗區	 Peiping or Peking (Beijing)	北平	Běipíng	平 píng	(Xicheng District)	西城區	 Tientsin (Tianjin)	天津	Tiānjīn	津 jīn	(Heping District)	和平區	 Chungking (Chongqing)	重慶	Chóngqìng	渝 yú	(Yuzhong District)	渝中區	 Hankow (Hankou, Wuhan)	漢口	Hànkǒu	漢 hàn	(Jiang'an District)	江岸區	 Canton (Guangzhou)	廣州	Guǎngzhōu	穗 suì	(Yuexiu District)	越秀區	 Sian (Xi'an)	西安	Xī'ān	安 ān	(Weiyang District)	未央區	 Tsingtao (Qingdao)	青島	Qīngdǎo	膠 jiāo	(Shinan District)	市南區	  Now part of Jilin and Liaoning  Now part of Inner Mongolia and Hebei  Now part of Heilongjiang  Now part of Heilongjiang and Jilin  Now part of Hebei, Liaoning, and Inner Mongolia  Now mostly part of Inner Mongolia  The province was abolished in 1950 and incorporated into Heilongjiang province.  Now part of Tibet and Sichuan  Now part of Inner Mongolia  Now part of Heilongjiang  Now part of the State of Mongolia. As the successor of the Qing dynasty, the Nationalist government claimed Outer Mongolia, and for a short time under the Beiyang government occupied it. The Nationalist government recognised Mongolia's independence in the 1945 Sino-Soviet Treaty of Friendship due to pressure from the Soviet Union but that recognition was rescinded in 1953 during the Cold War.[44] Nobility Main article: Chinese nobility The Republic of China retained hereditary nobility like the Han Chinese nobles Duke Yansheng and Celestial Masters and Tusi chiefdoms like the Chiefdom of Mangshi, Chiefdom of Yongning, who continued possessing their titles in the Republic of China from the previous dynasties.  Military Main articles: Beiyang Army and National Revolutionary Army  Beiyang Army troops on parade The military power of the Republic of China was inherited from the New Army, mainly the Beiyang Army, which later split into many factions and attacked each other.[45] The National Revolutionary Army was established by Sun Yat-sen in 1925 in Guangdong with the goal of reunifying China under the Kuomintang. Originally organized with Soviet aid as a means for the KMT to unify China against warlordism, the National Revolutionary Army fought many major engagements: in the Northern Expedition against Beiyang Army warlords, in the Second Sino-Japanese War against the Imperial Japanese Army, and in the Chinese Civil War against the People's Liberation Army.[citation needed]   The NRA during World War II During the Second Sino-Japanese War, the armed forces of the Communist Party of China were nominally incorporated into the National Revolutionary Army, while remaining under separate command, but broke away to form the People's Liberation Army shortly after the end of the war. With the promulgation of the Constitution of the Republic of China in 1947 and the formal end of the KMT party-state, the National Revolutionary Army was renamed the Republic of China Armed Forces, with the bulk of its forces forming the Republic of China Army, which retreated to Taiwan in 1949 after their defeat in the Chinese Civil War. Units which surrendered and remained in mainland China were either disbanded or incorporated into the People's Liberation Army.[46]  Economy Main article: Economic history of China (1912–49)  Boat traffic and development along Suzhou Creek, Shanghai, 1920  A 10 Custom Gold Units bill, 1930 In the early years of the Republic of China, the economy remained unstable as the country was marked by constant warfare between different regional warlord factions. The Beiyang government in Beijing experienced constant changes in leadership, and this political instability led to stagnation in economic development until Chinese reunification in 1928 under the Kuomintang.[47] After this reunification, China entered a period of relative stability—despite ongoing isolated military conflicts and in the face of Japanese aggression in Shandong and Manchuria, in 1931—a period known as the "Nanjing Decade".  Chinese industries grew considerably from 1928 to 1931. While the economy was hit by the Japanese occupation of Manchuria in 1931 and the Great Depression from 1931 to 1935, industrial output recovered to their earlier peak by 1936. This is reflected by the trends in Chinese GDP. In 1932, China's GDP peaked at 28.8 billion, before falling to 21.3 billion by 1934 and recovering to 23.7 billion by 1935.[48] By 1930, foreign investment in China totaled 3.5 billion, with Japan leading (1.4 billion) followed by the United Kingdom (1 billion). By 1948, however, the capital investment had halted and dropped to only 3 billion, with the US and Britain being the leading investors.[49]  However, the rural economy was hit hard by the Great Depression of the 1930s, in which an overproduction of agricultural goods lead to falling prices for China as well as an increase in foreign imports (as agricultural goods produced in western countries were "dumped" in China). In 1931, Chinese imports of rice amounted to 21 million bushels compared with 12 million in 1928. Other imports saw even more increases. In 1932, 15 million bushels of grain were imported compared with 900,000 in 1928. This increased competition lead to a massive decline in Chinese agricultural prices and thus the income of rural farmers. In 1932, agricultural prices were at 41 percent of 1921 levels.[50] By 1934, rural incomes had fallen to 57 percent of 1931 levels in some areas.[50]  In 1937, Japan invaded China and the resulting warfare laid waste to China. Most of the prosperous east coast was occupied by the Japanese, who committed atrocities such as the Nanjing massacre. In one anti-guerilla sweep in 1942, the Japanese killed up to 200,000 civilians in a month. The war was estimated to have killed between 20 and 25 million Chinese, and destroyed all that Chiang had built up in the preceding decade.[51] Development of industries was severely hampered after the war by devastating civil conflict as well as the inflow of cheap American goods. By 1946, Chinese industries operated at 20% capacity and had 25% of the output of pre-war China.[52]  One effect of the war with Japan was a massive increase in government control of industries. In 1936, government-owned industries were only 15% of GDP. However, the ROC government took control of many industries to fight the war. In 1938, the ROC established a commission for industries and mines to supervise and control firms, as well as instilling price controls. By 1942, 70% of Chinese industry was owned by the government.[53]  Following the war with Japan, Chiang acquired Taiwan from Japan and renewed his struggle with the communists. However, the corruption of the KMT, as well as hyperinflation as a result of trying to fight the civil war, resulted in mass unrest throughout the Republic[54] and sympathy for the communists. In addition, the communists' promise to redistribute land gained them support among the large rural population. In 1949, the communists captured Beijing and later Nanjing. The People's Republic of China was proclaimed on 1 October 1949. The Republic of China relocated to Taiwan where Japan had laid an educational groundwork.[55]  See also flag	China portal flag	Taiwan portal Economic history of China (1912–49) Project National Glory Sino-German cooperation 1926–1941 Sino-Soviet relations Notes  Modified version used in 1921–1928.  Both Outer Mongolia and Tibet formed part of the de jure territory of the ROC and were internationally recognized as such. The ROC established de facto rule over Outer Mongolia between 1919 and 1921.  From 23 April 1949, the government was evacuated to Canton, Chungking and Chengtu in the mainland before declaring Taipei as its temporary capital on 7 December 1949. Chengtu was captured on 27 December.  As wartime provisional capital during the Second Sino-Japanese War.  Wuchang uprising started.  The last monarch of the Qing dynasty, Xuantong Emperor abdicated, Qing dynasty formally ended.  Chinese Communist Revolution.  Marco Polo Bridge Incident started.  Surrender of Japan at the end of World War II.  Left hand drive until 1946.  Although this is the present meaning of guó, in Old Chinese (when its pronunciation was something like /*qʷˤək/)[8] it meant the walled city of the Chinese and the areas they could control from them.[9]  Its use is attested from the 6th-century Classic of History, which states "Huangtian bestowed the lands and the peoples of the central state to the ancestors" (皇天既付中國民越厥疆土于先王).[10] References Citations  Dreyer, June Teufel (17 July 2003). The Evolution of a Taiwanese National Identity. Woodrow Wilson International Center for Scholars. Retrieved 13 January 2018.  司法院釋字第76號解釋, Judicial Yuan interpretation number 76 (English translation)  "中華民國九十四年年鑑：第一篇 總論 第二章 土地 第二節 大陸地區". Government Information Office, Executive Yuan, Republic of China. Archived from the original on 29 March 2012. Retrieved 5 December 2020.  "Exploring Chinese History :: Database Catalog :: Biographical Database :: Republican Era- (1912– 1949)".  Joachim, Martin D. (1993). Languages of the World: Cataloging Issues and Problems. ISBN 9781560245209.  "The abdication decree of Emperor Puyi (1912)". Chinese Revolution. 4 June 2013. Retrieved 22 May 2021.  Organic Law of the National Government of the Republic of China. China. 1 January 1928.  Baxter-Sagart.  Wilkinson, Endymion (2000), Chinese History: A Manual, Harvard-Yenching Institute Monograph No. 52, Cambridge: Harvard University Asia Center, p. 132, ISBN 978-0-674-00249-4  《尚書》, 梓材. (in Chinese)  Wright (2018).  China, Fiver thousand years of History and Civilization. City University Of Hong Kong Press. 2007. p. 116. ISBN 9789629371401. Retrieved 9 September 2014.  Roy, Denny (2004). Taiwan: A Political History. Ithaca, New York: Cornell University Press. pp. 55, 56. ISBN 0-8014-8805-2.  "Taiwan Timeline – Retreat to Taiwan". BBC News. 2000. Retrieved 21 June 2009.  China: U.S. policy since 1945. Congressional Quarterly. 1980. ISBN 0-87187-188-2. the city of Taipei became the temporary capital of the Republic of China  "Introduction to Sovereignty: A Case Study of Taiwan". Stanford Program on International and Cross-Cultural Education. 2004. Retrieved 25 February 2010.  "The Chinese Revolution of 1911". US Department of State. Retrieved 27 October 2016.  Fenby 2009, pp. 89–94  Fairbank; Goldman (1972). China. p. 235. ISBN 0-690-07612-6.  Jonathan Fenby, The Penguin History of Modern China (2013) p. 123.  Jonathan Fenby, "The silencing of Song." History Today (March 2013 (63#3 pp 5–7.  Fenby 2009, pp. 123–125  Fenby 2009, p. 131  Fenby 2009, pp. 136–138  Meyer, Kathryn; James H Wittebols; Terry Parssinen (2002). Webs of Smoke. Rowman & Littlefield. pp. 54–56. ISBN 0-7425-2003-X.  Pak, Edwin; Wah Leung (2005). Essentials of Modern Chinese History. Research & Education Assoc. pp. 59–61. ISBN 978-0-87891-458-6.  Guillermaz, Jacques (1972). A History of the Chinese Communist Party 1921–1949. Taylor & Francis. pp. 22–23.  Fenby 2009  "民國十六年，國民政府宣言定為首都，今以臺北市為我國中央政府所在地。" (in Chinese). Ministry of Education, ROC. Retrieved 22 December 2012.  Edmund S. K. Fung. In Search of Chinese Democracy: Civil Opposition in Nationalist China, 1929–1949 (Cambridge; New York: Cambridge University Press, 2000. ISBN 0521771242), p. 30.  Chen, Lifu; Ramon Hawley Myers (1994). Hsu-hsin Chang, Ramon Hawley Myers (ed.). The storm clouds clear over China: the memoir of Chʻen Li-fu, 1900–1993. Hoover Press. p. 102. ISBN 0-8179-9272-3. After the 1930 mutiny ended, Chiang accepted the suggestion of Wang Ching-wei, Yen Hsi-shan, and Feng Yü-hsiang that a provisional constitution for the political tutelage period be drafted.  Jing Zhiren (荆知仁). 中华民国立宪史 (in Chinese). 联经出版公司.  (Fung 2000, p. 5) "Nationalist disunity, political instability, civil strife, the communist challenge, the autocracy of Chiang Kai-shek, the ascendancy of the military, the escalating Japanese threat, and the "crisis of democracy" in Italy, Germany, Poland, and Spain, all contributed to a freezing of democracy by the Nationalist leadership."  Sino-U.S. Treaty for Relinquishment of Extraterritorial Rights in China  Sino-British Treaty for the Relinquishment of Extra-Territorial Rights in China  Urquhart, Brian. Looking for the Sheriff. New York Review of Books, 16 July 1998.  Brendan M. Howe (2016). Post-Conflict Development in East Asia. Routledge. p. 71. ISBN 9781317077404.  Jessup, John E. (1989). A Chronology of Conflict and Resolution, 1945–1985. New York: Greenwood Press. ISBN 0-313-24308-5.  Rummel, Rudolph (1994), Death by Government.  Valentino, Benjamin A. Final solutions: mass killing and genocide in the twentieth century Cornell University Press. 8 December 2005. p88  "The Republic of China Yearbook 2008 / CHAPTER 4 Government". Government Information Office, Republic of China (Taiwan). 2008. Retrieved 28 May 2009.[dead link]  Wilbur, Clarence Martin. The Nationalist Revolution in China, 1923–1928. Cambridge University Press, 1983, p. 190.  National Institute for Compilation and Translation of the Republic of China (Taiwan): Geography Textbook for Junior High School Volume 1 (1993 version): Lesson 10: pp. 47–49.  1945年「外モンゴル独立公民投票」をめぐる中モ外交交渉 (in Japanese).  Schillinger, Nicolas (2016). The Body and Military Masculinity in Late Qing and Early Republican China: The Art of Governing Soldiers. Lexington Books. p. 2. ISBN 978-1498531689.  Westad, Odd (2003). Decisive Encounters: The Chinese Civil War, 1946–1950. Stanford University Press. p. 305. ISBN 978-0-8047-4484-3. last major GMD stronghold.  Sun Jian, pages 613–614[citation needed]  Sun Jian, pg 1059–1071  Sun Jian, pg 1353  Sun Jian, page 1089  Sun Jian, page 615-616  Sun Jian, page 1319  Sun Jian, pg 1237–1240  Sun Jian, page 617-618  Gary Marvin Davison (2003). A short history of Taiwan: the case for independence. Praeger Publishers. p. 64. ISBN 0-275-98131-2. Basic literacy came to most of the school-aged populace by the end of the Japanese tenure on Taiwan. School attendance for Taiwanese children rose steadily throughout the Japanese era, from 3.8 percent in 1904 to 13.1 percent in 1917; 25.1 percent in 1920; 41.5 percent in 1935; 57.6 percent in 1940; and 71.3 percent in 1943. Sources For works on specific people and events, please see the relevant articles. Boorman, Howard, et al., eds.,Biographical Dictionary of Republican China. (New York: Columbia University Press, 4 vols, 1967–1971). 600 articles. Available online at Internet Archive. Botjer, George F. (1979). A short history of Nationalist China, 1919–1949. Putnam. p. 180. ISBN 9780399123825. Fenby, Jonathan (2009). The Penguin History of Modern China: The Fall and Rise of a Great Power, 1850–2008. London: Penguin. Harrison, Henrietta (2001). China. London: Arnold; New York: Oxford University Press. ISBN 0340741333.. In the series "Inventing the Nation." Jowett, Philip. (2013) China's Wars: Rousing the Dragon 1894–1949 (Bloomsbury Publishing, 2013). Leung, Edwin Pak-wah. Historical Dictionary of Revolutionary China, 1839-1976 (1992) online free to borrow Leung, Edwin Pak-wah. Political Leaders of Modern China: A Biographical Dictionary (2002) Li, Xiaobing. (2007) A History of the Modern Chinese Army excerpt Li, Xiaobing. (2012) China at War: An Encyclopedia excerpt Mitter, Rana (2004). A Bitter Revolution: China's Struggle with the Modern World. Oxford; New York: Oxford University Press. ISBN 0192803417. Sheridan, James E. (1975). China in Disintegration : The Republican Era in Chinese History, 1912-1949. New York: Free Press. ISBN 0029286107. Taylor, Jay (2009). The Generalissimo: Chiang Kai-Shek and the Struggle for Modern China. Cambridge, MA: Belknap Press of Harvard University Press. ISBN 9780674033382. van de Ven, Hans (2017). China at War: Triumph and Tragedy in the Emergence of the New China, 1937-1952. London: Profile Books Limited. ISBN 9781781251942. Vogel, Ezra F. China and Japan: Facing History (2019) excerpt Westad, Odd Arne. Restless Empire: China and the World since 1750 (2012) Online free to borrow Wilbur, Clarence Martin. Sun Yat-sen, frustrated patriot (Columbia University Press, 1976), a major scholarly biography online Historiography Yu, George T. "The 1911 Revolution: Past, Present, and Future," Asian Survey, 31#10 (1991), pp. 895–904, online historiography Wright, Tim (2018). "Republican China, 1911–1949". Chinese Studies. Oxford Bibliographies. Oxford University Press. doi:10.1093/OBO/9780199920082-0028. ISBN 9780199920082. External links  Chinese Revolutionary Destinations travel guide from Wikivoyage  Media related to Republic of China (1912–1949) at Wikimedia Commons vte China articles History	 TimelineAncient China (outline) (2070–221 BCE)Imperial China (political systems) (221 BC – 1912 AD)Modern China (1912 AD – present) Republic (1912–1949)People's Republic (1949–present) 1949–19761976–19891989–20022002–presentChronology Hundred Days' Reform1911 RevolutionWorld War IKuomintangNew Culture MovementSecond Sino-Japanese WarChinese Communist RevolutionProclamation of the People's Republic of ChinaKorean WarSino-Soviet splitCultural RevolutionReform and openingSino-Vietnamese War1989 ProtestsChinese space programOne country, two systems Geography	 BordersExtreme pointsGeologyNatural disastersRegions EastNortheastNorthSouth Central CentralSouthWestern NorthwestSouthwest Terrain	 BaysCanyonsCavesDesertsGrasslandsHillsIslandsMountains rangespassesPeninsulasNortheast / North / Central PlainsValleysVolcanoes Water	 CanalsLakesRiversWaterfallsWetlandsWater resourcesSeas BohaiYellowEast ChinaSouth China Ecosystem	 Protected areasNational parksNature reservesUNESCO Biosphere ReservesWildlife FaunaFlora Subdivisions	 Baseline islandsBorder crossingsCitiesProvince-level subdivisions Politics	 Law	 Judicial systemHuman rights LGBTTibetMacaoHong KongLaw enforcementNaming lawsNationality lawPenal system Government	 Civil serviceConstitutionElectionsEnvironmental policyForeign relationsNational People's Congress Standing CommitteeNational securityPolitical parties and movements Chinese Communist Party General SecretaryPolitburoDemocratic PartiesAnti-democratisationPro-democratisationPresident Vice PresidentState Council PremierVice Premier Military	 Central Military CommissionMinistry of National DefensePeople's Liberation Army GroundNavyAirRocketStrategic SupportPeople's Armed Police Coast GuardMilitia Maritime Militia Economy	 AgricultureBanking Central bankEconomic historyEnergyFinance systemForeign aid receivedForeign aid programHistorical GDPPovertyReformRenminbi (currency)Science and technology historySpecial Economic Zones (SEZs)Standard of livingTaxation in premodern ChinaTelecommunicationsTourismTransport Airlines Culture	 ArchaeologyArchivesArtCinemaCuisineDanceGardensInternetLibrariesMartial artsMediaMusicParksPhilosophyReligionSmokingSportsTea cultureTourismVariety artsHistorical and Cultural Site World Heritage SitesLiterature Society	 AnthemChinese DreamCorruptionCrimeEmblemEducationFlag"Generation Y"Harmonious Socialist SocietyHIV/AIDSIntellectualismLanguagesPopulation historyPovertyProstitutionPublic health food safety incidentsPublic holidaysRural lifeSex traffickingSexualitySocialism with Chinese characteristicsSocial issuesSocial relationsSocial structureSocial welfareSuicideTerrorismTime zonesRacismUrban lifeWater supply and sanitationWomenXiaokangPrimary stage of socialism Demographics	 EmigrationEthnic groupsEunuchsInternal migrationStatisticsUrbanization Outline CategoryPortal vte Taiwan articles vte Beiyang star.svg Warlord Era and warlordism during the Nanjing decade Emblem of the Kuomintang.svg Authority control Edit this at Wikidata Categories: Republic of China (1912–1949)History of the Republic of China1912 establishments in China1949 disestablishments in China20th century in ChinaFormer polities of the Cold WarStates and territories established in 1912States and territories disestablished in 1949Former republics Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadEditView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikiversity  Languages العربية Български Deutsch Ελληνικά Español Français Türkçe اردو 中文 46 more Edit links This page was last edited on 9 October 2021, at 06:15 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki   Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more East Asia From Wikipedia, the free encyclopedia Jump to navigationJump to search For other uses, see East Asia (disambiguation). East Asia East Asia (orthographic projection).svg Area	11,840,000 km2 (4,570,000 sq mi) (3rd) Population	1.6 billion (2020; 4th) Population density	141.9/km2 (54.8/sq mi) GDP (PPP)	$37 trillion (2021)[1] GDP (nominal)	$25.6 trillion (2021)[2] GDP per capita	$16,000 (nominal)[2] Demonym	East Asian Countries	 6 states[3][4][5][6] Dependencies	 2 autonomous dependencies Languages	Chinese, Japanese, Korean, Mongolian, Tibetan, Others Time zones	UTC+7, UTC+8 & UTC+9 Largest cities	List of urban areas:[7] BeijingShanghaiTokyoSeoulYokohama PyongyangUlaanbaatarTaipeiHong KongMacauShenzhenOsaka UN M49 code	030 – Eastern Asia 142 – Asia 001 – World East Asia Chinese name Simplified Chinese	东亚/东亚细亚 Traditional Chinese	東亞/東亞細亞 Transcriptions   Tibetan name Tibetan	ཨེ་ཤ་ཡ་ཤར་མ་ Korean name Hangul	동아시아/동아세아/동아 Hanja	東아시아/東亞細亞/東亞 Transcriptions   Mongolian name Mongolian Cyrillic	Зүүн Ази ᠵᠡᠭᠦᠨ ᠠᠽᠢ Transcriptions   Japanese name Kana	ひがしアジア/とうあ Kyūjitai	東亞細亞/東亞 Shinjitai	東亜細亜（東アジア）/東亜 Transcriptions   Uyghur name Uyghur	شەرقىي ئاسىي‎ Transcriptions   East Asia, sometimes defined geographically as Northeast Asia[8] and abbreviated as EA or NEA, is along with Southeast Asia located at the far eastern regions of Asia, which is defined in both geographical and ethno-cultural terms.[9][10]  The modern states of East Asia include China, Japan, Mongolia, North Korea, South Korea, and Taiwan.[3][4][5][6] China, North Korea, South Korea and Taiwan are all unrecognized by at least one other East Asian state due to severe ongoing political tensions in the region, specifically the division of Korea and the political status of Taiwan. Hong Kong and Macau, two small coastal quasi-dependent territories located in the south of China, are officially highly autonomous but are under de jure Chinese sovereignty. East Asia borders Siberia and the Russian Far East to the north, Southeast Asia to the south, South Asia to the southwest, and Central Asia to the west. To the east is the Pacific Ocean and to the southeast is Micronesia (a Pacific Ocean island group, classified as part of Oceania).  East Asia, especially Chinese civilization, is regarded as one of the earliest cradles of civilization. Other ancient civilizations in East Asia that still exist as independent countries in the present day include the Japanese, Korean and Mongolian civilizations. Various other civilizations existed in East Asia in the past but have since been absorbed into neighbouring civilizations in the present day, such as Tibet, Baiyue, Manchuria and Ryukyu, among many others. Taiwan has a relatively young history in the region after the prehistoric era; originally, it was a major site of Austronesian civilization prior to colonization by European colonial powers and China from the 17th century onward. For thousands of years, China was the leading civilization in the region, exerting influence on its neighbors.[11][12][13] Historically, societies in East Asia have fallen within the Chinese sphere of influence, and East Asian vocabulary and scripts are often derived from Classical Chinese and Chinese script. The Chinese calendar serves as the root from which many other East Asian calendars are derived. Major religions in East Asia include Buddhism (mostly Mahayana[14]), Confucianism and Neo-Confucianism, Taoism, Ancestral worship, and Chinese folk religion in Mainland China, Hong Kong, Macau and Taiwan, Shintoism in Japan, and Christianity, and Sindoism in Korea.[15][16][17] Tengerism and Tibetan Buddhism are prevalent among Mongols and Tibetans while other religions such as Shamanism are widespread among the indigenous populations of northeastern China such as the Manchus.[18][19][20] Major languages in East Asia include Mandarin Chinese, Japanese, and Korean. Major ethnic groups of East Asia include the Han (mainland China, Hong Kong, Macau, Taiwan), Yamato (Japan) and Koreans (North Korea, South Korea). Mongols, although not as populous as the previous three ethnic groups, constitute the majority of Mongolia's population. There are 76 officially-recognized minority or indigenous ethnic groups in East Asia; 55 native to mainland China (including Hui, Manchus, Chinese Mongols, Tibetans, Uyghurs and Zhuang in the frontier regions), 16 native to the island of Taiwan (collectively known as Taiwanese indigenous peoples), one native to the major Japanese island of Hokkaido (the Ainu) and four native to Mongolia (Turkic peoples). Ryukyuan people are an unrecognised ethnic group indigenous to the Ryukyu Islands in southern Japan, which stretch from Kyushu Island (Japan) to Taiwan. There are also several unrecognised indigenous ethnic groups in mainland China and Taiwan.  East Asian people comprise around 1.7 billion people, making up about 38% of the population in Continental Asia and 20.5% of the global population.[21][22][23] The region is home to major world metropolises such as Beijing, Hong Kong, Seoul, Shanghai, Taipei, and Tokyo. Although the coastal and riparian areas of the region form one of the world's most populated places, the population in Mongolia and Western China, both landlocked areas, is very sparsely distributed, with Mongolia having the lowest population density of a sovereign state. The overall population density of the region is 133 inhabitants per square kilometre (340/sq mi), about three times the world average of 45/km2 (120/sq mi).[when?][citation needed]  East Asia has some of the world's largest and most prosperous economies: Mainland China, Japan, South Korea, Taiwan, Hong Kong, and Macau.[24]   Contents 1	History 2	Definitions 2.1	Alternative definitions 3	Economy 4	Territorial and regional data 4.1	Etymology 4.2	Demographics 4.3	Ethnic groups 5	East Asian culture 5.1	Overview 5.2	Religions 5.3	Festivals 6	Collaboration 6.1	East Asian Youth Games 6.2	Free trade agreements 6.3	Military alliances 7	Major cities 8	See also 9	Notes 10	References 11	Further reading 12	External links History Main article: History of East Asia China was the first region settled in East Asia and was undoubtedly the core of East Asian civilization from where other parts of East Asia were formed.[25] The various other regions in East Asia were selective in the Chinese influences they adopted into their local customs. Historian Ping-ti Ho famously labeled Chinese civilization as the "Cradle of Eastern Civilization", in parallel with the "Cradle of Middle Eastern Civilization" along the Fertile Crescent encompassing Mesopotamia and Ancient Egypt[26] as well as the Cradle of Western Civilization encompassing Ancient Greece [a] and Ancient Rome [b]  Chinese civilization existed for about 1500 years before other East Asian civilizations emerged into history, Imperial China would exert much of its cultural, economic, technological, and political muscle onto its neighbors.[43][44][45][46] Succeeding Chinese dynasties exerted enormous influence across East Asia culturally, economically, politically and militarily for over two millennia.[46][47][48] The Imperial Chinese tributary system shaped much of East Asia's history for over two millennia due to Imperial China's economic and cultural influence over the region, and thus played a huge role in the history of East Asia in particular.[49][50][45] Imperial China's cultural preeminence not only led the country to become East Asia's first literate nation in the entire region, it also supplied Japan and Korea with Chinese loanwords and linguistic influences rooted in their writing systems.[51]  Under Emperor Wu of Han, the Han dynasty made China the regional power in East Asia, projecting much of its imperial power on its neighbors.[46][52] Han China hosted the largest unified population in East Asia, the most literate and urbanized as well as being the most economically developed, as well as the most technologically and culturally advanced civilization in the region at the time.[53][54] Cultural and religious interaction between the Chinese and other regional East Asian dynasties and kingdoms occurred. China's impact and influence on Korea began with the Han dynasty's northeastern expansion in 108 BC when the Han Chinese conquered the northern part of the Korean peninsula and established a province called Lelang. Chinese influence would soon take root in Korea through the inclusion of the Chinese writing system, monetary system, rice culture, and Confucian political institutions.[55] Jomon society in ancient Japan incorporated wet-rice cultivation and metallurgy through its contact with Korea. Starting from the fourth century AD, Japan incorporated the Chinese writing system which evolved into Kanji by the fifth century AD and has become a significant part of the Japanese writing system.[56] Utilizing the Chinese writing system allowed the Japanese to conduct their daily activities, maintain historical records and give form to various ideas, thoughts, and philosophies.[57] During the Tang dynasty, China exerted its greatest influence on East Asia as various aspects of Chinese culture spread to Japan and Korea.[58][59] As full-fledged medieval East Asian states were established, Korea by the fourth century AD and Japan by the seventh century AD, Japan and Korea actively began to incorporate Chinese influences such as Confucianism, the use of written Han characters, Chinese style architecture, state institutions, political philosophies, religion, urban planning, and various scientific and technological methods into their culture and society through direct contacts with Tang China and succeeding Chinese dynasties.[58][59][60] Drawing inspiration from the Tang political system, Prince Naka no oe launched the Taika Reform in 645 AD where he radically transformed Japan's political bureaucracy into a more centralized bureaucratic empire.[61] The Japanese also adopted Mahayana Buddhism, Chinese style architecture, and the imperial court's rituals and ceremonies, including the orchestral music and state dances had Tang influences. Written Chinese gained prestige and aspects of Tang culture such as poetry, calligraphy, and landscape painting became widespread.[61] During the Nara period, Japan began to aggressively import Chinese culture and styles of government which included Confucian protocol that served as a foundation for Japanese culture as well as political and social philosophy.[62][63] The Japanese also created laws adopted from the Chinese legal system that was used to govern in addition to the kimono, which was inspired from the Chinese robe (hanfu) during the eighth century AD.[64] For many centuries, most notably from the 7th to the 14th centuries, China stood as East Asia's most advanced civilization and foremost military and economic power exerting its influence as the transmission of advanced Chinese cultural practices and ways of thinking greatly shaped the region up until the nineteenth century.[65][66][67][68]  As East Asia's connections with Europe and the Western world strengthened during the late nineteenth century, China's power began to decline.[43][69] By the mid-nineteenth century, the weakening Qing dynasty became fraught with political corruption, obstacles and stagnation that was incapable of rejuvenating itself as a world power in contrast to the industrializing Imperial European colonial powers and a rapidly modernizing Japan.[70][71] The U.S. Commodore Matthew C. Perry would open Japan to Western ways, and the country would expand in earnest after the 1860s.[72][73][74] Around the same time, Japan with its rush to modernity transformed itself from an isolated feudal samurai state into East Asia's first industrialized nation in the modern era.[75][76][73] The modern and militarily powerful Japan would galvanize its position in the Orient as East Asia's greatest power with a global mission poised to advance to lead the entire world.[75][77] By the early 1900s, the Japanese empire succeeded in asserting itself as East Asia's most dominant power.[77] With its newly found international status, Japan would begin to challenge the European colonial powers and inextricably took on a more active geopolitical position in East Asia and world affairs at large.[78] Flexing its nascent political and military might, Japan soundly defeated the stagnant Qing dynasty during the First Sino-Japanese War as well as vanquishing imperial rival Russia in 1905; the first major military victory in the modern era of an East Asian power over a European one.[79][80][81][82][72] Its hegemony was the heart of an empire that would include Taiwan and Korea.[75] During World War II, Japanese expansionism with its imperialist aspirations through the Greater East Asia Co-Prosperity Sphere would incorporate Korea, Taiwan, much of eastern China and Manchuria, Hong Kong, and Southeast Asia under its control establishing itself as a maritime colonial power in East Asia.[83] After a century of exploitation by the European and Japanese colonialists, post-colonial East Asia saw the defeat and occupation of Japan by the victorious Allies as well as the division of China and Korea during the Cold War. The Korean peninsula became independent but then it was divided into two rival states, while Taiwan became the main territory of de facto state Republic of China after the latter lost Mainland China to the People's Republic of China in the Chinese Civil War. During the latter half of the twentieth century, the region would see the post war economic miracle of Japan, which ushered in three decades of unprecedented growth, only to experience an economic slowdown during the 1990s, but nonetheless Japan continues to remain a global economic power. East Asia would also see the economic rise of South Korea and Taiwan, and the integration of Mainland China into the global economy through its entry in the World Trade Organization while enhancing its emerging international status as a potential world power.[3][84][85] Although there have been no wars in East Asia for decades, the stability of the region remains fragile because of North Korea's nuclear program.  Definitions  Three sets of possible boundaries for the Central Asia region that overlap with conceptions of East Asia In common usage, the term "East Asia" typically refers to a region including Greater China, Japan, and Korea.[86][87][88][89][21][90][91][92][93][94][85]  China, Japan, and Korea represent the three core countries and civilizations of traditional East Asia - as they once shared a common written language, culture, as well as sharing Confucian philosophical tenets and the Confucian societal value system once instituted by Imperial China.[95][96][97][98][99] Other usages define Mainland China, Hong Kong, Macau, Japan, North Korea, South Korea and Taiwan as countries that constitute East Asia based on their geographic proximity as well as historical and modern cultural and economic ties, particularly with Japan and Korea having strong cultural influences that originated from China.[95][99][100][101][102][103] Some scholars include Vietnam as part of East Asia as it has been considered part of the greater Chinese sphere of influence. Though Confucianism continues to play an important role in Vietnamese culture, Chinese characters are no longer used in its written language and many scholarly organizations classify Vietnam as a Southeast Asian country.[104][105][106] Mongolia is geographically north of Mainland China yet Confucianism and the Chinese writing system and culture had limited impact on Mongolian society. Thus, Mongolia is sometimes grouped with Central Asian countries such as Turkmenistan, Kyrgyzstan, and Kazakhstan.[104][105] Xinjiang (East Turkestan) and Tibet are sometimes seen as part of Central Asia.[107][108][109]  Broader and looser definitions by international organizations such as the World Bank refer to the "three major Northeast Asian economies, i.e. Mainland China, Japan, and South Korea", as well as Mongolia, North Korea, the Russian Far East and Siberia.[110] The Council on Foreign Relations includes the Russia Far East, Mongolia, and Nepal.[111] The World Bank also acknowledges the roles of sub-national or de facto states, such as Hong Kong, Macau, and Taiwan. The Economic Research Institute for Northeast Asia defines the region as "China, Japan, the Koreas, Nepal, Mongolia, and eastern regions of the Russian Federation".[112]   The countries of East Asia also form the core of Northeast Asia, which itself is a broader region.  East Asia map of Köppen climate classification.  UNSD geoscheme for Asia based on statistic convenience rather than implying any assumption regarding political or other affiliation of countries or territories:[113]   North Asia   Central Asia   Western Asia   South Asia   East Asia   Southeast Asia The UNSD definition of East Asia is based on statistical convenience,[113] but also other common definitions of East Asia contain the Mainland China, Hong Kong, Macau, Mongolia, North Korea, South Korea, Taiwan and Japan.[9][114]  Alternative definitions In business and economics, "East Asia" is sometimes used to refer to the geographical area covering ten Southeast Asian countries in ASEAN, Greater China, Japan and Korea. However, in this context, the term "Far East" is used by the Europeans to cover ASEAN countries and the countries in East Asia. However, being a Eurocentric term, Far East describes the region's geographical position in relation to Europe rather than its location within Asia. Alternatively, the term "Asia Pacific Region" is often used in describing East Asia, Southeast Asia as well as Oceania.[citation needed]  Observers preferring a broader definition of "East Asia" often use the term Northeast Asia to refer to China, the Korean Peninsula, and Japan, with Southeast Asia covering the ten ASEAN countries as well as the island of Taiwan. This usage is often seen in economic and diplomatic discussions.[115][116][117] The Council on Foreign Relations of the United States defines Northeast Asia as Japan and Korea.[111]  Economy Main article: Economy of East Asia Customs territory	GDP nominal billions of USD (2021)[1]	GDP nominal per capita USD (2021)[1]	GDP PPP billions of USD (2021)[1]	GDP PPP per capita USD (2021)[1]  China	16,642.318	11,819	26,656.766	17,205.654  Hong Kong[118]	368.633	49,036	472.395	58,165.200  Macau[119]	39.449	58,004	61.623	58,930.534  Japan	5,378.136	42,928	5,585.786	41,636.628  Mongolia	14.233	4,172	42.412	12,259.059  North Korea	N/A	N/A	N/A	N/A  South Korea	1,806.707	34,866	2,436.875	44,292.194  Taiwan[c]	759.104	32,123	1,403.663	54,019.882 East Asia	$25,008.58	$14,858	$36,659.52	$21,779.585 Territorial and regional data Etymology Flag	Common Name	Official Name	ISO 3166 Country Codes[120] Exonym	Endonym	Exonym	Endonym	ISO Short Name	Alpha-2 Code	Alpha-3 Code	Numeric 	China	中国	People's Republic of China	中华人民共和国	China	CN	CHN	156 	Hong Kong	香港	Hong Kong Special Administrative Region of the People's Republic of China	中華人民共和國香港特別行政區	Hong Kong	HK	HKG	344 	Macau	澳門	Macao Special Administrative Region of the People's Republic of China	中華人民共和國澳門特別行政區	Macao	MO	MAC	446 	Japan	日本	Japan	日本国	Japan	JP	JPN	392 	Mongolia	Монгол улс / ᠮᠣᠩᠭᠣᠯ ᠤᠯᠤᠰ	Mongolia	Монгол Улс（ᠮᠣᠩᠭᠣᠯ ᠤᠯᠤᠰ）	Mongolia	MN	MNG	496 	North Korea	조선	Democratic People's Republic of Korea	조선민주주의인민공화국	Korea (the Democratic People's Republic of)	KP	PRK	408 	South Korea	한국	Republic of Korea	대한민국	Korea (the Republic of)	KR	KOR	410 	Taiwan[121]	臺灣 / 台灣	Republic of China	中華民國	Taiwan [122]	TW	TWN	158 Demographics State/Territory	Area km2	Population[123][124] (2018)	Population density per km2	HDI[125]	Capital/Administrative Center  China	9,640,011[d]	1,427,647,786[e]	138	0.761	Beijing  Hong Kong	1,104	7,371,730	6,390	0.949	Hong Kong  Macau	30	631,636	18,662	0.914	Macao  Japan	377,930	127,202,192	337	0.919	Tokyo  Mongolia	1,564,100	3,170,216	2	0.737	Ulaanbaatar  North Korea	120,538	25,549,604	198	0.733	Pyongyang[126]  South Korea	100,210	51,171,706	500	0.916	Seoul  Taiwan	36,197		639	0.916	Taipei[127] East Asia	11,840,000	1,683,205,624	141	Increase0.856 (very high) Ethnic groups Main articles: East Asian people and Ethnic groups of East Asia Ethnicity	Native name	Population	Language(s)	Writing system(s)	Major states/territories*	Traditional attire Han/Chinese	漢族 or 汉族	1,313,345,856[128]	Chinese (Mandarin, Min, Wu, Yue, Jin, Gan, Hakka, Xiang, Huizhou, Pinghua, etc.)	Simplified Han characters, Traditional Han characters	China (Hong KongMacau) Taiwan Japan South Korea	 Hanfu man and lady.jpg Yamato/Japanese	大和民族	125,117,000[129]	Japanese	Han characters (Kanji), Katakana, Hiragana	Japan	 Shinto married couple.jpg Korean	조선족 (朝鮮族) 한민족 (韓民族)	79,432,225[citation needed]	Korean	Hangul, Han characters (Hanja)	South Korea North Korea China Japan	 Hanbok (female and male).jpg Bai	白族	1,858,063	Bai, Southwestern Mandarin	Simplified Han characters, Latin script	China	 Bai 5.JPG Hui	回族	10,586,087[citation needed]	Northwestern Mandarin, other Chinese Dialects, Huihui language, etc.	Simplified Han characters[f]	China	 HuiChineseMuslim3.jpg Mongols	Монголчууд ᠮᠣᠩᠭᠣᠯᠴᠤᠳ Монгол/ᠮᠣᠩᠭᠣᠯ	8,942,528	Mongolian	Mongol script, Cyrillic script	Mongolia China Russia	 Mongolian Musician.jpg Zhuang	壮族/Bouxcuengh	18,000,000	Zhuang, Southwestern Mandarin, etc.	Simplified Han characters, Latin script	China	 Zhuang's beautiful maiden in Chongzuo Fusui.jpg Uyghurs	维吾尔族/ئۇيغۇر	15,000,000+[130]	Uyghur	Arabic alphabet, Latin script	China[g]	 Uyghur-elders-sunday-market-Kashgar.jpg Manchus	满族/ᠮᠠᠨᠵᡠ	10,422,873[citation needed]	Northeastern Mandarin, Manchu language	Simplified Han characters, Mongol script	China	 Akšan.jpg Hmong/Miao	苗族/Ghaob Xongb/Hmub/Mongb	9,426,007[citation needed]	Hmong/Miao, Southwestern Mandarin	Latin script, Simplified Han characters	China	 贵州黔东南苗族女性（a Miao woman in Qiandongnan，Guizhou）.jpg Tibetans	藏族/བོད་པ་	6,500,000	Tibetan, Rgyal Rong, Rgu, etc.	Tibetan script	China	 People of Tibet46.jpg Yi	彝族/ꆈꌠ	8,714,393	Various Loloish, Southwestern Mandarin	Yi script, Simplified Han characters	China	 Ethnic Yi China Costume.jpg Tujia	土家族	8,353,912	Northern Tujia, Southern Tujia	Simplified Han characters	China	 Tujia women.jpg Kam	侗族/Gaeml	2,879,974	Gaeml	Simplified Han characters, Latin script	China	 Ethic Dong Liping Guizhou China.jpg Tu	土族/Monguor	289,565	Tu, Northwestern Mandarin	Simplified Han characters	China	 Nadun Picture 1.jpg Daur	达斡尔族/ᠳᠠᠭᠤᠷ	131,992	Daur, Northeastern Mandarin	Mongol script, Simplified Han characters	China Mongolia	 Daur woman smiling.jpg Indigenous Taiwanese Peoples	臺灣原住民/ 高山族/ Yincomin/ Kasetaivang/ Inanuwayan	533,600	Austronesian languages (Amis, Yami), etc.	Latin script, Traditional Han characters	Taiwan	 Tao1.jpg Ryukyuan	琉球民族	1,900,000	Japanese Ryukyuan	Han characters (Kanji), Katakana, Hiragana	Japan Taiwan	 Five men wearing Ryukyuan Dress.JPG Ainu	アイヌ/ Aynu/ Айну	200,000	Japanese Ainu[131]	Han characters (Kanji), Katakana, Hiragana	Japan	 AinuSan.jpg Note: The order of states/territories follows the population ranking of each ethnicity, within East Asia only. East Asian culture Main article: Culture of East Asia Main category: East Asian culture Overview The culture of East Asia has largely been influenced by China, as it was the civilization that had the most dominant influence in the region throughout the ages that ultimately laid the foundation for East Asian civilization.[132] The vast knowledge and ingenuity of Chinese civilization and the classics of Chinese literature and culture were seen as the foundations for a civilized life in East Asia. Imperial China served as a vehicle through which the adoption of Confucian ethical philosophy, Chinese calendar system, political and legal systems, architectural style, diet, terminology, institutions, religious beliefs, imperial examinations that emphasized a knowledge of Chinese classics, political philosophy and cultural value systems, as well as historically sharing a common writing system reflected in the histories of Japan and Korea.[133][46][134][135][136][137][138][139][99] The Imperial Chinese tributary system was the bedrock of network of trade and foreign relations between China and its East Asian tributaries, which helped to shape much of East Asian affairs during the ancient and medieval eras. Through the tributary system, the various dynasties of Imperial China facilitated frequent economic and cultural exchange that influenced the cultures of Japan and Korea and drew them into a Chinese international order.[140][141] The Imperial Chinese tributary system shaped much of East Asia's foreign policy and trade for over two millennia due to Imperial China's economic and cultural dominance over the region, and thus played a huge role in the history of East Asia in particular.[50][141] The relationship between China and its cultural influence on East Asia has been compared to the historical influence of Greco-Roman civilization on Europe and the Western World.[137][135][141][133]  Religions Main article: East Asian religions Religion	Native name	Creator/Current Leader	Founded Time	Main Denomination	Major book	Type	Est. Followers	Ethnic groups	States/territories Chinese folk religion	中國民間信仰 or 中国民间信仰	Spontaneous formation	5000 years from now[citation needed]	Salvationist, Wuism, Nuo	Chinese classics, Huangdi Sijing, precious scrolls, etc.	Prehistoric，pantheism，and polytheism	~900,000,000[142][143]	Han, Hmong, Qiang, Tujia (worship of the same ancestor-gods)	China (Hong Kong Macau) Taiwan Taoism	道教	Zhang Daoling, was considered the founder of Taoism by Taoists. He founded Zhengyi, the earlist denomination of Taoism. Zhang Daoling reformed the Chinese folk religion from Szechuan, into a real, organised, and regulated religion, in 125A.D.. Wang Chongyang founded the Quanzhen Denomination. Tale says Wang Chongyang met two Gods, Lü Dongbin and Han Zhongli, during Jin dynasty (1115–1234) in 1159. He then get started to study Taoism himself. Three years later, he finished his studying, and founded Quanzhen. The new leader of Zhengyi need to be the son or paternal nephew of the previous leader, confirmed by the court of Zhengyi, in Mount Longhu, Jiangxi. Also beginning from the Song Dynasty, the leaders of Zhengyi get started to be confirmed and titled by the Emperor of China. In 1949, the 63th leader, Zhang Enfu, fled to Taiwan with Chiang Kai-shek, leader of the Kuomintang, died in 1969 in Taipei. The Kuomintang Authority titled his cousin Zhang Yuanxian as the 64th leader, while the Court of Zhengyi back in Jiangxi argued that the oracle already foreseen the leadership will end at the 63th generation. Zhang Yuanxian died in 2008, only left a daughter as heir. Meanwhile, the Kuomintang Authority didn't confirmed the next leader. On the other hand, in Mainland China, Zhang Enfu's second daughter's son, Lu Jintao, changes his surname to Zhang, and get in charge of the Court of Zhengyi currently. For the leader of Quanzhen, the last (18th) leader (1335-1362) was Wanyan Deming, titled by the Emperor of Yuan Dynasty. Wanyan Deming was a Jurchen Taoist, the Wanyan family was the imperial house of Jin Dynasty. There is no official leader of Quanzhen after Wanyan Deming anymore.[citation needed]	125 A.D. Eastern Han dynasty[citation needed]	Zhengyi, Quanzhen	Tao Te Ching	Pantheism, polytheism	~20,000,000[143]	Han, Zhuang, Hmong, Yao, Qiang, Tujia	China (Hong Kong Macau) Taiwan East Asian Buddhism/Chinese Buddhism	漢傳佛教 or 汉传佛教	The Emperor of the Eastern Han Dynasty, Liu Zhuang, made a dream about the Buddha occasionally, then sent people to the Western Regions to Introduce Buddhism to the Capital, Chang'an, in 67 A.D. In 384 A.D., during the Eastern Jin dynasty, Indian Mālānanda introduced the Chinese Buddhism to Baekje. In 552 A.D., King Seong of Baekje offered Buddhism to the Emperor Kinmei of Japan.[citation needed]	67 A.D. Eastern Han dynasty	Mahayana	Diamond Sutra	Non-God, Dualism.	~300,000,000	Han, Korean, Yamato	China (Hong Kong Macau) Japan North Korea South Korea Taiwan Tibetan Buddhism	藏传佛教/བོད་བརྒྱུད་ནང་བསྟན།	Tonpa Shenrab Miwoche, Prince of the Ancient Xang Xung Kingdom.	1800 years ago	Mahayana, Bon	Anuttarayoga Tantra	Non-God	~10,000,000	Tibetans, Manchus, Mongols	China Mongolia Shamanism[h]	萨满教 or Бөө мөргөл	Spontaneous formation	Prehistoric period		N/A	Prehistoric, polytheism, and pantheism	N/A	Manchus, Mongols, Oroqen	China Mongolia Shintoism	神道	Spontaneous formation	Jōmon period	Shinto sects	Kojiki, Nihon Shoki	Prehistoric，pantheism，and polytheism	N/A	Yamato	Japan Shindo/Muism	신도 or 무교	Spontaneous formation	900 years ago	Shindo sects	N/A	Prehistoric，pantheism，and polytheism	N/A	Korean	North Korea South Korea Ryukyuan religion	琉球神道 or ニライカナイ信仰	Spontaneous formation	N/A	N/A	N/A	Prehistoric，pantheism，and polytheism	N/A	Ryukyuan	Japan (Okinawa Prefecture) Festivals  This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (November 2020) (Learn how and when to remove this template message) Festival	Native Name	Other name	Calendar	Date	Gregorian date	Activity	Religious practices	Food	Major ethnicities	Major states/territories Lunar New Year	農曆新年/农历新年 or 春節/春节	Spring Festival	Chinese	Month 1 Day 1	21 Jan–20 Feb	Family Reunion, Ancestors Worship, Tomb Sweeping, Fireworks	Worship the King of Gods	Jiaozi	Han, Manchus etc.	China (Hong Kong Macau) Mongolia Taiwan Korean New Year	설날 or 설	Seollal	Korean	Month 1 Day 1	21 Jan–20 Feb	Ancestors Worship, Family Reunion, Tomb Sweeping	N/A	Tteokguk	Korean	North Korea South Korea Losar or Tsagaan Sar	藏历新年/ལོ་གསར་ or 查干萨日/Цагаан сар	White Moon	Tibetan, Mongolian	Month 1 Day 1	25 Jan – 2 Mar	Family Reunion, Ancestors Worship, Tomb Sweeping, Fireworks	N/A	Chhaang or Buuz	Tibetans, Mongols, Tu etc.	China Mongolia New Year	元旦	Yuan Dan	Gregorian	1 Jan	1 Jan	Fireworks	N/A	N/A	N/A	China (Hong Kong Macau) Japan Mongolia North Korea South Korea Taiwan Lantern Festival	元宵節 or 元宵节	Upper Yuan Festival (上元节)	Chinese	Month 1 Day 15	4 Feb – 6 Mar	Lanterns Expo, Ancestors Worship, Tomb Sweeping	Birthdate of the God of Sky-officer	Yuanxiao	Han	China (Hong Kong Macau) Taiwan Daeboreum	대보름 or 정월 대보름	Great Full Moon	Korean	Month 1 Day 15	4 Feb – 6 Mar	Greeting of the moon, kite-flying, Jwibulnori, eating nuts (Bureom)	Bonfires (daljip taeugi)	Ogok-bap, namul, nuts	Korean	North Korea South Korea Hanshi Festival	寒食節 or 寒食节	Cold Food Festival	Solar term	Traditionally, on the 105th day after the Winter solstice. Revised to 1 day before the Qingming Festival by Johann Adam Schall von Bell (Chinese: 汤若望) during the Qing dynasty.	April 3–5	Ancestors Worship, Tomb Sweeping, No cooking hot meal/setting fire, Cold food only. Cuju, etc. (People used to mix this one with the Qingming Festival due to their close dates)	In Memory of a loyal Ancient named Jie Zhitui (Chinese: 介子推), ordered by the Monarch of the Jin (Chinese state), Duke Wen of Jin (Chinese: 重耳)	Cold Food, e.g. Qingtuan	Han, Korean, Mongols	China (Hong Kong Macau) North Korea South Korea Taiwan Qingming Festival	清明節 or 清明节	Tomb Sweeping Day	Solar term	15th day after the Vernal Equinox. Just 1 day after the Hanshi Festival, but in much higher repute.	April 4-6th	Ancestors Worship, Tomb Sweeping, Excursion, Planting trees, Flying kites, Tug of war, Cuju, etc. (Almost the same with the Hanshi Festival's, due to their close dates)	Burning Hell money for deceased family members. Planting willow brances to keep ghosts away from houses.	Boiled eggs	Han, Korean, Mongols	China (Hong Kong Macau) North Korea South Korea Taiwan Dragon Boat Festival	端午節 or 端午节 or 단오	Duanwu Festival / Dano (Surit-nal)	Chinese / Korean	Month 5 Day 5		Driving poisons & plague away. (China - Dragon Boat Race, Wearing colored lines, Hanging felon herb on the front door.) / (Korea - Washing hair with iris water, ssireum)	Worship various Gods	Zongzi / Surichwitteok (rice cake with herbs)	Han, Korean, Yamato	China (Hong Kong Macau) North Korea South Korea Japan Taiwan Ghost Festival	中元節 or 中元节 or 백중	Mid Yuan Festival	Chinese	Month 7 Day 15		Ancestors Worship, Tomb Sweeping	Birthdate of the God of Earth-officer		Han, Korean, Yamato	China (Hong Kong Macau) North Korea South Korea Japan Taiwan Mid-Autumn Festival	中秋節 or 中秋节	中秋祭	Chinese	Month 8 Day 15		Family Reunion, Enjoying Moon view	Worship the Moon Goddess	Mooncake	Han	China (Hong Kong Macau) Taiwan Chuseok	추석 or 한가위	Hangawi	Korean	Month 8 Day 15		Family Reunion, Ancestors Worship, Tomb Sweeping, Enjoying Moon view	N/A	Songpyeon, Torantang (Taro soup)	Korean	North Korea South Korea Tsukimi	月見 or お月見	Tsukimi or Otsukimi	Gregorian	Month 8 Day 15		Family Reunion, Enjoying Moon view	Worship the Moon	Tsukimi Dango, Sweet Potato	Yamato	Japan * Double Ninth Festival	重陽節 or 重阳节	Double Positive Festival	Chinese	Month 9 Day 09		Climbing Mountain, Taking care of elderly, Wearing Cornus.	Worship various Gods		Han, Korean, Yamato	China (Hong Kong Macau) North Korea South Korea Japan Taiwan* Lower Yuan Festival	下元節 or 下元节	N/A	Chinese	Month 10 Day 15		Ancestors Worship, Tomb Sweeping	Birthdate of the God of Water-officer	Ciba	Han	China (Hong Kong Macau) Taiwan Dongzhi Festival	冬至 or 동지 or 冬至	N/A	Gregorian	Between Dec 21 and Dec 23	Between Dec 21 and Dec 23	Ancestors Worship, Rites to dispel bad spirits	N/A	Tangyuan, Patjuk, Zenzai, Kabocha	Han, Korean, Yamato	China (Hong Kong Macau) North Korea South Korea Japan Taiwan Small New Year	小年	Jizao (祭灶)	Chinese	Month 12 Day 23		Cleaning Houses	Worship the God of Hearth	tanggua	Han, Mongols	China (Hong Kong Macau) Mongolia Taiwan *Japan switched the date to the Gregorian calendar after the Meiji Restoration. *Not always on that Gregorian date, sometimes April 4.  Collaboration East Asian Youth Games  This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (November 2020) (Learn how and when to remove this template message) Main article: East Asian Youth Games Formerly the East Asian Games, it is a multi-sport event organised by the East Asian Games Association (EAGA) and held every four years since 2019 among athletes from East Asian countries and territories of the Olympic Council of Asia (OCA), as well as the Pacific island of Guam, which is a member of the Oceania National Olympic Committees.  It is one of five Regional Games of the OCA. The others are the Central Asian Games, the Southeast Asian Games (SEA Games), the South Asian Games and the West Asian Games.  Free trade agreements  This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (November 2020) (Learn how and when to remove this template message) Name of agreement	Parties	Leaders at the time	Negotiation begins	Signing date	Starting time	Current status China–South Korea FTA	China South Korea	Xi Jinping, Park Geun-hye	May, 2012	Jun 01, 2015	Dec 30, 2015	Enforced China–Japan–South Korea FTA	China Japan South Korea	Xi Jinping, Shinzō Abe, Park Geun-hye	Mar 26, 2013	N/A	N/A	10 round negotiation Japan-Mongolia EPA	Japan Mongolia	Shinzō Abe, Tsakhiagiin Elbegdorj	-	Feb 10, 2015	-	Enforced China-Mongolia FTA	China Mongolia	Xi Jinping, Tsakhiagiin Elbegdorj	N/A	N/A	N/A	Officially proposed China-HK CEPA	China Hong Kong	Jiang Zemin, Tung Chee-hwa	-	Jun 29, 2003	-	Enforced China-Macau CEPA	China Macau	Jiang Zemin, Edmund Ho Hau-wah	-	Oct 18, 2003	-	Enforced Hong Kong-Macau CEPA	Hong Kong Macau	Carrie Lam, Fernando Chui	Oct 09, 2015	N/A	N/A	Negotiating ECFA	China Taiwan	Hu Jintao, Ma Ying-jeou	Jan 26, 2010	Jun 29, 2010	Aug 17, 2010	Enforced CSSTA (Based on ECFA)	China Taiwan	Xi Jinping, Ma Ying-jeou	Mar, 2011	Jun 21, 2013	N/A	Abolished CSGTA (Based on ECFA)	China Taiwan	Hu Jintao, Ma Ying-jeou	Feb 22, 2011	N/A	N/A	Suspended Military alliances Name	Abbr.	Parties within the region Shanghai Cooperation Organisation	SCO	China (Hong Kong Macau) Russia General Security of Military Information Agreement	GSOMIA	Japan South Korea Sino-North Korean Mutual Aid and Cooperation Friendship Treaty	-	China (Hong Kong Macau) North Korea Treaty of Mutual Cooperation and Security between the United States and Japan	-	United States Japan Mutual Defense Treaty Between the United States and the Republic of Korea	-	United States South Korea Taiwan Relations Act (Sino-American Mutual Defense Treaty before 1980)	TRA (SAMDT)	United States Taiwan Major non-NATO ally (Global Partners of NATO)	-	NATO United States Japan South Korea Taiwan[144] Major cities Main article: Cities of East Asia vteLargest population centres of East Asia [145][146] Rank	City name	Country	Pop.	 Tokyo Skyline20210123.jpg Tokyo Seoul (South Korea).jpg Seoul  1	Tokyo	Japan	38,140,000	Pudong Shanghai November 2017 panorama.jpg Shanghai Beijing skyline from northeast 4th ring road (cropped).jpg Beijing  2	Seoul	South Korea	25,520,000 3	Shanghai	China	24,484,000 4	Beijing	China	21,240,000 5	Osaka	Japan	20,337,000 6	Chongqing	China	13,744,000 7	Guangzhou	China	13,070,000 8	Tianjin	China	11,558,000 9	Shenzhen	China	10,828,000 10	Chengdu	China	10,104,000   Tokyo is the capital of Japan and one of the largest cities in the world, both in metropolitan population and economy.     Taipei is the capital, financial centre of Taiwan and anchors a major high-tech industrial area in Taiwan.     Seoul is the capital of South Korea, leading global technology hub.     Shanghai is the largest city in China.     Beijing is the capital of the People's Republic of China.     Osaka is the second largest metropolitan area in Japan.     Guangzhou is one of the most important cities in southern China. It has a history of over 2,200 years and was a major terminus of the maritime Silk Road and continues to serve as a major port and transportation hub today.     Nagoya is the third largest metropolitan area in Japan. Nagoya is famous as the location of Lexus headquarters.     Kyoto was the imperial capital of Japan for eleven centuries.     Ulaanbaatar is the capital of Mongolia with a population of 1 million as of 2008.     Hong Kong is one of the global financial centres and is known as a cosmopolitan metropolis.     Pyongyang is the capital of North Korea, and is a metropolis on the Korean Peninsula.     Xi'an or Chang'an is the oldest of the Four Great Ancient Capitals of China, having held the position under several of the most important dynasties. It has a significant cultural influence in East Asia.    File:Pass over Eastern Asia to Philippine Sea and Guam.ogv Pass of the ISS over Mongolia, looking out west towards the Pacific Ocean, China, and Japan. As the video progresses, you can see major cities along the coast and the Japanese islands on the Philippine Sea. The island of Guam can be seen further down the pass into the Philippine Sea, and the pass ends just to the east of New Zealand. A lightning storm can be seen as light pulses near the end of the video.  See also icon	Geography portal icon	Asia portal China–Japan–South Korea trilateral summit East Asia Summit East Asia–United States relations East Asian Community East Asian languages East Asian studies East Asian cultural sphere Notes  See[27][28][29][30][31][32][33][34][35][36][37]  [38][39][40][41][42]  listed as "Taiwan Province of China" by the IMF  Includes all area which under PRC's government control (excluding "South Tibet" and disputed islands).  A note by the United Nations: "For statistical purposes, the data for China do not include Hong Kong and Macao, Special Administrative Regions (SAR) of China, and Taiwan Province of China."  The Hui people also use the Arabic alphabet in the religious field.  The Khotons also in Mongolia.  almost Manchu, Mongolian References  "World Economic Outlook Database, October 2020". IMF.  "World Economic Outlook Database". International Monetary Fund. October 2020. Retrieved 10 November 2020.  Kort, Michael (2005). The Handbook Of East Asia. Lerner Publishing Group. p. 7. ISBN 978-0761326724.  "East Asia". rand.org. RAND Corporation. Retrieved 12 August 2021.  "Tasks of German foreign policy-East Asia" (PDF). auswaertiges-amt.de. German Federal Foreign Office. May 2002. Retrieved 12 August 2021.  "Countries of Asia". nationsonline.org. Nations Online. Retrieved 12 August 2021.  "Demographia.com" (PDF).  "Northeast Asia". un.org. United Nations.  "East Asia". Encarta. Microsoft. Archived from the original on 2009-10-31. Retrieved 2008-01-12. the countries and regions of Mainland China, Hong Kong, Macau, Taiwan, Mongolia, South Korea, North Korea and Japan.  Miller, David Y. (2007). Modern East Asia: An Introductory History. Routledge. pp. xxi–xxiv. ISBN 978-0765618221.  Zaharna, R.S.; Arsenault, Amelia; Fisher, Ali (2013). Relational, Networked and Collaborative Approaches to Public Diplomacy: The Connective Mindshift (1st ed.). Routledge (published 2013-05-01). p. 93. ISBN 978-0415636070.  Holcombe, Charles (2017). A History of East Asia: From the Origins of Civilization to the Twenty-First Century. Cambridge University Press. p. 13. ISBN 978-1107544895.  Szonyi, Michael (2017). A Companion to Chinese History. Wiley-Blackwell. p. 90. ISBN 978-1118624609.  Selin, Helaine (2010). Nature Across Cultures: Views of Nature and the Environment in Non-Western Cultures. Springer. p. 350. ISBN 978-9048162710.  Salkind, Neil J. (2008). Encyclopedia of Educational Psychology. Sage Publications. p. 56. ISBN 978-1412916882.  Kim, Chongho (2003). Korean Shamanism: The Cultural Paradox. Ashgate. ISBN 9780754631859.  Andreas Anangguru Yewangoe, "Theologia crucis in Asia", 1987 Rodopi  Heissig, Walther (2000). The Religions of Mongolia. Translated by Samuel, Geoffrey. Kegan Paul International. p. 46. ISBN 9780710306852.  Elliott (2001), p. 235.  Shirokogorov (1929), p. 204.  Spinosa, Ludovico (2007). Wastewater Sludge. Iwa Publishing. p. 57. ISBN 978-1843391425.  Wang, Yuchen; Lu Dongsheng; Chung Yeun-Jun; Xu Shuhua (2018). "Genetic structure, divergence and admixture of Han Chinese, Japanese and Korean populations". Hereditas. 155: 19. doi:10.1186/s41065-018-0057-5. PMC 5889524. PMID 29636655.  Wang, Yuchen; Lu, Dongsheng; Chung, Yeun-Jun; Xu, Shuhua (2018). "Genetic structure, divergence and admixture of Han Chinese, Japanese and Korean populations". Hereditas (published April 6, 2018). 155: 19. doi:10.1186/s41065-018-0057-5. PMC 5889524. PMID 29636655.  "East Asia in the 21st Century | Boundless World History". courses.lumenlearning.com. Retrieved 2019-11-25.  Walker, Hugh Dyson (2012-11-20). East Asia: A New History. AuthorHouse. ISBN 978-1-4772-6517-8.  Holcombe, Charles (2017-01-11). A History of East Asia. Cambridge University Press. ISBN 978-1-107-11873-7.  Maura Ellyn; Maura McGinnis (2004). Greece: A Primary Source Cultural Guide. The Rosen Publishing Group. p. 8. ISBN 978-0-8239-3999-2.  John E. Findling; Kimberly D. Pelle (2004). Encyclopedia of the Modern Olympic Movement. Greenwood Publishing Group. p. 23. ISBN 978-0-313-32278-5.  Wayne C. Thompson; Mark H. Mullin (1983). Western Europe, 1983. Stryker-Post Publications. p. 337. ISBN 9780943448114. for ancient Greece was the cradle of Western culture ...  Frederick Copleston (1 June 2003). History of Philosophy Volume 1: Greece and Rome. A&C Black. p. 13. ISBN 978-0-8264-6895-6. PART I PRE-SOCRATIC PHILOSOPHY CHAPTER II THE CRADLE OF WESTERN THOUGHT:  Mario Iozzo (2001). Art and History of Greece: And Mount Athos. Casa Editrice Bonechi. p. 7. ISBN 978-88-8029-435-1. The capital of Greece, one of the world's most glorious cities and the cradle of Western culture,  Marxiano Melotti (25 May 2011). The Plastic Venuses: Archaeological Tourism in Post-Modern Society. Cambridge Scholars Publishing. p. 188. ISBN 978-1-4438-3028-7. In short, Greece, despite having been the cradle of Western culture, was then an “other” space separate from the West.  Library Journal. 97. Bowker. April 1972. p. 1588. Ancient Greece: Cradle of Western Culture (Series), disc. 6 strips with 3 discs, range: 44–60 fr., 17–18 min  Stanley Mayer Burstein (2002). Current Issues and the Study of Ancient History. Regina Books. p. 15. ISBN 978-1-930053-10-6. and making Egypt play the same role in African education and culture that Athens and Greece do in Western culture.  Murray Milner, Jr. (8 January 2015). Elites: A General Model. John Wiley & Sons. p. 62. ISBN 978-0-7456-8950-0. Greece has long been considered the seedbed or cradle of Western civilization.  Slavica viterbiensia 003: Periodico di letterature e culture slave della Facoltà di Lingue e Letterature Straniere Moderne dell'Università della Tuscia. Gangemi Editore spa. 10 November 2011. p. 148. ISBN 978-88-492-6909-3. The Special Case of Greece The ancient Greece was a cradle of the Western culture,  Kim Covert (1 July 2011). Ancient Greece: Birthplace of Democracy. Capstone. p. 5. ISBN 978-1-4296-6831-6. Ancient Greece is often called the cradle of western civilization. ... Ideas from literature and science also have their roots in ancient Greece.  Henry Turner Inman. Rome: the cradle of western civilisation as illustrated by existing monuments. ISBN 9781177738538.  Michael Ed. Grant (1964). The Birth Of Western Civilisation, Greece & Rome. Amazon.co.uk. Thames & Hudson. Retrieved 4 January 2016.  HUXLEY, George; et al. "9780500040034: The Birth of Western Civilization: Greece and Rome". AbeBooks.com. Retrieved 4 January 2016.  "Athens. Rome. Jerusalem and Vicinity. Peninsula of Mt. Sinai.: Geographicus Rare Antique Maps". Geographicus.com. Retrieved 4 January 2016.  "Download This PDF eBooks Free" (PDF). File104.filthbooks.org. Archived from the original (PDF) on 7 January 2016. Retrieved 4 January 2016.  Ball, Desmond (2005). The Transformation of Security in the Asia/Pacific Region. Routledge. p. 104. ISBN 978-0714646619.  Walker, Hugh Dyson (2012). East Asia: A New History. AuthorHouse. p. 119.  Amy Chua; Jed Rubenfeld (2014). The Triple Package: How Three Unlikely Traits Explain the Rise and Fall of Cultural Groups in America. Penguin Press HC. p. 121. ISBN 978-1594205460.  Kang, David C. (2012). East Asia Before the West: Five Centuries of Trade and Tribute. Columbia University Press. pp. 33–34. ISBN 978-0231153195.  Goucher, Candice; Walton, Linda (2012). World History: Journeys from Past to Present. Routledge (published September 11, 2012). p. 232. ISBN 978-0415670029.  Smolnikov, Sergey (2018). Great Power Conduct and Credibility in World Politics. ISBN 9783319718859.  Lone, Stewart (2007). Daily Lives of Civilians in Wartime Asia: From the Taiping Rebellion to the Vietnam War. Greenwood. p. 3. ISBN 978-0313336843.  Warren I. Cohen. East Asia at the Center : Four Thousand Years of Engagement with the World. (New York: Columbia University Press, 2000. ISBN 0231101082  Norman, Jerry (1988). Chinese. Cambridge University Press. p. 17. ISBN 978-0521296533.  Cohen, Warren (2000). East Asia at the Center : Four Thousand Years of Engagement with the World. Columbia University Press. p. 60. ISBN 978-0231101080.  Chua, Amy (2009). Day of Empire: How Hyperpowers Rise to Global Dominance--and Why They Fall. Anchor. p. 62. ISBN 978-1400077410.  Leibo, Steve (2012). East and Southeast Asia 2012. Stryker Post. p. 19. ISBN 978-1610488853.  Tsai, Henry (2009-02-15). Maritime Taiwan: Historical Encounters with the East and the West. Routledge. p. 3. ISBN 978-0765623287.  Kshetry, Gopal (2008). Foreigners in Japan: A Historical Perspective. Xlibris Corp. p. 30. ISBN 978-1425770495.  Kshetry, Gopal (2008). Foreigners in Japan: A Historical Perspective. Xlibris Corp. p. 31. ISBN 978-1425770495.  Lockard, Craig (1999). "Tang Civilization and the Chinese Centuries" (PDF). Encarta Historical Essays: 2–3.  Lockard, Craig (1999). "Tang Civilization and the Chinese Centuries" (PDF). Encarta Historical Essays: 7.  Fagan, Brian M. (1999). The Oxford Companion to Archaeology. Oxford University Press. p. 362. ISBN 978-0195076189.  Lockard, Craig (1999). "Tang Civilization and the Chinese Centuries" (PDF). Encarta Historical Essays: 8.  Lockard, Craig A. (2009). Societies Networks And Transitions: Volume B From 600 To 1750. Wadsworth. pp. 290–291. ISBN 978-1-4390-8540-0.  Embree, Ainslie; Gluck, Carol (1997). Asia in Western and World History: A Guide for Teaching. M.E. Sharpe. p. 352. ISBN 9781563242656. Japan culture tang dynasty.  Kshetry, Gopal (2008). Foreigners in Japan: A Historical Perspective. Xlibris Corp. p. 32. ISBN 978-1425770495.  Brown, John (2006). China, Japan, Korea: Culture and Customs. Createspace Independent. p. 33. ISBN 978-1419648939.  Lind, Jennifer (February 13, 2018). "Life in China's Asia: What Regional Hegemony Would Look Like". Foreign Affairs.  Lockard, Craig (1999). "Tang Civilization and the Chinese Centuries" (PDF). Encarta Historical Essays.  Ellington, Lucien (2009). Japan (Nations in Focus). p. 21.  John M. Roberts (1997). A Short History of the World. Oxford University Press. p. 272. ISBN 0-19-511504-X.  Hayes, Louis D (2009). Political Systems of East Asia: China, Korea, and Japan. Greenlight. pp. xi. ISBN 978-0765617866.  Hayes, Louis D (2009). Political Systems of East Asia: China, Korea, and Japan. Greenlight. p. 15. ISBN 978-0765617866.  Tindall, George Brown; Shi, David E. (2009). America: A Narrative History (1st ed.). W. W. Norton & Company (published November 16, 2009). p. 926. ISBN 978-0393934083.  April, K.; Shockley, M. (2007). Diversity: New Realities in a Changing World. Palgrave Macmillan (published February 6, 2007). pp. 163. ISBN 978-0230001336.  Cohen, Warren (2000). East Asia at the Center : Four Thousand Years of Engagement with the World. Columbia University Press. p. 286. ISBN 978-0231101080.  Batty, David (2005-01-17). Japan's War in Colour (documentary). TWI.  Asian History Module Learning. Rex Bookstore Inc. 2002. p. 186. ISBN 978-9712331244.  Goldman, Merie; Gordon, Andrew (2000). Diversity: New Realities in a Changing World. Harvard University Press (published August 15, 2000). p. 3. ISBN 978-0674000971.  Cohen, Warren (2000). East Asia at the Center : Four Thousand Years of Engagement with the World. Columbia University Press. p. 273. ISBN 978-0231101080.  Shiping, Hua; Hu, Amelia (2014). East Asian Development Model: Twenty-first century perspectives (1st ed.). Routledge (published 2014-12-09). pp. 78–79. ISBN 978-0415737272.  Lee, Yong Wook; Key, Young Son (2014). China's Rise and Regional Integration in East Asia: Hegemony or community? (1st ed.). Routledge (published March 14, 2014). p. 45. ISBN 978-0313350825.  "Sino-Japanese War (1894–95)". Encyclopædia Britannica. Retrieved 12 November 2012.  "The Japanese Economy". Walk Japan. 2010-12-16.  Tindall, George Brown; Shi, David E. (2009). America: A Narrative History (1st ed.). W. W. Norton & Company (published November 16, 2009). p. 1147. ISBN 978-0393934083.  Northrup, Cynthia Clark; Bentley, Jerry H.; Eckes Jr., Alfred E. (2004). Encyclopedia of World Trade: From Ancient Times to the Present. Routledge. p. 297. ISBN 978-0765680587.  Paul, Erik (2012). Neoliberal Australia and US Imperialism in East Asia. Palgrave Macmillan. p. 114. ISBN 978-1137272775.  "Introducing East Asian Peoples" (PDF). International Mission Board. September 10, 2016.  Gilbet Rozman (2004), Northeast Asia's stunted regionalism: bilateral distrust in the shadow of globalization. Cambridge University Press, pp. 3-4  "Northeast Asia dominates patent filing growth." Retrieved on August 8, 2001.  "Paper: Economic Integration in Northeast Asia." Retrieved on August 8, 2011.  Kim, Johnny S. (2013). Solution-Focused Brief Therapy: A Multicultural Approach. Sage Publications. p. 55. ISBN 978-1452256672.  Shiping, Hua; Hu, Amelia (2014). East Asian Development Model: Twenty-first century perspectives (1st ed.). Routledge (published 2014-12-09). p. 3. ISBN 978-0415737272.  Ness, Immanuel; Bellwood, Peter (2014). The Global Prehistory of Human Migration (1st ed.). Wiley-Blackwell (published 2014-11-10). p. 217. ISBN 978-1118970591.  Kort, Michael (2003). The Handbook Of East Asia. 21st Century. p. 7–9. ISBN 978-0761326724.  Spinosa, Ludovico (2007). Wastewater Sludge. Iwa Publishing. p. 57. ISBN 978-1843391425.  Prescott, Anne (2015). East Asia in the World: An Introduction. Routledge. p. 3. ISBN 978-0765643223.  Ikeo, Aiko (1996). Economic Development in Twentieth-Century East Asia: The International Context. Routledge. p. 1. ISBN 978-0415149006.  Yoshimatsu, H. (2014). Comparing Institution-Building in East Asia: Power Politics, Governance, and Critical Junctures. Palgrave Macmillan. p. 1. ISBN 978-1137370549.  Kim, Mikyoung (2015). Routledge Handbook of Memory and Reconciliation in East Asia. Routledge. ISBN 978-0415835138.  Hazen, Dan; Spohrer, James H. (2005). Building Area Studies Collections. Otto Harrassowitz (published 2005-12-31). p. 130. ISBN 978-3447055123.  Grabowski, Richard; Self, Sharmistha; Shields, William (2012). Economic Development: A Regional, Institutional, and Historical Approach (2nd ed.). Routledge (published September 25, 2012). p. 59. ISBN 978-0765633538.  Ng, Arden (4 February 2019). "East Asia is the World's Largest Economy at $29.6 Trillion USD, Including 4 of the Top 25 Countries Globally". Blueback.  Currie, Lorenzo (2013). Through the Eyes of the Pack. Xlibris Corp. p. 163. ISBN 978-1493145171.  Asato, Noriko (2013). Handbook for Asian Studies Specialists: A Guide to Research Materials and Collection Building Tools. Libraries Unlimited. p. 1. ISBN 978-1598848427.  Prescott, Anne (2015). East Asia in the World: An Introduction. Routledge. p. 6. ISBN 978-0765643223.  Miller, David Y. (2007). Modern East Asia: An Introductory History. Routledge. p. xi. ISBN 978-0765618221.  "Central Themes for a Unit on China | Central Themes and Key Points | Asia for Educators | Columbia University". afe.easia.columbia.edu. Retrieved 2018-12-01. "Within the Pacific region, China is potentially a major economic and political force. Its relations with Japan, Korea, and its Southeast Asian neighbors, Vietnam, Cambodia, Laos, Malaysia, Thailand, Indonesia, and the Philippines, will be determined by how they perceive this power will be used."  Cummings, Sally N. (2013). Understanding Central Asia: Politics and Contested Transformations. Routledge. ISBN 978-1-134-43319-3.  Saez, Lawrence (2012). The South Asian Association for Regional Cooperation (SAARC): An emerging collaboration architecture. Routledge. ISBN 978-1-136-67108-1.  Cornell, Svante E. Modernization and Regional Cooperation in Central Asia: A New Spring? (PDF). Central Asia-Caucasus Institute and the Silk Road Studies.  Aminian, Nathalie; Fung, K.C.; Ng, Francis. "Integration of Markets vs. Integration by Agreements" (PDF). Policy Research Working Paper. World Bank.  "Northeast Asia." Council on Foreign Relations. Retrieved on August 10, 2009.  Economic Research Institute for Northeast Asia (1999). Japan and Russia in Northeast Asia: Partners in the 21st Century. Greenwood Publishing Group. p. 248.  "United Nations Statistics Division – Standard Country and Area Codes Classifications (M49)". United Nations Statistics Division. 2015-05-06. Retrieved 2010-07-24.  "Composition of macro geographical (continental) regions, geographical sub-regions, and selected economic and other groupings". United Nations Statistics Division. 11 February 2013. Retrieved 28 May 2013.  Christopher M. Dent (2008). East Asian regionalism. London: Routledge. pp. 1–8.  Charles Harvie, Fukunari Kimura, and Hyun-Hoon Lee (2005), New East Asian regionalism. Cheltenham and Northamton: Edward Elgar, pp. 3–6.  Peter J. Katzenstein and Takashi Shiraishi (2006), Beyond Japan: the dynamics of East Asian regionalism. Ithaca: Cornell University Press, pp. 1–33  Listed as "Hong Kong SAR" by IMF  Listed as "Macao SAR" by IMF  "Country codes". iso.org.  From 1949 to 1971, the ROC was referred as "China" or "Nationalist China".  "Country codes". iso.org.  ""World Population prospects – Population division"". population.un.org. United Nations Department of Economic and Social Affairs, Population Division. Retrieved November 9, 2019.  ""Overall total population" – World Population Prospects: The 2019 Revision" (xslx). population.un.org (custom data acquired via website). United Nations Department of Economic and Social Affairs, Population Division. Retrieved November 9, 2019.  "| Human Development Reports". www.hdr.undp.org. Retrieved 2018-10-14.  Seoul was the de jure capital of the DPRK from 1948 to 1972.  Taipei is the ROC's seat of government by regulation. Constitutionally, there is no official capital appointed for the ROC.  CIA Factbook  人口推計 – 平成 28年 12月 報 (PDF).  "新疆维吾尔自治区统计局". www.xjtj.gov.cn.  Gordon, Raymond G. Jr., ed. (2005). Ethnologue: Languages of the World (15th ed.). Dallas: SIL International. ISBN 978-1-55671-159-6. OCLC 224749653.  Lim, SK (2011-11-01). Asia Civilizations: Ancient to 1800 AD. ASIAPAC. p. 56. ISBN 978-9812295941.  Goscha, Christopher (2016). The Penguin History of Modern Vietnam: A History. Allen Lane. ISBN 978-1846143106.  Amy Chua; Jed Rubenfeld (2014). The Triple Package: How Three Unlikely Traits Explain the Rise and Fall of Cultural Groups in America. Penguin Press HC. p. 122. ISBN 978-1594205460.  Walker, Hugh Dyson (2012). East Asia: A New History. AuthorHouse. p. 2.  Lewis, Mark Edward (2012). China's Cosmopolitan Empire: The Tang Dynasty. Belknap Press (published April 9, 2012). p. 156. ISBN 978-0674064010.  Reischauer, Edwin O. (1974). "The Sinic World in Perspective". Foreign Affairs. 52 (2): 341–348. doi:10.2307/20038053. JSTOR 20038053.  Lim, SK (2011-11-01). Asia Civilizations: Ancient to 1800 AD. ASIAPAC. p. 89. ISBN 978-9812295941.  Richter, Frank-Jurgen (2002). Redesigning Asian Business: In the Aftermath of Crisis. Quorum Books. p. 15. ISBN 978-1567205251.  Vohra 1999, p. 22  Amy Chua; Jed Rubenfeld (2014). The Triple Package: How Three Unlikely Traits Explain the Rise and Fall of Cultural Groups in America. Penguin Press HC. pp. 121–122. ISBN 978-1594205460.  Wenzel-Teuber, Katharina (2012). "People's Republic of China: Religions and Churches Statistical Overview 2011" (PDF). Religions & Christianity in Today's China. II (3): 29–54. ISSN 2192-9289. Archived from the original (PDF) on 27 April 2017.  Wenzel-Teuber, Katharina (2017). "Statistics on Religions and Churches in the People's Republic of China – Update for the Year 2016" (PDF). Religions & Christianity in Today's China. VII (2): 26–53. Archived from the original (PDF) on 22 July 2017.  Shirley Kan (December 2009). Taiwan: Major U.S. Arms Sales Since 1990. DIANE Publishing. p. 52. ISBN 978-1-4379-2041-3.  United Nations (March 12, 2017). "The World's Cities in 2016" (PDF). United Nations.  통계표명 : 주민등록 인구통계 (in Korean). Ministry of Government Administration and Home Affairs. Archived from the original on 3 March 2011. Retrieved 4 April 2015. Further reading Church, Peter. A short history of South-East Asia (John Wiley & Sons, 2017). Clyde, Paul H., and Burton F. Beers. The Far East: A History of Western Impacts and Eastern Responses, 1830-1975 (1975) online 3rd edition 1958 Crofts, Alfred. A history of the Far East (1958) online free to borrow Dennett, Tyler. Americans in Eastern Asia (1922) online free Ebrey, Patricia Buckley, and Anne Walthall. East Asia: A cultural, social, and political history (Cengage Learning, 2013). Embree, Ainslie T., ed. Encyclopedia of Asian history (1988) vol. 1 online; vol 2 online; vol 3 online; vol 4 online Fairbank, John K., Edwin Reischauer, and Albert M. Craig. East Asia: The great tradition and East Asia: The modern transformation (1960) [2 vol 1960] online free to borrow, famous textbook. Flynn, Matthew J. China Contested: Western Powers in East Asia (2006), for secondary schools Gelber, Harry. The dragon and the foreign devils: China and the world, 1100 BC to the present (2011). Green, Michael J. By more than providence: grand strategy and American power in the Asia Pacific since 1783 (2017) a major scholarly survey excerpt Hall, D.G.E. History of South East Asia (Macmillan International Higher Education, 1981). Holcombe, Charles. A History of East Asia (2d ed. Cambridge UP, 2017). excerpt Iriye, Akira. After Imperialism; The Search for a New Order in the Far East 1921-1931. (1965). Jensen, Richard, Jon Davidann, and Yoneyuki Sugita, eds. Trans-Pacific Relations: America, Europe, and Asia in the Twentieth Century (Praeger, 2003), 304 pp online review Keay, John. Empire's End: A History of the Far East from High Colonialism to Hong Kong (Scribner, 1997). online free to borrow Levinson, David, and Karen Christensen, eds. Encyclopedia of Modern Asia. (6 vol. Charles Scribner's Sons, 2002). Mackerras, Colin. Eastern Asia: an introductory history (Melbourne: Longman Cheshire, 1992). Macnair, Harley F. & Donald Lach. Modern Far Eastern International Relations. (2nd ed 1955) 1950 edition online free, 780pp; focus on 1900-1950. Miller, David Y. Modern East Asia: An Introductory History (Routledge, 2007) Murphey, Rhoads. East Asia: A New History (1996) Norman, Henry. The Peoples and Politics of the Far East: Travels and studies in the British, French, Spanish and Portuguese colonies, Siberia, China, Japan, Korea, Siam and Malaya (1904) online Paine, S. C. M. The Wars for Asia, 1911-1949 (2014) excerpt Prescott, Anne. East Asia in the World: An Introduction (Routledge, 2015) Ring, George C. Religions of the Far East: Their History to the Present Day (Kessinger Publishing, 2006). Szpilman, Christopher W. A., Sven Saaler. "Japan and Asia" in Routledge Handbook of Modern Japanese History (2017) online Steiger, G. Nye. A history of the Far East (1936). Vinacke, Harold M. A History of the Far East in Modern Times (1964) online free Vogel, Ezra. China and Japan: Facing History (2019) excerpt Woodcock, George. The British in the Far East (1969) online External links 	Wikimedia Commons has media related to Eastern Asia. 	Look up east asia in Wiktionary, the free dictionary. 	Wikivoyage has a travel guide for East Asia. High resolution map of East Asian region vte Asia articles vte East Asia Countries and regions	 PR China MainlandHong KongMacauJapan RyukyuMongoliaNorth KoreaSouth KoreaTaiwan  Ethnic groups	 AinuHan SubgroupsHuiKoreans in ChinaManchuMiaoMongolicQiangRyukyuansIndigenous TaiwaneseTibetansTujiaUyghursYamatoYiZhuangother ethnic groups in China unrecognizedhistorical Culture	 Age reckoningArchitecture‎Art ChineseJapaneseKoreanTaiwaneseBlepharoplastyBuddhismCalligraphyCinemaCuisineCultural sphereDanceDecorative knotworkDragonFashionFestivalsGardensGothic typefaceHan charactersHip-and-gable roofLanguagesLiteratureMādhyamakaMusicMythologyPhilosophyReligionScriptsSealSino-Xenic pronunciationsSurnamesTelevisionYogācāraZodiac Environment	 East Asia Climate PartnershipMonsoonRainy seasonFlora Economy and Politics	 China–Japan–South Korea trilateral summitComprehensive Economic Partnership for East AsiaCapitalismEast Asia SummitEast Asian Bureau of Economic ResearchEast Asian CommunityFour Asian TigersHuman rights in East AsiaPortsStock exchanges History	 ArchaeologyArchaeological culturesBronze AgeIron AgeFormer countries Sports	 China–Japan–Korea Friendship Athletic MeetingEast Asian Football FederationEast Asian GamesEast Asian Judo ChampionshipsEast Asian martial artsEast Asian Youth GamesEAFF E-1 Football Championship Education	 Association of East Asian Research UniversitiesCrossAsiaEast Asian Economic ReviewEast Asia Image CollectionEast Asia Law ReviewEast Asian studiesJournal of East Asian StudiesLudwigshafen East Asia Institute Military	 Horses in East Asian warfareMiyamoto MusashiSun TzuThe Art of WarThe Book of Five RingsYi Sun-sin Science and technology	 Needham Research InstitutePrintingSwordsTraditional medicine Places adjacent to East Asia Authority control Edit this at Wikidata Categories: East AsiaRegions of AsiaRegions of Eurasia Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadEditView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikivoyage  Languages Български Deutsch Ελληνικά Français 한국어 Македонски Монгол Shqip Türkçe 114 more Edit links This page was last edited on 7 October 2021, at 06:10 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki   Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more Page semi-protected South Korea From Wikipedia, the free encyclopedia Jump to navigationJump to search "Republic of Korea" redirects here. For the Democratic People's Republic of Korea, see North Korea. For other uses, see Korea (disambiguation). "Daehanminguk" redirects here. For the government in exile that used the same name, see Provisional Government of the Republic of Korea. Coordinates: 36°N 128°E  Republic of Korea 대한민국 (Korean) Daehan Minguk Centered taegeuk on a white rectangle inclusive of four black trigrams Flag Centered taegeuk on a hibiscus syriacus surrounded by five stylized petals and a ribbon Emblem Motto:  "홍익인간" (de facto) "Hongik Ingan" "To broadly benefit the human world"[1] Anthem:  "애국가" "Aegukga" "The Patriotic Song" MENU0:00 National seal "국새" Seal of South Korea.svg Land controlled by South Korea shown in dark green; land claimed but uncontrolled shown in light green Land controlled by South Korea shown in dark green; land claimed but uncontrolled shown in light green Capital and largest city Seoul 37°33′N 126°58′E Official languages	Korean (Pyojuneo) Korean Sign Language[2] Official script	Korean Ethnic groups (2019)[3]	 95.1% Korean 4.9% non-Korean Religion (2015)[4][5]	 56.1% No religion 27.6% Christianity[a] 15.5% Korean Buddhism 0.8% Others Demonym(s)	 South KoreanKorean Government	Unitary presidential constitutional republic • President Moon Jae-in • Prime Minister Kim Boo-kyum • Speaker of the National Assembly Park Byeong-seug • Chief Justice Kim Myeong-soo • President of the Constitutional Court Yoo Nam-seok Legislature	National Assembly Establishment history • First Kingdom c. 7th century BCE • Declaration of Independence 1 March 1919 • Provisional Government 11 April 1919 • Independence from Japan 15 August 1945 • US administration of Korea south of the 38th parallel 8 September 1945 • ROK established 15 August 1948 • Current constitution 25 February 1988 • Admitted to the UN 17 September 1991 Area • Total 100,363 km2 (38,750 sq mi) (107th) • Water (%) 0.3 (301 km2 / 116 mi2) Population • 2019 estimate Neutral increase 51,709,098[6] (27th) • Density 507/km2 (1,313.1/sq mi) (13th) GDP (PPP)	2021 estimate • Total Increase $2.436 trillion[7] (14th) • Per capita Increase $47,027[7] (28th) GDP (nominal)	2021 estimate • Total Increase $1.806 trillion[7] (10th) • Per capita Increase $34,866[7] (28th) Gini (2018)	Positive decrease 34.5[8] medium HDI (2019)	Increase 0.916[9] very high · 23rd Currency	Korean Republic won (₩) (KRW) Time zone	UTC+9 (Korea Standard Time) Date format	 yyyy년 m월 d일 yyyy. m. d. (CE) Mains electricity	220 V–60 Hz Driving side	right Calling code	+82 ISO 3166 code	KR Internet TLD	 .kr.한국 Preceded by	 	Fifth Republic of Korea   Republic of Korea South Korea with Hanja.svg "Republic of Korea" in Hangul (top) and Hanja (bottom) scripts. South Korean name Hangul	대한민국 Hanja	大韓民國 Transcriptions   South Korea South Korean name Hangul	남한 Hanja	南韓 Transcriptions   North Korean name Chosŏn'gŭl	남조선 Hancha	南朝鮮 Transcriptions   Korea South Korean name Hangul	한국 Hanja	韓國 Transcriptions   North Korean name Chosŏn'gŭl	조선 Hancha	朝鮮 Transcriptions   South Korea,[b] officially the Republic of Korea (ROK),[c] is a country in East Asia, constituting the southern part of the Korean Peninsula, and sharing a land border with North Korea. About 25 million people, around half of the country's population of 51 million, live in the Seoul Capital Area.  The Korean Peninsula was inhabited as early as the Lower Paleolithic period. Its first kingdom was noted in Chinese records in the early 7th century BCE. Following the unification of the Three Kingdoms of Korea into Silla and Balhae in the late 7th century, Korea was ruled by the Goryeo dynasty (918–1392) and the Joseon dynasty (1392–1897). The succeeding Korean Empire was annexed in 1910 into the Empire of Japan. Japanese rule in Korea ended following the former's surrender in World War II, after which Korea was divided into two zones; a northern zone occupied by the Soviet Union and a southern zone occupied by the United States. After negotiations on reunification failed, the latter became the Republic of Korea in August 1948 while the former became North Korea.  In 1950, a North Korean invasion began the Korean War, which saw extensive United States-led U.N. intervention in support of the South, while the North received support from China and from the Soviet Union. After the war's end in 1953, the country's economy began to soar, recording the fastest rise in average GDP per capita in the world between 1980 and 1990. The June Struggle led to the end of authoritarian rule in 1987 and the country is now considered among the most advanced democracies in Asia, with the highest level of press freedom. However, corruption and political scandals have become growing problems in recent years; all four living former South Korean presidents have been sentenced to prison for various crimes ranging from abuse of authority to bribery and embezzlement; with two still currently serving their sentences.[15]  South Korea is a developed country and is ranked as the seventh-highest country on the Human Development Index (HDI) in the Asia and Oceania region. Its economy ranks as the world's tenth-largest by nominal GDP. Its citizens enjoy one of the world's fastest Internet connection speeds and the densest high-speed railway network. The country is the world's fifth-largest exporter and eighth-largest importer. South Korea was in 2017 the world's 7th largest emitter of carbon emissions and the 5th largest emitter per capita. Since the 21st century, South Korea has been renowned for its globally influential pop culture, particularly in music (K-pop), TV dramas and cinema, a phenomenon referred to as the Korean Wave.[16][17][18][19][20] It is a member of the OECD's Development Assistance Committee, the G20, and the Paris Club.   Contents 1	Etymology 2	History 2.1	Ancient Korea 2.2	Three Kingdoms of Korea 2.3	Unified Dynasties 2.4	Modern history 2.4.1	Korean War 2.4.2	Post-Korean War (1960–1990) 2.4.3	Contemporary South Korea 3	Geography, climate and environment 3.1	Geography 3.2	Climate 3.3	Environment 4	Government 5	Administrative divisions 6	Demographics 6.1	Education 6.2	Language 6.3	Religion 6.4	Health 7	Foreign relations 7.1	North Korea 7.2	China and Russia 7.3	Japan 7.4	European Union 7.5	United States 8	Military 8.1	United States contingent 8.2	Conscientious objection 9	Economy 9.1	Transportation, energy and infrastructure 9.2	Tourism 9.3	South Korean National Pension System 10	Science and technology 10.1	Cyber security 10.2	Aerospace engineering 10.3	Robotics 10.4	Biotechnology 11	Culture 11.1	Art 11.2	Architecture 11.3	Cuisine 11.4	Entertainment 11.5	Holidays 11.6	Sports 12	See also 13	Notes 14	References 15	Further reading 16	External links Etymology See also: Names of Korea  The name Korea is derived from Goguryeo, also known as Koryŏ, one of the Three Kingdoms of Korea. The name Korea derives from the name Goryeo. The name Goryeo itself was first used by the ancient kingdom of Goguryeo, which was considered a great power of East Asia during its time, in the 5th century as a shortened form of its name.[21][22][23][24] The 10th-century kingdom of Goryeo succeeded Goguryeo,[25][26][27][28][excessive citations]and thus inherited its name, which was pronounced by the visiting Persian merchants as "Korea".[29] The modern name of Koreia, appears in the first Portuguese maps of 1568 by João vaz Dourado as Conrai [30] and later in the late 16th century and early 17th century as Korea (Corea) in the maps of Teixeira Albernaz of 1630.[31]  The kingdom of Goryeo became first known to Westerners when Afonso de Albuquerque conquered Malacca in 1511 and described the peoples who traded with this part of the world known by the Portuguese as the Gores.[32] Despite the coexistence of the spellings Corea and Korea in 19th century publications, some Koreans believe that Imperial Japan, around the time of the Japanese occupation, intentionally standardized the spelling on Korea, making Japan appear first alphabetically.[33][34][35]  After Goryeo was replaced by Joseon in 1392, Joseon became the official name for the entire territory, though it was not universally accepted.[citation needed] The new official name has its origin in the ancient kingdom of Gojoseon (2333 BCE). In 1897, the Joseon dynasty changed the official name of the country from Joseon to Daehan Jeguk (Korean Empire). The name Daehan (Great Han) derives from Samhan (Three Han), referring to the Three Kingdoms of Korea, not the ancient confederacies in the southern Korean Peninsula.[36][37] However, the name Joseon was still widely used by Koreans to refer to their country, though it was no longer the official name. Under Japanese rule, the two names Han and Joseon coexisted. There were several groups who fought for independence, the most notable being the Provisional Government of the Republic of Korea (대한민국 임시정부 / 大韓民國臨時政府).  Following the surrender of Japan, in 1945, the Republic of Korea (대한민국 / 大韓民國, IPA: ˈtɛ̝ːɦa̠nminɡuk̚, lit. 'Great Korean People's State'; About this soundlisten) was adopted as the legal English name for the new country. However, it is not a direct translation of the Korean name.[38] As a result, the Korean name "Daehan Minguk" is sometimes used by South Koreans as a metonym to refer to the Korean ethnicity (or "race") as a whole, rather than just the South Korean state.[39][38]  Since the government only controlled the southern part of the Korean Peninsula, the informal term South Korea was coined, becoming increasingly common in the Western world. While South Koreans use Han (or Hanguk) to refer to both Koreas collectively, North Koreans and ethnic Koreans living in China and Japan use the term Joseon instead.  History Main article: History of Korea Ancient Korea  Seokguram Grotto from the Silla era, a UNESCO World Heritage Site  Balhae (violet) and Silla (blue), circa 830 CE  The oldest surviving metal movable type book, the Jikji, was printed in 1377, and Goryeo created the world's first metal-based movable type in 1234.[40][41][42][43][44]  The Tripitaka Koreana — the Buddhist canon (Tripiṭaka) carved onto roughly 80,000 woodblocks and stored (and still remaining) at Haeinsa, also a UNESCO World Heritage Site The Korean Peninsula was inhabited as early as the Lower Paleolithic period.[45][46] The history of Korea begins with the founding of Joseon (also known as "Gojoseon", or Old Joseon, to differentiate it with the 14th century dynasty) in 2333 BCE by Dangun, according to Korea's foundation mythology.[47][48] Gojoseon was noted in Chinese records in the early 7th century.[49] Gojoseon expanded until it controlled the northern Korean Peninsula and parts of Manchuria. Gija Joseon was purportedly founded in the 12th century BCE, but its existence and role have been controversial in the modern era.[48][50] In 108 BCE, the Han dynasty defeated Wiman Joseon and installed four commanderies in the northern Korean peninsula. Three of the commanderies fell or retreated westward within a few decades. As Lelang commandery was destroyed and rebuilt around this time, the place gradually moved toward Liaodong. Thus, its force was diminished and it only served as a trade center until it was conquered by Goguryeo in 313.[51][52][53]  Three Kingdoms of Korea During the period known as the Proto–Three Kingdoms of Korea, the states of Buyeo, Okjeo, Dongye and Samhan occupied the whole Korean peninsula and southern Manchuria. From them, Goguryeo, Baekje and Silla emerged to control the peninsula as the Three Kingdoms of Korea. Goguryeo, the largest and most powerful among them, was a highly militaristic state,[54][55] and competed with various Chinese dynasties during its 700 years of history. Goguryeo experienced a golden age under Gwanggaeto the Great and his son Jangsu,[56][57][58][59] who both subdued Baekje and Silla during their times, achieving a brief unification of the Three Kingdoms of Korea and becoming the most dominant power on the Korean Peninsula.[60][61] In addition to contesting for control of the Korean Peninsula, Goguryeo had many military conflicts with various Chinese dynasties,[62] most notably the Goguryeo–Sui War, in which Goguryeo defeated a huge force said to number over a million men.[63][64][65][66][67][excessive citations] Baekje was a great maritime power;[68] its nautical skill, which made it the Phoenicia of East Asia, was instrumental in the dissemination of Buddhism throughout East Asia and continental culture to Japan.[69][70] Baekje was once a great military power on the Korean Peninsula, especially during the time of Geunchogo,[71] but was critically defeated by Gwanggaeto the Great and declined.[72][self-published source] Silla was the smallest and weakest of the three, but it used cunning diplomatic means to make opportunistic pacts and alliances with the more powerful Korean kingdoms, and eventually Tang China, to its great advantage.[73][74]  The unification of the Three Kingdoms by Silla in 676 led to the North South States Period, in which much of the Korean Peninsula was controlled by Later Silla, while Balhae controlled the northern parts of Goguryeo. Balhae was founded by a Goguryeo general and formed as a successor state to Goguryeo. During its height, Balhae controlled most of Manchuria and parts of the Russian Far East, and was called the "Prosperous Country in the East".[75] Later Silla was a golden age of art and culture,[76][77][78][79] as evidenced by the Hwangnyongsa, Seokguram, and Emille Bell. Relationships between Korea and China remained relatively peaceful during this time. Later Silla carried on the maritime prowess of Baekje, which acted like the Phoenicia of medieval East Asia,[80] and during the 8th and 9th centuries dominated the seas of East Asia and the trade between China, Korea and Japan, most notably during the time of Jang Bogo; in addition, Silla people made overseas communities in China on the Shandong Peninsula and the mouth of the Yangtze River.[81][82][83][84] Later Silla was a prosperous and wealthy country,[85] and its metropolitan capital of Gyeongju[86] was the fourth largest city in the world.[87][88][89][90] Buddhism flourished during this time, and many Korean Buddhists gained great fame among Chinese Buddhists[91] and contributed to Chinese Buddhism,[92] including: Woncheuk, Wonhyo, Uisang, Musang,[93][94][95][96] and Kim Gyo-gak, a Silla prince whose influence made Mount Jiuhua one of the Four Sacred Mountains of Chinese Buddhism.[97][98][99][100][101][excessive citations] However, Later Silla weakened under internal strife and the revival of Baekje and Goguryeo, which led to the Later Three Kingdoms period in the late 9th century.  Unified Dynasties  Changdeok Palace, one of the Five Grand Palaces built during the Joseon Dynasty and another UNESCO World Heritage Site In 936, the Later Three Kingdoms were united by Wang Geon, a descendant of Goguryeo nobility,[102] who established Goryeo as the successor state of Goguryeo.[25][26][27][28] Balhae had fallen to the Khitan Empire in 926, and a decade later the last crown prince of Balhae fled south to Goryeo, where he was warmly welcomed and included into the ruling family by Wang Geon, thus unifying the two successor nations of Goguryeo.[103] Like Silla, Goryeo was a highly cultural state, and invented the metal movable type printing press.[40][41][42][43][44][104][105][excessive citations] After defeating the Khitan Empire, which was the most powerful empire of its time,[106][107] in the Goryeo–Khitan War, Goryeo experienced a golden age that lasted a century, during which the Tripitaka Koreana was completed and there were great developments in printing and publishing, promoting learning and dispersing knowledge on philosophy, literature, religion, and science; by 1100, there were 12 universities that produced famous scholars and scientists.[108][109] However, the Mongol invasions in the 13th century greatly weakened the kingdom. Goryeo was never conquered by the Mongols, but exhausted after three decades of fighting, the Korean court sent its crown prince to the Yuan capital to swear allegiance to Kublai Khan, who accepted, and married one of his daughters to the Korean crown prince.[110] Henceforth, Goryeo continued to rule Korea, though as a tributary ally to the Mongols for the next 86 years. During this period, the two nations became intertwined as all subsequent Korean kings married Mongol princesses,[110] and the last empress of the Yuan dynasty was a Korean princess. In the mid-14th century, Goryeo drove out the Mongols to regain its northern territories, briefly conquered Liaoyang, and defeated invasions by the Red Turbans. However, in 1392, General Yi Seong-gye, who had been ordered to attack China, turned his army around and staged a coup.  Yi Seong-gye declared the new name of Korea as "Joseon" in reference to Gojoseon, and moved the capital to Hanseong (one of the old names of Seoul).[111] The first 200 years of the Joseon dynasty were marked by peace, and saw great advancements in science[112][113] and education,[114] as well as the creation of Hangul by Sejong the Great to promote literacy among the common people.[115] The prevailing ideology of the time was Neo-Confucianism, which was epitomized by the seonbi class: nobles who passed up positions of wealth and power to lead lives of study and integrity. Between 1592 and 1598, Toyotomi Hideyoshi launched invasions of Korea, but his advance was halted by Korean forces (most notably the Joseon Navy led by Admiral Yi Sun-sin and his renowned "turtle ship")[116][117][118][119][120][excessive citations] with assistance from Righteous Army militias formed by Korean civilians, and Ming dynasty Chinese troops. Through a series of successful battles of attrition, the Japanese forces were eventually forced to withdraw, and relations between all parties became normalized. However, the Manchus took advantage of Joseon's war-weakened state and invaded in 1627 and 1637, and then went on to conquer the destabilized Ming dynasty. After normalizing relations with the new Qing dynasty, Joseon experienced a nearly 200-year period of peace. Kings Yeongjo and Jeongjo particularly led a new renaissance of the Joseon dynasty during the 18th century.[121][122] In the 19th century, the royal in-law families gained control of the government, leading to mass corruption and weakening of the state, and severe poverty and peasant rebellions throughout the country. Furthermore, the Joseon government adopted a strict isolationist policy, earning the nickname "the hermit kingdom", but ultimately failed to protect itself against imperialism and was forced to open its borders. After the First Sino-Japanese War and the Russo-Japanese War, Korea was occupied by Japan (1910–45). Towards the end of World War II, the U.S. proposed dividing the Korean peninsula into two occupation zones (a U.S. and Soviet one). Dean Rusk and Charles H. Bonesteel III suggested the 38th parallel as the dividing line, as it placed Seoul under U.S. control. To the surprise of Rusk and Bonesteel, the Soviets accepted their proposal and agreed to divide Korea.[123]  Modern history Main article: History of South Korea  The War Memorial of Korea, built in remembrance of the Korean War (1950–1953)  Between 1962 and 1994, the South Korean economy grew at an average of 10% annually, fueled by annual export growth of 20%,[124] in a period called the Miracle on the Han River. Despite the initial plan of a unified Korea in the 1943 Cairo Declaration, escalating Cold War antagonism between the Soviet Union and the United States eventually led to the establishment of separate governments, each with its own ideology, leading to the division of Korea into two political entities in 1948: North Korea and South Korea. In the South, Syngman Rhee, an opponent of communism, who had been backed and appointed by the United States as head of the provisional government, won the first presidential elections of the newly declared Republic of Korea in May. In the North, however, a former anti-Japanese guerrilla and communist activist, Kim Il-sung, was appointed premier of the Democratic People's Republic of Korea in September.  In October, the Soviet Union declared Kim Il-sung's government as sovereign over both parts. The UN declared Rhee's government as "a lawful government having effective control and jurisdiction over that part of Korea where the UN Temporary Commission on Korea was able to observe and consult" and the Government "based on elections which was observed by the Temporary Commission" in addition to a statement that "this is the only such government in Korea."[125] Both leaders began an authoritarian repression of their political opponents inside their region, seeking for a unification of Korea under their control. While South Korea's request for military support was denied by the United States, North Korea's military was heavily reinforced by the Soviet Union.  Korean War On 25 June 1950, North Korea invaded South Korea, sparking the Korean War, the Cold War's first major conflict, which continued until 1953. At the time, the Soviet Union had boycotted the United Nations (UN), thus forfeiting their veto rights. This allowed the UN to intervene in a civil war when it became apparent that the superior North Korean forces would unify the entire country. The Soviet Union and China backed North Korea, with the later participation of millions of Chinese troops. After an ebb and flow that saw both sides facing defeat with massive losses among Korean civilians in both the north and the south, the war eventually reached a stalemate. During the war, Rhee's party promoted the One-People Principle (based on the German ideology of the Herrenvolk) an effort to build an obedient citizenry through ethnic homogeneity and authoritarian appeals to nationalism.[126]  The 1953 armistice, never signed by South Korea, split the peninsula along the demilitarized zone near the original demarcation line. No peace treaty was ever signed, resulting in the two countries remaining technically at war. Approximately 3 million people died in the Korean War, with a higher proportional civilian death toll than World War II or the Vietnam War, making it perhaps the deadliest conflict of the Cold War-era. In addition, virtually all of Korea's major cities were destroyed by the war.[127][128][129][130][131][excessive citations]  Post-Korean War (1960–1990)  President Park Chung-hee played a pivotal role in rapidly developing South Korea's economy through export-oriented industrialization. In 1960, a student uprising (the "April 19 Revolution") led to the resignation of the autocratic then-President Syngman Rhee. This was followed by 13 months of political instability as South Korea was led by a weak and ineffectual government. This instability was broken by the 16 May 1961, coup led by General Park Chung-hee. As president, Park oversaw a period of rapid export-led economic growth enforced by political repression.  Park was heavily criticized as a ruthless military dictator, who in 1972 extended his rule by creating a new constitution, which gave the president sweeping (almost dictatorial) powers and permitted him to run for an unlimited number of six-year terms. The Korean economy developed significantly during Park's tenure. The government developed the nationwide expressway system, the Seoul subway system, and laid the foundation for economic development during his 17-year tenure, which ended with his assassination in 1979.  The years after Park's assassination were marked again by political turmoil, as the previously suppressed opposition leaders all campaigned to run for president in the sudden political void. In 1979, General Chun Doo-hwan led the Coup d'état of December Twelfth. Following the Coup d'état, Chun Doo-hwan planned to rise to power through several measures. On 17 May, Chun Doo-hwan forced the Cabinet to expand martial law to the whole nation, which had previously not applied to the island of Jejudo. The expanded martial law closed universities, banned political activities, and further curtailed the press. Chun's assumption of the presidency through the events of 17 May triggered nationwide protests demanding democracy; these protests were particularly focused in the city of Gwangju, to which Chun sent special forces to violently suppress the Gwangju Democratization Movement.[132]  Chun subsequently created the National Defense Emergency Policy Committee and took the presidency according to his political plan. Chun and his government held South Korea under a despotic rule until 1987, when a Seoul National University student, Park Jong-chul, was tortured to death.[133] On 10 June, the Catholic Priests Association for Justice revealed the incident, igniting the June Democracy Movement around the country. Eventually, Chun's party, the Democratic Justice Party, and its leader, Roh Tae-woo, announced the 6.29 Declaration, which included the direct election of the president. Roh went on to win the election by a narrow margin against the two main opposition leaders, Kim Dae-jung and Kim Young-sam. Seoul hosted the Olympic Games in 1988, widely regarded as successful and a significant boost for South Korea's global image and economy.[134]  South Korea was formally invited to become a member of the United Nations in 1991. The transition of Korea from autocracy to modern democracy was marked in 1997 by the election of Kim Dae-jung, who was sworn in as the eighth president of South Korea, on 25 February 1998. His election was significant given that he had in earlier years been a political prisoner sentenced to death (later commuted to exile). He won against the backdrop of the 1997 Asian Financial Crisis, where he took IMF advice to restructure the economy and the nation soon recovered its economic growth, albeit at a slower pace.[135]  Contemporary South Korea  President Kim Dae-jung, the 2000 Nobel Peace Prize recipient for advancing democracy and human rights in South Korea and East Asia and for reconciliation with North Korea, was sometimes called the "Nelson Mandela of Asia."[135] In June 2000, as part of president Kim Dae-jung's "Sunshine Policy" of engagement, a North–South summit took place in Pyongyang, the capital of North Korea. Later that year, Kim received the Nobel Peace Prize "for his work for democracy and human rights in South Korea and in East Asia in general, and for peace and reconciliation with North Korea in particular".[136] However, because of discontent among the population for fruitless approaches to the North under the previous administrations and, amid North Korean provocations, a conservative government was elected in 2007 led by President Lee Myung-bak, former mayor of Seoul. Meanwhile, South Korea and Japan jointly co-hosted the 2002 FIFA World Cup. However, South Korean and Japanese relations later soured because of conflicting claims of sovereignty over the Liancourt Rocks.   South Korea became the first non-G7 chair of the G-20 when it hosted the 2010 Seoul summit.[137] In 2010, there was an escalation in attacks by North Korea. In March 2010 the South Korean warship ROKS Cheonan was sunk with the loss of 46 South Korean sailors, allegedly by a North Korean submarine. In November 2010 Yeonpyeong island was attacked by a significant North Korean artillery barrage, with 4 people losing their lives. The lack of a strong response to these attacks from both South Korea and the international community (the official UN report declined to explicitly name North Korea as the perpetrator for the Cheonan sinking) caused significant anger with the South Korean public.[138] South Korea saw another milestone in 2012 with the first ever female president Park Geun-hye elected and assuming office. Daughter of another former president, Park Chung-hee, she carried on a conservative brand of politics. President Park Geun-hye's administration was formally accused of corruption, bribery, and influence-peddling for the involvement of close friend Choi Soon-sil in state affairs. There followed a series of massive public demonstrations from November 2016[139] and she was removed from office.[140] After the fallout of President Park's impeachment and dismissal, new elections were held and Moon Jae-in of the Democratic party won the presidency, assuming office on 10 May 2017. His tenure so far has seen an improving political relationship with North Korea, some increasing divergence in the military alliance with the United States, and the successful hosting of the Winter Olympics in Pyeongchang.[141] The COVID-19 pandemic affected the nation in 2020. That same year, South Korea recorded more deaths than births, resulting in a population decline for the first time on record.[142]  Geography, climate and environment Geography Main articles: Geography of South Korea and Geology of South Korea  Topography of South Korea South Korea occupies the southern portion of the Korean Peninsula, which extends some 1,100 km (680 mi) from the Asian mainland. This mountainous peninsula is flanked by the Yellow Sea to the west, and the Sea of Japan to the east. Its southern tip lies on the Korea Strait and the East China Sea.  The country, including all its islands, lies between latitudes 33° and 39°N, and longitudes 124° and 130°E. Its total area is 100,032 square kilometers (38,622.57 sq mi).[143]  South Korea can be divided into four general regions: an eastern region of high mountain ranges and narrow coastal plains; a western region of broad coastal plains, river basins, and rolling hills; a southwestern region of mountains and valleys; and a southeastern region dominated by the broad basin of the Nakdong River.[144] South Korea is home to three terrestrial ecoregions: Central Korean deciduous forests, Manchurian mixed forests, and Southern Korea evergreen forests.[145]  South Korea's terrain is mostly mountainous, most of which is not arable. Lowlands, located primarily in the west and southeast, make up only 30% of the total land area.  About three thousand islands, mostly small and uninhabited, lie off the western and southern coasts of South Korea. Jeju-do is about 100 kilometers (62 miles) off the southern coast of South Korea. It is the country's largest island, with an area of 1,845 square kilometers (712 square miles). Jeju is also the site of South Korea's highest point: Hallasan, an extinct volcano, reaches 1,950 meters (6,400 feet) above sea level. The easternmost islands of South Korea include Ulleungdo and Liancourt Rocks (Dokdo/Takeshima), while Marado and Socotra Rock are the southernmost islands of South Korea.[144]  South Korea has 20 national parks and popular nature places like the Boseong Tea Fields, Suncheon Bay Ecological Park, and the first national park of Jirisan.[146]  Climate Main article: Climate of South Korea Seoul Climate chart (explanation) J F M A M J J A S O N D   22  2−6	   24  4−4	   46  101	   77  187	   102  2313	   133  2718	   328  2922	   348  3022	   138  2617	   49  2010	   53  123	   25  4−3 Average max. and min. temperatures in °C Precipitation totals in mm Source: [147] Imperial conversion South Korea tends to have a humid continental climate and a humid subtropical climate, and is affected by the East Asian monsoon, with precipitation heavier in summer during a short rainy season called jangma (장마), which begins end of June through the end of July. Winters can be extremely cold with the minimum temperature dropping below −20 °C (−4 °F) in the inland region of the country: in Seoul, the average January temperature range is −7 to 1 °C (19 to 34 °F), and the average August temperature range is 22 to 30 °C (72 to 86 °F). Winter temperatures are higher along the southern coast and considerably lower in the mountainous interior.[148] Summer can be uncomfortably hot and humid, with temperatures exceeding 30 °C (86 °F) in most parts of the country. South Korea has four distinct seasons; spring, summer, autumn and winter. Spring usually lasts from late March to early May, summer from mid-May to early September, autumn from mid-September to early November, and winter from mid-November to mid-March.  Rainfall is concentrated in the summer months of June through September. The southern coast is subject to late summer typhoons that bring strong winds, heavy rains and sometime floods. The average annual precipitation varies from 1,370 millimeters (54 in) in Seoul to 1,470 millimeters (58 in) in Busan.  Environment Main articles: Environment of South Korea, Pollution in South Korea, and Climate change in South Korea  Jeju Island is a UNESCO World Heritage Site.  Cheonggyecheon river is a modern public recreation space in downtown Seoul. During the first 20 years of South Korea's growth surge, little effort was made to preserve the environment.[149] Unchecked industrialization and urban development have resulted in deforestation and the ongoing destruction of wetlands such as the Songdo Tidal Flat.[150] However, there have been recent efforts to balance these problems, including a government run $84 billion five-year green growth project that aims to boost energy efficiency and green technology.[151]  The green-based economic strategy is a comprehensive overhaul of South Korea's economy, utilizing nearly two percent of the national GDP. The greening initiative includes such efforts as a nationwide bike network, solar and wind energy, lowering oil dependent vehicles, backing daylight saving time and extensive usage of environmentally friendly technologies such as LEDs in electronics and lighting.[152] The country – already the world's most wired – plans to build a nationwide next-generation network that will be 10 times faster than broadband facilities, in order to reduce energy usage.[152]  The renewable portfolio standard program with renewable energy certificates runs from 2012 to 2022.[153] Quota systems favor large, vertically integrated generators and multinational electric utilities, if only because certificates are generally denominated in units of one megawatt-hour. They are also more difficult to design and implement than a Feed-in tariff.[154] Around 350 residential micro combined heat and power units were installed in 2012.[155]  South-Korea was in 2017 the world's 7th largest emitter of carbon emmsions And the 5th largest emitter per capita. The president Moon Jae-in pledged to reduce greenhouse gas emissions which contribute to climate change to zero in 2050.[156][157]  Seoul's tap water recently became safe to drink, with city officials branding it "Arisu" in a bid to convince the public.[158] Efforts have also been made with afforestation projects. Another multibillion-dollar project was the restoration of Cheonggyecheon, a stream running through downtown Seoul that had earlier been paved over by a motorway.[159] One major challenge is air quality, with acid rain, sulfur oxides, and annual yellow dust storms being particular problems.[149] It is acknowledged that many of these difficulties are a result of South Korea's proximity to China, which is a major air polluter.[149] South Korea had a 2019 Forest Landscape Integrity Index mean score of 6.02/10, ranking it 87th globally out of 172 countries.[160]  South Korea is a member of the Antarctic-Environmental Protocol, Antarctic Treaty, Biodiversity Treaty, Kyoto Protocol (forming the Environmental Integrity Group (EIG), regarding UNFCCC,[161] with Mexico and Switzerland), Desertification, Endangered Species, Environmental Modification, Hazardous Wastes, Law of the Sea, Marine Dumping, Comprehensive Nuclear-Test-Ban Treaty (not into force), Ozone Layer Protection, Ship Pollution, Tropical Timber 83, Tropical Timber 94, Wetlands, and Whaling.[162]  Government Main article: Government of South Korea  Separation of powers and the election system of South Korea Moon Jae-in presidential portrait.jpg	Kim Boo-kyum - 20170119 k (cropped).jpg Moon Jae-in 19th President	Kim Boo-kyum 47th Prime Minister The South Korean government's structure is determined by the Constitution of the Republic of Korea. Like many democratic states,[163] South Korea has a government divided into three branches: executive, judicial, and legislative. The executive and legislative branches operate primarily at the national level, although various ministries in the executive branch also carry out local functions. Local governments are semi-autonomous, and contain executive and legislative bodies of their own. The judicial branch operates at both the national and local levels. South Korea is a constitutional democracy.   The National Assembly of South Korea The constitution has been revised several times since its first promulgation in 1948 at independence. However, it has retained many broad characteristics and with the exception of the short-lived Second Republic of South Korea, the country has always had a presidential system with an independent chief executive.[164] Under its current constitution the state is sometimes referred to as the Sixth Republic of South Korea. The first direct election was also held in 1948.  Although South Korea experienced a series of military dictatorships from the 1960s until the 1980s, it has since developed into a successful liberal democracy. Today, the CIA World Factbook describes South Korea's democracy as a "fully functioning modern democracy".[165] South Korea is ranked 45th on the Corruption Perceptions Index (9th in the Asia-Pacific region), with a score of 57 out of 100.[166]  Administrative divisions Main article: Administrative divisions of South Korea See also: Provinces of South Korea, Special cities of South Korea, and Provinces of Korea The major administrative divisions in South Korea are eight provinces, one special self-governing province, six metropolitan cities (self-governing cities that are not part of any province), one special city and one special self-governing city.  Map	Namea	Hangul	Hanja	Populationc GangwonSeoulIncheonGyeonggiS. ChungcheongN. ChungcheongSejongDaejeonN. GyeongsangN. JeollaDaeguUlsanBusanS. GyeongsangGwangjuS. JeollaJejuNorth KoreaJapanYellow SeaKorea Strait (Busan Strait)Korea Strait (Tsushima Strait)Sea of Japan (East Sea)	Special city (Teukbyeol-si)a Seoul	서울특별시	서울特別市b	9,830,452 Metropolitan city (Gwangyeok-si)a Busan	부산광역시	釜山廣域市	3,460,707 Daegu	대구광역시	大邱廣域市	2,471,136 Incheon	인천광역시	仁川廣域市	2,952,476 Gwangju	광주광역시	光州廣域市	1,460,972 Daejeon	대전광역시	大田廣域市	1,496,123 Ulsan	울산광역시	蔚山廣域市	1,161,303 Special self-governing city (Teukbyeol-jachi-si)a Sejong	세종특별자치시	世宗特別自治市	295,041 Province (Do)a Gyeonggi	경기도	京畿道	12,941,604 Gangwon	강원도	江原道	1,545,452 North Chungcheong	충청북도	忠淸北道	1,595,164 South Chungcheong	충청남도	忠淸南道	2,120,666 North Jeolla	전라북도	全羅北道	1,847,089 South Jeolla	전라남도	全羅南道	1,890,412 North Gyeongsang	경상북도	慶尙北道	2,682,897 South Gyeongsang	경상남도	慶尙南道	3,377,126 Special self-governing province (Teukbyeol-jachi-do)a Jeju	제주특별자치도	濟州特別自治道	661,511 a Revised Romanisation; b See Names of Seoul; c May As of 2018.[167]  Demographics Main article: Demographics of South Korea See also: Koreans  Population pyramid of South Korea in 2016 Population[168][169] Year	Million 1950	19.2 2000	47.3 2018	51.2 In April 2016, South Korea's population was estimated to be around 50.8 million by National Statistical Office, with continuing decline of working age population and total fertility rate.[170][171] The country is noted for its population density, which was an estimated 505 per square kilometer in 2015,[170] more than 10 times the global average. Aside from micro-states and city-states, South Korea is the world's third most densely-populated country.[172] In practice the population density in much of South Korea is higher than the national one, as most of the country's land is uninhabitable due to being used for other purposes such as farming.[172] Most South Koreans live in urban areas, because of rapid migration from the countryside during the country's quick economic expansion in the 1970s, 1980s and 1990s.[173] The capital city of Seoul is also the country's largest city and chief industrial center. According to the 2005 census, Seoul had a population of 10 million inhabitants. The Seoul National Capital Area has 24.5 million inhabitants (about half of South Korea's entire population) making it the world's second largest metropolitan area. Other major cities include Busan (3.5 million), Incheon (3.0 million), Daegu (2.5 million), Daejeon (1.4 million), Gwangju (1.4 million) and Ulsan (1.1 million).[174]   Koreans in traditional dress The population has also been shaped by international migration. After World War II and the division of the Korean Peninsula, about four million people from North Korea crossed the border to South Korea. This trend of net entry reversed over the next 40 years because of emigration, especially to North America through the United States and Canada. South Korea's total population in 1955 was 21.5 million,[175] and has more than doubled, to 50 million, by 2010.[176]  South Korea is considered one of the most ethnically homogeneous societies in the world with ethnic Koreans representing approximately 96% of total population. Precise numbers are difficult since statistics do not record ethnicity and given many immigrants are ethnically Korean themselves, and some South Korean citizens are not ethnically Korean.[177]  The percentage of foreign nationals has been growing rapidly.[178] As of 2016, South Korea had 1,413,758 foreign residents, 2.75% of the population;[177] however, many of them are ethnic Koreans with a foreign citizenship. For example, migrants from China (PRC) make up 56.5% of foreign nationals, but approximately 70% of the Chinese citizens in Korea are Joseonjok (조선족), PRC citizens of Korean ethnicity.[179] Regardless of the ethnicity, there are 28,500 US military personnel serving in South Korea, most serving a one-year unaccompanied tour (though approximately 10% serve longer tours accompanied by family), according to the Korea National Statistical Office.[180][181] In addition, about 43,000 English teachers from English-speaking countries reside temporarily in Korea.[182] Currently, South Korea has one of the highest rates of growth of foreign born population, with about 30,000 foreign born residents obtaining South Korean citizenship every year since 2010.  Large numbers of ethnic Koreans live overseas, sometimes in Korean ethnic neighbourhoods also known as Koreatowns. The four largest diaspora population can be found in China (2.3 million), the United States (1.8 million), Japan (0.85 million), and Canada (0.25 million).  South Korea's birth rate was the world's lowest in 2009,[183] at an annual rate of approximately 9 births per 1000 people.[184] Fertility saw some modest increase afterwards,[185] but dropped to a new global low in 2017,[186] with fewer than 30,000 births per month for the first time since records began[187] and less than 1 child per woman in 2018.[188] The average life expectancy in 2008 was 79.10 years,[189] (which was 34th in the world[190]) but by 2015 it had increased to around 81.[191] South Korea has the steepest decline in working age population of the OECD nations.[192] In 2015, National Statistical Office estimated that the population of the country will have reached its peak by 2035.[170][171]    vte Largest cities or towns in South Korea 2015 Population and Housing Census[193] Rank	Name	Province	Pop.	Rank	Name	Province	Pop.	 Seoul Seoul Busan Busan	1	Seoul	Seoul	9,904,312	11	Yongin	Gyeonggi	971,327	Incheon Incheon Daegu Daegu 2	Busan	Busan	3,448,737	12	Seongnam	Gyeonggi	948,757 3	Incheon	Incheon	2,890,451	13	Bucheon	Gyeonggi	843,794 4	Daegu	Daegu	2,446,052	14	Cheongju	North Chungcheong	833,276 5	Daejeon	Daejeon	1,538,394	15	Ansan	Gyeonggi	747,035 6	Gwangju	Gwangju	1,502,881	16	Jeonju	North Jeolla	658,172 7	Suwon	Gyeonggi	1,194,313	17	Cheonan	South Chungcheong	629,062 8	Ulsan	Ulsan	1,166,615	18	Namyangju	Gyeonggi	629,061 9	Changwon	South Gyeongsang	1,059,241	19	Hwaseong	Gyeonggi	608,725 10	Goyang	Gyeonggi	990,073	20	Anyang	Gyeonggi	585,177 Education Main article: Education in South Korea  Seoul National University is considered to be the most prestigious university in South Korea. A centralized administration in South Korea oversees the process for the education of children from kindergarten to the third and final year of high school. The school year is divided into two semesters, the first of which begins at the beginning of March and ends in mid-July, the second of which begins in late August and ends in mid-February. The schedules are not uniformly standardized and vary from school to school. Most South Korean middle schools and high schools have school uniforms, modeled on western-style uniforms. Boys' uniforms usually consist of trousers and white shirts, and girls wear skirts and white shirts (this only applies in middle schools and high schools). The country adopted a new educational program to increase the number of their foreign students through 2010. According to the Ministry of Education, Science and Technology, the number of scholarships for foreign students in South Korea would have (under the program) doubled by that time, and the number of foreign students would have reached 100,000.[194]  South Korea is one of the top-performing OECD countries in reading literacy, mathematics and sciences with the average student scoring 519, compared with the OECD average of 492, placing it ninth in the world and has one of the world's most highly educated labor forces among OECD countries.[195][196] The country has one of the world's highest-educated labour forces among OECD countries.[197][198][199][200][excessive citations] The country is well known for its highly feverish outlook on education, where its national obsession with education has been called "education fever".[201][202][203] This obsession with education has catapulted the resource poor nation consistently atop the global education rankings where in 2014 national rankings of students' math and science scores by the Organization for Economic and Cooperation and Development (OECD), South Korea ranked second place worldwide, after Singapore.[204]  Higher education is a serious issue in South Korea society, where it is viewed as one of the fundamental cornerstones of South Korean life. Education is regarded with a high priority for South Korean families as success in education is often a source of pride for families and within South Korean society at large, and is a necessity to improve one's socioeconomic position in South Korean society.[205][206] South Koreans view education as the main propeller of social mobility for themselves and their family as a gateway to the South Korean middle class. Graduating from a top university is the ultimate marker of prestige, high socioeconomic status, promising marriage prospects, and a respectable career path.[207] The entrance into a top tier higher educational institution leads to a prestigious, secure and well-paid white collar job with the government, banks, or a major South Korean conglomerate such as Samsung, Hyundai or LG Electronics.[208] An average South Korean child's life revolves around education as pressure to succeed academically is deeply ingrained in South Korean children from an early age. With incredible pressure on high school students to secure places at the nation's best universities, its institutional reputation and alumni networks are strong predictors of future career prospects. The top three universities in South Korea, often referred to as "SKY", are Seoul National University, Korea University and Yonsei University.[209][210] Intense competition for top grades and academic pressure to be the top student is deeply ingrained in the psyche of South Korean students at a young age.[210] Yet with only so many places at the nations most prestigious universities and even fewer places at top-tier companies, many young people remain disappointed and are often unwilling to lower their sights with the result of many feeling as underachievers. There is a major cultural taboo in South Korean society attached to those who have not achieved formal university education where those who do not hold university degrees face social prejudice and are often looked down by others as second-class citizens resulting in fewer opportunities for employment, improvement of one's socioeconomic position and prospects for marriage.[211][212]   KAIST main campus in Daejeon In 2015, the country spent 5.1% of its GDP on all levels of education – roughly 0.8 percentage points above the Organisation for Economic Co-operation and Development (OECD) average of 4.3%.[213] A strong investment in education, a militant drive for success as well as the passion for excellence has helped the resource poor country rapidly grow its economy over the past 60 years from a war torn wasteland.[214]  International opinion regarding the South Korean education system has been divided. It has been praised for various reasons, including its comparatively high test results and its major role in ushering South Korea's economic development creating one of the world's most educated workforces.[215] South Korea's highly enviable academic performance has persuaded British education ministers to actively remodel their own curriculums and exams to try to emulate Korea's militant drive and passion for excellence and high educational achievement.[215] Former U.S. President Barack Obama has also praised the country's rigorous school system, where over 80 percent of South Korean high school graduates go on to university.[216] The nation's high university entrance rate has created a highly skilled workforce making South Korea among the most highly educated countries in the world with one of the highest percentages of its citizens holding a tertiary education degree.[217] In 2017, the country ranked fifth for the percentage of 25 to 64 year olds that have attained tertiary education with 47.7 percent.[217] In addition, 69.8 percent of South Koreans aged 25–34 have completed some form of tertiary education qualification and bachelor's degrees are held by 34.2 percent of South Koreans aged 25–64, the most in the OECD.[213][217]  The system's rigid and hierarchical structure has been criticized for stifling creativity and innovation;[218][219] described as intensely and "brutally" competitive,[220] the system is often blamed for the high suicide rate in the country, particularly the growing rates among those aged 10–19. Various media outlets attribute the country's high suicide rate to the nationwide anxiety around the country's college entrance exams, which determine the trajectory of students' entire lives and careers.[221][222] Former South Korean hagwon teacher Se-Woong Koo wrote that the South Korean education system amounts to child abuse and that it should be "reformed and restructured without delay".[223] The system has also been criticized for producing an excess supply of university graduates creating an overeducated and underemployed labor force; in the first quarter of 2013 alone, nearly 3.3 million South Korean university graduates were jobless, leaving many graduates overqualified for jobs requiring less education.[224] Further criticism has been stemmed for causing labor shortages in various skilled blue collar labor and vocational occupations, where many go unfilled as the negative social stigma associated with vocational careers and not having a university degree continues to remain deep-rooted in South Korean society.[212][225][226][227][228][229][230][231][excessive citations]  Language Main articles: Korean language and Korean dialects  Dialects of the Korean language Korean is the official language of South Korea, and is classified by most linguists as a language isolate. It incorporates a significant number of loan words from Chinese. Korean uses an indigenous writing system called Hangul, created in 1446 by King Sejong to provide a convenient alternative to the Classical Chinese Hanja characters that were difficult to learn and did not fit the Korean language well. South Korea still uses some Chinese Hanja characters in limited areas, such as print media and legal documentation.  The Korean language in South Korea has a standard dialect known as Seoul (after the capital city), with an additional 4 Korean language dialect groups in use around the country.  Almost all South Korean students today learn English throughout their education, with some optionally choosing Japanese or Mandarin as well.[232]  Religion Main article: Religion in South Korea See also: Irreligion in South Korea Religion in South Korea (2015 census)[233][5]    Irreligious (56.1%)   Protestantism (19.7%)   Korean Buddhism (15.5%)   Catholicism (7.9%)   Other (0.8%) According to the results of the census of 2015 more than half of the South Korean population (56.1%) declared themselves not affiliated with any religious organizations.[233] In a 2012 survey, 52% declared themselves "religious", 31% said they were "not religious" and 15% identified themselves as "convinced atheists".[234] Of the people who are affiliated with a religious organization, most are Christians and Buddhists. According to the 2015 census, 27.6% of the population were Christians (19.7% identified themselves as Protestants, 7.9% as Roman Catholics), and 15.5% were Buddhists.[233] Other religions include Islam (130,000 Muslims, mostly migrant workers from Pakistan and Bangladesh but including some 35,000 Korean Muslims,[235]) the homegrown sect of Won Buddhism, and a variety of indigenous religions, including Cheondoism (a Confucianizing religion), Jeungsanism, Daejongism, Daesun Jinrihoe and others. Freedom of religion is guaranteed by the constitution, and there is no state religion.[236] Overall, between the 2005 and 2015 censuses there has been a slight decline of Christianity (down from 29% to 27.6%), a sharp decline of Buddhism (down from 22.8% to 15.5%), and a rise of the unaffiliated population (from 47.2% to 56.9%).[233]  Christianity is South Korea's largest organized religion, accounting for more than half of all South Korean adherents of religious organizations. There are approximately 13.5 million Christians in South Korea today; about two thirds of them belonging to Protestant churches, and the rest to the Catholic Church.[233] The number of Protestants has been stagnant throughout the 1990s and the 2000s, but increased to a peak level throughout the 2010s. Roman Catholics increased significantly between the 1980s and the 2000s, but declined throughout the 2010s.[233] Christianity, unlike in other East Asian countries, found fertile ground in Korea in the 18th century, and by the end of the 18th century it persuaded a large part of the population as the declining monarchy supported it and opened the country to widespread proselytism as part of a project of Westernization. The weakness of Korean Sindo, which, unlike Japanese Shinto and China's religious system, never developed into a national religion of high status,[237] combined with the impoverished state of Korean Buddhism (after 500 years of suppression at the hands of the Joseon state, by the 20th century it was virtually extinct) left a free hand to Christian churches. Christianity's similarity to native religious narratives has been studied as another factor that contributed to its success in the peninsula.[238] The Japanese colonization of the first half of the 20th century further strengthened the identification of Christianity with Korean nationalism, as the Japanese coopted native Korean Sindo into the Nipponic Imperial Shinto that they tried to establish in the peninsula.[239] Widespread Christianization of the Koreans took place during State Shinto,[239] after its abolition, and then in the independent South Korea as the newly established military government supported Christianity and tried to utterly oust native Sindo.   Buddha's Birthday celebration in Seoul Among Christian denominations, Presbyterianism is the largest. About nine million people belong to one of the hundred different Presbyterian churches; the biggest ones are the HapDong Presbyterian Church, TongHap Presbyterian Church, the Koshin Presbyterian Church. South Korea is also the second-largest missionary-sending nation, after the United States.[240]  Buddhism was introduced to Korea in the 4th century.[241] It became soon a dominant religion in the southeastern kingdom of Silla, the region that hitherto hosts the strongest concentration of Buddhists in South Korea. In the other states of the Three Kingdoms Period, Goguryeo and Baekje, it was made the state religion respectively in 372 and 528. It remained the state religion in Later Silla (North South States Period) and Goryeo. It was later suppressed throughout much of the subsequent history under the unified kingdom of Joseon (1392–1897), which officially adopted a strict Korean Confucianism. Today, South Korea has about 7 million Buddhists,[233] most of them affiliated to the Jogye Order. Most of the National Treasures of South Korea are Buddhist artifacts.  Health Main article: Health in South Korea South Korea has a universal healthcare system.[242] It has the world's second best healthcare system.[243]  Suicide in South Korea is the 10th highest in the world according to the World Health Organization, as well as the highest suicide rate in the OECD.[244][245][246][247][248][excessive citations]  South Korean hospitals have advanced medical equipment and facilities readily available, ranking 4th for MRI units per capita and 6th for CT scanners per capita in the OECD.[249] It also had the OECD's second largest number of hospital beds per 1000 people at 9.56 beds.  Life expectancy has been rising rapidly and South Korea ranked 11th in the world for life expectancy at 82.3 years by the WHO in 2015.[250] It also has the third highest health adjusted life expectancy in the world.[251]  Foreign relations Main article: Foreign relations of South Korea  Former Secretary-General of the United Nations (2007–2016), Ban Ki-moon South Korea maintains diplomatic relations with more than 188 countries. The country has also been a member of the United Nations since 1991, when it became a member state at the same time as North Korea. On 1 January 2007, Former South Korean Foreign Minister Ban Ki-moon served as UN Secretary-General from 2007 to 2016. It has also developed links with the Association of Southeast Asian Nations as both a member of ASEAN Plus three, a body of observers, and the East Asia Summit (EAS).  In November 2009 South Korea joined the OECD Development Assistance Committee, marking the first time a former aid recipient country joined the group as a donor member.  South Korea hosted the G-20 Summit in Seoul in November 2010, a year that saw South Korea and the European Union conclude a free trade agreement (FTA) to reduce trade barriers. South Korea went on to sign a Free Trade Agreements with Canada and Australia in 2014, and another with New Zealand in 2015.  North Korea Main article: North Korea–South Korea relations  The Joint Security Area Both North and South Korea claim complete sovereignty over the entire peninsula and outlying islands.[252] Despite mutual animosity, reconciliation efforts have continued since the initial separation between North and South Korea. Political figures such as Kim Koo worked to reconcile the two governments even after the Korean War.[253] With longstanding animosity following the Korean War from 1950 to 1953, North Korea and South Korea signed an agreement to pursue peace.[254] On 4 October 2007, Roh Moo-Hyun and North Korean leader Kim Jong-il signed an eight-point agreement on issues of permanent peace, high-level talks, economic cooperation, renewal of train services, highway and air travel, and a joint Olympic cheering squad.[254]   North Korean leader Kim Jong-un and South Korean President Moon Jae-in shake hands inside the Peace House Despite the Sunshine Policy and efforts at reconciliation, the progress was complicated by North Korean missile tests in 1993, 1998, 2006, 2009, and 2013. By early 2009, relationships between North and South Korea were very tense; North Korea had been reported to have deployed missiles,[255] ended its former agreements with South Korea,[256] and threatened South Korea and the United States not to interfere with a satellite launch it had planned.[257] North and South Korea are still technically at war (having never signed a peace treaty after the Korean War) and share the world's most heavily fortified border.[258] On 27 May 2009, North Korean media declared that the Armistice is no longer valid because of the South Korean government's pledge to "definitely join" the Proliferation Security Initiative.[259] To further complicate and intensify strains between the two nations, the sinking of the South Korean warship Cheonan in March 2010, is affirmed by the South Korean government[260] to have been caused by a North Korean torpedo, which the North denies. President Lee Myung-bak declared in May 2010 that Seoul would cut all trade with North Korea as part of measures primarily aimed at striking back at North Korea diplomatically and financially, except for the joint Kaesong Industrial Project, and humanitarian aid.[261] North Korea initially threatened to sever all ties, to completely abrogate the previous pact of non-aggression, and to expel all South Koreans from a joint industrial zone in Kaesong, but backtracked on its threats and decided to continue its ties with South Korea. Despite the continuing ties, Kaesong industrial zone has seen a large decrease in investment and manpower as a result of this military conflict. In February 2016, the Kaesong complex was closed by Seoul in reaction to North Korea's launch of a rocket earlier in the month[262] unanimously condemned by the United Nations security council.[263] The 2017 election of President Moon Jae-in has seen a change in approach towards the North, and both sides used the South Korean held 2018 Winter Olympics as an opportunity for engagement,[264] with a very senior North Korean political delegation sent to the games, along with a reciprocal visit by senior South Korean cabinet members to the North soon afterwards.[265]  China and Russia Main articles: China–South Korea relations, South Korea–Taiwan relations, and Russia–South Korea relations Historically, Korea had close relations with the dynasties in China, and some Korean kingdoms were members of the Imperial Chinese tributary system.[266][267][268][269][excessive citations] The Korean kingdoms also ruled over some Chinese kingdoms including the Khitan people and the Manchurians before the Qing dynasty and received tributes from them.[270] In modern times, before the formation of South Korea, Korean independence fighters worked with Chinese soldiers during the Japanese occupation. However, after World War II, the People's Republic of China embraced Maoism while South Korea sought close relations with the United States. The PRC assisted North Korea with manpower and supplies during the Korean War, and in its aftermath the diplomatic relationship between South Korea and the PRC almost completely ceased. Relations thawed gradually and South Korea and the PRC re-established formal diplomatic relations on 24 August 1992. The two countries sought to improve bilateral relations and lifted the forty-year-old trade embargo,[271] and South Korean–Chinese relations have improved steadily since 1992.[271] The Republic of Korea broke off official relations with the Republic of China (Taiwan) upon gaining official relations with the People's Republic of China, which does not recognize Taiwan's sovereignty.[272]   South Korean president Moon Jae-in meets with Russian president Vladimir Putin China has become South Korea's largest trading partner by far, sending 26% of South Korean exports in 2016 worth $124 billion, as well as an additional $32 billion worth of exports to Hong Kong.[273] South Korea is also China's 4th largest trading partner, with $93 billion of Chinese imports in 2016.[274]  The 2017 deployment of THAAD defense missiles by the United States military in South Korea in response to North Korean missile tests has been protested strongly by the Chinese government, concerned that the technologically advanced missile defense could be used more broadly against China.[275] Relations between the governments have cooled in response, with South Korean commercial and cultural interests in China having been targeted, and Chinese tourism to South Korea having been curtailed.[276] The situation was largely resolved by South Korea making significant military concessions to China in exchange for THAAD, including not deploying any more anti-ballistic missile systems in South Korea and not participating in an alliance between the United States and Japan.[277]  South Korea and Russia are participants in the Six-party talks on the North Korea's nuclear proliferation issue. Moon Jae-in's administration has focused on increasing South Korea's consumption of natural gas. These plans include re-opening dialogue around a natural gas pipeline that would come from Russia and pass through North Korea.[278] In June 2018, president Moon Jae-in became the first South Korean leader to speak in the Russian Parliament.[279] On 22 June, Moon Jae-in and Putin signed a document for foundation of free trade area.[280]  Japan Main article: Japan–South Korea relations See also: History of Japan–Korea relations and Japan–Korea disputes  Liancourt Rocks have become an issue known as the Liancourt Rocks dispute. Korea and Japan have had difficult relations since ancient times, but also significant cultural exchange, with Korea acting as the gateway between Asia and Japan. Contemporary perceptions of Japan are still largely defined by Japan's 35 year colonization of Korea in the 20th century, which is generally regarded in South Korea as having been very negative. Japan is today South Korea's third largest trading partner, with 12% ($46 billion) of exports in 2016.[273]  There were no formal diplomatic ties between South Korea and Japan directly after independence the end of World War II in 1945. South Korea and Japan eventually signed the Treaty on Basic Relations between Japan and the Republic of Korea in 1965 to establish diplomatic ties. There is heavy anti-Japanese sentiment in South Korea because of a number of unsettled Japanese-Korean disputes, many of which stem from the period of Japanese occupation after the Japanese annexation of Korea. During World War II, more than 100,000 Koreans served in the Imperial Japanese Army.[281][282] Korean women were coerced and forced to serve the Imperial Japanese Army as sexual slaves, called comfort women, in both Korea and throughout the Japanese war fronts.[283][284][285][286][excessive citations]  Longstanding issues such as Japanese war crimes against Korean civilians, the negationist re-writing of Japanese textbooks relating Japanese atrocities during World War II, the territorial disputes over the Liancourt Rocks, known in South Korea as "Dokdo" and in Japan as "Takeshima",[287] and visits by Japanese politicians to the Yasukuni Shrine, honoring Japanese people (civilians and military) killed during the war continue to trouble Korean-Japanese relations. The Liancourt Rocks were the first Korean territories to be forcibly colonized by Japan in 1905. Although it was again returned to Korea along with the rest of its territory in 1951 with the signing of the Treaty of San Francisco, Japan does not recant on its claims that the Liancourt Rocks are Japanese territory.[288] In response to then-Prime Minister Junichiro Koizumi's visits to the Yasukuni Shrine, former President Roh Moo-hyun suspended all summit talks between South Korea and Japan in 2009.[289] A summit between the nations' leaders was eventually held on 9 February 2018 during the Korean held Winter Olympics.[290] South Korea asked the International Olympic Committee (IOC) to ban the Japanese Rising Sun Flag from the 2020 Summer Olympics in Tokyo,[291][292] and the IOC said in a statement "sports stadiums should be free of any political demonstration. When concerns arise at games time we look at them on a case-by-case basis."[293]  European Union Main article: South Korea–European Union relations The European Union (EU) and South Korea are important trading partners, having negotiated a free trade agreement for many years since South Korea was designated as a priority FTA partner in 2006. The free trade agreement was approved in September 2010, and took effect on 1 July 2011.[294] South Korea is the EU's tenth largest trade partner, and the EU has become South Korea's fourth largest export destination. EU trade with South Korea exceeded €90 billion in 2015 and has enjoyed an annual average growth rate of 9.8% between 2003 and 2013.[295]  The EU has been the single largest foreign investor in South Korea since 1962, and accounted for almost 45% of all FDI inflows into Korea in 2006. Nevertheless, EU companies have significant problems accessing and operating in the South Korean market because of stringent standards and testing requirements for products and services often creating barriers to trade. Both in its regular bilateral contacts with South Korea and through its FTA with Korea, the EU is seeking to improve this situation.[295]  United States Main article: South Korea–United States relations  President Moon Jae-in and U.S. President Joe Biden having lunch on May 21, 2021, on the Oval Office Patio of the White House The close relationship began directly after World War II, when the United States temporarily administrated Korea for three years (mainly in the South, with the Soviet Union engaged in North Korea) after Japan. Upon the onset of the Korean War in 1950, U.S. forces were sent to defend against an invasion from North Korea of the South, and subsequently fought as the largest contributor of UN troops. The United States participation was critical for preventing the near defeat of the Republic of Korea by northern forces, as well as fighting back for the territory gains that define the South Korean nation today.  Following the Armistice, South Korea and the U.S. agreed to a "Mutual Defense Treaty", under which an attack on either party in the Pacific area would summon a response from both.[296] In 1967, South Korea obliged the mutual defense treaty, by sending a large combat troop contingent to support the United States in the Vietnam War. The US has over 23,000 troops stationed in South Korea, including the U.S. Eighth Army, Seventh Air Force, and U.S. Naval Forces Korea. The two nations have strong economic, diplomatic, and military ties, although they have at times disagreed with regard to policies towards North Korea, and with regard to some of South Korea's industrial activities that involve usage of rocket or nuclear technology. There had also been strong anti-American sentiment during certain periods, which has largely moderated in the modern day.[297]  The two nations also share a close economic relationship, with the U.S being South Korea's second largest trading partner, receiving $66 billion in exports in 2016.[273] In 2007, a free trade agreement known as the Republic of Korea-United States Free Trade Agreement (KORUS FTA) was signed between South Korea and the United States, but its formal implementation was repeatedly delayed, pending approval by the legislative bodies of the two countries. On 12 October 2011, the U.S. Congress passed the long-stalled trade agreement with South Korea.[298] It went into effect on 15 March 2012.[299]  Military Main article: Republic of Korea Armed Forces Ambox current red Americas.svg This section's factual accuracy may be compromised due to out-of-date information. Please help update this article to reflect recent events or newly available information. (March 2012) Unresolved tension with North Korea has prompted South Korea to allocate 2.6% of its GDP and 15% of all government spending to its military (Government share of GDP: 14.967%), while maintaining compulsory conscription for men.[300] Consequently, South Korea has the world's seventh largest number of active troops (599,000 in 2018), the world's highest number of reserve troops (3,100,000 in 2018)[301] and the tenth largest defense budget. As of 2019 South Korea has a defense budget of $43.1 billion. The South Korean military is ranked as the 6th most powerful military force in the world as of 2020.[302]  The South Korean military consists of the Army (ROKA), the Navy (ROKN), the Air Force (ROKAF), and the Marine Corps (ROKMC), and reserve forces.[303] Many of these forces are concentrated near the Korean Demilitarized Zone. All South Korean males are constitutionally required to serve in the military, typically 18 months. Previous exceptions for South Korean citizens of mixed race no longer apply since 2011.[304]   ROKN Sejong the Great, a King Sejong the Great -class guided-missile destroyer built by Hyundai Heavy Industries In addition to male conscription in South Korea's sovereign military, 1,800 Korean males are selected every year to serve 18 months in the KATUSA Program to further augment the United States Forces Korea (USFK).[305] In 2010, South Korea was spending ₩1.68 trillion in a cost-sharing agreement with the US to provide budgetary support to the US forces in Korea, on top of the ₩29.6 trillion budget for its own military.   The South Korean-developed K2 Black Panther, built by Hyundai Rotem The South Korean army has 2,500 tanks in operation, including the K1A1 and K2 Black Panther, which form the backbone of the South Korean army's mechanized armor and infantry forces. A sizable arsenal of many artillery systems, including 1,700 self-propelled K55 and K9 Thunder howitzers and 680 helicopters and UAVs of numerous types, are assembled to provide additional fire, reconnaissance, and logistics support. South Korea's smaller but more advanced artillery force and wide range of airborne reconnaissance platforms are pivotal in the counter-battery suppression of North Korea's large artillery force, which operates more than 13,000 artillery systems deployed in various state of fortification and mobility.[306]  The South Korean navy has made its first major transformation into a blue-water navy through the formation of the Strategic Mobile Fleet, which includes a battle group of Chungmugong Yi Sun-sin class destroyers, Dokdo class amphibious assault ship, AIP-driven Type 214 submarines, and King Sejong the Great class destroyers, which is equipped with the latest baseline of Aegis fleet-defense system that allows the ships to track and destroy multiple cruise missiles and ballistic missiles simultaneously, forming an integral part of South Korea's indigenous missile defense umbrella against the North Korean military's missile threat.[307]  The South Korean air force operates 840 aircraft, making it world's ninth largest air force, including several types of advanced fighters like F-15K, heavily modified KF-16C/D,[308] and the indigenous T-50 Golden Eagle,[309][310] supported by well-maintained fleets of older fighters such as F-4E and KF-5E/F that still effectively serve the air force alongside the more modern aircraft. In an attempt to gain strength in terms of not just numbers but also modernity, the commissioning of four Boeing 737 AEW&C aircraft, under Project Peace Eye for centralized intelligence gathering and analysis on a modern battlefield, will enhance the fighters' and other support aircraft's ability to perform their missions with awareness and precision.  In May 2011, Korea Aerospace Industries Ltd., South Korea's largest plane maker, signed a $400 million deal to sell 16 T-50 Golden Eagle trainer jets to Indonesia, making South Korea the first country in Asia to export supersonic jets.[311]   ROKAF FA-50, a supersonic combat aircraft developed by Korea Aerospace Industries From time to time, South Korea has sent its troops overseas to assist American forces. It has participated in most major conflicts that the United States has been involved in the past 50 years. South Korea dispatched 325,517 troops to fight alongside American, Australian, Filipino, New Zealand and South Vietnamese soldiers in the Vietnam War, with a peak strength of 50,000.[312] In 2004, South Korea sent 3,300 troops of the Zaytun Division to help re-building in northern Iraq, and was the third largest contributor in the coalition forces after only the US and Britain.[313] Beginning in 2001, South Korea had so far deployed 24,000 troops in the Middle East region to support the War on Terrorism. A further 1,800 were deployed since 2007 to reinforce UN peacekeeping forces in Lebanon.   ROKS Dokdo, the lead ship of the Dokdo-class amphibious assault ship, built by Hanjin Heavy Industries United States contingent The United States has stationed a substantial contingent of troops to defend South Korea. There are approximately 28,500 U.S. military personnel stationed in South Korea,[314] most of them serving one year unaccompanied tours. The U.S. troops, which are primarily ground and air units, are assigned to USFK and mainly assigned to the Eighth United States Army of the U.S. Army and Seventh Air Force of the U.S. Air Force. They are stationed in installations at Osan, Kunsan, Yongsan, Dongducheon, Sungbuk, Camp Humphreys, and Daegu, as well as at Camp Bonifas in the DMZ Joint Security Area.  A fully functioning UN Command is at the top of the chain of command of all forces in South Korea, including the U.S. forces and the entire South Korean military – if a sudden escalation of war between North and South Korea were to occur the United States would assume control of the South Korean armed forces in all military and paramilitary moves. There has been long-term agreement between the United States and South Korea that South Korea should eventually assume the lead for its own defense. This transition to a South Korean command has been slow and often postponed, although it is currently scheduled to occur in the early 2020s.[315]  Conscientious objection Ambox current red Americas.svg This section needs to be updated. Please help update this article to reflect recent events or newly available information. (October 2019) Male citizens who refuse or reject to undertake military services because of conscientious objection are typically imprisoned, with over 600 individuals usually imprisoned at any given time; more than the rest of the world put together.[316] The vast majority of these are young men from the Jehovah's Witnesses Christian denomination.[317] See Conscription in South Korea. However, in a court ruling of 2018, conscientious objectors were permitted to reject military service.[318]  Economy Main article: Economy of South Korea See also: Economic inequality in South Korea Share of world GDP (PPP)[319] Year	Share 1980	0.63% 1990	1.18% 2000	1.55% 2010	1.65% 2017	1.60%  Graphical depiction of South Korea's product exports in 28 color-coded categories  The Bank of Korea, the central bank of the South Korea and issuer of the South Korean won  The Samsung headquarters in Samsung Town, located in Seocho-gu, Seoul  The Lotte World Tower in Songpa-gu, Seoul, is the tallest building in South Korea and the 5th tallest in the world. South Korea's mixed economy[320][321][322] ranks 10th nominal[323] and 13th purchasing power parity GDP in the world, identifying it as one of the G-20 major economies. It is a developed country with a high-income economy and is the most industrialized member country of the OECD. South Korean brands such as LG Electronics and Samsung are internationally famous and garnered South Korea's reputation for its quality electronics and other manufactured goods.[324]  Its massive investment in education has taken the country from mass illiteracy to a major international technological powerhouse. The country's national economy benefits from a highly skilled workforce and is among the most educated countries in the world with one of the highest percentages of its citizens holding a tertiary education degree.[325] South Korea's economy was one of the world's fastest-growing from the early 1960s to the late 1990s, and was still one of the fastest-growing developed countries in the 2000s, along with Hong Kong, Singapore and Taiwan, the other three Asian Tigers.[326] It recorded the fastest rise in average GDP per capita in the world between 1980 and 1990.[327] South Koreans refer to this growth as the Miracle on the Han River.[328] The South Korean economy is heavily dependent on international trade, and in 2014, South Korea was the fifth-largest exporter and seventh-largest importer in the world.  Despite the South Korean economy's high growth potential and apparent structural stability, the country suffers damage to its credit rating in the stock market because of the belligerence of North Korea in times of deep military crises, which has an adverse effect on South Korean financial markets.[329][330] The International Monetary Fund compliments the resilience of the South Korean economy against various economic crises, citing low state debt and high fiscal reserves that can quickly be mobilized to address financial emergencies.[331] Although it was severely harmed by the 1997 Asian financial crisis, the South Korean economy managed a rapid recovery and subsequently tripled its GDP.[332]  Furthermore, South Korea was one of the few developed countries that were able to avoid a recession during the global financial crisis.[333] Its economic growth rate reached 6.2 percent in 2010 (the fastest growth for eight years after significant growth by 7.2 percent in 2002),[334] a sharp recovery from economic growth rates of 2.3% in 2008 and 0.2% in 2009 during the Great Recession. The unemployment rate in South Korea also remained low in 2009, at 3.6%.[335]  South Korea became a member of the Organisation for Economic Co-operation and Development (OECD) in 1996.[336]  The following list includes the largest South Korean companies by revenue in 2017 who are all listed as part of the Fortune Global 500:  Rank[337]	Name	Headquarters	Revenue (Mil. $)	Profit (Mil. $)	Assets (Mil. $) 1.	Samsung Electronics	Suwon	173,957	19,316	217,104 2.	Hyundai Motor	Seoul	80,701	4,659	148,092 3.	SK Holdings	Seoul	72,579	659	85.332 4.	Korea Electric Power	Naju	51,500	6,074	147,265 5.	LG Electronics	Seoul	47,712	66	31,348 6.	POSCO	Pohang	45,621	1,167	66,361 7.	Kia Motors	Seoul	45,425	2,373	42,141 8.	Hanwha	Seoul	40,606	423	128,247 9.	Hyundai Heavy Industries	Ulsan	33,881	469	40,783 10.	Hyundai Mobis	Seoul	32,972	2,617	34,541 11.	Samsung Life Insurance	Seoul	26,222	1,770	219,157 12.	Lotte Shopping	Seoul	25,444	144	34,710 13.	Samsung C&T	Seoul	24,217	92	36,816 14.	LG Display	Seoul	22,840	781	20,606 15.	GS Caltex	Seoul	22,207	1,221	15,969 Transportation, energy and infrastructure Main articles: Transport in South Korea and Energy in South Korea  Incheon International Airport's Maglev station  South Korea developed the HEMU 430X high-speed train, which can travel at over 430 km/h (267 mph), making South Korea the world's fourth country after France, Japan and China to develop a high-speed train running above 420 km/h on conventional rails.  The Daegu Metro Line 3 monorail South Korea has a technologically advanced transport network consisting of high-speed railways, highways, bus routes, ferry services, and air routes that crisscross the country. Korea Expressway Corporation operates the toll highways and service amenities en route.  Korail provides frequent train services to all major South Korean cities. Two rail lines, Gyeongui and Donghae Bukbu Line, to North Korea are now being reconnected. The Korean high-speed rail system, KTX, provides high-speed service along Gyeongbu and Honam Line. Major cities including Seoul, Busan, Incheon, Daegu, Daejeon and Gwangju have urban rapid transit systems.[338] Express bus terminals are available in most cities.[339]  South Korea's main gateway and largest airport is Incheon International Airport, serving 58 million passengers in 2016.[340] Other international airports include Gimpo, Busan and Jeju. There are also many airports that were built as part of the infrastructure boom but are barely used.[341] There are also many heliports.[342]  The national carrier, Korean Air served over 26,800,000 passengers, including almost 19,000,000 international passengers in 2016.[343] A second carrier, Asiana Airlines also serves domestic and international traffic. Combined, South Korean airlines serve 297 international routes.[344] Smaller airlines, such as Jeju Air, provide domestic service with lower fares.[345]  South Korea is the world's fifth-largest nuclear power producer and the second-largest in Asia as of 2010.[346] Nuclear power in South Korea supplies 45% of electricity production, and research is very active with investigation into a variety of advanced reactors, including a small modular reactor, a liquid-metal fast/transmutation reactor and a high-temperature hydrogen generation design. Fuel production and waste handling technologies have also been developed locally. It is also a member of the ITER project.[347]  South Korea is an emerging exporter of nuclear reactors, having concluded agreements with the UAE to build and maintain four advanced nuclear reactors,[348] with Jordan for a research nuclear reactor,[349][350] and with Argentina for construction and repair of heavy-water nuclear reactors.[351][352] As of 2010, South Korea and Turkey are in negotiations regarding construction of two nuclear reactors.[353] South Korea is also preparing to bid on construction of a light-water nuclear reactor for Argentina.[352]  South Korea is not allowed to enrich uranium or develop traditional uranium enrichment technology on its own, because of US political pressure,[354] unlike most major nuclear powers such as Japan, Germany, and France, competitors of South Korea in the international nuclear market. This impediment to South Korea's indigenous nuclear industrial undertaking has sparked occasional diplomatic rows between the two allies. While South Korea is successful in exporting its electricity-generating nuclear technology and nuclear reactors, it cannot capitalize on the market for nuclear enrichment facilities and refineries, preventing it from further expanding its export niche. South Korea has sought unique technologies such as pyroprocessing to circumvent these obstacles and seek a more advantageous competition.[355] The US has recently been wary of South Korea's burgeoning nuclear program, which South Korea insists will be for civilian use only.[346]  South Korea is the third highest ranked Asian country in the World Economic Forum's Network Readiness Index (NRI) after Singapore and Hong Kong respectively – an indicator for determining the development level of a country's information and communication technologies. South Korea ranked number 10 overall in the 2014 NRI ranking, up from 11 in 2013.[356]  Tourism Main article: Tourism in South Korea  Haeundae Beach in Busan In 2016, 17 million foreign tourists visited South Korea[357][358] With rising tourist prospects, especially from foreign countries outside of Asia, the South Korean government has set a target of attracting 20 million foreign tourists a year by 2017.[359]  South Korean tourism is driven by many factors, including the prominence of Korean pop culture such as South Korean pop music and television dramas, known as the Korean Wave or (Hallyu), has gained popularity throughout East Asia. The Hyundai Research Institute reported that the Korean Wave has a direct impact in encouraging direct foreign investment back into the country through demand for products, and the tourism industry.[360] Among East Asian countries, China was the most receptive, investing 1.4 billion in South Korea, with much of the investment within its service sector, a sevenfold increase from 2001. According to an analysis by economist Han Sang-Wan, a 1 percent increase in the exports of Korean cultural content pushes consumer goods exports up 0.083 percent while a 1 percent increase in Korean pop content exports to a country produces a 0.019 percent bump in tourism.[360]  South Korean National Pension System See also: Aging of South Korea and Poverty in South Korea  It has been suggested that this article be split into multiple articles. (Discuss) (November 2020) The South Korean pension system was created to provide benefits to persons reaching old age, families and persons stricken with death of their primary breadwinner, and for the purposes of stabilizing its nations welfare state.[361] South Korea's pension system structure is primarily based on taxation and is income-related. In 2007 there was a total of 18,367,000 insured individuals with only around 511,000 persons excluded from mandatory contribution.[362] The current pension system is divided into four categories distributing benefits to participants through national, military personnel, governmental, and private school teacher pension schemes.[363] The national pension scheme is the primary welfare system providing allowances to the majority of persons. Eligibility for the national pension scheme is not dependent on income but on age and residence, where those between the ages of 18 to 59 are covered.[364] Any one who is under the age of 18 are dependents of someone who is covered or under a special exclusion where they are allowed to alternative provisions.[365] The national pension scheme is divided into four categories of insured persons – the workplace-based insured, the individually insured, the voluntarily insured, and the voluntarily and continuously insured.  Employees between the ages of 18 to 59 are covered under the workplace-based pension scheme and contribute 4.5% of their gross monthly earnings.[361] The national pension covers employees who work in firms that employ five or more employees, fishermen, farmers, and the self-employed in both rural and urban areas. Employers are also covered under the workplace-based pension scheme and help cover their employees obligated 9% contribution by providing the remaining 4.5%.[365] Anyone who is not employed, of the age of 60 or above, and excluded by article 6 of the National Pension Act[366] but of the ages between 18 and 59, is covered under the individually insured pension scheme.[366] Persons covered by the individually insured pension scheme are in charge of paying the entire 9% contribution themselves. Voluntarily insured persons are not subjected to mandatory coverage but can choose to be. This category comprises retirees who voluntarily choose to have additional benefits, individuals under the age of 27 without income, and individuals whose spouses are covered under a public welfare system, whether military, governmental, or private school teacher pensions.[364] Like the Individually insured persons, they too are in charge of covering the full amount of the contribution. Voluntarily and continuously insured persons consists of individuals 60 years of age who want to fulfill the minimum insured period of 20 years to qualify for old age pension benefits.[366] Excluding the workplace-based insured persons, all the other insured persons personally cover their own 9% contribution.[364]  South Korea's old-age pension scheme covers individuals age 60 or older for the rest of their life as long as they have satisfied the minimum of 20 years of national pension coverage beforehand.[365] Individuals with a minimum of 10 years covered under the national pension scheme and who are 60 years of age are able to be covered by under a 'reduced old-age pension' scheme. There also is an 'active old-age pension' scheme that covers individuals age 60 to 65 engaged in activities yielding earned income. Individuals age of 55 and younger than 60 who are not engaged in activities yielding earned income are eligible to be covered under the 'early old-age pension' scheme.[366] Around 60% of all Korean elders, age 65 and over are entitled to a 5% benefit of their past average income at an average of 90,000 Korean Won (KRW).[367] Basic old-age pension schemes covered individuals 65 years of age who earned below an amount set by presidential order. In 2010, that ceiling was 700,000 KRW for a single individual and 1,120,000 for a couple, equivalent to around $600.00 and $960.00.[365]  Science and technology Main article: History of science and technology in Korea See also: List of Korean inventions and discoveries  A 3D OLED TV made by Korean LG Display, the world's largest LCD and OLED maker Scientific and technological development in the South Korea at first did not occur largely because of more pressing matters such as the division of Korea and the Korean War that occurred right after its independence. It was not until the 1960s under the dictatorship of Park Chung-hee where South Korea's economy rapidly grew from industrialisation and the Chaebol corporations such as Samsung and LG. Ever since the industrialization of South Korea's economy, South Korea has placed its focus on technology-based corporations, which has been supported by infrastructure developments by the government. South Korean corporations Samsung and LG were ranked first and third largest mobile phone companies in the world in the first quarter of 2012, respectively.[368] An estimated 90% of South Koreans own a mobile phone.[369] Aside from placing/receiving calls and text messaging, mobile phones in the country are widely used for watching Digital Multimedia Broadcasting (DMB) or viewing websites.[370] Over one million DMB phones have been sold and the three major wireless communications providers SK Telecom, KT, and LG U+ provide coverage in all major cities and other areas. South Korea has the fastest Internet download speeds in the world,[371] with an average download speed of 25.3 Mbit/s.[372]  South Korea leads the OECD in graduates in science and engineering.[373] From 2014 to 2019, the country ranked first among the most innovative countries in the Bloomberg Innovation Index.[374][375][376][377][excessive citations]  It was ranked 10th in the Global Innovation Index 2020, up from 11st in 2019.[378][379][380][381][excessive citations] Additionally, South Korea today is known as a Launchpad of a mature mobile market, where developers can reap benefits of a market where very few technology constraints exist. There is a growing trend of inventions of new types of media or apps, utilizing the 4G and 5G internet infrastructure in South Korea. South Korea has today the infrastructures to meet a density of population and culture that has the capability to create strong local particularity.[382]  Cyber security See also: Internet censorship in South Korea Following cyberattacks in the first half of 2013, whereby government, news-media, television station, and bank websites were compromised, the national government committed to the training of 5,000 new cybersecurity experts by 2017. The South Korean government blamed North Korea for these attacks, as well as incidents that occurred in 2009, 2011 and 2012, but Pyongyang denies the accusations.[383]  In late September 2013, a computer-security competition jointly sponsored by the defense ministry and the National Intelligence Service was announced. The winners were announced on 29 September 2013 and shared a total prize pool of 80 million won (US$74,000).[383]  South Korea's government maintains a broad-ranging approach toward the regulation of specific online content and imposes a substantial level of censorship on election-related discourse and on many websites that the government deems subversive or socially harmful.[384][385]  Aerospace engineering Main article: Korea Aerospace Research Institute  Naro-1 at the launch pad South Korea has sent up 10 satellites since 1992, all using foreign rockets and overseas launch pads, notably Arirang-1 in 1999, and Arirang-2 in 2006 as part of its space partnership with Russia.[386] Arirang-1 was lost in space in 2008, after nine years in service.[387]  In April 2008, Yi So-yeon became the first Korean to fly in space, aboard the Russian Soyuz TMA-12.[388][389]  In June 2009, the first spaceport of South Korea, Naro Space Center, was completed at Goheung, Jeollanam-do.[390] The launch of Naro-1 in August 2009 resulted in a failure.[391] The second attempt in June 2010 was also unsuccessful.[392] However, the third launch of the Naro 1 in January 2013 was successful.[393] The government plans to develop Naro-2 by the year 2018.[394]  South Korea's efforts to build an indigenous space launch vehicle have been marred due to persistent political pressure from the United States, who had for many decades hindered South Korea's indigenous rocket and missile development programs[395] in fear of their possible connection to clandestine military ballistic missile programs, which Korea many times insisted did not violate the research and development guidelines stipulated by US-Korea agreements on restriction of South Korean rocket technology research and development.[396] South Korea has sought the assistance of foreign countries such as Russia through MTCR commitments to supplement its restricted domestic rocket technology. The two failed KSLV-I launch vehicles were based on the Universal Rocket Module, the first stage of the Russian Angara rocket, combined with a solid-fueled second stage built by South Korea.  Robotics  Albert HUBO, developed by KAIST, can make expressive gestures with its five separate fingers. Robotics has been included in the list of main national R&D projects in Korea since 2003.[397] In 2009, the government announced plans to build robot-themed parks in Incheon and Masan with a mix of public and private funding.[398]  In 2005, Korea Advanced Institute of Science and Technology (KAIST) developed the world's second walking humanoid robot, HUBO. A team in the Korea Institute of Industrial Technology developed the first Korean android, EveR-1 in May 2006.[399] EveR-1 has been succeeded by more complex models with improved movement and vision.[400][401]  Plans of creating English-teaching robot assistants to compensate for the shortage of teachers were announced in February 2010, with the robots being deployed to most preschools and kindergartens by 2013.[402] Robotics are also incorporated in the entertainment sector as well; the Korean Robot Game Festival has been held every year since 2004 to promote science and robot technology.[403]  Biotechnology Since the 1980s, the Korean government has invested in the development of a domestic biotechnology industry, and the sector is projected to grow to $6.5 billion by 2010.[404] The medical sector accounts for a large part of the production, including production of hepatitis vaccines and antibiotics.  Recently, research and development in genetics and cloning has received increasing attention, with the first successful cloning of a dog, Snuppy (in 2005), and the cloning of two females of an endangered species of gray wolves by the Seoul National University in 2007.[405]  The rapid growth of the industry has resulted in significant voids in regulation of ethics, as was highlighted by the scientific misconduct case involving Hwang Woo-Suk.[406]  Since late 2020, SK Bioscience Inc. (a division of SK Group) has been producing a major proportion of the Vaxzevria vaccine (also known as COVID-19 Vaccine AstraZeneca), under license from the University of Oxford and AstraZeneca, for worldwide distribution through the COVAX facility under the WHO hospice. A recent agreement with Novavax expands its production for a second vaccine to 40 million doses in 2022, with a $450 million investment in domestic and overseas facilities.[407]  Culture Main article: Culture of South Korea See also: Culture of Korea  A musician playing a gayageum South Korea shares its traditional culture with North Korea, but the two Koreas have developed distinct contemporary forms of culture since the peninsula was divided in 1945. Historically, while the culture of Korea has been heavily influenced by that of neighboring China, it has nevertheless managed to develop a unique cultural identity that is distinct from its larger neighbor.[408] Its rich and vibrant culture left 19 UNESCO Intangible Cultural Heritages of Humanity, the third largest in the world, along with 12 World Heritage Sites. The South Korean Ministry of Culture, Sports and Tourism actively encourages the traditional arts, as well as modern forms, through funding and education programs.[409]  The industrialization and urbanization of South Korea have brought many changes to the way modern Koreans live. Changing economics and lifestyles have led to a concentration of population in major cities, especially the capital Seoul, with multi-generational households separating into nuclear family living arrangements. A 2014 Euromonitor study found that South Koreans drink the most alcohol on a weekly basis compared to the rest of the world. South Koreans drink 13.7 shots of liquor per week on average and, of the 44 other countries analyzed, Russia, the Philippines, and Thailand follow.[410]  Art Main article: Korean art  A blue and white porcelain peach-shaped water dropper from the Joseon Dynasty in the 18th century Korean art has been highly influenced by Buddhism and Confucianism, which can be seen in the many traditional paintings, sculptures, ceramics and the performing arts.[411] Korean pottery and porcelain, such as Joseon's baekja and buncheong, and Goryeo's celadon are well known throughout the world.[412] The Korean tea ceremony, pansori, talchum and buchaechum are also notable Korean performing arts.  Post-war modern Korean art started to flourish in the 1960s and 1970s, when South Korean artists took interest in geometrical shapes and intangible subjects. Establishing a harmony between man and nature was also a favorite of this time. Because of social instability, social issues appeared as main subjects in the 1980s. Art was influenced by various international events and exhibits in Korea, and with it brought more diversity.[413] The Olympic Sculpture Garden in 1988, the transposition of the 1993 edition of the Whitney Biennial to Seoul,[414] the creation of the Gwangju Biennale[415] and the Korean Pavilion at the Venice Biennale in 1995[416] were notable events.  Architecture Main article: Architecture of South Korea See also: Korean architecture  Namdaemun Because of South Korea's tumultuous history, construction and destruction has been repeated endlessly, resulting in an interesting melange of architectural styles and designs.[417]  Korean traditional architecture is characterized by its harmony with nature. Ancient architects adopted the bracket system characterized by thatched roofs and heated floors called ondol.[418] People of the upper classes built bigger houses with elegantly curved tiled roofs with lifting eaves. Traditional architecture can be seen in the palaces and temples, preserved old houses called hanok,[419] and special sites like Hahoe Folk Village, Yangdong Village of Gyeongju and Korean Folk Village. Traditional architecture may also be seen at the nine UNESCO World Heritage Sites in South Korea.[420]   Bulguksa, a UNESCO World Heritage Site Western architecture was first introduced to Korea at the end of the 19th century. Churches, offices for foreign legislation, schools and university buildings were built in new styles. With the annexation of Korea by Japan in 1910 the colonial regime intervened in Korea's architectural heritage, and Japanese-style modern architecture was imposed. The anti-Japanese sentiment, and the Korean War, led to the destruction of most buildings constructed during that time.[421]  Korean architecture entered a new phase of development during the post-Korean War reconstruction, incorporating modern architectural trends and styles. Stimulated by the economic growth in the 1970s and 1980s, active redevelopment saw new horizons in architectural design. In the aftermath of the 1988 Seoul Olympics, South Korea has witnessed a wide variation of styles in its architectural landscape due, in large part, to the opening up of the market to foreign architects.[422] Contemporary architectural efforts have been constantly trying to balance the traditional philosophy of "harmony with nature" and the fast-paced urbanization that the country has been going through in recent years.[423]  Cuisine Main article: Korean cuisine  Bibimbap Korean cuisine, hanguk yori (한국요리; 韓國料理), or hansik (한식; 韓食), has evolved through centuries of social and political change. Ingredients and dishes vary by province. There are many significant regional dishes that have proliferated in different variations across the country in the present day. The Korean royal court cuisine once brought all of the unique regional specialties together for the royal family. Meals consumed both by the royal family and ordinary Korean citizens have been regulated by a unique culture of etiquette.  Korean cuisine is largely based on rice, noodles, tofu, vegetables, fish and meats. Traditional Korean meals are noted for the number of side dishes, banchan (반찬), which accompany steam-cooked short-grain rice. Every meal is accompanied by numerous banchan. Kimchi (김치), a fermented, usually spicy vegetable dish is commonly served at every meal and is one of the best known Korean dishes. Korean cuisine usually involves heavy seasoning with sesame oil, doenjang (된장), a type of fermented soybean paste, soy sauce, salt, garlic, ginger, and gochujang (고추장), a hot pepper paste. Other well-known dishes are Bulgogi (불고기), grilled marinated beef, Gimbap (김밥), and Tteokbokki (떡볶이), a spicy snack consisting of rice cake seasoned with gochujang or a spicy chili paste.  Soups are also a common part of a Korean meal and are served as part of the main course rather than at the beginning or the end of the meal. Soups known as guk (국) are often made with meats, shellfish and vegetables. Similar to guk, tang (탕; 湯) has less water, and is more often served in restaurants. Another type is jjigae (찌개), a stew that is typically heavily seasoned with chili pepper and served boiling hot.  Popular Korean alcoholic beverages include Soju, Makgeolli and Bokbunja ju.  Korea is unique among East Asian countries in its use of metal chopsticks. Metal chopsticks have been discovered in Goguryeo archaeological sites.[424]  Entertainment Main articles: Korean Wave, Cinema of South Korea, Korean drama, and K-pop  BTS, one of the most successful K-pop groups In addition to domestic consumption, South Korea has a thriving entertainment industry where various facets of South Korean entertainment, including television dramas, films, and popular music, has generated significant financial revenues for the nation's economy. The cultural phenomenon known as Hallyu or the "Korean Wave", has swept many countries across Asia making South Korea a major soft power as an exporter of popular culture and entertainment, rivaling Western nations such as the United States and the United Kingdom.[425][426]   The girl group Blackpink is the highest-charting female Korean act on the Billboard Hot 100, peaking at number 13 with "Ice Cream" (2020), and on the Billboard 200. Until the 1990s, trot and traditional Korean folk based ballads dominated South Korean popular music. The emergence of the South Korean pop group Seo Taiji and Boys in 1992 marked a turning point for South Korean popular music, also known as K-pop, as the genre modernized itself from incorporating elements of popular musical genres from across the world such as Western popular music, experimental, jazz, gospel, Latin, classical, hip hop, rhythm and blues, electronic dance, reggae, country, folk, and rock on top of its uniquely traditional Korean music roots.[427] Western-style pop, hip hop, rhythm and blues, rock, folk, electronic dance oriented acts have become dominant in the modern South Korean popular music scene, though trot is still enjoyed among older South Koreans. K-pop stars and groups are well known across Asia and have found international fame making millions of dollars in export revenue. Many K-pop acts have also been able to secure a strong overseas following using online social media platforms such as the video sharing website YouTube. South Korean singer PSY became an international sensation when his song "Gangnam Style" topped global music charts in 2012.  Since the success of the film Shiri in 1999, the Korean film industry has begun to gain recognition internationally. Domestic film has a dominant share of the market, partly because of the existence of screen quotas requiring cinemas to show Korean films at least 73 days a year.[428] 2019's Parasite, directed by Bong Joon Ho, became the highest-grossing film in South Korea as well as the first non-English language film to win Best Picture at the United States-based Academy Awards that year amongst numerous other accolades.  South Korean television shows have become popular outside of Korea. South Korean television dramas, known as K-dramas, have begun to find fame internationally. Many dramas tend to have a romantic focus, such as Princess Hours, You're Beautiful, Playful Kiss, My Name is Kim Sam Soon, Boys Over Flowers, Winter Sonata, Autumn in My Heart, Full House, City Hunter, All About Eve, Secret Garden, I Can Hear Your Voice, Master's Sun, My Love from the Star, Healer, Descendants of the Sun, Guardian: The Lonely and Great God, and Crash Landing on You. Historical dramas have included Faith, Dae Jang Geum, The Legend, Dong Yi, Moon Embracing the Sun, Sungkyunkwan Scandal, and Iljimae, Kingdom[429][430]  Holidays Main article: Public holidays in South Korea  Traditional Korean folk dance There are many official public holidays in South Korea. Korean New Year's Day, or "Seollal", is celebrated on the first day of the Korean lunar calendar. Korean Independence Day falls on 1 March, and commemorates the 1 March Movement of 1919. Memorial Day is celebrated on 6 June, and its purpose is to honor the men and women who died in South Korea's independence movement. Constitution Day is on 17 July, and it celebrates the promulgation of Constitution of the Republic of Korea. Liberation Day, on 15 August, celebrates Korea's liberation from the Empire of Japan in 1945. Every 15th day of the 8th lunar month, Koreans celebrate the Midautumn Festival, in which Koreans visit their ancestral hometowns and eat a variety of traditional Korean foods. On 1 October, Armed Forces day is celebrated, honoring the military forces of South Korea. 3 October is National Foundation Day. Hangul Day, on 9 October commemorates the invention of hangul, the native alphabet of the Korean language.  Sports Main article: Sport in South Korea  Seoul Sports Complex, Korea's largest integrated sports center The martial art taekwondo originated in Korea. In the 1950s and 1960s, modern rules were standardized, with taekwondo becoming an official Olympic sport in 2000.[431] Other Korean martial arts include Taekkyon, hapkido, Tang Soo Do, Kuk Sool Won, kumdo and subak.[432]  Football and baseball have traditionally been regarded as the most popular sports in Korea.[433] Recent polling indicates that a majority, 41% of South Korean sports fans continue to self-identify as football fans, with baseball ranked 2nd at 25% of respondents. However, the polling did not indicate the extent to which respondents follow both sports.[434] The national football team became the first team in the Asian Football Confederation to reach the FIFA World Cup semi-finals in the 2002 FIFA World Cup, jointly hosted by South Korea and Japan. The Korea Republic national team (as it is known) has qualified for every World Cup since Mexico 1986, and has broken out of the group stage twice: first in 2002, and again in 2010, when it was defeated by eventual semi-finalist Uruguay in the Round of 16. At the 2012 Summer Olympics, South Korea won the bronze medal for football.   Sajik Baseball Stadium in Busan. Baseball is one of the most popular sports in South Korea. Baseball was first introduced to Korea in 1905 and has since become increasingly popular, with some sources claiming it has surpassed football as the most popular sport in the country.[435][436][437] Recent years have been characterized by increasing attendance and ticket prices for professional baseball games.[438][439] The Korea Professional Baseball league, a 10-team circuit, was established in 1982. The South Korea national team finished third in the 2006 World Baseball Classic and second in the 2009 tournament. The team's 2009 final game against Japan was widely watched in Korea, with a large screen at Gwanghwamun crossing in Seoul broadcasting the game live.[440] In the 2008 Summer Olympics, South Korea won the gold medal in baseball.[441] Also in 1982, at the Baseball Worldcup, Korea won the gold medal. At the 2010 Asian Games, the Korean National Baseball team won the gold medal. Several Korean players have gone on to play in Major League Baseball.  Basketball is a popular sport in the country as well. South Korea has traditionally had one of the top basketball teams in Asia and one of the continent's strongest basketball divisions. Seoul hosted the 1967 and 1995 Asian Basketball Championship. The Korea national basketball team has won a record number of 23 medals at the event to date.[442]   Taekwondo, a Korean martial art and Olympic sport South Korea hosted the Asian Games in 1986 (Seoul), 2002 (Busan), and 2014 (Incheon). It also hosted the Winter Universiade in 1997, the Asian Winter Games in 1999, and the Summer Universiade in 2003 and 2015. In 1988, South Korea hosted the Summer Olympics in Seoul, coming fourth with 12 gold medals, 10 silver medals, and 11 bronze medals. South Korea regularly performs well in archery, shooting, table tennis, badminton, short track speed skating, handball, field hockey, freestyle wrestling, Greco-Roman wrestling, baseball, judo, taekwondo, speed skating, figure skating, and weightlifting. The Seoul Olympic Museum is dedicated to the 1988 Summer Olympics. On 6 July 2011, Pyeongchang was chosen by the IOC to host the 2018 Winter Olympics.  South Korea has won more medals in the Winter Olympics than any other Asian country, with a total of 45 (23 gold, 14 silver, and 8 bronze). At the 2010 Winter Olympics, South Korea ranked fifth in the overall medal rankings. South Korea is especially strong in short track speed skating. Speed skating and figure skating are also popular, and ice hockey is an emerging sport, with Anyang Halla winning their first ever Asia League Ice Hockey title in March 2010.[443]  Seoul hosted a professional triathlon race, which is part of the International Triathlon Union (ITU) World Championship Series in May 2010.[444] In 2011, the South Korean city of Daegu hosted the 2011 IAAF World Championships in Athletics.[445]  In October 2010, South Korea hosted its first Formula One race at the Korea International Circuit in Yeongam, about 400 kilometres (250 mi) south of Seoul.[446] The Korean Grand Prix was held from 2010 to 2013, but was not placed on the 2014 F1 calendar.[447]  Domestic horse racing events are also followed by South Koreans and Seoul Race Park in Gwacheon, Gyeonggi-do is located closest to Seoul out of the country's three tracks.[448]  Competitive video gaming, also called Esports (sometimes written e-Sports), has become more popular in South Korea in recent years, particularly among young people.[449] The two most popular games are League of Legends and StarCraft. The gaming scene of South Korea is managed by the Korean e-Sports Association.  See also icon	Asia portal flag	South Korea portal Index of South Korea–related articles Outline of South Korea State Council of South Korea ("cabinet" of South Korea) Notes  19.7% are Protestant, 7.9% are Catholic  Korean: 한국 / 韓國, RR: Hanguk; literally 남한 / 南韓, RR: Namhan, or 남조선 / 南朝鮮, MR: Namchosŏn in North Korean usage  Korean: 대한민국 / 大韓民國, RR: Daehan Minguk References  "A New Way of Seeing Country Social Responsibility" (PDF). Faculty of Philosophy and Social-Political Sciences: 6. Archived from the original (PDF) on 25 September 2013. Retrieved 16 January 2014.  [시행 2016.8.4.] [법률 제13978호, 2016.2.3., 제정] [Enforcement 2016.8.4. Law No. 13978, enacted on February 3, 2016] (in Korean). 2016. Retrieved 26 July 2017.  "Foreign population in Korea tops 2.5 million". koreatimes. 24 February 2020.  Kim, Han-soo; Shon, Jin-seok (20 December 2016). 신자 수, 개신교 1위… "종교 없다" 56%. Chosun Ilbo. Retrieved 2 July 2017.  Quinn, Joseph Peter (2019). "South Korea". In Demy, Timothy J.; Shaw, Jeffrey M. (eds.). Religion and Contemporary Politics: A Global Encyclopedia. ABC-CLIO. p. 365. ISBN 978-1-4408-3933-7. Retrieved 3 June 2020.  Kosis 100대 지표.  "World Economic Outlook Database, October 2020". IMF.org. International Monetary Fund. Retrieved 14 October 2020.  Inequality - Income inequality - OECD Data. OECD. Retrieved 17 July 2021.  "Human Development Report 2020" (PDF). United Nations Development Programme. 15 December 2020. Retrieved 15 December 2020.  "South Korea's troubling history of jailing ex-presidents". AEI. 9 October 2018.  Deutsche Welle (www.dw.com). "Former South Korean president sentenced to prison | DW | 30 November 2020". DW.COM. Retrieved 10 February 2021.  "Ex-President Roh Tae-woo to Pay Remainder of Massive Fine". The Chosunilbo. 22 August 2013. Retrieved 27 October 2019.  "South Korea : President's impeachment on a background of political scandal". Perspective Monde (in French). Université de Sherbrooke. 7 February 2017.  "South Korea ex-leader jailed for 15 years". BBC News. 5 October 2018.  [10][11][12][13][14]  Yong Jin, Dal (2011). "Hallyu 2.0: The New Korean Wave in the Creative Industry". International Institute Journal. 2 (1).  CNN, Lara Farrar for. "'Korean Wave' of pop culture sweeps across Asia".  "The Global Impact of South Korean Popular Culture: Hallyu Unbound ed. by Valentina Marinescu". ResearchGate.  Kim, Harry (2 February 2016). "Surfing the Korean Wave: How K-pop is taking over the world | The McGill Tribune". The McGill Tribune. Archived from the original on 23 November 2018. Retrieved 31 May 2019.  Nguyen Hoai Phuong, Duong. Korean Wave as Cultural Imperialism: A study of K-pop Reception in Vietnam (PDF) (Thesis). Leiden University.  Roberts, John Morris; Westad, Odd Arne (2013). The History of the World. Oxford University Press. p. 443. ISBN 978-0-19-993676-2. Retrieved 15 July 2016.  Gardner, Hall (27 November 2007). Averting Global War: Regional Challenges, Overextension, and Options for American Strategy. Palgrave Macmillan. pp. 158–159. ISBN 978-0-230-60873-3. Retrieved 15 July 2016.  Laet, Sigfried J. de (1994). History of Humanity: From the seventh to the sixteenth century. UNESCO. p. 1133. ISBN 978-92-3-102813-7. Retrieved 8 November 2016.  Walker, Hugh Dyson (20 November 2012). East Asia: A New History. AuthorHouse. pp. 6–7. ISBN 978-1-4772-6517-8. Retrieved 19 November 2016.  Rossabi, Morris (20 May 1983). China Among Equals: The Middle Kingdom and Its Neighbors, 10th–14th Centuries. University of California Press. p. 323. ISBN 978-0-520-04562-0. Retrieved 8 November 2016.  Yi, Ki-baek (1984). A New History of Korea. Harvard University Press. p. 103. ISBN 978-0-674-61576-2. Retrieved 8 November 2016.  Kim, Djun Kil (30 January 2005). The History of Korea. ABC-CLIO. p. 57. ISBN 978-0-313-03853-2. Retrieved 8 November 2016.  Grayson, James H. (5 November 2013). Korea – A Religious History. Routledge. p. 79. ISBN 978-1-136-86925-9. Retrieved 8 November 2016.  Yunn, Seung-Yong (1996), "Muslims earlier contact with Korea", Religious culture of Korea, Hollym International, p. 99  Dourado, Fernão. "Atlas de Fernão Vaz Dourado". Arquivo nacional da Torre do Tombo.  "1369MAPAS E ICONOGRAFIA DOS SÉCS. XVI E XVII" (PDF).  pato, Raymundo. "Cartas de Afonso de Albuquerque, vol. 1".  Korea原名Corea? 美國改的名. United Daily News (in Chinese). 5 July 2008. Retrieved 28 March 2014.  Barbara Demick (15 September 2003). "A 'C' Change in Spelling Sought for the Koreas". Los Angeles Times. Retrieved 28 March 2016.  "Korea vs Corea". Monster Island. 14 May 2005. Archived from the original on 1 November 2009. Retrieved 28 March 2016.  이기환 (30 August 2017). [이기환의 흔적의 역사]국호논쟁의 전말…대한민국이냐 고려공화국이냐. 경향신문 (in Korean). The Kyunghyang Shinmun. Retrieved 2 July 2018.  이덕일. [이덕일 사랑] 대~한민국. 조선닷컴 (in Korean). Chosun Ilbo. Retrieved 2 July 2018.  Myers, Brian Reynolds (28 December 2016). "Still the Unloved Republic". Sthele Press. Archived from the original on 13 March 2018. Retrieved 10 June 2019. Taehan minguk. In English it is translated as Republic of Korea or South Korea, names which to us foreigners denote the state as a political entity distinct from its northern neighbor. To most people here, however, Taehan minguk conveys that sense only when used in contrastive proximity with the word Pukhan (North Korea). Ask South Koreans when the Taehan minguk was established; more will answer '5000 years ago' than 'in 1948,' because to them it is simply the full name for Hanguk, Korea, the homeland. That’s all it meant to most people who shouted those four syllables so proudly during the World Cup in 2002.  Myers, Brian Reynolds (20 May 2018). "North Korea's state-loyalty advantage". Free Online Library. Archived from the original on 20 May 2018.  "Korean Classics : Asian Collections: An Illustrated Guide (Library of Congress – Asian Division)". Library of Congress. Retrieved 19 August 2016.  "Gutenberg Bible". British Library. Retrieved 19 August 2016.  "Korea, 1000–1400 A.D. | Chronology | Heilbrunn Timeline of Art History". The Metropolitan Museum of Art. Retrieved 19 August 2016.  Chandler, Daniel; Munday, Rod (2016). "Movable type". In Chandler, Daniel; Munday, Rod (eds.). A Dictionary of Media and Communication. Oxford University Press. doi:10.1093/acref/9780199568758.001.0001. ISBN 978-0-19-956875-8. Retrieved 19 August 2016.  Ebrey, Patricia Buckley; Walthall, Anne (1 January 2013). East Asia: A Cultural, Social, and Political History. Cengage Learning. ISBN 978-1-285-52867-0. Retrieved 19 August 2016.  "Ancient civilizations" (Press release). Canada: Royal Ontario Museum. 12 December 2005. Retrieved 25 April 2010.  "Prehistoric Korea". About Korea. Archived from the original on 2 March 2008. Retrieved 12 July 2008., Office of the Prime Minister.  "Korea's History". Asian Shravan. Archived from the original on 28 January 2010. Retrieved 17 February 2009.  * Seth, Michael J. (2010). A History of Korea: From Antiquity to the Present. Rowman & Littlefield Publishers. p. 443. ISBN 978-0-7425-6717-7. "An extreme manifestation of nationalism and the family cult was the revival of interest in Tangun, the mythical founder of the first Korean state... Most textbooks and professional historians, however, treat him as a myth." Stark, Miriam T. (2008). Archaeology of Asia. John Wiley & Sons. p. 49. ISBN 978-1-4051-5303-4. "Although Kija may have truly existed as a historical figure, Tangun is more problematical." Schmid, Andre (2013). Korea Between Empires. Columbia University Press. p. 270. ISBN 978-0-231-50630-4. "Most [Korean historians] treat the [Tangun] myth as a later creation." Peterson, Mark (2009). Brief History of Korea. Infobase Publishing. p. 5. ISBN 978-1-4381-2738-5. "The Tangun myth became more popular with groups that wanted Korea to be independent; the Kija myth was more useful to those who wanted to show that Korea had a strong affinity to China." Hulbert, H. B. (2014). The History of Korea. Routledge. p. 73. ISBN 978-1-317-84941-4. "If a choice is to be made between them, one is faced with the fact that the Tangun, with his supernatural origin, is more clearly a mythological figure than Kija."  Peterson, Mark; Margulies, Phillip (2009). A Brief History of Korea. Infobase Publishing. p. 6. ISBN 978-1-4381-2738-5.  Hwang, Kyung-moon (2010). A History of Korea, An Episodic Narrative. Palgrave Macmillan. p. 4. ISBN 978-0-230-36453-0.  Early Korea Archived 25 June 2015 at the Wayback Machine. Shsu.edu. Retrieved 17 April 2015.  낙랑군. terms.naver.com.  이문영 (15 July 2011). 이야기보따리 삼국시대: 역사친구 004. Sowadang. ISBN 978-89-93820-14-0 – via Google Books.  Yi, Ki-baek (1984). A New History of Korea. Harvard University Press. pp. 23–24. ISBN 978-0-674-61576-2. Retrieved 21 November 2016.  Walker, Hugh Dyson (November 2012). East Asia: A New History. AuthorHouse. p. 104. ISBN 978-1-4772-6516-1. Retrieved 21 November 2016.  Yi, Hyŏn-hŭi; Pak, Sŏng-su; Yun, Nae-hyŏn (2005). New history of Korea. Jimoondang. p. 201. ISBN 978-89-88095-85-0. He launched a military expedition to expand his territory, opening the golden age of Goguryeo.  Hall, John Whitney (1988). The Cambridge History of Japan. Cambridge University Press. p. 362. ISBN 978-0-521-22352-2. Retrieved 29 July 2016.  Embree, Ainslie Thomas (1988). Encyclopedia of Asian history. Scribner. p. 324. ISBN 978-0-684-18899-7. Retrieved 29 July 2016.  Cohen, Warren I. (20 December 2000). East Asia at the Center: Four Thousand Years of Engagement with the World. Columbia University Press. p. 50. ISBN 978-0-231-50251-1. Retrieved 29 July 2016.  Kim, Jinwung (5 November 2012). A History of Korea: From "Land of the Morning Calm" to States in Conflict. Indiana University Press. p. 35. ISBN 978-0-253-00078-1. Retrieved 11 October 2016.  "Kings and Queens of Korea". KBS World Radio. Archived from the original on 28 August 2016. Retrieved 26 August 2016.  Walker, Hugh Dyson (20 November 2012). East Asia: A New History. AuthorHouse. p. 161. ISBN 978-1-4772-6517-8. Retrieved 8 November 2016.  White, Matthew (7 November 2011). Atrocities: The 100 Deadliest Episodes in Human History. W. W. Norton & Company. p. 78. ISBN 978-0-393-08192-3. Retrieved 8 November 2016.  Grant, Reg G. (2011). 1001 Battles That Changed the Course of World History. Universe Pub. p. 104. ISBN 978-0-7893-2233-3. Retrieved 8 November 2016.  Bedeski, Robert (12 March 2007). Human Security and the Chinese State: Historical Transformations and the Modern Quest for Sovereignty. Routledge. p. 90. ISBN 978-1-134-12597-5. Retrieved 8 November 2016.  Yi, Ki-baek (1984). A New History of Korea. Harvard University Press. p. 47. ISBN 978-0-674-61576-2. Retrieved 29 July 2016. Koguryŏ was the first to open hostilities, with a bold assault across the Liao River against Liao-hsi, in 598. The Sui emperor, Wen Ti, launched a retaliatory attack on Koguryŏ but met with reverses and turned back in mid-course. Yang Ti, the next Sui emperor, proceeded in 612 to mount an invasion of unprecedented magnitude, marshalling a huge force said to number over a million men. And when his armies failed to take Liao-tung Fortress (modern Liao-yang), the anchor of Koguryŏ's first line of defense, he had a nearly a third of his forces, some 300,000 strong, break off the battle there and strike directly at the Koguryŏ capital of P'yŏngyang. But the Sui army was lured into a trap by the famed Koguryŏ commander Ŭlchi Mundŏk, and suffered a calamitous defeat at the Salsu (Ch'ŏngch'ŏn) River. It is said that only 2,700 of the 300,000 Sui soldiers who had crossed the Yalu survived to find their way back, and the Sui emperor now lifted the siege of Liao-tung Fortress and withdrew his forces to China proper. Yang Ti continued to send his armies against Koguryŏ but again without success, and before long his war-weakened empire crumbled.  Nahm, Andrew C. (2005). A Panorama of 5000 Years: Korean History (Second revised ed.). Seoul: Hollym International Corporation. p. 18. ISBN 978-0-930878-68-9. China, which had been split into many states since the early 3rd century, was reunified by the Sui dynasty at the end of the 6th century. Soon after that, Sui China mobilized a large number of troops and launched war against Koguryŏ. However, the people of Koguryŏ were united and they were able to repel the Chinese aggressors. In 612, Sui troops invaded Korea again, but Koguryŏ forces fought bravely and destroyed Sui troops everywhere. General Ŭlchi Mundŏk of Koguryŏ completely wiped out some 300,000 Sui troops which came across the Yalu River in the battles near the Salsu River (now Ch'ŏngch'ŏn River) with his ingenious military tactics. Only 2,700 Sui troops were able to flee from Korea. The Sui dynasty, which wasted so much energy and manpower in aggressive wars against Koguryŏ, fell in 618.  Ebrey, Patricia Buckley; Walthall, Anne; Palais, James B. (2006). East Asia: A Cultural, Social, and Political History. Houghton Mifflin. p. 123. ISBN 978-0-618-13384-0. Retrieved 12 September 2016.  Kitagawa, Joseph (5 September 2013). The Religious Traditions of Asia: Religion, History, and Culture. Routledge. p. 348. ISBN 978-1-136-87590-8. Retrieved 29 July 2016.  Ebrey, Patricia Buckley; Walthall, Anne; Palais, James B. (2013). East Asia: A Cultural, Social, and Political History, Volume I: To 1800. Cengage Learning. p. 104. ISBN 978-1-111-80815-0. Retrieved 12 September 2016.  A Brief History of Korea. Ewha Womans University Press. 1 January 2005. pp. 29–30. ISBN 978-89-7300-619-9. Retrieved 21 November 2016.  Yu, Chai-Shin (2012). The New History of Korean Civilization. iUniverse. p. 27. ISBN 978-1-4620-5559-3. Retrieved 21 November 2016.[self-published source]  Kim, Jinwung (2012). A History of Korea: From "Land of the Morning Calm" to States in Conflict. Indiana University Press. pp. 44–45. ISBN 978-0-253-00024-8. Retrieved 12 September 2016.  Wells, Kenneth M. (3 July 2015). Korea: Outline of a Civilisation. Brill. pp. 18–19. ISBN 978-90-04-30005-7. Retrieved 12 September 2016.  Injae, Lee; Miller, Owen; Jinhoon, Park; Hyun-Hae, Yi (15 December 2014). Korean History in Maps. Cambridge University Press. pp. 64–65. ISBN 978-1-107-09846-6. Retrieved 24 February 2017.  DuBois, Jill (2004). Korea. Marshall Cavendish. p. 22. ISBN 978-0-7614-1786-6. Retrieved 29 July 2016. golden age of art and culture.  Randel, Don Michael (2003). The Harvard Dictionary of Music. Harvard University Press. p. 273. ISBN 978-0-674-01163-2. Retrieved 29 July 2016.  Hopfner, Jonathan (10 September 2013). Moon Living Abroad in South Korea. Avalon Travel. p. 21. ISBN 978-1-61238-632-4. Retrieved 29 July 2016.  Kim, Djun Kil (30 January 2005). The History of Korea. ABC-CLIO. p. 47. ISBN 978-0-313-03853-2. Retrieved 30 September 2016.  Kitagawa, Joseph (5 September 2013). The Religious Traditions of Asia: Religion, History, and Culture. Routledge. p. 348. ISBN 978-1-136-87590-8. Retrieved 21 July 2016.  Gernet, Jacques (31 May 1996). A History of Chinese Civilization. Cambridge University Press. p. 291. ISBN 978-0-521-49781-7. Retrieved 21 July 2016. Korea held a dominant position in the north-eastern seas.  Reischauer, Edwin Oldfather (1 May 1955). Ennins Travels in Tang China. John Wiley & Sons Canada, Limited. pp. 276–283. ISBN 978-0-471-07053-5. Retrieved 21 July 2016. From what Ennin tells us, it seems that commerce between East China, Korea and Japan was, for the most part, in the hands of men from Silla. Here in the relatively dangerous waters on the eastern fringes of the world, they performed the same functions as did the traders of the placid Mediterranean on the western fringes. This is a historical fact of considerable significance but one which has received virtually no attention in the standard historical compilations of that period or in the modern books based on these sources. ... While there were limits to the influence of the Koreans along the eastern coast of China, there can be no doubt of their dominance over the waters off these shores. ... The days of Korean maritime dominance in the Far East actually were numbered, but in Ennin's time the men of Silla were still the masters of the seas in their part of the world.  Kim, Djun Kil (30 May 2014). The History of Korea, 2nd Edition. ABC-CLIO. p. 3. ISBN 978-1-61069-582-4. Retrieved 21 July 2016.  Seth, Michael J. (2006). A Concise History of Korea: From the Neolithic Period Through the Nineteenth Century. Rowman & Littlefield. p. 65. ISBN 978-0-7425-4005-7. Retrieved 21 July 2016.  MacGregor, Neil (6 October 2011). A History of the World in 100 Objects. Penguin UK. ISBN 978-0-14-196683-0. Retrieved 30 September 2016.  Chŏng, Yang-mo; Smith, Judith G. (1998). Arts of Korea. Metropolitan Museum of Art. p. 230. ISBN 978-0-87099-850-8. Retrieved 30 September 2016.  International, Rotary (April 1989). The Rotarian. Rotary International. p. 28. Retrieved 30 September 2016.  Ross, Alan (17 January 2013). After Pusan. Faber & Faber. ISBN 978-0-571-29935-5. Retrieved 30 September 2016.  Mason, David A. "Gyeongju, Korea's treasure house". Korean Culture and Information Service (KOCIS). Archived from the original on 3 October 2016. Retrieved 30 September 2016.  Adams, Edward Ben (1990). Koreaʾs pottery heritage. Seoul International Pub. House. p. 53. ISBN 9788985113069. Retrieved 30 September 2016.  Mun, Chanju; Green, Ronald S. (2006). Buddhist Exploration of Peace and Justice. Blue Pine Books. p. 147. ISBN 978-0-9777553-0-1. Retrieved 29 July 2016.  McIntire, Suzanne; Burns, William E. (25 June 2010). Speeches in World History. Infobase Publishing. p. 87. ISBN 978-1-4381-2680-7. Retrieved 29 July 2016.  Jr, Robert E. Buswell; Jr, Donald S. Lopez (24 November 2013). The Princeton Dictionary of Buddhism. Princeton University Press. p. 187. ISBN 978-1-4008-4805-8. Retrieved 29 July 2016.  Poceski, Mario (13 April 2007). Ordinary Mind as the Way: The Hongzhou School and the Growth of Chan Buddhism. Oxford University Press. p. 24. ISBN 978-0-19-804320-1. Retrieved 29 July 2016.  Wu, Jiang; Chia, Lucille (15 December 2015). Spreading Buddha's Word in East Asia: The Formation and Transformation of the Chinese Buddhist Canon. Columbia University Press. p. 155. ISBN 978-0-231-54019-3. Retrieved 29 July 2016.  Wright, Dale S. (25 March 2004). The Zen Canon: Understanding the Classic Texts. Oxford University Press. ISBN 978-0-19-988218-2. Retrieved 29 July 2016.  Su-il, Jeong (18 July 2016). The Silk Road Encyclopedia. Seoul Selection. ISBN 978-1-62412-076-3. Retrieved 29 July 2016.  Nikaido, Yoshihiro (28 October 2015). Asian Folk Religion and Cultural Interaction. Vandenhoeck & Ruprecht. p. 137. ISBN 978-3-8470-0485-1. Retrieved 29 July 2016.  Leffman, David; Lewis, Simon; Atiyah, Jeremy (2003). China. Rough Guides. p. 519. ISBN 978-1-84353-019-0. Retrieved 29 July 2016.  Leffman, David (2 June 2014). The Rough Guide to China. Penguin. ISBN 978-0-241-01037-2. Retrieved 29 July 2016.  DK Eyewitness Travel Guide: China. Penguin. 21 June 2016. p. 240. ISBN 978-1-4654-5567-3. Retrieved 29 July 2016.  박, 종기 (24 August 2015). 고려사의 재발견: 한반도 역사상 가장 개방적이고 역동적인 500년 고려 역사를 만나다 (in Korean). 휴머니스트. ISBN 978-89-5862-902-3. Retrieved 27 October 2016.  Lee, Ki-Baik (1984). A New History of Korea. Cambridge: Harvard University Press. p. 103. ISBN 978-0-674-61576-2. When Parhae perished at the hands of the Khitan around this same time, much of its ruling class, who were of Koguryŏ descent, fled to Koryŏ. Wang Kŏn warmly welcomed them and generously gave them land. Along with bestowing the name Wang Kye ("Successor of the Royal Wang") on the Parhae crown prince, Tae Kwang-hyŏn, Wang Kŏn entered his name in the royal household register, thus clearly conveying the idea that they belonged to the same lineage, and also had rituals performed in honor of his progenitor. Thus Koryŏ achieved a true national unification that embraced not only the Later Three Kingdoms but even survivors of Koguryŏ lineage from the Parhae kingdom.  "World Treasures: Beginnings". Library of Congress. 29 July 2010. Archived from the original on 29 August 2016. Retrieved 15 July 2016.  "Digital Jikji". Digital Jikji. Archived from the original on 13 March 2011. Retrieved 25 April 2010.  Bulliet, Richard; Crossley, Pamela; Headrick, Daniel; Hirsch, Steven; Johnson, Lyman (1 January 2014). The Earth and Its Peoples, Brief: A Global History. Cengage Learning. p. 264. ISBN 978-1-285-44551-9. Retrieved 12 September 2016.  Cohen, Warren I. (20 December 2000). East Asia at the Center: Four Thousand Years of Engagement with the World. Columbia University Press. p. 107. ISBN 978-0-231-50251-1. Retrieved 12 September 2016.  Lee, Kenneth B. (1997). Korea and East Asia: The Story of a Phoenix. Greenwood Publishing Group. p. 61. ISBN 978-0-275-95823-7. Retrieved 28 July 2016.  Bowman, John (5 September 2000). Columbia Chronologies of Asian History and Culture. Columbia University Press. p. 202. ISBN 978-0-231-50004-3. Retrieved 1 August 2016. The Mongolian-Khitan invasions of the late tenth century challenge the stability of the Koryo government, but a period of prosperity follows the defeat of the Khitan in 1018..  Lee, Kenneth B. (1997). Korea and East Asia: The Story of a Phoenix. Greenwood Publishing Group. p. 72. ISBN 978-0-275-95823-7. Retrieved 12 November 2016.  Yi, Ki-baek (1984). A New History of Korea. Harvard University Press. p. 165. ISBN 978-0-674-61576-2. Retrieved 19 November 2016.  Selin, Helaine (11 November 2013). Encyclopaedia of the History of Science, Technology, and Medicine in Non-Westen Cultures. Springer Science & Business Media. pp. 505–506. ISBN 978-94-017-1416-7. Retrieved 27 July 2016.  Haralambous, Yannis; Horne, P. Scott (28 November 2007). Fonts & Encodings. O'Reilly Media, Inc. p. 155. ISBN 978-0-596-10242-5. Retrieved 8 November 2016.  Lee, Kenneth B. (1997). Korea and East Asia: The Story of a Phoenix. Greenwood Publishing Group. p. 86. ISBN 978-0-275-95823-7. Retrieved 27 July 2016.  Koerner, E.F.K.; Asher, R. E. (28 June 2014). Concise History of the Language Sciences: From the Sumerians to the Cognitivists. Elsevier. p. 54. ISBN 978-1-4832-9754-5. Retrieved 8 November 2016.  Turnbull, Stephen (20 November 2012). The Samurai Invasion of Korea 1592–98. Osprey Publishing. p. 17. ISBN 978-1-78200-712-8. Retrieved 25 March 2015. "His naval victories were to prove decisive in the Japanese defeat, although Yi was to die during his final battle in 1598."  Perez, Louis (2013). Japan At War: An Encyclopedia. Santa Barbara, CA: ABC-CLIO. p. 140. ISBN 978-1-59884-741-3."Just as a complete Japanese victory appeared imminent, Admiral Yi entered the war and quickly turned the tide."  Perez, Louis (2013). Japan At War: An Encyclopedia. Santa Barbara, CA: ABC-CLIO. pp. 140–141. ISBN 978-1-59884-741-3."Yi's successes gave Korea complete control of the sea lanes around the peninsula, and the Korean navy was able to intercept most of the supplies and communications between Japan and Korea"  Elisonas, Jurgis. "The inseparable trinity: Japan's relations with China and Korea". The Cambridge History of Japan. Vol. 4. Ed. John Whitney Hall. Cambridge: Cambridge University Press, 1991. p. 278  Lee, Ki-baik. A New History of Korea. Trans. Edward W. Wagner and Edward J. Schultz. Seoul: Ilchokak, 1984. pp. 212  신형식 (January 2005). A Brief History of Korea. Ewha Womans University Press. ISBN 978-89-7300-619-9. Retrieved 8 November 2016.  Beirne, Paul (April 2016). Su-un and His World of Symbols: The Founder of Korea's First Indigenous Religion. Routledge. ISBN 978-1-317-04749-0. Retrieved 8 November 2016.  Fry, Michael (5 August 2013). "National Geographic, Korea, and the 38th Parallel". National Geographic. Retrieved 15 May 2021.  "Republic of Korea". worldbank.org. Archived from the original on 2 May 2014.  "195 (III) The problem of the independence of Korea" Archived 23 October 2013 at the Wayback Machine, 12 December 1948, Resolutions Adopted by the General Assembly During its Third Session, p. 25.  Su-kyoung Hwang, Korea's Grievous War. Philadelphia: University of Pennsylvania Press, 2016; pg. 90–95.  Kim, Samuel S. (2014). "The Evolving Asian System". International Relations of Asia. Rowman & Littlefield. p. 45. ISBN 978-1-4422-2641-8. With three of the four major Cold War fault lines—divided Germany, divided Korea, divided China, and divided Vietnam—East Asia acquired the dubious distinction of having engendered the largest number of armed conflicts resulting in higher fatalities between 1945 and 1994 than any other region or sub-region. Even in Asia, while Central and South Asia produced a regional total of 2.8 million in human fatalities, East Asia's regional total is 10.4 million including the Chinese Civil War (1 million), the Korean War (3 million), the Vietnam War (2 million), and the Pol Pot genocide in Cambodia (1 to 2 million).  Cumings, Bruce (2011). The Korean War: A History. Modern Library. p. 35. ISBN 978-0-8129-7896-4. Various encyclopedias state that the countries involved in the three-year conflict suffered a total of more than 4 million casualties, of which at least 2 million were civilians—a higher percentage than in World War II or Vietnam. A total of 36,940 Americans lost their lives in the Korean theater; of these, 33,665 were killed in action, while 3,275 died there of nonhostile causes. Some 92,134 Americans were wounded in action, and decades later, 8,176 were still reported as missing. South Korea sustained 1,312,836 casualties, including 415,004 dead. Casualties among other UN allies totaled 16,532, including 3,094 dead. Estimated North Korean casualties numbered 2 million, including about one million civilians and 520,000 soldiers. An estimated 900,000 Chinese soldiers lost their lives in combat.  McGuire, James (2010). Wealth, Health, and Democracy in East Asia and Latin America. Cambridge University Press. p. 203. ISBN 978-1-139-48622-4. In Korea, war in the early 1950s cost nearly 3 million lives, including nearly a million civilian dead in South Korea.  Painter, David S. (1999). The Cold War: An International History. Routledge. p. 30. ISBN 978-0-415-15316-4. Before it ended, the Korean War cost over 3 million people their lives, including over 50,000 US servicemen and women and a much higher number of Chinese and Korean lives. The war also set in motion a number of changes that led to the militarization and intensification of the Cold War.  Lewy, Guenter (1980). America in Vietnam. Oxford University Press. pp. 450–453. ISBN 978-0-19-987423-1. For the Korean War the only hard statistic is that of American military deaths, which included 33,629 battle deaths and 20,617 who died of other causes. The North Korean and Chinese Communists never published statistics of their casualties. The number of South Korean military deaths has been given as in excess of 400,000; the South Korean Ministry of Defense puts the number of killed and missing at 281,257. Estimates of communist troops killed are about one-half million. The total number of Korean civilians who died in the fighting, which left almost every major city in North and South Korea in ruins, has been estimated at between 2 and 3 million. This adds up to almost 1 million military deaths and a possible 2.5 million civilians who were killed or died as a result of this extremely destructive conflict. The proportion of civilians killed in the major wars of this century (and not only in the major ones) has thus risen steadily. It reached about 42 percent in World War II and may have gone as high as 70 percent in the Korean War. ... we find that the ratio of civilian to military deaths [in Vietnam] is not substantially different from that of World War II and is well below that of the Korean War.  Flashback: The Kwangju massacre, 17 May 2000.  "20 years later, father still seeks truth in son's death" Archived 3 March 2016 at the Wayback Machine, The Hankyoreh, 15 January 2007. Retrieved 15 July 2010.  "Two Decedes After Seoul Olympics". Korea Times. 30 October 2007.  "Kim Dae-jung". The Guardian. 18 August 2009.  "The Nobel Peace Prize 2000". The Nobel Foundation. 2000. Retrieved 17 February 2009.  Oliver, Christian. "Seoul: S Korea looks forward to its own party," Financial Times (UK). 25 June 2010.  Cheonan and Yeonpyeong. The Northeast Asian Response to North Korea's Provocations (PDF). Asia Foundation. 1 May 2011.  Langan, Peter (28 November 2016). "How long will Seoul protests remain peaceful?". Asia Times. Retrieved 2 December 2016.  "South Korea's president is removed from office as court upholds her impeachment". Los Angeles Times. 10 March 2017. Retrieved 10 March 2017.  "South Korea's Moon may be on brink of legacy-defining moment". USA Today. 11 February 2018.  Gladstone, Rick (4 January 2021). "As Birthrate Falls, South Korea's Population Declines, Posing Threat to Economy". New York Times. Retrieved 5 January 2021.  The estimated area rises steadily from year to year, possibly because of land reclamation. 행정구역(구시군)별 국토적. Korea Statistical Information Service (in Korean). Archived from the original on 17 September 2004. Retrieved 27 March 2006.  Geography of Korea, Asia Info Organization  Dinerstein, Eric; et al. (2017). "An Ecoregion-Based Approach to Protecting Half the Terrestrial Realm". BioScience. 67 (6): 534–545. doi:10.1093/biosci/bix014. ISSN 0006-3568. PMC 5451287. PMID 28608869.  "Korea National Park Service official site". Retrieved 29 October 2010.  Climate data in seoul, 1971 ~ 2000(in Korean), Korea Meteorological Administration.  South Korea climate Archived 30 March 2014 at the Wayback Machine, U.S. Library of Congress, Country studies  "Korea Air Pollution Problems". American University of Washington. Archived from the original on 9 March 2010. Retrieved 18 February 2010.  Randolph T. Hester (28 August 2009). "Letter to Lee administration: Save the Songdo Tidal Flat". The Hankyoreh. Archived from the original on 11 May 2011. Retrieved 18 February 2010.  Wang, Ucilla (28 July 2008 ) South Korea Boosts Renewable-Energy Investments by 60%. Greentechmedia.com  "South Korea's green new deal". CNN.com. 18 October 2009. Retrieved 21 October 2009.  R&D status and prospects on fuel cells in Korea. fuelcellseminar.com  Renewable Energy Policy Mechanisms by Paul Gipe Archived 10 May 2012 at the Wayback Machine (1.3MB) Lauber, V. (2004). "REFIT and RPS: Options for a harmonized Community framework", Energy Policy, Vol. 32, Issue 12, pp. 1405–1414. Lauber, V. (2008). "Certificate Trading – Part of the Solution or Part of the Problem?" Ljubljana Conference on the Future of GHG Emissions Trading in the EU, March 2008. Salzburg, Austria: University of Salzburg. Retrieved 16 March 2009 at www.uni-salzburg.at/politikwissenschaft/lauber  The fuel cell industry review 2012. fuelcelltoday.com.  Cha, Josh Smith, Sangmi (8 June 2020). "Jobs come first in South Korea's ambitious 'Green New Deal' climate plan". Reuters. Retrieved 29 September 2020.  Herald, The Korea (8 September 2020). "Moon vows to shut down 30 more coal plants to bring cleaner air and battle climate change". www.koreaherald.com. Retrieved 29 September 2020.  "Seoul City holds 2nd Arisu Festival to show tap water is safe to drink". Newsworld. Archived from the original on 28 September 2007.  "Seoul Metropolitan Government – "A Clean, Attractive & Global City, Seoul!"". Archived from the original on 15 February 2009.  Grantham, H. S.; et al. (2020). "Anthropogenic modification of forests means only 40% of remaining forests have high ecosystem integrity – Supplementary Material". Nature Communications. 11 (1): 5978. doi:10.1038/s41467-020-19493-3. ISSN 2041-1723. PMC 7723057. PMID 33293507.  "Party Groupings". United Nations Framework Convention on Climate Change. 28 November 2007. Archived from the original on 5 June 2013. Retrieved 18 February 2010.  Public Domain This article incorporates public domain material from the CIA World Factbook website https://www.cia.gov/the-world-factbook/.  "Index of Democracy 2008" (PDF). The Economist Intelligence Unit. Archived from the original (PDF) on 14 December 2008. Retrieved 25 April 2010.  "South Korea – Constitution". International Constitutional Law. Retrieved 16 February 2009.  "Korea, South". The World Factbook. Central Intelligence Agency. 10 February 2009. Retrieved 16 February 2009.  "Corruption Perceptions Index 2018 Executive Summary p.8" (PDF). transparency.org. Transparency International. Retrieved 13 March 2019.  행정안전부. 행정안전부> 정책자료> 통계> 주민등록 인구통계. www.mois.go.kr. Archived from the original on 20 April 2018. Retrieved 2 May 2018.  ""World Population prospects – Population division"". population.un.org. United Nations Department of Economic and Social Affairs, Population Division. Retrieved 9 November 2019.  ""Overall total population" – World Population Prospects: The 2019 Revision" (xslx). population.un.org (custom data acquired via website). United Nations Department of Economic and Social Affairs, Population Division. Retrieved 9 November 2019.  "Population Projections for Provinces (2013~2040)" (PDF). Statistics Korea. 16 April 2016. Retrieved 20 May 2016.  "Major Indicators of Korea". Korean Statistical Information Service. Retrieved 9 September 2016.  Breen, Michael (4 April 2017). The New Koreans: The Story of a Nation. Macmillan. ISBN 978-1-4668-7156-4 – via Google Books.  "South Korea". CIA Country Studies. Retrieved 22 April 2006.  Populations for all cities as of 2005, "Summary of Census Population (by administrative district/sex/age)". NSO Database. Archived from the original on 5 October 2010. Retrieved 11 May 2009.  "South Korea – Population Trends". Library of Congress Country Studies.  "Korea's Population Tops 50 Million". The Chosun Ilbo. 1 February 2010. Archived from the original on 30 April 2010. Retrieved 25 April 2010.  "Population by Census (2016)". Korean Statistical Information Service. Archived from the original on 28 February 2018. Retrieved 11 March 2018.  Choe Sang-Hun (2 November 2009). "South Koreans Struggle With Race". The New York Times.  "More Than 1 Million Foreigners Live in Korea (According to the article, approximately 443,566 people are considered to be Chinese residents in South Korea with Korean ethnicity.)". The Chosun Ilbo. 6 August 2009. Archived from the original on 9 September 2009. Retrieved 18 October 2009.  Kostat.go.kr Archived 12 May 2010 at the Wayback Machine, 대한민국 통계청  Jung Sung-ki (4 November 2009). "US Soldiers in Korea Negative About Rotation to Middle East". The Korea Times. Retrieved 25 April 2010.  Kang Shin-Who (26 November 2009). "Foreign Teachers Unenthusiastic Over Culture Course". The Korea Times. Seoul. Retrieved 18 February 2010.  Kim Rahn (22 May 2009). "South Korea's birthrate world's lowest". The Korea Times. Seoul. Retrieved 25 April 2010.  "South Korea". CIA World Factbook. 26 June 2009. Retrieved 7 February 2011.  "Childbirths in S. Korea grow 5.7 pct in 2010" Archived 26 May 2012 at the Wayback Machine  "South Korea's fertility rate is the lowest in the world". The Economist. 30 June 2018. Retrieved 24 November 2019.  "S. Korea's childbirth tally drops to another historic low in October". 27 December 2018. Archived from the original on 23 January 2019. Retrieved 24 November 2019.  "Fertility rate dips below 1 in 2018: official". The Korean Times. January 2019. Archived from the original on 30 January 2019. Retrieved 24 November 2019.  CIA – The World Factbook 2008 – Rank Order – Life expectancy at birth  "The World Factbook". CIA. Retrieved 10 August 2013.  Life expectancy at birth, total (years) |Data |Table. Data.worldbank.org. Retrieved 20 June 2016.  Leipziger, Danny (6 February 2014). "South Korea's Japanese Mirror". The Diplomat. Archived from the original on 11 February 2014. Retrieved 6 February 2014.  2015년 인구주택총조사 전수집계결과 보도자료 [2015 Population and Housing Census]. Statistics Korea.  "South Korea Now Open For Foreign Students". Education-blog.net. 28 August 2008. Archived from the original on 22 March 2019. Retrieved 25 April 2010.  "PISA – Results in Focus" (PDF). OECD. p. 5.  "Korea – Student performance (PISA 2015)". OECD.  "What the world can learn from the latest PISA test results". 10 December 2016.  "Education OECD Better Life". OECD. Archived from the original on 31 May 2016. Retrieved 29 May 2016.  "What the world can learn from the latest PISA test results". The Economist. 10 December 2016.  "Education OECD Better Life". OECD. Archived from the original on 31 May 2016. Retrieved 29 May 2016.  Ripley, Amanda (25 September 2011). "South Korea: Kids, Stop Studying So Hard!". Time.  Habibi, Nader (11 December 2015). "The overeducated generation". Archived from the original on 18 November 2016.  Cobbold, Trevor (14 November 2013). "South Korea's Education Success Has a Dark Side". Archived from the original on 18 November 2016.  Diamond, Anna (17 November 2016). "Why South Korea Is So Fixated With the College-Entrance Exam".  Lee, Ji-Yeon (26 September 2014). "Vocational Education and Training in Korea: Achieving the Enhancement of National Competitiveness" (PDF). KRIVET. Archived from the original (PDF) on 20 December 2016.  Strother, Jason (10 November 2012). "Drive for education drives South Korean families into the red". Christian Science Monitor.  "South Korean education ranks high, but it's the kids who pay". 30 March 2015.  "South Koreans Consider The Trades Over University Education". Public Radio International.  David Santandreu Calonge (30 March 2015). "South Korean education ranks high, but it's the kids who pay". Retrieved 3 July 2015.  WeAreTeachers Staff (5 April 2013). "South Korea's School Success". WeAreTeachers. Archived from the original on 5 July 2015. Retrieved 3 July 2015.  "Korea Awash with the Under-Skilled and Overeducated". The Chosun Ilbo. 8 December 2011. Retrieved 23 October 2016.  Na Jeong-ju (23 May 2012). "Meister schools fight social prejudice". The Korea Times. Archived from the original on 17 August 2016. Retrieved 15 July 2016.  "Korea" (PDF). OECD. Archived from the original (PDF) on 15 August 2019. Retrieved 16 August 2019.  "High performance, high pressure in South Korea's education system". ICEF Monitor. 23 January 2014. Retrieved 29 May 2016.  Reeta Chakrabarti (2 December 2013). "South Korea's schools: Long days, high results". BBC News. Retrieved 28 October 2016.  "The Pressures of the South Korean Education System". 20 April 2013. Archived from the original on 20 December 2016. Retrieved 11 December 2016.  "Korea: Overview of the Education System (EAG 2019)" (2019). GPSEducation.OECD.org. OECD. Retrieved 21 February 2020.  "South Korean students wracked with stress". 8 December 2013.  Ripley, Amanda (25 September 2011). "Teacher, Leave Those Kids Alone". Time. Retrieved 4 December 2013.  Thomas, Tanya (27 April 2010). "Intensely Competitive Education In South Korea Leads to Education Fever". Medindia. Retrieved 4 December 2013.  "The All-Work, No-Play Culture Of South Korean Education". 15 April 2015.  Janda, Michael (22 October 2013). "Korea's Rigorous Education System Has Delivered Growth, but It is Literally Killing the Country's Youth". Australian Broadcasting Corporation. Retrieved 4 December 2013.  Koo, Se-Woong (2 August 2014). "An Assault Upon Our Children". The New York Times. Retrieved 19 August 2015.  "Over 3 Million Highly Educated People Unemployed". The Chosun Ilbo. 27 June 2013.  "Lee calls for end to prejudices against non-college graduates". Yonhap. 5 March 2012. Retrieved 2 October 2016.  Na Jeong-ju (23 May 2012). "Meister schools fight social prejudice". The Korea Times. Archived from the original on 17 August 2016. Retrieved 15 July 2016.  "S Korea's vocational education needs to tackle its shortcomings". The Nation. 6 January 2014. Archived from the original on 27 March 2019. Retrieved 19 August 2016.  Ju-min Park (11 November 2015). "Bleak job prospects drive South Korean youth to vocational schools". Reuters. Retrieved 29 May 2016.  "Lee calls for end to prejudices against non-college graduates". Yonhap. 5 March 2012. Retrieved 2 October 2016.  Horn, Michael B. (14 March 2014). "Meister of Korean school reform: A conversation with Lee Ju-Ho". Archived from the original on 24 September 2016. Retrieved 29 May 2016.  "South Koreans Consider The Trades Over University Education". Global Politics. 18 November 2011. Retrieved 29 May 2016.  "Chinese, Second-most Popular Foreign Language at Schools in South Korea". china.org.cn. 30 June 2004.  South Korea National Statistical Office's 19th Population and Housing Census (2015): "Religion organizations' statistics". Retrieved 20 December 2016  WIN-Gallup International: "Global Index of Religiosity and Atheism 2012" Archived 21 October 2013 at the Wayback Machine.  "Korea's Muslims Mark Ramadan". The Chosun Ilbo. Seoul. 11 September 2008. Archived from the original on 13 September 2008.  "Constitution of the Republic of Korea". Constitutional Court of Korea. Archived from the original on 23 March 2008.  Ogata, Mamoru Billy (1984). A Comparative Study of Church Growth in Korea and Japan: With Special Application to Japan. Fuller Theological Seminary. pp. 32 ff.  Kim, Andrew Eungi (Spring–Summer 2000). "Christianity, Shamanism, and Modernization in South Korea" (PDF). CrossCurrents. Archived from the original (PDF) on 10 January 2014. Retrieved 8 June 2013.  Korean Social Sciences Journal, 24 (1997). Korean Social Science Research Council. pp. 33–53  Moll, Rob (1 March 2006). "Missions Incredible". Christianity Today. Carol Stream, IL. Retrieved 17 February 2009.  "Buddhism in Korea". Korean Buddhism Magazine. Seoul. 1997. Archived from the original on 26 April 2009. Retrieved 17 February 2009.  (in French) Health at a Glance 2015 |OECD READ edition. Keepeek.com. Retrieved 20 June 2016.  "Revealed: Countries With The Best Health Care Systems, 2019 > CEOWORLD magazine". 5 August 2019.  Why South Korea has high suicide rates. KOREA NOW. 13 March 2021. Archived from the original on 8 August 2021. Retrieved 7 September 2021 – via YouTube.  "Suicide rates, age standardized - Data by country". World Health Organization. 2015. Archived from the original on 18 October 2017. Retrieved 13 April 2017.  Evans, Stephen (5 November 2015). "Korea's hidden problem: Suicidal defectors". BBC News. United Kingdom of Great Britain and Northern Ireland: British Broadcasting Corporation. Archived from the original on 2 June 2016. Retrieved 17 May 2016. South Korea consistently has the highest suicide rate of all the 34 industrialized countries in the OECD.  "World Happiness Report 2016 Update". UN Sustainable Development Solutions Network; Earth Institute (University of Columbia). 20 March 2016. pp. 20–21–22. Archived from the original on 17 March 2016. Retrieved 20 March 2016.  "Suicide rates, age standardized – Data by country". World Health Organization. 2015. Retrieved 13 April 2017.  (in French) Health at a Glance 2015 |OECD READ edition. Keepeek.com. Retrieved 20 June 2016.  "Life expectancy increased by 5 years since 2000, but health inequalities persist". WHO. 19 May 2016.  "WHO – World Health Statistics 2016: Monitoring health for the SDGs". WHO.  "Can North Korea get South to join dispute with Japan over two islands in Asia?". Newsweek. 21 March 2018.  modern Korean history – Home. Modernkoreanhistory.weebly.com. Retrieved 17 April 2015.  "North, South Korea pledge peace, prosperity". Reuters. 4 October 2007. Retrieved 17 February 2009.  "North Korea deploying more missiles". BBC News. 23 February 2009.  "North Korea tears up agreements". BBC News. 30 January 2009. Retrieved 8 March 2009.  "North Korea warning over satellite". BBC News. 3 March 2009. Retrieved 8 March 2009.  "Koreas agree to military hotline". CNN.com. 4 June 2004. Retrieved 18 February 2010.  "Proliferation Security Initiation". 31 May 2003. Retrieved 8 May 2012.  Jung Sung-ki (13 September 2010). "Seoul reaffirms N. Korea's torpedo attack in final report". The Korea Times. Seoul.  "Seoul Decides to Continue Kaesong Project, Humanitarian Aid". The Chosun Ilbo. Seoul. 25 May 2010.  "Seoul shuts down joint North-South Korea industrial complex". The Guardian. 10 February 2016.  "North Korea rocket launch: UN security council condemns latest violation". The Guardian. 7 February 2016.  "South Korean president says Olympics have lowered tensions with North". The Washington Post. 17 February 2018.  "South Koreans meet North Korean leader Kim for talks about talks". Reuters. 5 March 2018.  Korea Herald. (2004) Korea now, p. 31; excerpt, "The Chinese also insist that even though Goguryeo was part of Chinese domain, Silla and Baekje were states subjected to China's tributary system."  Pratt, Keith L. (1999). Korea: a historical and cultural dictionary. p. 482.  Kwak, p. 99. at Google Books; excerpt, "Korea's tributary relations with China began as early as the fifth century, were regularized during the Goryeo dynasty (918–1392), and became fully institutionalized during the Yi dynasty (1392–1910)."  Seth, Michael J. (2006). A concise history of Korea, p. 64, at Google Books; excerpt, "China found instead that its policy of using trade and cultural exchanges and offering legitimacy and prestige to the Silla monarchy was effective in keeping Silla safely in the tributary system. Indeed, the relationship that was worked out in the late seventh and early eighth centuries can be considered the beginning of the mature tributary relationship that would characterize Sino-Korean interchange most of the time until the late nineteenth century;"  A New History of Korea p. 61  "Asia Times – News and analysis from Korea; North and South". Asia Times. Hong Kong. 11 September 2004. Archived from the original on 11 September 2004. Retrieved 25 April 2010.  Kristof, Nicholas D. (24 August 1992). "Chinese and South Koreans Formally Establish Relations". The New York Times.  "South Korea Country Profile". MIT. 10 March 2018. Archived from the original on 9 April 2019. Retrieved 9 March 2018.  "China Country Profile". MIT. 10 March 2018. Archived from the original on 18 July 2018. Retrieved 9 March 2018.  "Defense Ministry's regular press conference on July 28". Chinese Ministry of National Defence. 28 July 2016. Archived from the original on 14 January 2019. Retrieved 9 March 2018.  "Thaad retaliation slashes Olympics visitors from China". Korea Joongang Daily. 2 March 2018.  "China wins its war against South Korea's US THAAD missile shield – without firing a shot". South China Morning Post. 18 November 2017.  Adams, Rod. "Moon Jae-in Making Friends By Importing More Gas". Forbes. Retrieved 30 July 2017.  "Are Warming Russia-South Korea Relations a Game-changer?". The Diplomat. 18 July 2018.  "South Korea, Russia to begin preparations for FTA negotiations: Moon". The Straits Times. 22 June 2018.  A Brief History of the US-Korea Relations Prior to 1945. "While less than 100 Koreans in America enlisted in the US military during World War II, more than 100,000 Koreans served in the Japanese army as officers and soldiers. There were two Korean Lt. Generals in the Japanese Army: a Chosun prince, whose rank was honorary and who commanded no troops; and Lt. Gen. Hong Sa-Ik, who was a professional military man from the old Chosun army."  "Truth Commission on Forced Mobilization under the japanese Imperialism Republic of Korea". Archived from the original on 14 February 2009. Retrieved 18 March 2009.  従軍慰安婦の正体. atwiki.jp. Archived from the original on 12 July 2012. Retrieved 19 August 2012.  Soh, C. Sarah (May 2001). "Japan's Responsibility Toward Comfort Women Survivors". San Francisco: Japan Policy Research Institute. Archived from the original on 28 June 2012. Retrieved 3 February 2012.  "WCCW's Mission". Washington Coalition for Comfort Women Issues. 2011. Archived from the original on 2 May 2010. Retrieved 18 February 2010.  朝日新聞が日韓関係を破壊した 慰安婦についての大誤報を謝罪することが関係修復の条件. jbpress.ismedia.jp. Retrieved 19 August 2012.  Kim Hee-sung (22 February 2008). "Professor from Japan Discovers Map Proving Dokdo Island is Korean Territory". DYNAMIC-KOREA.COM. Archived from the original on 14 May 2011.  "Dokdo Takeshima Island Liancourt Rocks The Historical Facts of the Dokdo / Takeshima Island Dispute Between Korea and Japan". www.dokdo-takeshima.com.  "President Roh Moo-hyun will not hold a summit with Japanese Prime Minister Junichiro Koizumi until Koizumi stops visits to Japan's Yasukuni shrine". Voice of America. 17 March 2006. Archived from the original on 7 May 2008. Retrieved 15 February 2009.  "Japan PM tells South Korea's Moon that 2015 'comfort women' deal is final". Reuters. 9 February 2018.  "South Korea formally requests Japan's 'rising sun' flag be banned at 2020 Olympics". The Independent. 11 September 2019.  "South Korea asks IOC to ban Japan's use of 'Rising Sun' flag at Olympics". Reuters. 11 September 2019.  "S. Korea urges IOC to ban Japanese imperial flag from 2020 Olympics". Kyodo News. 12 September 2019. Retrieved 5 September 2020.  "EU agrees free trade deal with S.Korea". Agence France-Presse. 16 September 2009.  "South Korea-EU – trade in goods – Statistics Explained". ec.europa.eu. Archived from the original on 23 September 2017. Retrieved 23 September 2017.  "Mutual Defense Treaty Between the United States and the Republic of Korea; October 1, 1953". Yale Law School.  Haesook Chae (2010). "South Korean Attitudes toward the ROK–U.S. Alliance: Group Analysis". PS: Political Science & Politics. 43 (3): 493–501. doi:10.1017/S1049096510000727. S2CID 155083075.  Appelbaum, Bintamin; Steinhauer, Jennifer (13 October 2011). "Congress Ends 5-Year Standoff on Trade Deals in Rare Accord". The New York Times.  "New Opportunities for U.S. Exporters Under the U.S.-Korea Trade Agreement". 9 June 2012.  John Pike. "Defense Budget – South Korea". Globalsecurity.org. Retrieved 29 October 2010.  "2018 Defence White Paper" (PDF). December 2018.  "2019 Military Strength Ranking". www.globalfirepower.com.  GlobalSecurity on Military of Republic of Korea, Globalsecurity.org  Lee Tae-hoon (30 September 2009). "Military Duty Exemption for Biracial Koreans Will Be Scrapped". The Korea Times. Seoul. Retrieved 18 February 2010.  "Eighth United States Army (EUSA)". GlobalSecurity.org. 27 December 2005. Retrieved 6 February 2010. The KATUSA Program is significant not only because of the military manpower and monetary savings that it provides to the U.S. Army, but also because it represents ROK/U.S. cooperation and commitment to deter war. The KATUSA Program is symbolic of ROK/U.S. friendship and mutual support.  "OPLAN 5027 Major Theater War – West". www.globalsecurity.org.  "South Korea Beefs Up Anti-Air Defenses as North Blusters". Defense Industry Daily. 31 May 2009.  "F-16 Air Forces – South Korea". F-16.net. Archived from the original on 30 July 2013. Retrieved 10 August 2013.  JPG image. imageshack.us  JPG image. imageshack.us  Bomi Lim (26 May 2011). "Korea Aerospace Signs Deal to Sell Trainer Jets to Indonesia" Archived 20 July 2011 at the Wayback Machine. The Jakarta Globe.  Heo, Man-ho (25 March 2009). "North Korea's Continued Detention of South Korean POWs since the Korean and Vietnam Wars North Korea's Continued Detention of South Korean POWs since the Korean and Vietnam Wars". Man-ho Heo. 14 (2): 141–165. doi:10.1080/10163270209464030.  "Zaytun Division official website". Retrieved 17 February 2009.[dead link]  "America's Unsinkable Fleet". Newsweek. New York. 26 February 2007. Retrieved 17 February 2009.  "Allies' future command to be led by S. Korean general: minister". Yonhap News. 22 February 2018.  "Amnesty International calls on South Korea to free conscientious objectors". The Guardian. 13 May 2015.  "South Korean Jehovah's Witnesses Face Stigma of Not Serving in Army". The New York Times. 10 April 2015.  Sang-Hun, Choe (1 November 2018). "In Landmark Ruling, South Korea's Top Court Acquits Conscientious Objector". The New York Times.  "Report for Selected Countries and Subjects". www.imf.org. Retrieved 19 September 2018.  South Korea: Introduction >> globalEDGE: Your source for Global Business Knowledge. Globaledge.msu.edu. Retrieved 5 October 2016.  SOUTH KOREA Market overview Archived 25 October 2016 at the Wayback Machine. tiq.qld.gov.au  Kerr, Anne; Wright, Edmund (2015). A Dictionary of World History. Oxford University Press. pp. 367–. ISBN 978-0-19-968569-1.  Report for Selected Countries and Subjects, International Monetary Fund.  Behnke, Alison (2004). North Korea in Pictures. Lerner Publishing Group. p. 60. ISBN 978-0-8225-1908-9.  "OECD.Stat Education and Training > Education at a Glance > Educational attainment and labor-force status > Educational attainment of 25–64 year-olds". OECD. Archived from the original on 31 January 2016.  Economic Growth Rates of Advanced Economies. International Monetary Fund. Retrieved 8 September 2010.  "GDP per capita growth (annual %) – Data". data.worldbank.org.  Kleiner, Jürgen (2001). Korea, A Century of Change. River Edge, NJ: World Scientific. ISBN 978-981-02-4657-0.  "Moody's Raises Korea's Credit Range". The Chosun Ilbo. Seoul. 2 August 2010. Retrieved 14 August 2010.  "Financial markets unstable in S.Korea following Cheonan sinking". Hankyeoreh. 26 May 2010. Retrieved 14 August 2010.  "S Korea stands among world's highest-level fiscal reserve holders: IMF". Xinhua. Beijing. 7 September 2010. Retrieved 8 September 2010.  Nattavud Pimpa (6 December 2013). "Lessons from South Korea's Chaebol economy". The Conversation Australia. Retrieved 15 December 2013.  "South Korea Survived Recession With CEO Tactics". Newsweek. New York. 10 May 2010.  "South Korea GDP grew revised 6.2pc in 2010". Business Recorder. Karachi. Agence France-Presse. 30 March 2011. Archived from the original on 27 April 2011.  "Background Note: South Korea". U.S. State Department. 7 July 2011.  "About Korea" Archived 1 January 2016 at the Wayback Machine. Paris: OECD.  "Samsung Electronics". Fortune.  "Subway". Korea Tourism Organization. Archived from the original on 3 December 2013. Retrieved 18 July 2010.  Express bus terminal guide Archived 23 September 2010 at the Wayback Machine, Korea Express Bus Lines Association.  "Surging Seoul: Traffic at Incheon Airport is booming. But can South Korea's Big Two airlines capitalize?". Airline Weekly. 23 October 2017. Retrieved 9 March 2018.  "South Korea's abandoned airports". BBC News. 18 May 2009.  "Transportation Statistics > Heliports (most recent) by country". NationMaster. 2008. Retrieved 21 February 2009.  "Company Info". Korean Air. Retrieved 9 March 2018.  "International Aviation Policy". Ministry of Land, Transportation and Maritime Affairs. Archived from the original on 15 September 2009. Retrieved 19 May 2005.  Lee Eun-joo (2 July 2010). "If you're looking for a ticket to Jeju, leave late". Joongang Daily (Seoul). Retrieved 15 July 2010.  "Another Korean Nuclear Issue". The Diplomat. 19 July 2010. Retrieved 14 August 2010.  "ITER Members". ITER. Retrieved 2 March 2017.  "South Korea wins landmark Gulf nuclear power deal". Reuters. 29 December 2009.  "All systems go for Jordan's first nuclear reactor". UPI. 31 March 2010.  "South Korea-Jordan sign $130M nuclear deal". World Nuclear News. 27 July 2010.  "Korea, Argentina Sign MOU for Nuclear Plant Project". The Chosun Ilbo. Seoul. 18 September 2010.  "Argentina eyes nuclear role in S. America". UPI. 17 September 2010.  "Korea nearing Turkey nuclear plant contract". The Korea Times. Seoul. 15 June 2010.  Choe Sang-Hun (14 July 2010). "U.S. Wary of South Korea's Plan to Reuse Nuclear Fuel". The New York Times.  "S. Korean Pyroprocessing Awaits U.S. Decision". Arms Control Association. 6 October 2010. Retrieved 29 October 2010.  "NRI Overall Ranking 2014" (PDF). World Economic Forum. Retrieved 28 June 2014.  UNTWO (July 2017). UNWTO Tourism Highlights 2017. doi:10.18111/9789284419029. ISBN 978-92-844-1902-9.  Kolesnikov-Jessop, Sonia (11 November 2010). "South Korea Sets Its Sights on Foreign Tourists". The New York Times.  "Double-digit Growth". BusinessKorea. Archived from the original on 20 January 2015.  "Hallyu fuels foreign investment in Korea". The Korea Times. Archived from the original on 20 January 2015. Retrieved 20 January 2015.  Bang, Ha-Nam, Study of Korean Corporations’ Retirement Allowance Schemes, Korea Labor Institute, 1998.  "South Korea and Japan's Pension System Compared" (PDF). Archived from the original (PDF) on 20 December 2016.  "The Korean Pension System: Current State and Tasks Ahead" (PDF). OECD.  "Coverage". National Pension Service. Archived from the original on 21 February 2016. Retrieved 1 December 2016.  "Social Security Programs Throughout the World: Asia and the Pacific, 2010 – South Korea". U.S. Social Security Administration, Office of Retirement and Disability. Retrieved 1 December 2016.  "The National Pension Act: Republic of Korea" (PDF). The World Bank.  Soo-Wan Kim (3 December 2016). The Multi-pillar system of old-age income security in Korea: Its development, current status and issues Welfare Asia (PDF). Welfare Asia.  Samsung number One in the World Archived 15 January 2013 at the Wayback Machine, International Data Corporation, 29 January 2010. Retrieved 7 July 2010.  "Koreans love their mobile phones", Joongang Daily, 28 January 2009. Retrieved 7 July 2010.  Cho Jin-seo (12 February 2006). "Terrestrial-DMB adds color to Korean lifestyle" Archived 30 April 2011 at the Wayback Machine, The Korea Times (Seoul). "Facts from 'Digital Korea'", CNN Asia, 16 October 2007. Retrieved 7 July 2010.  Galloway, Lindsey. "Five countries on the frontline of tech". www.bbc.com.  "Household Download Index". Archived from the original on 19 February 2012. Retrieved 12 February 2012.  "These are the 10 smartest countries in the world when it comes to science". Business Insider. 4 December 2015. Retrieved 26 October 2016.  "These Are the World's Most Innovative Countries". 5 May 2019 – via www.bloomberg.com.  Service (KOCIS), Korean Culture and Information. "Korea is the most innovative country: Bloomberg : Korea.net : The official website of the Republic of Korea". www.korea.net.  "The Bloomberg Innovation Index". Bloomberg.  David Shamah (4 February 2015). "Bloomberg: Israel Is World's 5th Most Innovative Country, Ahead Of US, UK". No Camels. Retrieved 29 October 2016.  "Release of the Global Innovation Index 2020: Who Will Finance Innovation?". www.wipo.int. Retrieved 2 September 2021.  "Global Innovation Index 2019". www.wipo.int. Retrieved 2 September 2021.  "RTD - Item". ec.europa.eu. Retrieved 2 September 2021.  "Global Innovation Index". INSEAD Knowledge. 28 October 2013. Retrieved 2 September 2021.  Tesla, Agence (22 June 2016). "Can South Korean Startups (and the government) Save its Flailing Giant Tech Conglomerates? – Innovation is Everywhere". Retrieved 18 July 2016.  Kwanwoo Jun (23 September 2013). "Seoul Puts a Price on Cyberdefense". The Wall Street Journal. Retrieved 24 September 2013.  "South Korean war on 'fake news' raises concern of censorship". Reuters. 26 October 2018.  "Is South Korea Sliding Toward Digital Dictatorship?". Forbes. 25 February 2019.  "Korea, Russia Enter Full-Fledged Space Partnership". Defence Talk. 5 July 2007. Retrieved 7 June 2013.  South Korea Confirms Contact With Satellite Lost, Space Daily, 7 January 2008. Retrieved 15 July 2010.  "Scientist Yi So Yeon becomes first Korean astronaut", The Times (London), 9 April 2008  "First S Korean astronaut launches". BBC News (8 April 2008). Retrieved 17 April 2015.  "S. Korea Completes Work on Naro Space Center" Archived 17 April 2015 at the Wayback Machine, The Korea Times (Seoul), 10 June 2009. Retrieved 15 July 2010.  "S. Korean satellite lost shortly after launch". Yonhap. 26 August 2009. Retrieved 10 August 2013.  "Global Insider: South Korea's Space Program". Worldpoliticsreview.com. 29 June 2010. Retrieved 10 August 2013.  Chris Bergin (30 January 2013). "South Korea launch STSAT-2C via KSLV-1". NASASpaceFlight.com. Retrieved 8 March 2013.  "Naro-1 explodes after takeoff", Joongang Daily (Seoul), 11 June 2010. Retrieved 15 July 2010.  "South Korea's first rocket ready – at last". Asia Times. Hong Kong. 11 August 2009. Archived from the original on 24 July 2012. Retrieved 21 August 2010.  "S. Korea DAPA commissioner confirms 500 km-range ballistic missile development research". The Hankyeoreh. 9 October 2009. Retrieved 21 August 2010.  Special Report: [Business Opportunities] R&D Archived 21 February 2012 at WebCite. Ministry of Knowledge Economy, 3 September 2007. Retrieved 15 July 2009.  "Robot parks, a world first". JoongAng Daily, 13 February 2009. Retrieved 15 July 2009.  Android Has Human-Like Skin and Expressions, Live Science, 8 May 2006. Retrieved 15 July 2009.  "Female Android Debuts in S. Korea, National Geographic, May 15, 2006". National Geographic. 28 October 2010. Retrieved 10 August 2013.  "EveR-3, Yonhap News, April 20, 2009" (in Korean). News.naver.com. 20 April 2009. Retrieved 10 August 2013.  South Korean Robot English Teachers Are Go, Popular Science, 24 February 2010. Retrieved 15 July 2010.  Korean Robot Game Festival Archived 14 May 2011 at the Wayback Machine, Official Site  "Bio International Convention Korea Country Profile" (PDF). Bio2008.org. Archived from the original (PDF) on 17 September 2011. Retrieved 29 October 2010.  AFP. "Discovery Channel :: News – Animals :: Endangered Wolf Cloned in South Korea". Dsc.discovery.com. Archived from the original on 9 January 2010. Retrieved 25 April 2010.  "Biotechnology" (PDF). Retrieved 25 April 2010.  Dunleavy, Kevin (25 February 2021). "With $900M IPO, SK Bioscience has big plans for manufacturing expansion—even beyond COVID-19 vaccines" FiercePharma. Retrieved 24 April 2021.  Fairbank, John K.; Reischauer, Edwin O.; Craig, Albert M. (1978). East Asia: Tradition & Transformation. Boston: Houghton Mifflin. ISBN 978-0-395-25812-5.  "Associated Organisations". MCT. Archived from the original on 24 December 2005. Retrieved 11 April 2006. See also "Mission and Goal". Korea Cultural Administration. Archived from the original on 30 April 2006. Retrieved 11 April 2006.  Roberto A. Ferdman; Ritchie King (2 February 2014). "South Koreans drink twice as much liquor as Russians and more than four times as much as Americans". Quartz. Archived from the original on 8 February 2014. Retrieved 9 February 2014.  Korean painting Archived 30 July 2010 at the Wayback Machine, Asia Art  Korean Pottery and Celadon, Asian Relocation Management Korea  Contemporary Korean Art in 1990s Archived 11 September 2018 at the Wayback Machine, apexart, 1999  (in Korean) Whitney Biennal to come to Seoul again, Seoul News, 26 March 2010. Retrieved 13 July 2010.  "Gwangju Biennale". Gwangju Biennale. Archived from the original on 10 July 2010. Retrieved 29 October 2010.  Korean Pavilion, La Biennale di Venezia.  Korean architecture, Asian Info Organization  Chung Ah-young (31 March 2010). "Exhibit Focuses on Traditional Architecture" Archived 20 December 2014 at the Wayback Machine, The Korea Times; Photos of traditional Korean shelters  List of traditional Korean houses, Asian Tradition in Architecture  "UNESCO World Heritage: Republic of Korea". Unesco. Retrieved 29 October 2010.  Brief Review of Korea Modern Architecture, Prof. Park Kil-ryong (Kukmin University), modified by Architectural Design Lab, GSNU.  Contemporary Korean architecture, Asian Info Organization  "Korean buildings that captivate world". Archived from the original on 29 April 2011., Asia News, 15 January 2010; Lee Hoo-nam (16 April 2009)."Still, slow waters of Korean architecture", Joongang Daily (Seoul). Retrieved 10 July 2010.  재미있는 동양3국의 젓가락 문화비교 Archived 19 June 2018 at the Wayback Machine. Article.joins.com (19 May 2012). Retrieved 5 October 2016.  "'Korean Wave' piracy hits music industry". BBC News. 9 November 2001. Retrieved 25 June 2010.  Chow, Kat. "How The South Korean Government Made K-Pop A Thing". npr.org. National Public Radio. Retrieved 4 September 2021.  Seo Taiji, KBS World  "S.Korea's Screen Quota Hinders Market Access" Archived 3 July 2018 at the Wayback Machine, KBS World, 16 July 2010.  "List of Korean dramas". Koreandrama.org. 4 June 2007. Retrieved 29 October 2010.  콘텐츠산업정보포털. portal.kocca.kr (in Korean). Retrieved 27 March 2021.  "Taekwondo". World Taekwondo Federation. 29 November 2002. Archived from the original on 21 January 2010. Retrieved 10 August 2013.  "Korea Martial Arts Federation" (in Korean). Archived from the original on 19 July 2011.  프로스포츠, 흥행 봄날 오나…야구·축구 인기몰이 중. EBN. 17 March 2015. Retrieved 13 April 2016.  한국갤럽조사연구소. Gallup.co.kr. 20 May 2009. Retrieved 10 August 2013.  KOIS (Korea Overseas Information Service) (2003). Handbook of Korea, 11th ed. Seoul: Hollym. p. 632. ISBN 978-1-56591-212-0.  Trading Markets.com. "S. Korean Game Developer NCsoft Interested in Pro Baseball". 21 December 2010. Accessed 26 December 2010.  Min-sik, Yoon (25 October 2013). "Baseball comes roaring back to Seoul". The Korea Herald. Retrieved 9 November 2013.  Kim Yang-hee (21 April 2011). "Professional baseball rising in popularity". The Hankyoreh. Accessed 21 April 2011.  나라지표-프로스포츠 관중현황. Index.go.kr (26 January 2016). Retrieved 20 June 2016.  Wakabayashi, Daisuke; Park Sungha (24 March 2009). "Japan beats South Korea to be Baseball Champions". The Wall Street Journal (New York). 20 November 2010.  "South Korea takes Olympics baseball gold". Los Angeles Times (blog). 23 August 2008. Retrieved 7 July 2010.  "FIBA Asia Competition Archives". Competition Archives. International Basketball Federation FIBA. 26 September 2011. Archived from the original on 7 August 2014. Retrieved 15 April 2012.  "Asia League Ice Hockey official site". alhockey.com. Retrieved 29 October 2010.  "Dextro Energy International Triathlon Union World championship Series Seoul". Archived from the original on 9 June 2010. Retrieved 26 June 2010.  "2011 World Championships Results". SuperSport. MultiChoice (Pty) Ltd. 2011. Retrieved 27 December 2013.  "2013 Formula 1 Korean Grand Prix". Formula 1. Formula One World Championship Limited. 2003–2013. Retrieved 27 December 2013.  Benson, Andrew (4 December 2013). "New Jersey, Mexico, and Korea dropped from 2014 F1 calendar". BBC Sports. Retrieved 27 December 2013.  "Horse Racing". Korea Be Inspired. Korea Tourism Organization. 2013. Archived from the original on 28 December 2013. Retrieved 27 December 2013.  Jin, Dal Yong (2010). Korea's Online Gaming Empire. The MIT Press. p. 59. ISBN 978-0-262-01476-2. Further reading Amsden, Alice (1992). Asia's Next Giant: South Korea and Late Industrialization. Oxford University Press. ISBN 978-0195076035. Breen, Michael (2004). The Koreans: Who They Are, What They Want, Where Their Future Lies. St. Martin's Griffin. ISBN 978-0-312-32609-8. Hart, Dennis (2003). From Tradition to Consumption: Constructing a Capitalist Culture in South Korea. Seoul: Author. ISBN 978-89-88095-44-7. Cumings, Bruce (1997). Korea's place in the sun. New York: W.W. Norton. ISBN 978-0-393-31681-0. Lew, Yong Ick. The Making of the First Korean President: Syngman Rhee's Quest for Independence (University of Hawai'i Press; 2013); scholarly biography; 576 pages; Nahm, Andrew C. (1996). Korea: A history of the Korean people (2nd ed.). Seoul: Hollym. ISBN 978-1-56591-070-6. Schneidewind, Dieter K. (2016). Economic Miracle Market South Korea: A Blueprint for Economic Growth in Developing Nations. Springer. ISBN 978-981-10-0613-5. Yang Sung-chul (1999). The North and South Korean political systems: A comparative analysis (rev. ed.). Seoul: Hollym. ISBN 978-1-56591-105-5. Yonhap News Agency (2004). Korea Annual 2004. Seoul. ISBN 978-89-7433-070-5. Yuan, Robert T. (1988). Biotechnology in Singapore, South Korea, and Taiwan. Macmillan Publishers ltd. ISBN 978-1-349-10768-1. External links South Korea at Wikipedia's sister projects Definitions from Wiktionary Media from Wikimedia Commons News from Wikinews Quotations from Wikiquote Texts from Wikisource Textbooks from Wikibooks Travel guides from Wikivoyage Official website (Korea.net) Korea Tourism Guide website Korea National Statistical Office South Korea. The World Factbook. Central Intelligence Agency. A Country Study: South Korea in the Library of Congress South Korea at Curlie Korea OECD South Korea profile from the BBC News South Korea Encyclopædia Britannica entry Key Development Forecasts for South Korea from International Futures vte Unification flag of Korea.svg Index of Korea-related articles Related articles Authority control Edit this at Wikidata Categories: South Korea1948 establishments in South KoreaEast Asian countriesG20 nationsKoreaKorean-speaking countries and territoriesMember states of the United NationsNortheast Asian countriesRepublicsStates and territories established in 1948Former Japanese colonies Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadView sourceView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikinews Wikiquote Wikivoyage  Languages Български Deutsch Ελληνικά Français 한국어 Македонски Shqip Türkçe 中文 243 more Edit links This page was last edited on 8 October 2021, at 18:04 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki   Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more Operation Pokpoong From Wikipedia, the free encyclopedia Jump to navigationJump to search Operation Pokpoong 폭풍 작전 (暴風 作戰) Part of the Korean War Date	25–30 June 1950 Location	 38th parallel north Result	 DPRK victory  DPRK takes control of Seoul Dissolution of most of ROK forces DPRK occupies most of Korean Peninsula Successful ROK delaying tactics  Devastation of DPRK II Corps UN passes UNSC Resolution 84 United Nations joins the war DPRK fails to achieve strategic goals Belligerents  North Korea Soviet Union Soviet Union (limited)	 South Korea United States United States Commanders and leaders North Korea Choe Yong-geon North Korea Kang Geon	South Korea Shin Sung-mo South Korea Chae Byeong-deok † South Korea Chung Il-kwon South Korea Son Won-il United States Douglas MacArthur Strength North Korea 198,380[1]	South Korea 105,752[1] vte Korean War Operation Pokpoong (폭풍 작전; Korean for Storm) was an offensive operation of the Democratic People's Republic of Korea (DPRK) against the Republic of Korea (ROK) that marked the start of the Korean War. The operation began at 04:00 KST on 25 June 1950 along the 38th parallel north without a declaration of war.  The operation was planned by the DPRK and the Union of Soviet Socialist Republics (USSR) with the USSR supplying weapons such as tanks and aircraft to its ally. The DPRK was able to take control of the southern capital Seoul within a few days.[2]  The original goal for the operation was to occupy the entire Korean Peninsula by 15 August 1950 ― 50 days, with an average 10 km advance each day ― in commemoration of the 5th anniversary of the Gwangbokjeol.[2] However, heavy losses incurred by the DPRK II Corps, which was in charge of the eastern front, at the hands of the Republic of Korea Army (ROKA) 6th Infantry Division, enabled the ROK to delay the DPRK advance. The United States joined the war on 27 June and the United Nations Security Council passed Resolution 84 on 7 July.   Contents 1	Background 2	Order of battle 2.1	Democratic People's Republic of Korea 2.1.1	Army 2.1.2	38th Parallel Guard 2.2	Republic of Korea 2.2.1	Army 3	Controversy over origins of battle 4	Battle 5	North Korean command during battle 6	Propaganda 7	Aftermath 8	References Background Joseph Stalin’s influence over Kim Il-Sung dictated the timing of the invasion.[3] Kim Il-Sung and ROK leader Syngman Rhee both wanted to reunify Korea. Kim's objective was to achieve reunification through force. Kim was not able to achieve his goal without Stalin's assistance.[4] On 30 January 1950, Stalin contacted Ambassador Terenty Shtykov and explained he was ready to help organize an invasion plan. Stalin noted that in order to capture South Korea, Kim Il-Sung would need to be prepared to minimise the risk of a lengthy battle.[3] In the lead up to April 1950, Kim requested to launch an invasion on repeated occasions but Stalin did not allow Kim to launch the invasion until favorable tactical conditions in the Far East emerged.[4]  Since March 1950, the Korean People's Army (KPA) started to build up its armament, and redeployed its troops to get ready to attack South Korea. On 16 May officers of the DPRK and USSR began final inspections for the war.[5]  Kim Il-sung met Stalin in Moscow in April 1950 to formulate the invasion plan. Stalin permitted the plan on the condition that the Chinese allies were also in agreement.[3] On 13 May 1950, Kim Il-Sung went to Beijing to meet Mao Zedong. On 14 May 1950, Mao reviewed Stalin's telegram and approved the North Korean invasion.[3] Stalin had dispatched Lieutenant General Vasiliev, to prepare the invasion plan before the Stalin-Kim meeting was held in Moscow in April 1950. On 29 May 1950, Vasiliev and General Kang Kon, the Chief of the General Staff of the KPA, finalised the invasion plan.[3]  On 10 June the DPRK Ministry of People's Defense secretly summoned all division and brigade commanders to Pyongyang for a meeting.[5] Kang Kon, ordered troops to be fully ready for an offensive operation in disguise of defensive operation by 23 June. On 11 June the KPA was reorganized into two corps and the divisions that were placed at the rear started to move as close as 10 to 15 km of north to the 38th Parallel.[5] Advanced forces from the KPA 2nd Division moved to Kumhwa on the same day. The entire division was placed in Kumhwa by 14 June 1950.[6] By 23 June 1950, all KPA forces involved in the invasion were positioned around the 38th Parallel.[3]  On 18 June the Ministry of People's Defense sent Reconnaissance Order Number 1 (정찰명령 제1호) to division commanders to gather information about locations of the ROKA forces and terrain. On 22 June after completion of reconnaissance and reorganization and approval from Stalin, Soviet military advisors ordered the Ministry of People's Defense to send Engagement Order Number 1 (전투명령 제1호) to its divisions.[5]  In the meantime, Kim Il-sung informed Stalin that the war would be started on 25 June and Stalin consented to the plan. As scheduled, the KPA began the operation and crossed the 38th Parallel at 04:00 KST on 25 June 1950. When the war began, Kim Il-sung held a governmental emergency meeting and stated the following to the members of the Workers' Party of Korea who did not realize the situation:  Comrades, the forces of traitor Rhee Syngman have crossed the 38th parallel and started a full-scale invasion to challenge our northern republic.[5]  Order of battle Almost the entire forces from both sides were involved in the operation either directly or indirectly. The order is at the beginning stage of the operation, and only the major combatants are listed below.  Democratic People's Republic of Korea Army I Corps 1st Infantry Division 1st Infantry Regiment 2nd Infantry Regiment 3rd Infantry Regiment 3rd Infantry Division 7th Infantry Regiment 8th Infantry Regiment 9th Infantry Regiment 4th Infantry Division 5th Infantry Regiment 16th Infantry Regiment 18th Infantry Regiment 6th Infantry Division 13th Infantry Regiment 14th Infantry Regiment 15th Infantry Regiment II Corps 2nd Infantry Division 5th Infantry Division 10th Infantry Regiment 11th Infantry Regiment 12th Infantry Regiment 7th Infantry Division 8th Infantry Division 81st Infantry Regiment 82nd Infantry Regiment 83rd Infantry Regiment 15th Infantry Division 48th Infantry Regiment 49th Infantry Regiment 50th Infantry Regiment 9th Infantry Division 10th Infantry Division 13th Infantry Division 105th Armored Brigade 107th Armored Regiment 109th Armored Regiment 203rd Armored Regiment 206th Mechanized Regiment 549th Infantry Regiment 766th Infantry Regiment 38th Parallel Guard 1st Guard Brigade 3rd Guard Brigade Republic of Korea Army Capital Division 3rd Infantry Regiment 18th Infantry Regiment 1st Infantry Division 11th Infantry Regiment 12th Infantry Regiment 13th Infantry Regiment 2nd Infantry Division 5th Infantry Regiment 16th Infantry Regiment 25th Infantry Regiment 3rd Infantry Division 18th Infantry Regiment 22nd Infantry Regiment 23rd Infantry Regiment 5th Infantry Division 15th Infantry Regiment 20th Infantry Regiment 6th Infantry Division 2nd Infantry Regiment 7th Infantry Regiment 19th Infantry Regiment 7th Infantry Division 1st Infantry Regiment 9th Infantry Regiment 8th Infantry Division 10th Infantry Regiment 21st Infantry Regiment 17th Infantry Regiment Controversy over origins of battle There have been conflicting accounts regarding the opening phases of the battle from sources on both sides. This resulted in discrepancies about which army initiated military action on 25 June 1950.[7]  A report on behalf of the United Nations Commission on Korea was submitted on 24 June 1950 by two Australian military observers, Major F. S. B. Peach and Squadron Leader R. J. Rankin.[8] The report made claim that ROK forces were organised entirely for defence and were in no condition to carry out an attack on a large scale against the forces of the north.[9] The inadequate resources of the ROKA, in particular the absence of armor, air support and heavy artillery, rendered a South Korean invasion of the North militarily impossible. At 17:00 on 25 June the field observers had reported that North Korean forces had that morning mounted a surprise attack all along the 38th Parallel.[9]  However, Kim Il Sung had claimed in a broadcast made on 26 June at 09:20 that South Korea had attacked the north in the section of Haeju, provoking counterattacks.[7] In the light of the report by Peach and Rankin, UNCOK unanimously rejected the North Korean contention. There remains undisclosed information from the Soviet and North Korean side.[7]  Battle On 24 June 1950, the North Korean forces were ordered in their starting positions by 24:00.[6]  On 25 June Washington received a report at 10:00 detailing that North Korean forces has invaded the south across several locations that morning. The report claimed combat was initiated at 04:40 when Ongjin was hit by North Korean artillery fire.[10] Individual KPA units advanced 3 to 5 kilometres into South Korean territory within the first three hours.[6] The ROKA put up a strong resistance in the direction of Ongjin, Kaizin and Seoul. Osin, Kaesong and Sinyuri were captured on the first day.[10] KPA forces advanced 12 kilometres in the Sunsen direction and 8 kilometres along the eastern coast.[6]  Two amphibious landings occurred on the coast south of Kangnung at 05:25. One landing occurred in the Korio region and consisted of two battalions of naval infantry and 1,000 partisans. The other landing occurred in the Urutsyn area and consisted of 600 partisans.[6] The city of Urutsyn was captured. The South Korean military engaged the North Korean warships but the landings were successful.[6]  The KPA invasion was spearheaded by Soviet manufactured T-34 medium, diesel-fuelled tanks that could operate at up to thirty kilometres an hour. The T-34 was equipped with high-velocity 85 mm guns and was lined with medium armour.[11] The armor proved nearly impregnable to the ill-equipped ROKA which lacked tanks and antitank guns capable of penetrating the T-34's armor. The T-34 weighed 29 tons, making it light enough to withstand limits on Korean railroads due to bridge capacities being thirty tons.[6][11] Air support was provided 150 Soviet manufactured Yakovlev Yak-9 fighters, Ilyushin Il-10 attack bombers and Yakovlev Yak-11 trainer aircraft.[11] The aircraft utilised blitzkrieg warfare strategy and bombarded Seoul and strategic locations.[11]  The battle continued on 26 June with further advances by KPA forces into South Korea.The Kaisan and Ongjin peninsula were cleared. The 1st and 4th Divisions captured Tongducheb and Bunsan. The 2nd Division took Siunseen. The 6th Division crossed the bay and captured the point in the direction of Kimpo Airfield. The forces from the amphibious landings advanced and had taken the port of Tubuiri.[6] The main force advanced through the Uijeongbu corridor towards Seoul.[11]  The South Korean forces did not have enough aircraft or tanks to counter the invasion.[10] A significant portion of the South Korean forces, numbering 65,000 combat troops and 33,000 support troops, began deserting.[11] On 28 June ROK forces demolished the Hangang Bridge in an attempt to slow the KPA invasion.[8] The demolition resulted in South Korean refugee casualties and stranded the ROKA 5th Division. KPA forces were able to cross the river later that day and occupy Seoul.[8]  North Korean command during battle A Soviet report made during the invasion highlighted the inadequacies in KPA operations. Communication within the KPA was inefficient. The general staff did not direct battle, since from the beginning of the forward advance staff communication was weak. The unit commanders did not receive commands from senior staff. The report stated that the KPA command did not have battle experience. Once Soviet military advisers withdrew the battle was poorly commanded. The directed use of tanks and artillery in battle was tactically unsound. However, the KPA soldiers were enthusiastic and dedicated to completing their role. The people of North Korea also responded positively to the news of the invasion. They had a strong belief in the North Korean government and the KPA.[6]  Propaganda In the United States, the invasion was reported in mainstream media as an act of aggression by North Korea. The event also became an additional source of political division during the Cold War period. An article from The New York Times (27 June 1950) headlined U.S. Blames Russia[12] describes the event as an “act of aggression”, “lawless” and "an invasion of the American-sponsored republic as another threat by Russia into a soft spot of the free countries.” It also claimed “the [US] Administration held Soviet Union responsible as the motivating power behind the North Korean government.”  The official North Korean history of the Korean War describes the battle under the title ‘Outstanding and Brilliant Victory’, and claims that the battle was an anti-imperialist defence measure against the “enemies of the people” [US]. The United States imperialists had successfully overtaken South Korean. The United States prompted the South Korean forces to launch a surprise armed invasion of the DPRK at dawn on 25 June 1950. Over 100,000 South Korean soldiers attacked, penetrating two kilometres into Northern Korea territory. The aim was to conquer the [North] Korean people. The report refers to the South Korean troops as “puppets” of the “aggressive, imperialist” United States and that the “country and people were faced with a grave danger.”[13]  Aftermath On 30 June President of the United States Harry S. Truman released a statement that indicated the invasion of South Korea had grown the threat of Communism to the Pacific area and the United States. In response to the invasion, Truman ordered United States provide assistance with air and land forces in Korea. Moreover, Truman ordered the United States Seventh Fleet to prevent any attack on Formosa and strengthened the United States forces in the Philippines.[14]  As a result of North Korea's invasion, the United Nations Security Council (UNSC) passed United Nations Security Council Resolution 84. The Resolution authorised the use of the UN flag in operations against North Korean forces and those nations partaking. The UNSC provided a recommendation to members to provide assistance to the Republic of Korea in repelling the North Korean attack and restoring worldwide peace and security.[15]  References  "전쟁 직전 남˙북한의 전력 차이는?" (PDF). Republic of Korea Ministry of National Defense.  "준비된 도발". Republic of Korea Ministry of National Defense. Archived from the original on 2015-07-24. Retrieved 2011-11-18.  Weathersby, Kathryn (1993). "The Soviet Role in the Early Phase of the Korean War: New Documentary Evidence". The Journal of American-East Asian Relations. 2 (4): 425–458. doi:10.1163/187656193X00149 – via JSTOR.  Kim, Youngho (1999). "The origins of the Korean War: Civil war or Stalin's Rollback?". Diplomacy & Statecraft. 10 (1): 186–214. doi:10.1080/09592299908406115. ISSN 0959-2296.  "북한군의 남침 전투명령은 어떻게 하달됐는가?" (PDF). Republic of Korea Ministry of National Defense. Archived from the original (PDF) on 2012-04-05.  "Top Secret Report on the Military Situation in South Korea from Shtykov to Comrade Zakharov." (26 June 1950)". History and Public Policy Program Digital Archive, Collection of Soviet military documents obtained in 1994 by the British Broadcasting Corporation for a BBC TimeWatch documentary titled “Korea, Russia’s Secret War” (January 1996). 26 June 1950.  Lowe, Peter (1981). The origins of the Korean War (Second ed.). Routledge. ISBN 978-1-315-84312-4. OCLC 889272377.  Johnston, William (2008). A War of Patrols. UBC Press. ISBN 978-0-7748-5054-4. OCLC 923440696.  O'Neill, Robert (1981). Australia in the Korean War 1950-53. Australian War Memorial and the Australian Government Publishing Service. ISBN 0-642-04329-9. OCLC 8475749.  Cumings, Bruce (2002). The origins of the Korean War. Seoul, Korea: Yuksabipyungsa. ISBN 89-7696-613-9. OCLC 56572103.  Keene, R (2010-06-01). "The Korean War: It Started On A Sunday in June". The Leatherneck. 93: 18–22.  Special To The New York Times (1950-06-25). "U.S BLAMES RUSSIA". The New York Times.  Pictorial, Korea (1993). Outstanding Leadership and Brilliant Victory (Excerpts). North Korea International Documentation Project (NKIDP).  "Statement by the President, Truman on Korea". History and Public Policy Program Digital Archive, Public Papers of the Presidents, Harry S. Truman, 1945-1953. 27 June 1950.  "United Nations Security Council Resolution 84". History and Public Policy Program Digital Archive, United Nations. Department of Public Information. 5 July 1950. Categories: Military operations of the Korean WarJune 1950 eventsJuly 1950 events1950 in Korea1950 in military history Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadEditView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version  Languages Español 한국어 Bahasa Indonesia Português Русский Srpskohrvatski / српскохрватски Edit links This page was last edited on 27 September 2021, at 13:39 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki  United Nations Security Council From Wikipedia, the free encyclopedia Jump to navigationJump to search "Security Council" and "UNSC" redirect here. For other uses, see Security Council (disambiguation) and UNSC (disambiguation). United Nations Security Council Emblem of the United Nations.svg UN-Sicherheitsrat - UN Security Council - New York City - 2014 01 06.jpg UN Security Council Chamber in New York Abbreviation	UNSC Formation	24 October 1945 Type	Principal organ Legal status	Active Membership	15 countries ‍ Permanent members:  China  France  Russia  United Kingdom  United States ‍ Non-permanent members:  Estonia  India  Ireland  Kenya  Mexico  Niger  Norway  Saint Vincent and the Grenadines  Tunisia  Vietnam Website	un.org/securitycouncil Principal organs of the United Nations System Emblem of the United Nations.svg Secretariat Secretary-General Selection · Headquarters General Assembly President · Member countries Representatives · Resolution · Groups International Court of Justice President · Judges Jurisdiction · Cases · Headquarters Security Council Presidency · Members · Elections Resolution · List of resolutions · Veto Economic and Social Council President · Members Commissions · Committees · Agencies Trusteeship Council Trust territories Non-self-governing territories Website · Wikisource United Nations Charter vte The United Nations Security Council (UNSC) is one of the six principal organs of the United Nations (UN),[1] charged with ensuring international peace and security,[2] recommending the admission of new UN members to the General Assembly,[3] and approving any changes to the UN Charter.[4] Its powers include establishing peacekeeping operations, enacting international sanctions, and authorizing military action. The UNSC is the only UN body with the authority to issue binding resolutions on member states.  Like the UN as a whole, the Security Council was created after World War II to address the failings of the League of Nations in maintaining world peace. It held its first session on 17 January 1946, and in the ensuing decades was largely paralyzed by the Cold War between the United States and the Soviet Union and their respective allies. Nevertheless, it authorized military interventions in the Korean War and the Congo Crisis and peacekeeping missions in the Suez Crisis, Cyprus, and West New Guinea. With the collapse of the Soviet Union, UN peacekeeping efforts increased dramatically in scale, with the Security Council authorizing major military and peacekeeping missions in Kuwait, Namibia, Cambodia, Bosnia and Herzegovina, Rwanda, Somalia, Sudan, and the Democratic Republic of the Congo.  The Security Council consists of fifteen members, of which five are permanent:[5] the People’s Republic of China, the French Republic, the Russian Federation, the United Kingdom of Great Britain and Northern Ireland, and the United States of America. These were the great powers, or their successor states, that were the victors of World War II. Permanent members can veto any substantive resolution, including those on the admission of new member states to the United Nations or nominees for the office of Secretary-General. The remaining ten members are elected on a regional basis to serve a term of two years. The body's presidency rotates monthly among its members.  Resolutions of the Security Council are typically enforced by UN peacekeepers, military forces voluntarily provided by member states and funded independently of the main UN budget. As of March 2019, there are thirteen peacekeeping missions with over 81,000 personnel from 121 countries, with a total budget of nearly $6.7 billion.[6]   Contents 1	History 1.1	Background and creation 1.2	Cold War 1.3	Post-Cold War 2	Role 3	Members 3.1	Permanent members 3.1.1	Veto power 3.2	Non-permanent members 3.3	President 4	Meeting locations 4.1	Consultation room 5	Subsidiary organs/bodies 6	United Nations peacekeepers 7	Criticism and evaluations 8	Membership reform 9	See also 10	Notes 11	References 11.1	Citations 11.2	Sources 12	Further reading 13	External links History Background and creation Further information: History of the United Nations In the century prior to the UN's creation, several international treaty organizations and conferences had been formed to regulate conflicts between nations, such as the International Committee of the Red Cross and the Hague Conventions of 1899 and 1907.[7] Following the catastrophic loss of life in World War I, the Paris Peace Conference established the League of Nations to maintain harmony between the nations.[8] This organization successfully resolved some territorial disputes and created international structures for areas such as postal mail, aviation, and opium control, some of which would later be absorbed into the UN.[9] However, the League lacked representation for colonial peoples (then half the world's population) and significant participation from several major powers, including the US, the USSR, Germany, and Japan; it failed to act against the 1931 Japanese invasion of Manchuria, the Second Italo-Ethiopian War in 1935, the 1937 Japanese occupation of China, and Nazi expansions under Adolf Hitler that escalated into World War II.[10]   Chiang Kai-shek, Franklin D. Roosevelt, and Winston Churchill met at the Cairo Conference in 1943 during World War II.  British Prime Minister Winston Churchill, US President Franklin D. Roosevelt, and Soviet general secretary Joseph Stalin at the Yalta Conference, February 1945 On New Year's Day 1942, President Roosevelt, Prime Minister Churchill, Maxim Litvinov, of the USSR, and T. V. Soong, of the Republic of China, signed a short document, based on the Atlantic Charter and the London Declaration,[11][12] which later came to be known as the United Nations Declaration. The next day the representatives of twenty-two other nations added their signatures."[13] The term United Nations was first officially used when 26 governments signed this Declaration. By 1 March 1945, 21 additional states had signed.[14] "Four Powers" was coined to refer to the four major Allied countries: the United States, the United Kingdom, the Soviet Union, and the Republic of China.[15] and became the foundation of an executive branch of the United Nations, the Security Council.[16]  Following the 1943 Moscow Conference and Tehran Conference, in mid-1944, the delegations from the Allied "Big Four", the Soviet Union, the UK, the US and the Republic of China, met for the Dumbarton Oaks Conference in Washington, D.C. to negotiate the UN's structure,[17] and the composition of the UN Security Council quickly became the dominant issue. France, the Republic of China, the Soviet Union, the UK, and US were selected as permanent members of the Security Council; the US attempted to add Brazil as a sixth member but was opposed by the heads of the Soviet and British delegations.[18] The most contentious issue at Dumbarton and in successive talks proved to be the veto rights of permanent members. The Soviet delegation argued that each nation should have an absolute veto that could block matters from even being discussed, while the British argued that nations should not be able to veto resolutions on disputes to which they were a party. At the Yalta Conference of February 1945, the American, British, and Russian delegations agreed that each of the "Big Five" could veto any action by the council, but not procedural resolutions, meaning that the permanent members could not prevent debate on a resolution.[19]  On 25 April 1945, the UN Conference on International Organization began in San Francisco, attended by 50 governments and a number of non-governmental organizations involved in drafting the United Nations Charter.[20] At the conference, H. V. Evatt of the Australian delegation pushed to further restrict the veto power of Security Council permanent members.[21] Due to the fear that rejecting the strong veto would cause the conference's failure, his proposal was defeated twenty votes to ten.[22]  The UN officially came into existence on 24 October 1945 upon ratification of the Charter by the five then-permanent members of the Security Council and by a majority of the other 46 signatories.[20] On 17 January 1946, the Security Council met for the first time at Church House, Westminster, in London, United Kingdom.[23]  Cold War  Church House in London where the first Security Council Meeting took place on 17 January 1946 The Security Council was largely paralyzed in its early decades by the Cold War between the US and USSR and their allies, and the Council generally was only able to intervene in unrelated conflicts.[24] (A notable exception was the 1950 Security Council resolution authorizing a US-led coalition to repel the North Korean invasion of South Korea, passed in the absence of the USSR.)[20][25] In 1956, the first UN peacekeeping force was established to end the Suez Crisis;[20] however, the UN was unable to intervene against the USSR's simultaneous invasion of Hungary following that country's revolution.[26] Cold War divisions also paralysed the Security Council's Military Staff Committee, which had been formed by Articles 45–47 of the UN Charter to oversee UN forces and create UN military bases. The committee continued to exist on paper but largely abandoned its work in the mid-1950s.[27][28]  In 1960, the UN deployed the United Nations Operation in the Congo (UNOC), the largest military force of its early decades, to restore order to the breakaway State of Katanga, restoring it to the control of the Democratic Republic of the Congo by 1964.[29] However, the Security Council found itself bypassed in favour of direct negotiations between the superpowers in some of the decade's larger conflicts, such as the Cuban Missile Crisis or the Vietnam War.[30] Focusing instead on smaller conflicts without an immediate Cold War connection, the Security Council deployed the United Nations Temporary Executive Authority in West New Guinea in 1962 and the United Nations Peacekeeping Force in Cyprus in 1964, the latter of which would become one of the UN's longest-running peacekeeping missions.[31][32]  On 25 October 1971, over US opposition, but with the support of many Third World nations, along with the Socialist People's Republic of Albania, the mainland, communist People's Republic of China was given the Chinese seat on the Security Council in place of the Republic of China; the vote was widely seen as a sign of waning US influence in the organization.[33] With an increasing Third World presence and the failure of UN mediation in conflicts in the Middle East, Vietnam, and Kashmir, the UN increasingly shifted its attention to its ostensibly secondary goals of economic development and cultural exchange. By the 1970s, the UN budget for social and economic development was far greater than its budget for peacekeeping.[34]  Post-Cold War  US Secretary of State Colin Powell holds a model vial of anthrax while giving a presentation to the Security Council in February 2003. After the Cold War, the UN saw a radical expansion in its peacekeeping duties, taking on more missions in ten years than it had in its previous four decades.[35] Between 1988 and 2000, the number of adopted Security Council resolutions more than doubled, and the peacekeeping budget increased more than tenfold.[36] The UN negotiated an end to the Salvadoran Civil War, launched a successful peacekeeping mission in Namibia, and oversaw democratic elections in post-apartheid South Africa and post-Khmer Rouge Cambodia.[37] In 1991, the Security Council demonstrated its renewed vigor by condemning the Iraqi invasion of Kuwait on the same day of the attack, and later authorizing a US-led coalition that successfully repulsed the Iraqis.[38] Undersecretary-General Brian Urquhart later described the hopes raised by these successes as a "false renaissance" for the organization, given the more troubled missions that followed.[39]  Though the UN Charter had been written primarily to prevent aggression by one nation against another, in the early 1990s, the UN faced a number of simultaneous, serious crises within nations such as Haiti, Mozambique and the former Yugoslavia.[40] The UN mission to Bosnia faced "worldwide ridicule" for its indecisive and confused mission in the face of ethnic cleansing.[41] In 1994, the United Nations Assistance Mission for Rwanda failed to intervene in the Rwandan genocide in the face of Security Council indecision.[42]  In the late 1990s, UN-authorised international interventions took a wider variety of forms. The UN mission in the 1991–2002 Sierra Leone Civil War was supplemented by British Royal Marines, and the UN-authorised 2001 invasion of Afghanistan was overseen by NATO.[43] In 2003, the US invaded Iraq despite failing to pass a UN Security Council resolution for authorization, prompting a new round of questioning of the organization's effectiveness.[44] In the same decade, the Security Council intervened with peacekeepers in crises including the War in Darfur in Sudan and the Kivu conflict in the Democratic Republic of Congo. In 2013, an internal review of UN actions in the final battles of the Sri Lankan Civil War in 2009 concluded that the organization had suffered "systemic failure".[45] In November/December 2014, Egypt presented a motion proposing an expansion of the NPT (non-Proliferation Treaty), to include Israel and Iran; this proposal was due to increasing hostilities and destruction in the Middle-East connected to the Syrian Conflict as well as others. All members of the Security Council are signatory to the NPT, and all permanent members are nuclear weapons states.[46]  Role Part of a series on the UN Security Council resolutions Emblem of the United Nations.svg Members China · France · Russia United Kingdom · United States Non-permanent members Resolutions 1 to 1000           (1946–1995) 1 to 100 (1946–1953) 101 to 200 (1953–1965) 201 to 300 (1965–1971) 301 to 400 (1971–1976) 401 to 500 (1976–1982) 501 to 600 (1982–1987) 601 to 700 (1987–1991) 701 to 800 (1991–1993) 801 to 900 (1993–1994) 901 to 1000 (1994–1995) Resolutions 1001 to 2000           (1995–2011) 1001 to 1100 (1995–1997) 1101 to 1200 (1997–1998) 1201 to 1300 (1998–2000) 1301 to 1400 (2000–2002) 1401 to 1500 (2002–2003) 1501 to 1600 (2003–2005) 1601 to 1700 (2005–2006) 1701 to 1800 (2006–2008) 1801 to 1900 (2008–2009) 1901 to 2000 (2009–2011) Resolutions 2001 to 3000           (2011–present) 2001 to 2100 (2011–2013) 2101 to 2200 (2013–2015) 2201 to 2300 (2015–2016) 2301 to 2400 (2016–2018) 2401 to 2500 (2018–2019) 2501 to 2600 (2019–present) Vetoed resolutions List of vetoes · Power of veto UN Security Council UNBISnet · Wikisource vte The UN's role in international collective security is defined by the UN Charter, which authorizes the Security Council to investigate any situation threatening international peace; recommend procedures for peaceful resolution of a dispute; call upon other member nations to completely or partially interrupt economic relations as well as sea, air, postal, and radio communications, or to sever diplomatic relations; and enforce its decisions militarily, or by any means necessary. The Security Council also recommends the new Secretary-General to the General Assembly and recommends new states for admission as member states of the United Nations.[47][48] The Security Council has traditionally interpreted its mandate as covering only military security, though US Ambassador Richard Holbrooke controversially persuaded the body to pass a resolution on HIV/AIDS in Africa in 2000.[49]  Under Chapter VI of the Charter, "Pacific Settlement of Disputes", the Security Council "may investigate any dispute, or any situation which might lead to international friction or give rise to a dispute". The Council may "recommend appropriate procedures or methods of adjustment" if it determines that the situation might endanger international peace and security.[50] These recommendations are generally considered to not be binding, as they lack an enforcement mechanism.[51] A minority of scholars, such as Stephen Zunes, have argued that resolutions made under Chapter VI are "still directives by the Security Council and differ only in that they do not have the same stringent enforcement options, such as the use of military force".[52]  Under Chapter VII, the council has broader power to decide what measures are to be taken in situations involving "threats to the peace, breaches of the peace, or acts of aggression."[28] In such situations, the council is not limited to recommendations but may take action, including the use of armed force "to maintain or restore international peace and security."[28] This was the legal basis for UN armed action in Korea in 1950 during the Korean War and the use of coalition forces in Iraq and Kuwait in 1991 and Libya in 2011.[53][54] Decisions taken under Chapter VII, such as economic sanctions, are binding on UN members; the Security Council is the only UN body with authority to issue binding resolutions.[55][56]  The Rome Statute of the International Criminal Court recognizes that the Security Council has authority to refer cases to the Court in which the Court could not otherwise exercise jurisdiction.[57] The Council exercised this power for the first time in March 2005, when it referred to the Court "the situation prevailing in Darfur since 1 July 2002"; since Sudan is not a party to the Rome Statute, the Court could not otherwise have exercised jurisdiction.[58][59] The Security Council made its second such referral in February 2011 when it asked the ICC to investigate the Libyan government's violent response to the Libyan Civil War.[60]  Security Council Resolution 1674, adopted on 28 April 2006, "reaffirms the provisions of paragraphs 138 and 139 of the 2005 World Summit Outcome Document regarding the responsibility to protect populations from genocide, war crimes, ethnic cleansing and crimes against humanity".[61] The Security Council reaffirmed this responsibility to protect in Resolution 1706 on 31 August of that year.[62] These resolutions commit the Security Council to protect civilians in an armed conflict, including taking action against genocide, war crimes, ethnic cleansing, and crimes against humanity.[63]  Members Permanent members Main article: Permanent members of the United Nations Security Council See also: China and the United Nations, France and the United Nations, Russia and the United Nations, Soviet Union and the United Nations, United Kingdom and the United Nations, and United States and the United Nations The Security Council's five permanent members, below, have the power to veto any substantive resolution; this allows a permanent member to block adoption of a resolution, but not to prevent or end debate.[64]  Country	Regional group	Current state representation	Former state representation  China	Asia-Pacific	China People's Republic of China	Taiwan Republic of China (1945–1971)  France	Western Europe and Others	France French Fifth Republic	France Provisional Government (1945–1946) France French Fourth Republic (1946–1958)  Russia	Eastern Europe	Russia Russian Federation	Soviet Union Union of Soviet Socialist Republics (1945–1991)  United Kingdom	Western Europe and Others	United Kingdom United Kingdom of Great Britain and Northern Ireland	N/A  United States	Western Europe and Others	United States United States of America	N/A At the UN's founding in 1945, the five permanent members of the Security Council were the Republic of China, the Provisional Government of the French Republic, the Soviet Union, the United Kingdom, and the United States. There have been two major seat changes since then. China's seat was originally held by Chiang Kai-shek's Nationalist Government, the Republic of China. However, the Nationalists were forced to retreat to the island of Taiwan in 1949, during the Chinese Civil War. The Chinese Communist Party assumed control of mainland China, thenceforth known as the People's Republic of China. In 1971, General Assembly Resolution 2758 recognized the People's Republic as the rightful representative of China in the UN and gave it the seat on the Security Council that had been held by the Republic of China, which was expelled from the UN altogether with no opportunity for membership as a separate nation.[33] After the dissolution of the Soviet Union in 1991, the Russian Federation was recognized as the legal successor state of the Soviet Union and maintained the latter's position on the Security Council.[65] Additionally, France eventually reformed its government into the French Fifth Republic in 1958, under the leadership of Charles de Gaulle. France maintained its seat as there was no change in its international status or recognition, although many of its overseas possessions eventually became independent.[66]  The five permanent members of the Security Council were the victorious powers in World War II[67] and have maintained the world's most powerful military forces ever since. They annually topped the list of countries with the highest military expenditures.[68] In 2013, they spent over US$1 trillion combined on defence, accounting for over 55% of global military expenditures (the US alone accounting for over 35%).[68] They are also among the world's largest arms exporters[69] and are the only nations officially recognized as "nuclear-weapon states" under the Nuclear Non-Proliferation Treaty (NPT), though there are other states known or believed to be in possession of nuclear weapons.[70]  Veto power Main article: United Nations Security Council veto power See also: List of vetoed United Nations Security Council resolutions Number of resolutions vetoed by each of the five permanent members of the Security Council from 1946 until present.[71]v • t • e Under Article 27 of the UN Charter, Security Council decisions on all substantive matters require the affirmative votes of three-fifths (i.e. nine) of the members. A negative vote or "veto" by a permanent member prevents adoption of a proposal, even if it has received the required votes.[64] Abstention is not regarded as a veto in most cases, though all five permanent members must actively concur to amend the UN Charter or to recommend the admission of a new UN member state.[55] Procedural matters are not subject to a veto, so the veto cannot be used to avoid discussion of an issue. The same holds for certain decisions that directly regard permanent members.[64] A majority of vetoes are used not in critical international security situations, but for purposes such as blocking a candidate for Secretary-General or the admission of a member state.[72]  In the negotiations building up to the creation of the UN, the veto power was resented by many small countries, and in fact was forced on them by the veto nations—United States, United Kingdom, China, France and Soviet Union—through a threat that without the veto there will be no UN. Here is a description by Francis O. Wilcox, an adviser to U.S. delegation to the 1945 conference:  "At San Francisco, the issue was made crystal clear by the leaders of the Big Five: it was either the Charter with the veto or no Charter at all. Senator Connally [from the U.S. delegation] dramatically tore up a copy of the Charter during one of his speeches and reminded the small states that they would be guilty of that same act if they opposed the unanimity principle. 'You may, if you wish,' he said, 'go home from this Conference and say that you have defeated the veto. But what will be your answer when you are asked: "Where is the Charter"?'"[73]  As of 2012, 269 vetoes had been cast since the Security Council's inception.[a] In this period, China used the veto 9 times, France 18, the Soviet Union or Russia 128, the United Kingdom 32, and the United States 89. Roughly two-thirds of Soviet and Russian combined vetoes were in the first ten years of the Security Council's existence. Between 1996 and 2012, the United States vetoed 13 resolutions, Russia 7, and China 5, while France and the United Kingdom did not use the veto.[72]  An early veto by Soviet Commissar Andrei Vishinsky blocked a resolution on the withdrawal of French forces from the then-colonies of Syria and Lebanon in February 1946; this veto established the precedent that permanent members could use the veto on matters outside of immediate concerns of war and peace. The Soviet Union went on to veto matters including the admission of Austria, Cambodia, Ceylon, Finland, Ireland, Italy, Japan, Laos, Libya, Portugal, South Vietnam, and Transjordan as UN member states, delaying their joining by several years. The United Kingdom and France used the veto to avoid Security Council condemnation of their actions in the 1956 Suez Crisis. The first veto by the United States came in 1970, blocking General Assembly action in Southern Rhodesia. From 1985 to 1990, the U.S. vetoed 27 resolutions, primarily to block resolutions perceived as anti-Israel but also to protect its interests in Panama and Korea. The Soviet Union, the United States, and China have all vetoed candidates for Secretary-General, with the U.S. using the veto to block the re-election of Boutros Boutros-Ghali in 1996.[74]  Non-permanent members See also: List of members of the United Nations Security Council, United Nations Security Council elections, 2019, and 2020  A chart representing the Security Council seats held by each of the regional groups. The United States, a WEOG observer, is treated as if it were a full member. This is not how the seats are arranged in actual meetings.   African Group   Asia-Pacific Group   Eastern European Group   Group of Latin American and Caribbean States (GRULAC)   Western European and Others Group (WEOG) Along with the five permanent members, the Security Council of the United Nations has temporary members that hold their seats on a rotating basis by geographic region. Non-permanent members may be involved in global security briefings.[75] In its first two decades, the Security Council had six non-permanent members, the first of which were Australia, Brazil, Egypt, Mexico, the Netherlands, and Poland. In 1965, the number of non-permanent members was expanded to ten.[76]  These ten non-permanent members are elected by the United Nations General Assembly for two-year terms starting on 1 January, with five replaced each year.[77] To be approved, a candidate must receive at least two-thirds of all votes cast for that seat, which can result in deadlock if there are two roughly evenly matched candidates. In 1979, a standoff between Cuba and Colombia only ended after three months and a record 154 rounds of voting; both eventually withdrew in favour of Mexico as a compromise candidate.[78] A retiring member is not eligible for immediate re-election.[79]  The African Group is represented by three members; the Latin America and the Caribbean, Asia-Pacific, and Western European and Others groups by two apiece; and the Eastern European Group by one. Traditionally, one of the seats assigned to either the Asia-Pacific Group or the African Group is filled by a nation from the Arab world, alternating between the groups.[80] Currently, elections for terms beginning in even-numbered years select two African members, and one each within Eastern Europe, Asia-Pacific, and Latin America and the Caribbean; the traditional "Arab seat" is elected for this term. Terms beginning in odd-numbered years consist of two Western European and Other members, and one each from Asia-Pacific, Africa, and Latin America and the Caribbean.[78]  During the 2016 United Nations Security Council election, neither Italy nor the Netherlands met the required two-thirds majority for election. They subsequently agreed to split the term of the Western European and Others Group. It was the first time in over five decades that two members agreed to do so.[81] Usually, intractable deadlocks are resolved by the candidate countries withdrawing in favour of a third member state.  The current elected members, with the regions they were elected to represent, are as follows:[82][83][84][85][86]  Term	Africa	Asia-Pacific	Eastern Europe	Latin America and Caribbean	Western Europe and Other 2020	 Niger	 Tunisia		 Vietnam		 Estonia	 Saint Vincent and the Grenadines			 2021	 Kenya	 India	 Mexico	 Ireland	 Norway 2022					 President Main article: President of the United Nations Security Council  United Nations Security Council by political international per country's head of government. Dark red: International Meeting of Communist and Workers' Parties Red: Progressive Alliance Yellow: Liberal International Blue: International Democrat Union Gray: No international affiliation or independent. The role of president of the Security Council involves setting the agenda, presiding at its meetings and overseeing any crisis. The president is authorized to issue both Presidential Statements (subject to consensus among Council members) and notes,[87][88] which are used to make declarations of intent that the full Security Council can then pursue.[88] The presidency of the council is held by each of the members in turn for one month, following the English alphabetical order of the member states' names.[89]  The list of nations that will hold the Presidency in 2021 is as follows:[90]  Presidency in 2021 Month	Country January	 Tunisia February	 United Kingdom March	 United States April	 Vietnam May	 China June	 Estonia July	 France August	 India September	 Ireland October	 Kenya November	 Mexico December	 Niger Meeting locations  US President Barack Obama chairs a United Nations Security Council meeting.  The meeting room exhibits the United Nations Security Council mural by Per Krohg (1952). Unlike the General Assembly, the Security Council meets year-round. Each Security Council member must have a representative available at UN Headquarters at all times in case an emergency meeting becomes necessary.[91]  The Security Council generally meets in a designated chamber in the United Nations Conference Building in New York City. The chamber was designed by the Norwegian architect Arnstein Arneberg and was a gift from Norway. The United Nations Security Council mural by Norwegian artist Per Krohg (1952) depicts a phoenix rising from its ashes, symbolic of the world's rebirth after World War II.[92]  The Security Council has also held meetings in cities including Nairobi, Kenya; Addis Ababa, Ethiopia; Panama City, Panama; and Geneva, Switzerland.[91] In March 2010, the Security Council moved into a temporary facility in the General Assembly Building as its chamber underwent renovations as part of the UN Capital Master Plan.[93] The renovations were funded by Norway, the chamber's original donor, for a total cost of US$5 million.[94] The chamber reopened on 16 April 2013.[95]  Consultation room Because meetings in the Security Council Chamber are covered by the international press, proceedings are highly theatrical in nature. Delegates deliver speeches to justify their positions and attack their opponents, playing to the cameras and the audience at home. Delegations also stage walkouts to express their disagreement with actions of the Security Council.[96] Due to the public scrutiny of the Security Council Chamber,[97] all of the real work of the Security Council is conducted behind closed doors in "informal consultations".[98][99]  In 1978, West Germany funded the construction of a conference room next to the Security Council Chamber. The room was used for "informal consultations", which soon became the primary meeting format for the Security Council. In 1994, the French ambassador complained to the Secretary-General that "informal consultations have become the Council's characteristic working method, while public meetings, originally the norm, are increasingly rare and increasingly devoid of content: everyone knows that when the Council goes into public meeting everything has been decided in advance".[100] When Russia funded the renovation of the consultation room in 2013, the Russian ambassador called it "quite simply, the most fascinating place in the entire diplomatic universe".[101]  Only members of the Security Council are permitted in the conference room for consultations. The press is not admitted, and other members of the United Nations cannot be invited into the consultations.[102] No formal record is kept of the informal consultations.[103][104] As a result, the delegations can negotiate with each other in secret, striking deals and compromises without having their every word transcribed into the permanent record. The privacy of the conference room also makes it possible for the delegates to deal with each other in a friendly manner. In one early consultation, a new delegate from a Communist nation began a propaganda attack on the United States, only to be told by the Soviet delegate, "We don't talk that way in here."[99]  A permanent member can cast a "pocket veto" during the informal consultation by declaring its opposition to a measure. Since a veto would prevent the resolution from being passed, the sponsor will usually refrain from putting the resolution to a vote. Resolutions are vetoed only if the sponsor feels so strongly about a measure that it wishes to force the permanent member to cast a formal veto.[98][105] By the time a resolution reaches the Security Council Chamber, it has already been discussed, debated, and amended in the consultations. The open meeting of the Security Council is merely a public ratification of a decision that has already been reached in private.[106][98] For example, Resolution 1373 was adopted without public debate in a meeting that lasted just five minutes.[98][107]  The Security Council holds far more consultations than public meetings. In 2012, the Security Council held 160 consultations, 16 private meetings, and 9 public meetings. In times of crisis, the Security Council still meets primarily in consultations, but it also holds more public meetings. After the outbreak of the Ukraine crisis in 2013, the Security Council returned to the patterns of the Cold War, as Russia and the Western countries engaged in verbal duels in front of the television cameras. In 2016, the Security Council held 150 consultations, 19 private meetings, and 68 public meetings.[108]  Subsidiary organs/bodies Article 29 of the Charter provides that the Security Council can establish subsidiary bodies in order to perform its functions. This authority is also reflected in Rule 28 of the Provisional Rules of Procedure. The subsidiary bodies established by the Security Council are extremely heterogenous. On the one hand, they include bodies such as the Security Council Committee on Admission of New Members. On the other hand, both the International Criminal Tribunal for the former Yugoslavia and the International Criminal Tribunal for Rwanda were also created as subsidiary bodies of the Security Council. The by now numerous Sanctions Committees established in order to oversee implementation of the various sanctions regimes are also subsidiary bodies of the council.  United Nations peacekeepers Main articles: United Nations peacekeeping and List of United Nations peacekeeping missions After approval by the Security Council, the UN may send peacekeepers to regions where armed conflict has recently ceased or paused to enforce the terms of peace agreements and to discourage combatants from resuming hostilities. Since the UN does not maintain its own military, peacekeeping forces are voluntarily provided by member states. These soldiers are sometimes nicknamed "Blue Helmets" for their distinctive gear.[109][110] The peacekeeping force as a whole received the Nobel Peace Prize in 1988.[111]   South African soldiers patrolling as part of MONUSCO in 2018 In September 2013, the UN had 116,837 peacekeeping soldiers and other personnel deployed on 15 missions. The largest was the United Nations Organization Stabilization Mission in the Democratic Republic of the Congo (MONUSCO), which included 20,688 uniformed personnel. The smallest, United Nations Military Observer Group in India and Pakistan (UNMOGIP), included 42 uniformed personnel responsible for monitoring the ceasefire in Jammu and Kashmir. Peacekeepers with the United Nations Truce Supervision Organization (UNTSO) have been stationed in the Middle East since 1948, the longest-running active peacekeeping mission.[112]  UN peacekeepers have also drawn criticism in several postings. Peacekeepers have been accused of child rape, soliciting prostitutes, or sexual abuse during various peacekeeping missions in the Democratic Republic of the Congo,[113] Haiti,[114] Liberia,[115] Sudan and what is now South Sudan,[116] Burundi and Ivory Coast.[117] Scientists cited UN peacekeepers from Nepal as the likely source of the 2010–2013 Haiti cholera outbreak, which killed more than 8,000 Haitians following the 2010 Haiti earthquake.[118]  The budget for peacekeeping is assessed separately from the main UN organisational budget; in the 2013–2014 fiscal year, peacekeeping expenditures totalled $7.54 billion.[112][119] UN peace operations are funded by assessments, using a formula derived from the regular funding scale, but including a weighted surcharge for the five permanent Security Council members. This surcharge serves to offset discounted peacekeeping assessment rates for less developed countries. In 2020, the top 10 providers of assessed financial contributions to United Nations peacekeeping operations were the US (27.89%), China (15.21%), Japan (8.56%), Germany (6.09%), the United Kingdom (5.79%), France (5.61%), Italy (3.30%), Russian Federation (3.04%), Canada (2.73%), and South Korea (2.26%).[120]  Criticism and evaluations Main article: Criticism of the United Nations In examining the first sixty years of the Security Council's existence, British historian Paul Kennedy concludes that "glaring failures had not only accompanied the UN's many achievements, they overshadowed them", identifying the lack of will to prevent ethnic massacres in Bosnia and Rwanda as particular failures.[121] Kennedy attributes the failures to the UN's lack of reliable military resources, writing that "above all, one can conclude that the practice of announcing (through a Security Council resolution) a new peacekeeping mission without ensuring that sufficient armed forces will be available has usually proven to be a recipe for humiliation and disaster".[122]  A 2005 RAND Corporation study found the UN to be successful in two out of three peacekeeping efforts. It compared UN nation-building efforts to those of the United States, and found that seven out of eight UN cases are at peace.[123] Also in 2005, the Human Security Report documented a decline in the number of wars, genocides and human rights abuses since the end of the Cold War, and presented evidence, albeit circumstantial, that international activism – mostly spearheaded by the UN – has been the main cause of the decline in armed conflict since the end of the Cold War.[124]  Scholar Sudhir Chella Rajan argued in 2006 that the five permanent members of the United Nations Security Council, who are all nuclear powers, have created an exclusive nuclear club that predominately addresses the strategic interests and political motives of the permanent members – for example, protecting the oil-rich Kuwaitis in 1991 but poorly protecting resource-poor Rwandans in 1994.[125] Since three of the five permanent members are also European, and four are predominantly white Western nations, the Security Council has been described as a pillar of global apartheid by Titus Alexander, former Chair of Westminster United Nations Association.[126]  The Security Council's effectiveness and relevance is questioned by some because, in most high-profile cases, there are essentially no consequences for violating a Security Council resolution. During the Darfur crisis, Janjaweed militias, allowed by elements of the Sudanese government, committed violence against an indigenous population, killing thousands of civilians. In the Srebrenica massacre, Serbian troops committed genocide against Bosniaks, although Srebrenica had been declared a UN safe area, protected by 400 armed Dutch peacekeepers.[127]  In his 2009 speech, Muammar Gaddafi criticized the Security Council's veto powers and the wars permanent members of the Security Council engaged in.  The UN Charter gives all three powers of the legislative, executive, and judiciary branches to the Security Council.[128]  In his inaugural speech at the 16th Summit of the Non-Aligned Movement in August 2012, Ayatollah Ali Khamenei criticized the United Nations Security Council as having an "illogical, unjust and completely undemocratic structure and mechanism" and called for a complete reform of the body.[129]  The Security Council has been criticized for failure in resolving many conflicts, including Cyprus, Sri Lanka, Syria, Kosovo and the Israeli–Palestinian conflict, reflecting the wider short-comings of the UN. For example; at the 68th Session of the UN General Assembly, New Zealand Prime Minister John Key heavily criticized the UN's inaction on Syria, more than two years after the Syrian civil war began.[130]  There is evidence of bribery on the UNSC. Countries that are elected to the Security Council see a large increase in foreign aid from the US, averaging 59%. They also see an 8% increase in aid from the United Nations, mainly from UNICEF. The increase most strongly correlates to years in which the Security Council addresses issues relevant to the US. There is also evidence of increased foreign aid to elected countries from Japan and Germany. Membership on the UNSC results in reduced economic growth for a given country as compared to non-member countries (3.5% over four years compared to 8.7% for nonmembers). Elected members also experience a reduction in democracy and freedom of the press.[131]  Membership reform Main article: Reform of the United Nations Security Council  The G4 nations: Brazil, Germany, India, Japan  The Uniting for Consensus: Italy, Pakistan, Spain, Canada, Mexico, Argentina, Turkey, South Korea, and others. Proposals to reform the Security Council began with the conference that wrote the UN Charter and have continued to the present day. As British historian Paul Kennedy writes, "Everyone agrees that the present structure is flawed. But consensus on how to fix it remains out of reach."[132]  There has been discussion of increasing the number of permanent members. The countries which have made the strongest demands for permanent seats are Brazil, Germany, India, and Japan. Japan and Germany, the main defeated powers in WWII, had been the UN's second- and third-largest funders respectively before China took over as the second largest funder in recent years, while Brazil and India are two of the largest contributors of troops to UN-mandated peace-keeping missions.  Italy, another main defeated power in WWII and now the UN's sixth-largest funder, leads a movement known as the Uniting for Consensus in opposition to the possible expansion of permanent seats. Core members of the group include Canada, South Korea, Spain, Indonesia, Mexico, Pakistan, Turkey, Argentina and Colombia. Their proposal is to create a new category of seats, still non-permanent, but elected for an extended duration (semi-permanent seats). As far as traditional categories of seats are concerned, the UfC proposal does not imply any change, but only the introduction of small and medium size states among groups eligible for regular seats. This proposal includes even the question of veto, giving a range of options that goes from abolition to limitation of the application of the veto only to Chapter VII matters.  Former UN Secretary-General Kofi Annan asked a team of advisers to come up with recommendations for reforming the United Nations by the end of 2004. One proposed measure is to increase the number of permanent members by five, which, in most proposals, would include Brazil, Germany, India, and Japan (known as the G4 nations), one seat from Africa (most likely between Egypt, Nigeria or South Africa), and/or one seat from the Arab League.[133] On 21 September 2004, the G4 nations issued a joint statement mutually backing each other's claim to permanent status, together with two African countries. Currently the proposal has to be accepted by two-thirds of the General Assembly (128 votes).  The permanent members, each holding the right of veto, announced their positions on Security Council reform reluctantly. The United States has unequivocally supported the permanent membership of Japan and lent its support to India and a small number of additional non-permanent members. The United Kingdom and France essentially supported the G4 position, with the expansion of permanent and non-permanent members and the accession of Germany, Brazil, India and Japan to permanent member status, as well as an increase in the presence by African countries on the council. China has supported the stronger representation of developing countries and firmly opposed Japan's membership.[134]  In 2017, it was reported that the G4 nations were willing temporarily to forgo veto power if granted permanent UNSC seats.[135] In September 2017, U.S. Representatives Ami Bera and Frank Pallone introduced a resolution (H.Res.535) in the US House of Representatives (115th United States Congress), seeking support for India for permanent membership of the United Nations Security Council.[136]  See also icon	Politics portal 	Law portal Reform of the United Nations Small Five Group, a group formed to improve the working methods of the Security Council United Nations Department of Political and Peacebuilding Affairs, provides secretarial support to the Security Council United Nations Security Council Counter-Terrorism Committee, a standing committee of the Security Council Notes  This figure and the figures that follow exclude vetoes cast to block candidates for Secretary-General, as these occur in closed session; 43 such vetoes have occurred.[72] References Citations  "Article 7 (1) of Charter of the United Nations".  "Article 24 (1) of Charter of the United Nations".  "Article 4 (2) of Charter of the United Nations".  "Article 108 of Charter of the United Nations".  "Article 23 (1) of the Charter of the United Nations". www.un.org. United Nations. 26 June 1945. Retrieved 10 December 2018.  "DATA". United Nations Peacekeeping. Retrieved 4 May 2020.  Kennedy 2006, p. 5.  Kennedy 2006, p. 8.  Kennedy 2006, p. 10.  Kennedy 2006, p. 13–24.  United Nations, Dept of Public Information (1986). Everyone's United Nations. UN. p. 5. ISBN 978-92-1-100273-7.  Tandon, Mahesh Prasad; Tandon, Rajesh (1989). Public International Law. Allahabad Law Agency.  "Declaration by United Nations". United Nations. Retrieved 1 July 2015.  Osmańczyk 2004, p. 2445.  Urquhart, Brian. Looking for the Sheriff. New York Review of Books, 16 July 1998. Retrieved 7 June 2019.  Gaddis 2000.  Video: Allies Study Post-War Security Etc. (1944). Universal Newsreel. 1944. Retrieved 28 November 2014.  Meisler 1995, p. 9.  Meisler 1995, pp. 10–13.  "Milestones in United Nations History". Department of Public Information, United Nations. Archived from the original on 11 January 2012. Retrieved 22 November 2013.  Schlesinger 2003, p. 196.  Meisler 1995, pp. 18–19.  "What is the Security Council?". United Nations. Retrieved 15 January 2021.  Meisler 1995, p. 35.  Meisler 1995, pp. 58–59.  Meisler 1995, p. 114.  Kennedy 2006, pp. 38, 55–56.  "Charter of the United Nations: Chapter VII: Action with Respect to Threats to the Peace, Breaches of the Peace, and Acts of Aggression". United Nations. Retrieved 26 November 2013.  Meisler 1995, pp. 115–134.  Kennedy 2006, pp. 61–62.  Meisler 1995, pp. 156–157.  Kennedy 2006, p. 59.  Meisler 1995, pp. 195–197.  Meisler 1995, pp. 167–168, 224–225.  Meisler 1995, p. 286.  Fasulo 2004, p. 43; Meisler 1995, p. 334.  Meisler 1995, pp. 252–256.  Meisler 1995, pp. 264–277.  Meisler 1995, p. 334.  Kennedy 2006, pp. 66–67.  For quotation "worldwide ridicule", see Meisler 1995, p. 293; for description of UN missions in Bosnia, see Meisler 1995, pp. 312–329.  Kennedy 2006, p. 104.  Kennedy 2006, pp. 110–111.  Kennedy 2006, p. 111.  "UN failed during final days of Lankan ethnic war: Ban Ki-moon". FirstPost. Press Trust of India. 25 September 2013. Retrieved 5 November 2013.  "UNODA – Non-Proliferation of Nuclear Weapons (NPT)". United Nations.  "Charter of the United Nations: Chapter II: Membership". United Nations. Retrieved 26 November 2013.  "Charter of the United Nations: Chapter V: The Security Council". United Nations. Retrieved 9 June 2012.  Fasulo 2004, p. 46.  "Charter of the United Nations: Chapter VI: Pacific Settlement of Disputes". United Nations. Retrieved 26 November 2013.  See Fomerand 2009, p. 287; Hillier 1998, p. 568; Köchler 2001, p. 21; Matthews 1993, p. 130; Neuhold 2001, p. 66. For lack of enforcement mechanism, see Magliveras 1999, p. 113.  Zunes 2004, p. 291.  Kennedy 2006, pp. 56–57.  "Security Council Approves 'No-Fly Zone' Over Libya, Authorizing 'All Necessary Measures' to Protect Civilians, by Vote of 10 in Favour with 5 Abasentions". United Nations. 17 March 2011. Retrieved 26 November 2013.  Fomerand 2009, p. 287.  Fasulo 2004, p. 39.  Article 13 of the Rome Statute. United Nations. Retrieved 26 November 2013.  "Security Council Refers Situation in Darfur, Sudan, To Prosecutor of International Criminal Court" (Press release). United Nations Security Council. 31 March 2006. Retrieved 14 March 2007.  Wadhams, Nick (2 April 2005). "Bush relents to allow UN vote on Sudan war crimes". The Sydney Morning Herald. Retrieved 27 November 2013.  Gray-Block, Aaron and Greg Roumeliotis (27 February 2011). "Q+A: How will the world's war crimes court act on Libya?". Reuters. Retrieved 26 November 2013.  "Resolution 1674 (2006)". UN Security Council via Refworld. Retrieved 26 November 2013.  Mikulaschek 2010, p. 20.  Mikulaschek 2010, p. 49.  Fasulo 2004, pp. 40–41.  Blum 1992.  Permanent members of the United Nations Security Council  Kennedy 2006, p. 70.  "SIPRI Military Expenditure Database". Stockholm International Peace Research Institute. Retrieved 26 November 2013.  Nichols, Michelle (27 July 2012). "United Nations fails to agree landmark arms-trade treaty". Reuters. Retrieved 26 November 2013.  Medalia, Jonathan (14 November 1996). "92099: Nuclear Weapons Testing and Negotiation of a Comprehensive Test Ban Treaty". Global Security. Retrieved 26 November 2013.  "Security Council - Veto List". Dag Hammarskjöld Library Research Guide.  "Changing Patterns in the Use of the Veto in The Security Council" (PDF). Global Policy Forum. Retrieved 26 November 2013.  Wilcox 1945.  Kennedy 2006, pp. 52–54.  U.N. Security Council Briefing on the U.S. Air Strike in Syria on YouTube Time  "The UN Security Council". United Nations Foundation. Archived from the original on 20 June 2012. Retrieved 15 May 2012.  "Current Members". United Nations. Retrieved 4 January 2016.  "Special Research Report No. 4Security Council Elections 201121 September 2011". Security Council Report. Archived from the original on 8 June 2012. Retrieved 8 June 2012.  "Charter of the United Nations: Chapter V: The Security Council". United Nations. Retrieved 26 November 2013.  Malone, David (25 October 2003). "Reforming the Security Council: Where Are the Arabs?". The Daily Star. Beirut. Retrieved 3 January 2011.  "General Assembly Elects 4 New Non-permanent Members to Security Council, as Western and Others Group Fails to Fill Final Vacancy". United Nations. Retrieved 9 August 2016.  "Current Members". United Nations. Retrieved 1 January 2020.  "General Assembly Elects Estonia, Niger, Saint Vincent and Grenadines, Tunisia, Viet Nam as Non-Permanent Members of Security Council for 2020–2021". United Nations. 7 June 2019. Retrieved 1 January 2020.  "Kenya wins final contested seat on Security Council". news.un.org. 18 June 2020. Retrieved 19 June 2020.  "Kenya defeats Djibouti to win a seat at the UN Security Council". Aljazeera. 18 June 2020. Retrieved 19 June 2020.  Hamill, James. "South Africa returns to UN Security Council: here's the role it should play". The Conversation. Retrieved 25 November 2020.  "Notes by the president of the Security Council". United Nations. Retrieved 9 June 2012.  "UN Security Council: Presidential Statements 2008". United Nations. Retrieved 9 June 2012.  "Security Council Presidency in 2011 – United Nations Security Council". United Nations. Retrieved 9 June 2012.  "Security Council Presidency". United Nations Security Council. United Nations. Retrieved 5 January 2020.  "What is the Security Council?". United Nations. Retrieved 26 November 2013.  "The Security Council". United Nations Cyberschoolbus. United Nations. Retrieved 14 September 2012.  "UN Capital Master Plan Timeline". United Nations. Retrieved 29 September 2013.  "An unrecognizable Security Council Chamber". Norway Mission to the UN. 28 August 2012. Retrieved 29 September 2013.  "Secretary-General, at inauguaration of renovated Security Council Chamber, says room speaks 'language of dignity and seriousness'". United Nations. 16 April 2013. Retrieved 26 November 2013.  Haidar, Suhasini (1 September 2015). "India's walkout from UNSC was a turning point: Natwar". The Hindu. According to Mr. Singh, posted at India's permanent mission at the U.N. then, 1965 was a "turning point" for the U.N. on Kashmir, and a well-planned "walkout" from the U.N. Security Council by the Indian delegation as a protest against Pakistani Foreign Minister (and later PM) Zulfikar Ali Bhutto's speech ensured Kashmir was dropped from the UNSC agenda for all practical purposes.  Hovell, Devika (2016). The Power of Process: The Value of Due Process in Security Council Sanctions Decision-making. Oxford University Press. p. 145. ISBN 978-0-19-871767-6.  De Wet, Erika; Nollkaemper, André; Dijkstra, Petra, eds. (2003). Review of the Security Council by member states. Antwerp: Intersentia. pp. 31–32. ISBN 978-90-5095-307-8.  Bosco, David L. (2009). Five to Rule Them All: the UN Security Council and the Making of the Modern World. Oxford: Oxford University Press. pp. 138–139. ISBN 978-0-19-532876-9.  Elgebeily, Sherif (2017). The Rule of Law in the United Nations Security Council Decision-Making Process: Turning the Focus Inwards. pp. 54–55. ISBN 978-1-315-41344-0.  Sievers, Loraine; Daws, Sam (2014). The Procedure of the UN Security Council (4 ed.). Oxford: Oxford University Press. ISBN 978-0-19-150843-1.  "Security Council Handbook Glossary". United Nations Security Council. "Consultations of the whole" are consultations held in private with all 15 Council members present. Such consultations are held in the Consultations Room, are announced in the UN Journal, have an agreed agenda and interpretation, and may involve one or more briefers. The consultations are closed to non-Council Member States. "Informal consultations" mostly refer to "consultations of the whole", but in different contexts may also refer to consultations among the 15 Council members or only some of them held without a Journal announcement and interpretation.  "United Nations Security Council Meeting records". Retrieved 10 February 2017. The preparatory work for formal meetings is conducted in informal consultations for which no public record exists.  "Frequently Asked Questions". United Nations Security Council. Both open and closed meetings are formal meetings of the Security Council. Closed meetings are not open to the public and no verbatim record of statements is kept, instead the Security Council issues a Communiqué in line with Rule 55 of its Provisional Rules of Procedure. Consultations are informal meetings of the Security Council members and are not covered in the Repertoire.  "The Veto" (PDF). Security Council Report. 2015 (3). 19 October 2015.  Reid, Natalie (January 1999). "Informal Consultations". Global Policy Forum.  "Meeting record, Security Council, 4385th meeting". United Nations Repository. United Nations. 28 September 2001. S/PV.4385.  "Highlights of Security Council Practice 2016". Unite. United Nations. Retrieved 10 February 2017.  Fasulo 2004, p. 52.  Coulon 1998, p. ix.  Nobel Prize. "The Nobel Peace Prize 1988". Retrieved 3 April 2011.  "United Nations Peacekeeping Operations". United Nations. 30 September 2013. Retrieved 9 November 2013.  Lynch, Colum (16 December 2004). "U.N. Sexual Abuse Alleged in Congo". The Washington Post. Retrieved 21 November 2013.  "UN troops face child abuse claims". BBC News. 30 November 2006. Retrieved 21 November 2013.  "Aid workers in Liberia accused of sex abuse". The New York Times. 8 May 2006. Retrieved 22 November 2013.  Holt, Kate (4 January 2007). "UN staff accused of raping children in Sudan". The Telegraph. Retrieved 21 November 2013.  "Peacekeepers 'abusing children'". BBC. 28 May 2007. Retrieved 21 November 2013.  Watson, Ivan and Joe Vaccarello (10 October 2013). "U.N. sued for 'bringing cholera to Haiti', causing outbreak that killed thousands". CNN. Retrieved 18 November 2013.  Fasulo 2004, p. 115.  "How we are funded". United Nations Peacekeeping. Retrieved 17 February 2021.  Kennedy 2006, pp. 101–103, 110.  Kennedy 2006, p. 110.  RAND Corporation. "The UN's Role in Nation Building: From the Congo to Iraq" (PDF). Retrieved 30 December 2008.  Human Security Centre. "The Human Security Report 2005". Archived from the original on 28 July 2009. Retrieved 8 February 2007.  Rajan, Sudhir Chella (2006). "Global Politics and Institutions" (PDF). GTI Paper Series: Frontiers of a Great Transition. Tellus Institute. 3. Retrieved 11 December 2011.  Alexander 1996, pp. 158–160.  Deni 2007, p. 71: "As Serbian forces attacked Srebrenica in July 1995, the [400] Dutch soldiers escorted women and children out of the city, leaving behind roughly 7,500 Muslim men who were subsequently massacred by the attacking Serbs."  Creery, Janet (2004). "Read the fine print first". Peace Magazine (Jan–Feb 1994): 20. Retrieved 11 December 2011.  "Supreme Leader’s Inaugural Speech at 16th NAM Summit". Non-Aligned Movement News Agency. Retrieved 31 August 2012.  Key compromises on UN Syria deal Archived 30 September 2013 at the Wayback Machine. 3 News NZ. 28 September 2013.  Vreeland, James Raymond (11 May 2019). "Corrupting International Organizations". Annual Review of Political Science. 22 (1): 205–222. doi:10.1146/annurev-polisci-050317-071031. ISSN 1094-2939.  Kennedy 2006, p. 76.  "UN Security Council Reform May Shadow Annan's Legacy". Voice of America. 1 November 2006. Retrieved 11 December 2011.  "US embassy cables: China reiterates 'red lines'". The Guardian. 29 November 2010. Retrieved 11 December 2011. [I]t would be difficult for the Chinese public to accept Japan as a permanent member of the UNSC.  "India Offers To Temporarily Forgo Veto Power If Granted Permanent UNSC Seat". HuffPost. Retrieved 9 March 2017.  "US congressmen move resolution in support of India's UN security council claim". Hindustan Times. 27 September 2017. Retrieved 30 September 2017. Sources Alexander, Titus (1996). Unravelling Global Apartheid: An Overview of World Politics. Cambridge, Massachusetts: Polity Press. ISBN 978-0-7456-1353-6. Blum, Yehuda Z. (1992). "Russia Takes Over the Soviet Union's Seat at the United Nations" (PDF). European Journal of International Law. 3 (2): 354–362. doi:10.1093/ejil/3.2.354. Retrieved 8 February 2016. Coulon, Jocelyn (1998). Soldiers of Diplomacy: The United Nations, Peacekeeping, and the New World Order. University of Toronto Press. ISBN 978-0-8020-0899-2. Deni, John R. (2007). Alliance Management and Maintenance: Restructuring NATO for the 21st Century. Aldershot, England: Ashgate Publishing. ISBN 978-0-7546-7039-1. Fasulo, Linda (2004). An Insider's Guide to the UN. New Haven, Connecticut: Yale University Press. ISBN 978-0-300-10155-3. Fomerand, Jacques (2009). The A to Z of the United Nations. Lanham, Maryland: Scarecrow Press. ISBN 978-0-8108-5547-2. Gaddis, John Lewis (2000) [1972]. The United States and the Origins of the Cold War, 1941–1947. New York: Columbia University Press. ISBN 978-0-231-12239-9. Hillier, Timothy (1998). Sourcebook on Public International Law. Sourcebook Series. London: Cavendish Publishing. ISBN 978-1-85941-050-9. Hoopes, Townsend; Brinkley, Douglas (2000) [1997]. FDR and the Creation of the U.N. New Haven, Connecticut: Yale University Press. ISBN 978-0-300-08553-2. Kennedy, Paul (2006). The Parliament of Man: The Past, Present, and Future of the United Nations. New York: Random House. ISBN 978-0-375-50165-4. Köchler, Hans (2001). The Concept of Humanitarian Intervention in the Context of Modern Power: Is the Revival of the Doctrine of "Just War" Compatible with the International Rule of Law?. Studies in International Relations. 26. Vienna: International Progress Organization. ISBN 978-3-900704-20-9. Magliveras, Konstantinos D. (1999). Exclusion from Participation in International Organisations: The Law and Practice behind Member States' Expulsion and Suspension of Membership. Studies and Materials on the Settlement of International Disputes. 5. The Hague: Kluwer Law International. ISBN 978-90-411-1239-2. Manchester, William; Reid, Paul (2012). The Last Lion: Winston Spencer Churchill. Volume 3: Defender of the Realm. New York: Little Brown and Company. ISBN 978-0-316-54770-3. Matthews, Ken (1993). The Gulf Conflict and International Relations. London: Routledge. ISBN 978-0-415-07519-0. Meisler, Stanley (1995). United Nations: The First Fifty Years. New York: Atlantic Monthly Press. Mikulaschek, Christoph (2010). "Report from the 39th International Peace Institute Vienna Seminar on Peacemaking and Peacekeeping". In Winkler, Hans; Rød-Larsen, Terje; Mikulaschek, Christoph (eds.). The UN Security Council and the Responsibility to Protect: Policy, Process, and Practice (PDF). Favorita Papers. Diplomatic Academy of Vienna. pp. 20–49. ISBN 978-3-902021-67-0. Retrieved 8 February 2016. Mires, Charlene (2013). Capital of the World: The Race to Host the United Nations. New York University Press. ISBN 978-0-8147-0794-4. Neuhold, Hanspeter (2001). "The United Nations System for the Peaceful Settlement of International Disputes". In Cede, Frank; Sucharipa-Behrmann, Lilly (eds.). The United Nations: Law and Practice. The Hague: Kluwer Law International. ISBN 978-90-411-1563-8. Osmańczyk, Edmund Jan (2004). Mango, Anthony (ed.). Encyclopedia of the United Nations and International Agreements. 4. Taylor & Francis. ISBN 978-0-415-93924-9. Schlesinger, Stephen C. (2003). Act of Creation: The Founding of the United Nations: A Story of Super Powers, Secret Agents, Wartime Allies and Enemies, and Their Quest for a Peaceful World. Boulder, Colorado: Westview Press. ISBN 978-0-8133-3324-3. Wilcox, Francis O. (1945). "The Yalta Voting Formula". American Political Science Review. 39 (5): 943–956. doi:10.2307/1950035. ISSN 0003-0554. JSTOR 1950035. Zunes, Stephen (2004). "International Law, the UN and Middle Eastern Conflicts". Peace Review: A Journal of Social Justice. 16 (3): 285–292. doi:10.1080/1040265042000278513. ISSN 1040-2659. S2CID 143010895. Further reading Bailey, Sydney D.; Daws, Sam (1998). The Procedure of the UN Security Council (3rd ed.). Oxford University Press. ISBN 978-0-19-828073-6. Bosco, David L. (2009). Five to Rule Them All: The UN Security Council and the Making of the Modern World. New York: Oxford University Press. ISBN 978-0-19-532876-9. Cockayne, James; Mikulaschek, Christoph; Perry, Chris (2010). The United Nations Security Council and Civil War: First Insights from a New Dataset. New York: International Peace Institute. Retrieved 8 February 2016. Grieger, Gisela (2013). Reform of the UN Security Council (PDF). Library of the European Parliament. Retrieved 8 February 2016. Hannay, David (2008). New World Disorder: The UN after the Cold War – An Insider's View. London: I.B. Tauris. ISBN 978-1-84511-719-1. Hurd, Ian (2007). After Anarchy: Legitimacy and Power in the United Nations Security Council. Princeton, New Jersey: Princeton University Press. ISBN 978-0-691-12866-5. Köchler, Hans (1991). The Voting Procedure in the United Nations Security Council: Examining a Normative Contradiction in the UN Charter and its Consequences on International Relations (PDF). Studies in International Relations. 17. Vienna: International Progress Organization. ISBN 978-3-900704-10-0. Lowe, Vaughan; Roberts, Adam; Welsh, Jennifer; Zaum, Dominik, eds. (2008). The United Nations Security Council and War: The Evolution of Thought and Practice since 1945. Oxford University Press. ISBN 978-0-19-953343-5. Malone, David (1998). Decision-Making in the UN Security Council: The Case of Haiti, 1990–1997. Oxford: Clarendon Press. ISBN 978-0-19-829483-2. Matheson, Michael J. (2006). Council Unbound: The Growth of UN Decision Making on Conflict and Postconflict Issues after the Cold War. Washington: US Institute of Peace Press. ISBN 978-1-929223-78-7. Roberts, Adam; Zaum, Dominik (2008). Selective Security: War and the United Nations Security Council since 1945. Strategic Survey : The Annual Review of World Affairs. Adelphi Paper. 395. Abingdon, England: Routledge. ISBN 978-0-415-47472-6. ISSN 0567-932X. Vreeland, James; Dreher, Axel (2014). The Political Economy of the United Nations Security Council: Money and Influence. Cambridge, England: Cambridge University Press. ISBN 978-0-521-51841-3. External links 	Wikimedia Commons has media related to United Nations Security Council. Official website Edit this at Wikidata UN Security Council Research Guide Global Policy Forum – UN Security Council Security Council Report – information and analysis on the council's activities What's In Blue – a series of insights on evolving Security Council actions Center for UN Reform Education – information on current reform issues at the United Nations UN Democracy: hyperlinked transcripts of the United Nations General Assembly and the Security Council vte Security Council of the United Nations Power	 Charter of the United Nations Chapter VChapter VIIVetoResolution vetoed resolutions Organization	 Military ObserverPeacebuilding CommissionCounter-Terrorism CommitteePeacekeepingMilitary Staff Committee Missions	 United Nations CommandUnified Task ForceUN Mandate Members	 Permanent	  China France Russia United Kingdom United States 2020–2021	  Estonia Niger Saint Vincent and the Grenadines Tunisia Vietnam 2021–2022	  India Ireland Kenya Mexico Norway Related	 ElectionsPresidency of the Security CouncilChapter VI of the UN CharterReform of the Security CouncilSecurity Council muralArria formula meetingP5+1Small Five Group Category Category vte  United Nations Secretary-General: António GuterresDeputy Secretary-General: Amina J. MohammedGeneral Assembly President: Volkan Bozkır UN System	 Charter	 Preamble Principal organs	 Secretariat Secretary-GeneralDeputy Secretary-GeneralUnder-Secretary-GeneralGeneral Assembly PresidentInternational Court of Justice StatuteSecurity Council MembersPresidentEconomic and Social Council PresidentTrusteeship Council Funds, programmes, and other bodies	 Culture of PeaceITCIPCCIAEAMINURSOUNAIDSSCSLUNCTADUNCITRALUNCDFUNDGCUNDPUNDPO peacekeepingUNEP OzonActionUNEP/GRID-ArendalUNEP-WCMCUNFPAUN-HABITATOHCHRUNHCRUNHRCUNICEFUNICRIUNIDIRUNITARUN-OceansUNODCUNOPSUNOSATUNRISDUNRWAUNSDGUNSSCUNU UNU-OPUNU-CRISUNVUN WomenWFP Specialized agencies	 FAOICAOIFADILOIMFIMOITUUNESCOUNIDOUNWTOUPUWFEOWHOWIPOWMOWorld Bank Group IBRDIDAIFC Secretariat Offices and Departments	 HeadquartersEnvoy on YouthSpokesperson for the Secretary-GeneralGenevaPalace of NationsNairobiViennaEconomic and Social AffairsPolitical and Peacebuilding Affairs Dag Hammarskjöld LibrarySafety and SecurityPalestinian RightsPeace OperationsInternal OversightLegal AffairsDeveloping CountriesSport for Development and PeaceDisarmament AffairsOuter Space AffairsPartnershipsCoordination of Humanitarian AffairsUN organizations by locationSexual Violence in Conflict Members and observers	 Full membersFounding membersSecurity Council Permanent membersPermanent representatives to the UN listGeneral Assembly Observers European Union History	 Preceding years	 International Telegraph UnionUniversal Postal UnionInternational Peace ConferencePermanent Court of ArbitrationLeague of Nations archivescharterorganizationmembers Preparatory years	 London Declaration (1941)Atlantic Charter (1941)Declaration by United Nations (1942)Moscow Conference (1943)Tehran Conference (1943)Dumbarton Oaks Conference (1944)Yalta Conference (1945)Conference on International Organization (1945) Activities	 Peacekeeping missions historytimelineUniversal Declaration of Human Rights draftingHuman Rights DayEnlargementConvention on the Rights of the Child committeeDeclaration on the Rights of Indigenous Peoples Resolutions	 Security Council vetoesGeneral Assembly 66th67thSecurity Council CyprusIranIraqIsraelLebanonNagorno-KarabakhNorth KoreaPalestineSyriaWestern Sahara Elections	 Secretary-General (2021) (2016)International Court of Justice (2020) (2017) (2014) (2011)General Assembly President (2016)Security Council (2016) Related	 Bretton Woods systemComprehensive Nuclear-Test-Ban TreatyCriticismDelivering as OneFlag Honour FlagFour Nations InitiativeGenocide ConventionUN Global CompactInternational Covenant on Civil and Political RightsInternational Criminal CourtInternational Day of PeaceInternational Decade for a Culture of Peace and Non-Violence for the Children of the WorldInternational YearsInterpretersUN laissez-passerMilitary Staff CommitteeOfficial languagesOrganisation for the Prohibition of Chemical WeaponsPeacekeepingRalph Bunche ParkSustainable Development GoalsUnited Nations Postal AdministrationUN Block By BlockStandard Minimum Rules for the Administration of Juvenile JusticeStandard Minimum Rules for the Treatment of Prisoners (the Mandela Rules)Treaty SeriesTreaty on the Non-Proliferation of Nuclear WeaponsTreaty on the Prohibition of Nuclear WeaponsUN Advisory Committee of Local AuthoritiesUN DayMillennium DeclarationSecurity Council veto powerUN reform Security Council reformUN Art Collection Security Council muralUN Federal Credit UnionUN International School HanoiUN MandateUN Memorial Cemetery KoreaUniversity for PeaceVienna Declaration and Programme of ActionWoodrow Wilson MemorialWorld Federation of United Nations Associations Others	 OutlineUnited Nations Prize in the Field of Human RightsUnited Nations MedalUnited Nations RadioUN television film series (1964–1966)In popular cultureModel UN vte United Nations Security Council elections 1940s	 1946 (Jan)1946 (Nov)194719481949 1950s	 1950195119521953195419551956195719581959 1960s	 1960196119621963196419651966196719681969 1970s	 1970197119721973197419751976197719781979 1980s	 1980198119821983198419851986198719881989 1990s	 1990199119921993199419951996199719981999 2000s	 2000200120022003200420052006200720082009 2010s	 2010201120122013201420152016201720182019 2020s	 20202021202220232024 General AssemblyUNSC (MembersReform)Regional Groups (EEGGRULACWEOG) vte United Nations Charter Text	 PreambleChapter IIIIIIIVVVIVIIVIIIIXXXIXIIXIIIXIVXVXVIXVIIXVIIIXIXAmendments Organs created	 Security CouncilGeneral AssemblyEconomic and Social CouncilTrusteeship CouncilInternational Court of Justice (statute)SecretariatMilitary Staff Committee History	 Background	 Paris Peace ConferenceTreaty of VersaillesCovenant of the League of Nations Preparation	 London Declaration (1941)Atlantic Charter (1941)Declaration by United Nations (1942)Moscow Conference (1943)Tehran Conference (1943)Dumbarton Oaks Conference (1944)Yalta Conference (1945)Conference on International Organization (1945) Signatories	 Original members Complete textA coloured voting box.svg Politics portalJohnny-automatic-scales-of-justice.svg Law portal Authority control Edit this at Wikidata General	 Integrated Authority File (Germany)ISNI 1VIAF 1WorldCat National libraries	 France (data)United StatesJapanCzech RepublicAustraliaSwedenVatican Other	 Social Networks and Archival ContextSUDOC (France) 1 Categories: United Nations Security CouncilUnited Nations organsInternational securityOrganizations established in 1946 Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadEditView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikinews Languages Alemannisch العربية Արեւմտահայերէն Arpetan Asturianu Авар Azərbaycanca تۆرکجه বাংলা Bân-lâm-gú Башҡортса Беларуская Беларуская (тарашкевіца) Български Bosanski Brezhoneg Català Čeština Cymraeg Dansk Deutsch Eesti Ελληνικά Español Esperanto Euskara فارسی Føroyskt Français Galego 한국어 Հայերեն हिन्दी Hrvatski Ido Bahasa Indonesia Interlingua IsiXhosa Íslenska Italiano עברית Jawa ქართული Қазақша Kiswahili Kurdî Latina Latviešu Lëtzebuergesch Lietuvių Magyar मैथिली Македонски Malagasy മലയാളം मराठी მარგალური مصرى ဘာသာ မန် مازِرونی Bahasa Melayu Minangkabau Монгол မြန်မာဘာသာ Nederlands नेपाली 日本語 Norsk bokmål Norsk nynorsk Occitan Oʻzbekcha/ўзбекча ਪੰਜਾਬੀ پنجابی ភាសាខ្មែរ Polski Português Română Русиньскый Русский Scots Shqip සිංහල Simple English Slovenčina Slovenščina Soomaaliga کوردی Српски / srpski Srpskohrvatski / српскохрватски Suomi Svenska Tagalog தமிழ் Taqbaylit Татарча/tatarça ไทย Тоҷикӣ ತುಳು Türkçe Українська اردو Tiếng Việt 文言 吴语 ייִדיש Yorùbá 粵語 中文 Edit links This page was last edited on 1 October 2021, at 12:36 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki   Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more Western European and Others Group From Wikipedia, the free encyclopedia Jump to navigationJump to search  This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed. Find sources: "Western European and Others Group" – news · newspapers · books · scholar · JSTOR (October 2015) (Learn how and when to remove this template message) Group of Western European and Other States Emblem of the United Nations.svg Abbreviation	WEOG Formation	1961; 60 years ago Type	Regional group Legal status	Active A coloured voting box.svg Politics portal  WEOG member and observer states The Group of Western European and Other States, also known as the Western European and Other States Group or WEOG, is one of the five United Nations regional groups and is composed of 28 Member States mainly from Western Europe, but also from Oceania, North America, and Western Asia.[1]  The Group is a non-binding dialogue group where subjects concerning regional and international matters are discussed. Additionally, the Group works to help allocate seats on United Nations bodies by nominating candidates from the region.[2][3][4]  Unlike most other Regional Groups, WEOG is unusual in that geography is not the sole defining factor of its membership. Instead, its membership is based on geopolitical breakdown, namely its member states share a Western-Democratic common denominator.[5] For example, Canada, Australia and New Zealand are WEOG members even though they are not geographically close to Western Europe, but are culturally and politically descended from Western European states, in particular, the United Kingdom and, also in the case of Canada, from France.   Contents 1	Membership 1.1	Member states 1.2	Observer states 1.3	Israel 2	Suggested reform 3	Representation 3.1	Security Council 3.2	Economic and Social Council 3.3	Human Rights Council 3.4	Presidency of the General Assembly 4	Timeline of membership 5	See also 6	References 7	Notes Membership Member states The following are the current Member States of the Western European and Others Group:[6][7]  Western Europe:  Andorra  Austria  Belgium  Denmark  Finland  France[a]  Germany[b]  Greece  Iceland  Ireland  Italy  Liechtenstein  Luxembourg  Malta  Monaco  Netherlands  Norway  Portugal  San Marino  Spain  Sweden   Switzerland  Turkey  United Kingdom of Great Britain and Northern Ireland[c] Oceania:  Australia  New Zealand North America:  Canada Western Asia:  Israel[d] Observer states  United States of America[e] The United States of America is not formally a member of any regional group, but attends meetings of WEOG as an observer and is considered to be a member of the group for electoral purposes.[6] Israel While geographically located in Asia, Israel has been blocked from joining the Asia-Pacific Group by various Arab states. Since the regional groupings were created in the early 60s, Israel had been unable to participate in the political and professional consultations within the framework of the United Nations and its agencies. It was also unable to have its representatives elected to United Nations institutions due to the fact that it was not part of any regional group.[5][8]  This changed in May 2000, when Israel became a temporary member of the WEOG at the United Nations in New York, allowing it to put forward candidates for election to various United Nations General Assembly bodies. However, this temporary membership still precluded Israel from participating in activities at United Nations offices in Geneva, Nairobi, Rome and Vienna.[9]  On 30 April 2004, the United States House of Representatives passed a resolution calling for the full inclusion of Israel in WEOG, directing the U.S. Government to pursue action to "ensure the extension and upgrade of Israel's membership in the Western European and Others Group at the United Nations."[10] This was accomplished in May 2004, when Israel was granted a permanent renewal for WOEG proceedings in New York.  However, it wasn't until November 2013 when Israel was finally admitted into WEOG proceedings at the United Nations Geneva Office, 1 January 2014.[11][12]  Suggested reform In his address before the General Assembly at the 55th General Debate, Vinci Niel Clodumar, the head of the Nauru Delegation, advocated for the creation of a new Oceania regional group to include both Australia and New Zealand, as well as the ASEAN member countries, Japan, the Republic of Korea and the Pacific island countries. In his speech he mentioned that "the 11 Pacific island countries are drowning in the Asian Group, while Australia and New Zealand...are marooned in the Group of Western European and other States."[13]  Representation Security Council The Western European and Other States Group holds 5 seats on the Security Council, 2 non-permanent and 3 permanent. The current members of the Security Council from the Group are:[14][15]  Country	Term  France	Permanent  United States of America	Permanent  United Kingdom of Great Britain and Northern Ireland	Permanent  Ireland	1 January 2021 – 31 December 2022  Norway	1 January 2021 – 31 December 2022 Economic and Social Council The Western European and Other States Group holds 13 seats on the United Nations Economic and Social Council. The current members of the Economic and Social Council from the Group are:[16][17]  Country	Term  Austria	1 January 2021 – 31 December 2023  France  Germany  Portugal  United Kingdom  Canada	1 January 2019 – 31 December 2021  Luxembourg  Netherlands  United States of America  Australia	1 January 2020 – 31 December 2022  Finland  Norway   Switzerland Human Rights Council The Western European and Other States Group holds 7 seats on the United Nations Human Rights Council. The current members of the Economic and Social Council from the Group are:[18][19]  Country	Term  France	1 January 2021 – 31 December 2023  United Kingdom  Austria	1 January 2019 – 31 December 2021  Denmark  Italy  Germany	1 January 2020 – 31 December 2022  Netherlands Presidency of the General Assembly Every five years in the years ending in 0 and 5, the Western European and Other States Group is eligible to elect a president to the General Assembly.[1]  The following is a list of presidents from the region since its official creation in 1961:[20]  Year Elected	Session	Name of President	Country	Note 1965	20th	Amintore Fanfani	 Italy	 1970	25th	Edvard Hambro	 Norway	 1975	30th	Gaston Thorn	 Luxembourg	 1980	35th	Rüdiger von Wechmar	 Federal Republic of Germany	Also chaired the eighth emergency special session of the General Assembly 1985	40th	Jaime de Piniés	 Spain	Also chaired the thirteenth special session of the General Assembly 1990	45th	Guido de Marco	 Malta	 1995	50th	Diogo de Freitas do Amaral	 Portugal	 2000	55th	Harri Holkeri	 Finland	Also chaired the tenth emergency special, twenty-fifth special and twenty-sixth special sessions of the General Assembly 2005	60th	Jan Eliasson	 Sweden	 2010	65th	Joseph Deiss	  Switzerland	 2015	70th	Mogens Lykketoft	 Denmark	 2020	75th	Volkan Bozkır	 Turkey	 Future 2025	75th	TBD	TBD	 2030	80th	TBD	TBD	 2035	85th	TBD	TBD	 Timeline of membership As the Western European Group changed significantly over time, the number of its members had also changed.  Years	Number of members	Notes 1961–1964	20	Australia, Austria, Belgium, Canada, Denmark, Finland, France, Greece, Iceland, Ireland, Italy, Luxembourg, Netherlands, New Zealand, Norway, Portugal, Spain, Sweden, Turkey, United Kingdom and United States (observer) joins the WEOG. 1964–1973	21	Malta joins the UN. 1973–1990	22	West Germany joins the UN. 1990	23	German reunification, West Germany becomes Germany, Liechtenstein joins the UN. 1992	24	San Marino joins the UN as part of WEOG. 1993–2000	26	Monaco and Andorra join the UN as part of WEOG. 2000–2002	27	Israel joins the WEOG. 2002–present	28	Switzerland joins the UN as part of WEOG. See also United Nations Regional Groups Israel and the United Nations List of members of the United Nations Security Council List of members of the United Nations Economic and Social Council JUSCANZ References  Wanza, Serah N. (27 November 2017). "What Are The Five Regional Groups of the United Nations?". Worldatlas. Worldatlas. Retrieved 26 February 2019.  Agam, Hasmy, and Sam Daws, Terence O'Brien and Ramesh Takur (26 March 1999). What is Equitable Geographic Representation in the Twenty-First Century (PDF) (Report). United Nations University. Retrieved 27 February 2019.  Volger, Helmut, ed. (2010). A Concise Encyclopedia of the United Nations (PDF). Choice Reviews Online. 48. Leiden: Martinus Nijhoff Publishers. pp. 592–6. doi:10.5860/choice.48-0623. ISBN 978-90-04-18004-8. S2CID 159105596. Archived from the original (PDF) on 2020-01-13.  Götz, Norbert (2008). "Western Europeans and Others: The Making of Europe at the United Nations". Alternatives. 33 (3): 359–81. doi:10.1177/030437540803300305. S2CID 145099552. Retrieved 13 January 2020.  "United Nations: Israel & the WEOG". Jewish Virtual Library. American-Israeli Cooperative Enterprise. n.d. Retrieved 13 January 2020.  "United Nations Regional Groups of Member States". United Nations Department for General Assembly and Conference management. United Nations. n.d. Retrieved 26 February 2019.  "United Nations Handbook 2018–19" (PDF). United Nations Handbook : An Annual Guide for Those Working with and within the United Nations (56 ed.). Wellington: Ministry of Foreign Affairs and Trade of New Zealand: 15–17. 2018. ISSN 0110-1951.  "Israel Accepted to WEOG". Israel Ministry of Foreign Affairs. State of Israel. 28 May 2000. Retrieved 13 January 2020.  Crossette, Barbara (1 June 200). "Israel's Bittersweet Moment: One Step Out of Isolation at U.N." New York Times. Retrieved 13 January 2020.  "Expressing the sense of the House of Representatives in support of full membership of Israel in the Western European and Others Group at the United Nations". Resolution No. H.RES.615 of 30 April 2004. United States House of Representatives.  Kerry, John (2 December 2013). "Israel Invited To Join the Western European and Others Group (WEOG) in Geneva" (Press release). Washington, DC: U.S. Mission to International Organizations in Geneva. U.S. Department of State. Retrieved 2020-01-13.  Lazaroff, Tovah (1 December 2013). "Israel invited to join UN's Western nations group in Geneva". Jerusalem Post. Jerusalem Post. Retrieved 13 January 2020.  United Nations General Assembly Session 55 Official Record PV.25. General Assembly: Fifty-fifth session - 25th plenary meeting A/55/PV.25 Vinci Niel Clodumar Nauru (in English). 20 September at 3pm. Retrieved 13 January 2020.  "Current Members". United Nations Security Council. United Nations. n.d. Retrieved 26 February 2019.  "General Assembly Elects Belgium, Dominican Republic, Germany, Indonesia, South Africa as Non-permanent Members of Security Council". United Nations Meetings Coverage & Press Releases. United Nations. 8 June 2018. Retrieved 13 January 2020.  "Members". United Nations Economic and Social Council. United Nations. n.d. Retrieved 26 February 2019.  "General Assembly Elects 19 Economic and Social Council Members to Terms Beginning 1 January 2020, Adopts Resolution Commemorating Signing of United Nations Charter". United Nations Meetings Coverage & Press Releases. United Nations. 14 June 2019. Retrieved 1 January 2020.  "Current Membership of the Human Rights Council, 1 January - 31 December 2019 by regional groups". United Nations Human Rights Council. United Nations. n.d. Retrieved 26 February 2019.  "General Assembly Elects 14 Member States to Human Rights Council, Appoints New Under-Secretary-General for Internal Oversight Services". United Nations Meetings Coverage & Press Releases. United Nations. 17 October 2019. Retrieved 1 January 2020.  "Past Presidents". United Nations General Assembly. United Nations. n.d. Retrieved 27 February 2019. Notes  Permanent member of the United Nations Security Council  Formerly represented by the Federal Republic of Germany until 1990  Permanent member of the United Nations Security Council  While geographically located in Asia, Israel has participated in WEOG since 2000  Permanent member of the United Nations Security Council Categories: United Nations coalitions and unofficial groups Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadEditView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version  Languages العربية فارسی Français Gagauz עברית 日本語 Suomi ไทย Türkçe Edit links This page was last edited on 3 June 2021, at 15:33 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki  Page semi-protected Greece From Wikipedia, the free encyclopedia Jump to navigationJump to search For other uses, see Greece (disambiguation) and Hellas. Hellenic Republic Ελληνική Δημοκρατία (Greek) Ellinikí Dimokratía Flag of Greece Flag Coat of arms of Greece Coat of arms Motto: Ελευθερία ή Θάνατος Elefthería í Thánatos ("Freedom or Death") Anthem: Ύμνος εις την Ελευθερίαν Ímnos is tin Eleftherían ("Hymn to Liberty") EU-Greece.svg EU-Greece (orthographic projection).svg Location of Greece (dark green) – in Europe (light green & dark grey) – in the European Union (light green)  Capital and largest city Athens 37°58′N 23°43′E Official language and national language	Greek Religion (2017)	73–93% Christianity 70–90% Greek Orthodoxy[1][a] 3% Other Christian 4–22% No religion[1][4] 2% Islam 1% Other religions[5] Demonym(s)	Greek Government	Unitary parliamentary republic • President Katerina Sakellaropoulou • Prime Minister Kyriakos Mitsotakis • Speaker of the Parliament Konstantinos Tasoulas Legislature	Hellenic Parliament Establishment history • Independence declared from the Ottoman Empire 25 March 1821 (traditional starting date of the Greek War of Independence), 15 January 1822 (official declaration) • Recognised 3 February 1830 • Current constitution 11 June 1975 Area • Total 131,957 km2 (50,949 sq mi)[6] (95th) • Water (%) 1.51 (as of 2015)[7] Population • 2020 estimate Neutral decrease 10,718,565[8] (85th) • 2011 census 10,816,286[9] • Density 82[10]/km2 (212.4/sq mi) (98th) GDP (PPP)	2020 estimate • Total Decrease $310.743 billion[11] (53th) • Per capita Decrease $29,045[11] (47th) GDP (nominal)	2020 estimate • Total Decrease $194.376 billion[11] (51th) • Per capita Decrease $18,168[11] (41th) Gini (2020)	Negative increase 31.1[12] medium · 60th HDI (2019)	Increase 0.888[13] very high · 32nd Currency	Euro (€) (EUR) Time zone	UTC+02:00 (Eastern European Time) • Summer (DST) UTC+03:00 (Eastern European Summer Time) Date format	dd-mm-yyyy (AD) Driving side	right Calling code	+30 ISO 3166 code	GR Internet TLD	 .gra.ελ The .eu domain is also used, as in other European Union member states. Greece (Greek: Ελλάδα, romanized: Elláda, [eˈlaða]), officially the Hellenic Republic,[b] is a country located in Southeast Europe. Its population is approximately 10.7 million as of 2018; Athens is its largest and capital city, followed by Thessaloniki. Situated on the southern tip of the Balkans, Greece is located at the crossroads of Europe, Asia, and Africa. It shares land borders with Albania to the northwest, North Macedonia and Bulgaria to the north, and Turkey to the northeast. The Aegean Sea lies to the east of the mainland, the Ionian Sea to the west, the Cretan Sea and the Mediterranean Sea to the south. Greece has the longest coastline on the Mediterranean Basin and the 11th longest coastline in the world at 13,676 km (8,498 mi) in length, featuring many islands, of which 227 are inhabited. Eighty percent of Greece is mountainous, with Mount Olympus being the highest peak at 2,918 metres (9,573 ft). The country consists of nine traditional geographic regions: Macedonia, Central Greece, the Peloponnese, Thessaly, Epirus, the Aegean Islands (including the Dodecanese and Cyclades), Thrace, Crete, and the Ionian Islands.  Greece is considered the cradle of Western civilization, being the birthplace of democracy, Western philosophy, Western literature, historiography, political science, major scientific and mathematical principles, theatre and the Olympic Games. From the eighth century BC, the Greeks were organised into various independent city-states, known as poleis (singular polis), which spanned the Mediterranean and the Black Sea. Philip II of Macedon united most of present-day Greece in the fourth century BC, with his son Alexander the Great rapidly conquering much of the ancient world, from the eastern Mediterranean to India. The subsequent Hellenistic period saw the height of Greek culture and influence in antiquity. Greece was annexed by Rome in the second century BC, becoming an integral part of the Roman Empire and its continuation, the Byzantine Empire, which was culturally and linguistically predominantly Greek. The Greek Orthodox Church, which emerged in the first century AD, helped shape modern Greek identity and transmitted Greek traditions to the wider Orthodox world. After falling under Ottoman dominion in the mid-15th century, Greece emerged as a modern nation state in 1830 following a war of independence. The country's rich historical legacy is reflected in part by its 18 UNESCO World Heritage Sites.  Greece is a unitary parliamentary republic, and a developed country, with an advanced high-income economy, and a high quality of life, ranking simultaneously very high in the Human Development Index. Its economy is the largest in the Balkans, where it is an important regional investor. A founding member of the United Nations, Greece was the tenth member to join the European Communities (precursor to the European Union) and has been part of the Eurozone since 2001. It is also a member of numerous other international institutions, including the Council of Europe, the North Atlantic Treaty Organization (NATO), the Organisation for Economic Co-operation and Development (OECD), the World Trade Organization (WTO), the Organization for Security and Co-operation in Europe (OSCE), and the Organisation internationale de la Francophonie (OIF). Greece's unique cultural heritage, large tourism industry, prominent shipping sector and geostrategic importance classify it as a middle power.[c]   Contents 1	Name 2	History 2.1	Prehistory and early history 2.2	Archaic and Classical period 2.3	Hellenistic and Roman periods (323 BC – 4th century AD) 2.4	Medieval period (4th – 15th century) 2.5	Venetian possessions and Ottoman rule (15th century – 1821) 2.6	Modern period 2.6.1	Greek War of Independence (1821–1832) 2.6.2	Kingdom of Greece 2.6.3	Expansion, disaster, and reconstruction 2.6.4	Dictatorship, World War II, and reconstruction 2.6.5	Military regime (1967–74) 2.6.6	Third Hellenic Republic 2.7	Recent history 3	Geography and climate 3.1	Islands 3.2	Climate 3.3	Biodiversity 4	Politics 4.1	Political parties 4.2	Foreign relations 4.3	Law and justice 4.4	Military 4.5	Administrative divisions 5	Economy 5.1	Introduction 5.2	Debt crisis (2010–2018) 5.3	Agriculture 5.4	Energy 5.5	Maritime industry 5.6	Tourism 5.7	Transport 5.8	Telecommunications 5.9	Science and technology 6	Demographics 6.1	Cities 6.2	Religion 6.3	Languages 6.4	Migration 6.5	Education 6.6	Healthcare system 7	Culture 7.1	Visual arts 7.2	Architecture 7.3	Theatre 7.4	Literature 7.5	Philosophy 7.6	Music and dances 7.7	Cuisine 7.8	Cinema 7.9	Sports 7.10	Mythology 7.11	Public holidays and festivals 8	See also 9	Notes 10	References 10.1	Citations 10.2	Bibliography 11	External links Name Main article: Name of Greece The native name of the country in Modern Greek is Ελλάδα (About this soundElláda, pronounced [eˈlaða]). The corresponding form in Ancient Greek and conservative formal Modern Greek (Katharevousa) is Ἑλλάς (Hellas, classical: [hel.lás], modern: [eˈlas]). This is the source of the English alternate name Hellas, which is mostly found in archaic or poetic contexts today. The Greek adjectival form ελληνικός (ellinikos, [eliniˈkos]) is sometimes also translated as Hellenic and is often rendered in this way in the formal names of Greek institutions, as in the official name of the Greek state, the Hellenic Republic (Ελληνική Δημοκρατία, [eliniˈci ðimokraˈti.a]).[22]  The English names Greece and Greek are derived, via the Latin Graecia and Graecus, from the name of the Graeci (Γραικοί, Graikoí; singular Γραικός, Graikós), who were among the first ancient Greek tribes to settle Magna Graecia in southern Italy. The term is ultimately derived from the Proto-Indo-European root *ǵerh₂-, "to grow old".  History Main article: History of Greece Prehistory and early history Main articles: Neolithic Greece, Pelasgians, Cycladic culture, Minoan civilization, and Mycenaean Greece  The entrance of the Treasury of Atreus (13th BC) in Mycenae  Herodotus (c. 484 BC—c. 425 BC), often considered the "father of history" The earliest evidence of the presence of human ancestors in the southern Balkans, dated to 270,000 BC, is to be found in the Petralona cave, in the Greek province of Macedonia.[23] The Apidima Cave in Mani, in southern Greece, contains the oldest remains of anatomically modern humans outside of Africa, dated to 210,000 years ago.[24][25][26] All three stages of the Stone Age (Paleolithic, Mesolithic, and Neolithic) are represented in Greece, for example in the Franchthi Cave.[27] Neolithic settlements in Greece, dating from the 7th millennium BC,[23] are the oldest in Europe by several centuries, as Greece lies on the route via which farming spread from the Near East to Europe.[28] Following the end of the Greek Neolithic period in 3.200 BC, a slow transition period between the stone economy to the bronze economy during the end of the 4th Millennium BC including Eutresis culture and Korakou culture with the first large buildings (House of the Tiles) until the middle of the 3rd Millenium BC took place in the Greek mainland.Tiryns culture before the Middle Helladic period that developed the socioeconomic base of the following Minoan civilization and Mycenean civilisation.[29]   Fresco displaying the Minoan ritual of "bull leaping", found in Knossos Greece is home to the first advanced civilizations in Europe and is considered the birthplace of Western civilisation,[d][33][34][35][36] beginning with the Cycladic civilization on the islands of the Aegean Sea at around 3200 BC,[37] the Minoan civilization in Crete (2700–1500 BC),[36][38] and then the Mycenaean civilization on the mainland (1600–1100 BC).[38] These civilizations possessed writing, the Minoans using an undeciphered script known as Linear A, and the Mycenaeans writing the earliest attested form of Greek in Linear B. The Mycenaeans gradually absorbed the Minoans, but collapsed violently around 1200 BC, along with other civilizations, during the regional event known as the Late Bronze Age collapse.[39] This ushered in a period known as the Greek Dark Ages, from which written records are absent. Though the unearthed Linear B texts are too fragmentary for the reconstruction of the political landscape and can't support the existence of a larger state, contemporary Hittite and Egyptian records suggest the presence of a single state under a "Great King" based in mainland Greece.[40][41]  Archaic and Classical period Main articles: Ancient Greece, Archaic Greece, and Classical Greece  Greek territories and colonies during the Archaic period (750–550 BC) The end of the Dark Ages is traditionally dated to 776 BC, the year of the first Olympic Games.[42] The Iliad and the Odyssey, the foundational texts of Western literature, are believed to have been composed by Homer in the 7th or 8th centuries BC.[43][44] With the end of the Dark Ages, there emerged various kingdoms and city-states across the Greek peninsula, which spread to the shores of the Black Sea, Southern Italy ("Magna Graecia") and Asia Minor. These states and their colonies reached great levels of prosperity that resulted in an unprecedented cultural boom, that of classical Greece, expressed in architecture, drama, science, mathematics and philosophy. In 508 BC, Cleisthenes instituted the world's first democratic system of government in Athens.[45][46]   The Parthenon on the Acropolis of Athens, icon of classical Greece. By 500 BC, the Persian Empire controlled the Greek city states in Asia Minor and Macedonia.[47] Attempts by some of the Greek city-states of Asia Minor to overthrow Persian rule failed, and Persia invaded the states of mainland Greece in 492 BC, but was forced to withdraw after a defeat at the Battle of Marathon in 490 BC. In response, the Greek city-states formed the Hellenic League in 481 BC, led by Sparta, which was the first historically recorded union of Greek states since the mythical union of the Trojan War.[48][49] A second invasion by the Persians followed in 480 BC. Following decisive Greek victories in 480 and 479 BC at Salamis, Plataea, and Mycale, the Persians were forced to withdraw for a second time, marking their eventual withdrawal from all of their European territories. Led by Athens and Sparta, the Greek victories in the Greco-Persian Wars are considered a pivotal moment in world history,[50] as the 50 years of peace that followed are known as the Golden Age of Athens, the seminal period of ancient Greek development that laid many of the foundations of Western civilization.   Alexander the Great, whose conquests led to the Hellenistic Age. Lack of political unity within Greece resulted in frequent conflict between Greek states. The most devastating intra-Greek war was the Peloponnesian War (431–404 BC), won by Sparta and marking the demise of the Athenian Empire as the leading power in ancient Greece. Both Athens and Sparta were later overshadowed by Thebes and eventually Macedon, with the latter uniting most of the city-states of the Greek hinterland in the League of Corinth (also known as the Hellenic League or Greek League) under the control of Phillip II.[51] Despite this development, the Greek world remained largely fragmented and would not be united under a single power until the Roman years.[52] Sparta did not join the League and actively fought against it, raising an army led by Agis III to secure the city-states of Crete for Persia.[53]   Map of Alexander's short-lived empire (334–323 BC). After his death the lands were divided between the Diadochi Following the assassination of Phillip II, his son Alexander III ("The Great") assumed the leadership of the League of Corinth and launched an invasion of the Persian Empire with the combined forces of the League in 334 BC. Undefeated in battle, Alexander had conquered the Persian Empire in its entirety by 330 BC. By the time of his death in 323 BC, he had created one of the largest empires in history, stretching from Greece to India. Upon his death, his empire split into several kingdoms, the most famous of which were the Seleucid Empire, Ptolemaic Egypt, the Greco-Bactrian Kingdom, and the Indo-Greek Kingdom. Many Greeks migrated to Alexandria, Antioch, Seleucia, and the many other new Hellenistic cities in Asia and Africa.[54] Although the political unity of Alexander's empire could not be maintained, it resulted in the Hellenistic civilization and spread the Greek language and Greek culture in the territories conquered by Alexander.[55] Greek science, technology, and mathematics are generally considered to have reached their peak during the Hellenistic period.[56]  Hellenistic and Roman periods (323 BC – 4th century AD) Main articles: Hellenistic Greece and Roman Greece See also: Wars of Alexander the Great and Roman Empire  The Antikythera mechanism (c. 100 BC) is considered to be the first known mechanical analog computer (National Archaeological Museum, Athens).  A view from the ancient royal Macedonian tombs in Vergina After a period of confusion following Alexander's death, the Antigonid dynasty, descended from one of Alexander's generals, established its control over Macedon and most of the Greek city-states by 276 BC.[57] From about 200 BC the Roman Republic became increasingly involved in Greek affairs and engaged in a series of wars with Macedon.[58] Macedon's defeat at the Battle of Pydna in 168 BC signalled the end of Antigonid power in Greece.[59] In 146 BC, Macedonia was annexed as a province by Rome, and the rest of Greece became a Roman protectorate.[58][60]  The process was completed in 27 BC when the Roman Emperor Augustus annexed the rest of Greece and constituted it as the senatorial province of Achaea.[60] Despite their military superiority, the Romans admired and became heavily influenced by the achievements of Greek culture, hence Horace's famous statement: Graecia capta ferum victorem cepit ("Greece, although captured, took its wild conqueror captive").[61] The epics of Homer inspired the Aeneid of Virgil, and authors such as Seneca the younger wrote using Greek styles. Roman heroes such as Scipio Africanus, tended to study philosophy and regarded Greek culture and science as an example to be followed. Similarly, most Roman emperors maintained an admiration for things Greek in nature. The Roman Emperor Nero visited Greece in AD 66, and performed at the Ancient Olympic Games, despite the rules against non-Greek participation. Hadrian was also particularly fond of the Greeks. Before becoming emperor, he served as an eponymous archon of Athens.   The Odeon of Herodes Atticus in Athens, built in 161 AD Greek-speaking communities of the Hellenised East were instrumental in the spread of early Christianity in the 2nd and 3rd centuries,[62] and Christianity's early leaders and writers (notably St. Paul) were mostly Greek-speaking, though generally not from Greece itself.[63] The New Testament was written in Greek, and some of its sections (Corinthians, Thessalonians, Philippians, Revelation of St. John of Patmos) attest to the importance of churches in Greece in early Christianity. Nevertheless, much of Greece clung tenaciously to paganism, and ancient Greek religious practices were still in vogue in the late 4th century AD,[64] when they were outlawed by the Roman emperor Theodosius I in 391–392.[65] The last recorded Olympic games were held in 393,[66] and many temples were destroyed or damaged in the century that followed.[67] In Athens and rural areas, paganism is attested well into the sixth century AD[67] and even later.[68] The closure of the Neoplatonic Academy of Athens by the Emperor Justinian in 529 is considered by many to mark the end of antiquity, although there is evidence that the Academy continued its activities for some time after that.[67] Some remote areas such as the southeastern Peloponnese remained pagan until well into the 10th century AD.[69]  Medieval period (4th – 15th century) Main articles: Byzantine Greece and Frankokratia See also: Byzantine Empire and Fourth Crusade  Dome of Hagia Sophia, Thessaloniki (8th century), one of the 15 UNESCO's Paleochristian and Byzantine monuments of the city  The Palace of the Grand Master of the Knights of Rhodes, originally built in the late 7th century as a Byzantine citadel and beginning from 1309 used by the Knights Hospitaller as an administrative centre The Roman Empire in the east, following the fall of the Empire in the west in the 5th century, is conventionally known as the Byzantine Empire (but was simply called "Kingdom of the Romans" in its own time) and lasted until 1453. With its capital in Constantinople, its language and culture were Greek and its religion was predominantly Eastern Orthodox Christian.[70]  From the 4th century, the Empire's Balkan territories, including Greece, suffered from the dislocation of barbarian invasions.[citation needed] The raids and devastation of the Goths and Huns in the 4th and 5th centuries and the Slavic invasion of Greece in the 7th century resulted in a dramatic collapse in imperial authority in the Greek peninsula.[71] Following the Slavic invasion, the imperial government retained formal control of only the islands and coastal areas, particularly the densely populated walled cities such as Athens, Corinth and Thessalonica, while some mountainous areas in the interior held out on their own and continued to recognise imperial authority.[71] Outside of these areas, a limited amount of Slavic settlement is generally thought to have occurred, although on a much smaller scale than previously thought.[72][73] However, the view that Greece in late antiquity underwent a crisis of decline, fragmentation and depopulation is now considered outdated, as Greek cities show a high degree of institutional continuity and prosperity between the 4th and 6th centuries AD (and possibly later as well). In the early 6th century, Greece had approximately 80 cities according to the Synecdemus chronicle, and the period from the 4th to the 7th century AD is considered one of high prosperity not just in Greece but in the entire Eastern Mediterranean.[74]   The Byzantine (Eastern Roman) Empire after the death of Basil II in 1025 Until the 8th century almost all of modern Greece was under the jurisdiction of the Holy See of Rome according to the system of Pentarchy. Byzantine Emperor Leo III moved the border of the Patriarchate of Constantinople westward and northward in the 8th century.[75]  The Byzantine recovery of lost provinces began toward the end of the 8th century and most of the Greek peninsula came under imperial control again, in stages, during the 9th century.[76][77] This process was facilitated by a large influx of Greeks from Sicily and Asia Minor to the Greek peninsula, while at the same time many Slavs were captured and re-settled in Asia Minor and the few that remained were assimilated.[72] During the 11th and 12th centuries the return of stability resulted in the Greek peninsula benefiting from strong economic growth – much stronger than that of the Anatolian territories of the Empire.[76] During that time, the Greek Orthodox Church was also instrumental in the spread of Greek ideas to the wider Orthodox world.[78][full citation needed]  Following the Fourth Crusade and the fall of Constantinople to the "Latins" in 1204, mainland Greece was split between the Greek Despotate of Epirus (a Byzantine successor state) and French rule[79] (known as the Frankokratia), while some islands came under Venetian rule.[80] The re-establishment of the Byzantine imperial capital in Constantinople in 1261 was accompanied by the empire's recovery of much of the Greek peninsula, although the Frankish Principality of Achaea in the Peloponnese and the rival Greek Despotate of Epirus in the north both remained important regional powers into the 14th century, while the islands remained largely under Genoese and Venetian control.[79] During the Paleologi dynasty (1261–1453) a new era of Greek patriotism emerged accompanied by a turning back to ancient Greece.[81][82][83]  As such prominent personalities at the time also proposed changing the imperial title to "Emperor of the Hellenes",[81][83] and, in late fourteenth century, the emperor was frequently referred to as the "Emperor of the Hellenes".[84] Similarly, in several international treaties of that time the Byzantine emperor is styled as "Imperator Graecorum".[85]  In the 14th century, much of the Greek peninsula was lost by the Byzantine Empire at first to the Serbs and then to the Ottomans.[86] By the beginning of the 15th century, the Ottoman advance meant that Byzantine territory in Greece was limited mainly to its then-largest city, Thessaloniki, and the Peloponnese (Despotate of the Morea).[86] After the fall of Constantinople to the Ottomans in 1453, the Morea was one of the last remnants of the Byzantine Empire to hold out against the Ottomans. However, this, too, fell to the Ottomans in 1460, completing the Ottoman conquest of mainland Greece.[87] With the Turkish conquest, many Byzantine Greek scholars, who up until then were largely responsible for preserving Classical Greek knowledge, fled to the West, taking with them a large body of literature and thereby significantly contributing to the Renaissance.[88]  Venetian possessions and Ottoman rule (15th century – 1821) Main articles: Ottoman Greece and Stato da Màr Further information: Phanariotes and Ecumenical Patriarchate of Constantinople See also: Kingdom of Candia and Ionian Islands under Venetian rule  The Byzantine castle of Angelokastro successfully repulsed the Ottomans during the First Great Siege of Corfu in 1537, the siege of 1571, and the Second Great Siege of Corfu in 1716, causing them to abandon their plans to conquer Corfu.[89] While most of mainland Greece and the Aegean islands was under Ottoman control by the end of the 15th century, Cyprus and Crete remained Venetian territory and did not fall to the Ottomans until 1571 and 1670 respectively. The only part of the Greek-speaking world that escaped long-term Ottoman rule was the Ionian Islands, which remained Venetian until their capture by the First French Republic in 1797, then passed to the United Kingdom in 1809 until their unification with Greece in 1864.[90]  While some Greeks in the Ionian Islands and Constantinople lived in prosperity, and Greeks of Constantinople (Phanariotes) achieved positions of power within the Ottoman administration,[91] much of the population of mainland Greece suffered the economic consequences of the Ottoman conquest. Heavy taxes were enforced, and in later years the Ottoman Empire enacted a policy of creation of hereditary estates, effectively turning the rural Greek populations into serfs.[92]  The Greek Orthodox Church and the Ecumenical Patriarchate of Constantinople were considered by the Ottoman governments as the ruling authorities of the entire Orthodox Christian population of the Ottoman Empire, whether ethnically Greek or not. Although the Ottoman state did not force non-Muslims to convert to Islam, Christians faced several types of discrimination intended to highlight their inferior status in the Ottoman Empire. Discrimination against Christians, particularly when combined with harsh treatment by local Ottoman authorities, led to conversions to Islam, if only superficially. In the 19th century, many "crypto-Christians" returned to their old religious allegiance.[93]   The White Tower of Thessaloniki, one of the best-known Ottoman structures remaining in Greece. The nature of Ottoman administration of Greece varied, though it was invariably arbitrary and often harsh.[93] Some cities had governors appointed by the Sultan, while others (like Athens) were self-governed municipalities. Mountainous regions in the interior and many islands remained effectively autonomous from the central Ottoman state for many centuries.[94][page needed]  When military conflicts broke out between the Ottoman Empire and other states, Greeks usually took up arms against the Ottomans, with few exceptions.[citation needed] Prior to the Greek Revolution of 1821, there had been a number of wars which saw Greeks fight against the Ottomans, such as the Greek participation in the Battle of Lepanto in 1571, the Epirus peasants' revolts of 1600–1601 (led by the Orthodox bishop Dionysios Skylosophos), the Morean War of 1684–1699, and the Russian-instigated Orlov Revolt in 1770, which aimed at breaking up the Ottoman Empire in favour of Russian interests.[94][page needed] These uprisings were put down by the Ottomans with great bloodshed.[95][96] On the other side, many Greeks were conscripted as Ottoman citizens to serve in the Ottoman army (and especially the Ottoman navy), while also the Ecumenical Patriarchate of Constantinople, responsible for the Orthodox, remained in general loyal to the empire.  The 16th and 17th centuries are regarded as something of a "dark age" in Greek history, with the prospect of overthrowing Ottoman rule appearing remote with only the Ionian islands remaining free of Turkish domination. Corfu withstood three major sieges in 1537, 1571 and 1716 all of which resulted in the repulsion of the Ottomans. However, in the 18th century, due to their mastery of shipping and commerce, a wealthy and dispersed Greek merchant class arose. These merchants came to dominate trade within the Ottoman Empire, establishing communities throughout the Mediterranean, the Balkans, and Western Europe. Though the Ottoman conquest had cut Greece off from significant European intellectual movements such as the Reformation and the Enlightenment, these ideas together with the ideals of the French Revolution and romantic nationalism began to penetrate the Greek world via the mercantile diaspora.[97] In the late 18th century, Rigas Feraios, the first revolutionary to envision an independent Greek state, published a series of documents relating to Greek independence, including but not limited to a national anthem and the first detailed map of Greece, in Vienna. Feraios was murdered by Ottoman agents in 1798.[98][99]  Modern period Main article: History of modern Greece Greek War of Independence (1821–1832)  This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed. (October 2017) (Learn how and when to remove this template message) Main article: Greek War of Independence See also: Modern Greek Enlightenment, Greek Declaration of Independence, and First Hellenic Republic  The sortie (exodus) of Messolonghi, depicting the Third Siege of Missolonghi, painted by Theodoros Vryzakis.  The Battle of Navarino in 1827 secured Greek independence. In the late eighteenth century, an increase in secular learning during the Modern Greek Enlightenment led to the revival among Greeks of the diaspora of the notion of a Greek nation tracing its existence to ancient Greece, distinct from the other Orthodox peoples, and having a right to political autonomy. One of the organizations formed in this intellectual milieu was the Filiki Eteria, a secret organization formed by merchants in Odessa in 1814.[100] Appropriating a long-standing tradition of Orthodox messianic prophecy aspiring to the resurrection of the eastern Roman empire and creating the impression they had the backing of Tsarist Russia, they managed amidst a crisis of Ottoman trade, from 1815 onwards, to engage traditional strata of the Greek Orthodox world in their liberal nationalist cause.[101] The Filiki Eteria planned to launch revolution in the Peloponnese, the Danubian Principalities and Constantinople. The first of these revolts began on 6 March 1821 in the Danubian Principalities under the leadership of Alexandros Ypsilantis, but it was soon put down by the Ottomans. The events in the north spurred the Greeks of the Peloponnese into action and on 17 March 1821 the Maniots declared war on the Ottomans.[102]  By the end of the month, the Peloponnese was in open revolt against the Ottomans and by October 1821 the Greeks under Theodoros Kolokotronis had captured Tripolitsa. The Peloponnesian revolt was quickly followed by revolts in Crete, Macedonia and Central Greece, which would soon be suppressed. Meanwhile, the makeshift Greek navy was achieving success against the Ottoman navy in the Aegean Sea and prevented Ottoman reinforcements from arriving by sea. In 1822 and 1824 the Turks and Egyptians ravaged the islands, including Chios and Psara, committing wholesale massacres of the population.[102] Approximately three-quarters of the Chios' Greek population of 120,000 were killed, enslaved or died of disease.[103][104] This had the effect of galvanizing public opinion in western Europe in favour of the Greek rebels.[105]  Tensions soon developed among different Greek factions, leading to two consecutive civil wars. Meanwhile, the Ottoman Sultan negotiated with Mehmet Ali of Egypt, who agreed to send his son Ibrahim Pasha to Greece with an army to suppress the revolt in return for territorial gain.[106] Ibrahim landed in the Peloponnese in February 1825 and had immediate success: by the end of 1825, most of the Peloponnese was under Egyptian control, and the city of Missolonghi—put under siege by the Turks since April 1825—fell in April 1826. Although Ibrahim was defeated in Mani, he had succeeded in suppressing most of the revolt in the Peloponnese, and Athens had been retaken.  After years of negotiation, three great powers, France, Russian Empire, and the United Kingdom, decided to intervene in the conflict and each nation sent a navy to Greece. Following news that combined Ottoman–Egyptian fleets were going to attack the Greek island of Hydra, the allied fleet intercepted the Ottoman–Egyptian fleet at Navarino. A week-long standoff ended with the Battle of Navarino (20 October 1827) which resulted in the destruction of the Ottoman–Egyptian fleet. A French expeditionary force was dispatched to supervise the evacuation of the Egyptian army from the Peloponnese, while the Greeks proceeded to the captured part of Central Greece by 1828. As a result of years of negotiation, the nascent Greek state was finally recognised under the London Protocol in 1830.  Kingdom of Greece  This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed. (October 2017) (Learn how and when to remove this template message) Main article: Kingdom of Greece  The Entry of King Otto in Athens, painted by Peter von Hess in 1839. In 1827, Ioannis Kapodistrias, from Corfu, was chosen by the Third National Assembly at Troezen as the first governor of the First Hellenic Republic. Kapodistrias established a series of state, economic and military institutions. Soon tensions appeared between him and local interests. Following his assassination in 1831 and the subsequent London conference a year later, the Great Powers of Britain, France and Russia installed Bavarian Prince Otto von Wittelsbach as monarch.[107] Otto's reign was despotic, and in its first 11 years of independence Greece was ruled by a Bavarian oligarchy led by Joseph Ludwig von Armansperg as Prime Minister and, later, by Otto himself, who held the title of both King and Premier.[107] Throughout this period Greece remained under the influence of its three protecting Great Powers, France, Russia, and the United Kingdom, as well as Bavaria.[108] In 1843 an uprising forced Otto to grant a constitution and a representative assembly.  Despite the absolutism of Otto's reign, the early years proved instrumental in creating institutions which are still the bedrock of Greek administration and education.[109] Important steps were taken in the creation of the education system, maritime and postal communications, effective civil administration and, most importantly, the legal code.[110] Historical revisionism took the form of de-Byzantinification and de-Ottomanisation, in favour of promoting the country's Ancient Greek heritage.[111] In this spirit, the national capital was moved from Nafplio, where it had been since 1829, to Athens, which was at the time a village.[112] Religious reform also took place, and the Church of Greece was established as Greece's national church, although Otto remained a Catholic. 25 March, the day of Annunciation, was chosen as the anniversary of the Greek War of Independence in order to reinforce the link between Greek identity and Orthodoxy.[111] Pavlos Karolidis called the Bavarian efforts to create a modern state in Greece as "not only appropriate for the peoples' needs, but also based on excellent administrative principles of the era".[110]  Otto was deposed in the 23 October 1862 Revolution. Multiple causes led to his deposition and exile, including the Bavarian-dominated government, heavy taxation, and a failed attempt to annex Crete from the Ottoman Empire.[107] The catalyst for the revolt was Otto's dismissal of Konstantinos Kanaris from the Premiership.[109] A year later, he was replaced by Prince Wilhelm (William) of Denmark, who took the name George I and brought with him the Ionian Islands as a coronation gift from Britain. A new Constitution in 1864 changed Greece's form of government from constitutional monarchy to the more democratic crowned republic.[113][114][115] In 1875 the concept of parliamentary majority as a requirement for the formation of a government was introduced by Charilaos Trikoupis,[116] curbing the power of the monarchy to appoint minority governments of its preference.   The territorial evolution of the Kingdom of Greece from 1832 to 1947. Corruption, coupled with Trikoupis' increased spending to fund infrastructure projects like the Corinth Canal, overtaxed the weak Greek economy and forced the declaration of public insolvency in 1893. Greece also accepted the imposition of an International Financial Control authority to pay off the country's debtors. Another political issue in 19th-century Greece was uniquely Greek: the language question. The Greek people spoke a form of Greek called Demotic. Many of the educated elite saw this as a peasant dialect and were determined to restore the glories of Ancient Greek.  Government documents and newspapers were consequently published in Katharevousa (purified) Greek, a form which few ordinary Greeks could read. Liberals favoured recognising Demotic as the national language, but conservatives and the Orthodox Church resisted all such efforts, to the extent that, when the New Testament was translated into Demotic in 1901, riots erupted in Athens and the government fell (the Evangeliaka). This issue would continue to plague Greek politics until the 1970s.  All Greeks were united, however, in their determination to liberate the Hellenic lands under Ottoman rule. Especially in Crete, a prolonged revolt in 1866–1869 had raised nationalist fervour. When war broke out between Russia and the Ottomans in 1877, Greek popular sentiment rallied to Russia's side, but Greece was too poor and too concerned about British intervention, to officially enter the war. Nevertheless, in 1881, Thessaly and small parts of Epirus were ceded to Greece as part of the Treaty of Berlin, while frustrating Greek hopes of receiving Crete.  Greeks in Crete continued to stage regular revolts, and in 1897, the Greek government under Theodoros Deligiannis, bowing to popular pressure, declared war on the Ottomans. In the ensuing Greco-Turkish War of 1897, the badly trained and equipped Greek army was defeated by the Ottomans. Through the intervention of the Great Powers, however, Greece lost only a little territory along the border to Turkey, while Crete was established as an autonomous state under Prince George of Greece. With state coffers empty, fiscal policy came under International Financial Control.[citation needed] Alarmed by the abortive Ilinden uprising of the autonomist Internal Macedonian Revolutionary Organization (IMRO) in 1903, the Greek government, aiming to quell Komitadjis (IMRO bands) and detach the Slavophone peasants of the region from Bulgarian influence, sponsored a guerrilla campaign in Ottoman-ruled Macedonia, led by Greek officers and known as the Macedonian Struggle, which ended with the Young Turk Revolution in 1908.[117]  Expansion, disaster, and reconstruction See also: Greece in the Balkan Wars, Greece in World War I, National Schism, Asia Minor Campaign, and Second Hellenic Republic  Hellenic Army formation in the World War I Victory Parade in Arc de Triomphe, Paris, July 1919. Amidst general dissatisfaction with the seeming inertia and unattainability of national aspirations under the premiership of the cautious reformist Theotokis, a group of military officers organised a coup in August 1909 and shortly thereafter called to Athens Cretan politician Eleftherios Venizelos, who conveyed a vision of national regeneration. After winning two elections and becoming Prime Minister in 1910,[118] Venizelos initiated wide-ranging fiscal, social, and constitutional reforms, reorganised the military, made Greece a member of the Balkan League, and led the country through the Balkan Wars. By 1913, Greece's territory and population had almost doubled, annexing Crete, Epirus, and Macedonia. In the following years, the struggle between King Constantine I and charismatic Venizelos over the country's foreign policy on the eve of First World War dominated the country's political scene and divided the country into two opposing groups. During parts of WW1, Greece had two governments: A royalist pro-German one in Athens and a Venizelist pro-Entente one in Thessaloniki. The two governments were united in 1917, when Greece officially entered the war on the side of the Entente.   Map of Greater Greece after the Treaty of Sèvres, when the Megali Idea seemed close to fulfillment, featuring Eleftherios Venizelos as its supervising genius. In the aftermath of World War I, Greece attempted further expansion into Asia Minor, a region with a large native Greek population at the time, but was defeated in the Greco-Turkish War of 1919–1922, contributing to a massive flight of Asia Minor Greeks.[119][120] These events overlapped, with both happening during the Greek genocide (1914–1922),[121][122][123][124] a period during which, according to various sources,[125] Ottoman and Turkish officials contributed to the death of several hundred thousand Asia Minor Greeks, along with similar numbers of Assyrians and a rather larger number of Armenians. The resultant Greek exodus from Asia Minor was made permanent, and expanded, in an official Population exchange between Greece and Turkey. The exchange was part of the terms of the Treaty of Lausanne which ended the war.[126]  The following era was marked by instability, as over 1.5 million propertyless Greek refugees from Turkey had to be integrated into Greek society. Cappadocian Greeks, Pontian Greeks, and non-Greek followers of Greek Orthodoxy were all subject to the exchange as well. Some of the refugees could not speak the language and were from what had been unfamiliar environments to mainland Greeks, such as in the case of the Cappadocians and non-Greeks. The refugees also made a dramatic post-war population boost, as the number of refugees was more than a quarter of Greece's prior population.[127]  Following the catastrophic events in Asia Minor, the monarchy was abolished via a referendum in 1924 and the Second Hellenic Republic was declared. In 1935, a royalist general-turned-politician Georgios Kondylis took power after a coup d'état and abolished the republic, holding a rigged referendum, after which King George II returned to Greece and was restored to the throne.  Dictatorship, World War II, and reconstruction See also: 4th of August Regime, Balkans campaign, Axis occupation of Greece, Hellenic State, and Greek Civil War An agreement between Prime Minister Ioannis Metaxas and the head of state George II followed in 1936, which installed Metaxas as the head of a dictatorial regime known as the 4th of August Regime, inaugurating a period of authoritarian rule that would last, with short breaks, until 1974.[128] Although a dictatorship, Greece remained on good terms with Britain and was not allied with the Axis.   The Axis occupation of Greece.<bt>  Italian   German   Bulgarian   Dodecanese, Italian possession since 1912 On 28 October 1940, Fascist Italy demanded the surrender of Greece, but the Greek administration refused, and, in the following Greco-Italian War, Greece repelled Italian forces into Albania, giving the Allies their first victory over Axis forces on land. The Greek struggle and victory against the Italians received exuberant praise at the time.[129][130] Most prominent is the quote attributed to Winston Churchill: "Hence we will not say that Greeks fight like heroes, but we will say that heroes fight like Greeks."[129] French general Charles de Gaulle was among those who praised the fierceness of the Greek resistance. In an official notice released to coincide with the Greek national celebration of the Day of Independence, De Gaulle expressed his admiration for the Greek resistance:  In the name of the captured yet still alive French people, France wants to send her greetings to the Greek people who are fighting for their freedom. The 25 March 1941 finds Greece in the peak of their heroic struggle and in the top of their glory. Since the Battle of Salamis, Greece had not achieved the greatness and the glory which today holds.[130]  The country would eventually fall to urgently dispatched German forces during the Battle of Greece, despite the fierce Greek resistance, particularly in the Battle of the Metaxas Line. Adolf Hitler himself recognised the bravery and the courage of the Greek army, stating in his address to the Reichstag on 11 December 1941, that: "Historical justice obliges me to state that of the enemies who took up positions against us, the Greek soldier particularly fought with the highest courage. He capitulated only when further resistance had become impossible and useless."[131]   People in Athens celebrate the liberation from the Axis powers, October 1944. Postwar Greece would soon experience a civil war and political polarization. The Nazis proceeded to administer Athens and Thessaloniki, while other regions of the country were given to Nazi Germany's partners, Fascist Italy and Bulgaria. The occupation brought about terrible hardships for the Greek civilian population. Over 100,000 civilians died of starvation during the winter of 1941–1942, tens of thousands more died because of reprisals by Nazis and collaborators, the country's economy was ruined, and the great majority of Greek Jews (tens of thousands) were deported and murdered in Nazi concentration camps.[132][133] The Greek Resistance, one of the most effective resistance movements in Europe, fought vehemently against the Nazis and their collaborators. The German occupiers committed numerous atrocities, mass executions, and wholesale slaughter of civilians and destruction of towns and villages in reprisals. In the course of the concerted anti-guerrilla campaign, hundreds of villages were systematically torched and almost 1 million Greeks left homeless.[133] In total, the Germans executed some 21,000 Greeks, the Bulgarians 40,000, and the Italians 9,000.[134][clarification needed]  Following liberation and the Allied victory over the Axis, Greece annexed the Dodecanese Islands from Italy and regained Western Thrace from Bulgaria. The country almost immediately descended into a bloody civil war between communist forces and the anti-communist Greek government, which lasted until 1949 with the latter's victory. The conflict, considered one of the earliest struggles of the Cold War,[135] resulted in further economic devastation, mass population displacement and severe political polarisation for the next thirty years.[136]  Although the post-war decades were characterised by social strife and widespread marginalisation of the left in political and social spheres, Greece nonetheless experienced rapid economic growth and recovery, propelled in part by the U.S.-administered Marshall Plan.[137] In 1952, Greece joined NATO, reinforcing its membership in the Western Bloc of the Cold War.  Military regime (1967–74) King Constantine II's dismissal of George Papandreou's centrist government in July 1965 prompted a prolonged period of political turbulence, which culminated in a coup d'état on 21 April 1967 by the Regime of the Colonels. Under the junta, civil rights were suspended, political repression was intensified, and human rights abuses, including state-sanctioned torture, were rampant. Economic growth remained rapid before plateauing in 1972. The brutal suppression of the Athens Polytechnic uprising on 17 November 1973 set in motion the events that caused the fall of the Papadopoulos regime, resulting in a counter-coup which overthrew Georgios Papadopoulos and established brigadier Dimitrios Ioannidis as the new junta strongman. On 20 July 1974, Turkey invaded the island of Cyprus in response to a Greek-backed Cypriot coup, triggering a political crisis in Greece that led to the regime's collapse and the restoration of democracy through Metapolitefsi.  Third Hellenic Republic  This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed. (October 2017) (Learn how and when to remove this template message) Main article: Third Hellenic Republic  Signing at Zappeion by Constantine Karamanlis of the documents for the accession of Greece to the European Communities in 1979. The former prime minister Konstantinos Karamanlis was invited back from Paris where he had lived in self-exile since 1963, marking the beginning of the Metapolitefsi era. The first multiparty elections since 1964 were held on the first anniversary of the Polytechnic uprising. A democratic and republican constitution was promulgated on 11 June 1975 following a referendum which chose to not restore the monarchy.  Meanwhile, Andreas Papandreou, George Papandreou's son, founded the Panhellenic Socialist Movement (PASOK) in response to Karamanlis's conservative New Democracy party, with the two political formations dominating in government over the next four decades. Greece rejoined NATO in 1980.[e][138] Greece became the tenth member of the European Communities (subsequently subsumed by the European Union) on 1 January 1981, ushering in a period of sustained growth. Widespread investments in industrial enterprises and heavy infrastructure, as well as funds from the European Union and growing revenues from tourism, shipping, and a fast-growing service sector raised the country's standard of living to unprecedented levels. Traditionally strained relations with neighbouring Turkey improved when successive earthquakes hit both nations in 1999, leading to the lifting of the Greek veto against Turkey's bid for EU membership.  Recent history The country adopted the euro in 2001 and successfully hosted the 2004 Summer Olympic Games in Athens.[139] More recently, Greece has suffered greatly from the late-2000s recession and has been central to the related European sovereign debt crisis. Due to the adoption of the euro, when Greece experienced financial crisis, it could no longer devalue its currency to regain competitiveness. Youth unemployment was especially high during the 2000s.[140] The Greek government-debt crisis, and subsequent austerity policies, have resulted in protests and social strife. Left-wing Syriza, led by Prime Minister Alexis Tsipras, governed Greece since 2015 until 2019. Syriza gained support by opposing the austerity policy that had affected Greeks since the beginning of the Greek government-debt crisis. However, prime minister Tsipras was succeeded by Kyriakos Mitsotakis after the landslide victory of centre-right New Democracy in the 2019 elections.[141]  In March 2020, Greece's parliament elected a non-partisan candidate, Ekaterini Sakellaropoulou, as the first female President of Greece.[142]  Geography and climate Main article: Geography of Greece 000 Greqia harta.PNG Flag of Albania.svgAlbaniaFlag of North Macedonia.svgNorth MacedoniaFlag of Bulgaria.svgBulgariaFlag of Turkey.svgTurkeyFlag of Greece.svgGreeceAthensThessalonikiKavalaThasosAlexandroupoliSamothraceCorfuIgoumenitsaLarissaVolosIoanninaChalcisPatrasCorinthNafplionSpartaAreopoliPiraeusEleusinaLauriumHeraklionMacedoniaThraceEpirusThessalyEuboeaCentral GreecePeloponneseMt. OlympusLefkadaCephaloniaZakynthosLemnosLesbosChiosSamosAndrosTinosMykonosIcariaPatmosNaxosMilosSantoriniKosRhodesKastellorizoKarpathosKassosKythiraGavdosAegeanSeaSea of CreteMyrtoanSeaIonianSeaMediterraneanSeaCreteAegeanIslandsCycladesDodecaneseIonianIslands  Navagio (shipwreck) bay, Zakynthos island Located in Southern[143] and Southeast Europe,[144] Greece consists of a mountainous, peninsular mainland jutting out into the sea at the southern end of the Balkans, ending at the Peloponnese peninsula (separated from the mainland by the canal of the Isthmus of Corinth) and strategically located at the crossroads of Europe, Asia, and Africa.[f] Due to its highly indented coastline and numerous islands, Greece has the 11th longest coastline in the world with 13,676 km (8,498 mi);[150] its land boundary is 1,160 km (721 mi). The country lies approximately between latitudes 34° and 42° N, and longitudes 19° and 30° E, with the extreme points being:[151]  North: Ormenio village South: Gavdos island East: Strongyli (Kastelorizo, Megisti) island West: Othonoi island Eighty percent of Greece consists of mountains or hills, making the country one of the most mountainous in Europe. Mount Olympus, the mythical abode of the Greek Gods, culminates at Mytikas peak 2,918 metres (9,573 ft),[152] the highest in the country. Western Greece contains a number of lakes and wetlands and is dominated by the Pindus mountain range. The Pindus, a continuation of the Dinaric Alps, reaches a maximum elevation of 2,637 m (8,652 ft) at Mt. Smolikas (the second-highest in Greece) and historically has been a significant barrier to east–west travel.  The Pindus range continues through the central Peloponnese, crosses the islands of Kythera and Antikythera and finds its way into southwestern Aegean, in the island of Crete where it eventually ends. The islands of the Aegean are peaks of underwater mountains that once constituted an extension of the mainland. Pindus is characterised by its high, steep peaks, often dissected by numerous canyons and a variety of other karstic landscapes. The spectacular Vikos Gorge, part of the Vikos-Aoos National Park in the Pindus range, is listed by the Guinness book of World Records as the deepest gorge in the world.[153] Another notable formation are the Meteora rock pillars, atop which have been built medieval Greek Orthodox monasteries.  Northeastern Greece features another high-altitude mountain range, the Rhodope range, spreading across the region of East Macedonia and Thrace; this area is covered with vast, thick, ancient forests, including the famous Dadia Forest in the Evros regional unit, in the far northeast of the country.  Extensive plains are primarily located in the regions of Thessaly, Central Macedonia and Thrace. They constitute key economic regions as they are among the few arable places in the country. Rare marine species such as the pinniped seals and the loggerhead sea turtle live in the seas surrounding mainland Greece, while its dense forests are home to the endangered brown bear, the Eurasian lynx, the roe deer and the wild goat.  Islands Main article: List of islands of Greece  The Greek mainland and several small islands seen from Nydri, Lefkada Greece features a vast number of islands - between 1,200 and 6,000, depending on the definition,[154] 227 of which are inhabited - and is considered a non-contiguous transcontinental country. Crete is the largest and most populous island; Euboea, separated from the mainland by the 60 m-wide Euripus Strait, is the second largest, followed by Lesbos and Rhodes.  The Greek islands are traditionally grouped into the following clusters: the Argo-Saronic Islands in the Saronic gulf near Athens, the Cyclades, a large but dense collection occupying the central part of the Aegean Sea, the North Aegean islands, a loose grouping off the west coast of Turkey, the Dodecanese, another loose collection in the southeast between Crete and Turkey, the Sporades, a small tight group off the coast of northeast Euboea, and the Ionian Islands, located to the west of the mainland in the Ionian Sea.  Climate Further information: Climate of Greece The climate of Greece is primarily Mediterranean,[155] featuring mild, wet winters and hot, dry summers.[156] This climate occurs at all coastal locations, including Athens, the Cyclades, the Dodecanese, Crete, the Peloponnese, the Ionian Islands and parts of the Central Continental Greece region. The Pindus mountain range strongly affects the climate of the country, as areas to the west of the range are considerably wetter on average (due to greater exposure to south-westerly systems bringing in moisture) than the areas lying to the east of the range (due to a rain shadow effect).  The mountainous areas of Northwestern Greece (parts of Epirus, Central Greece, Thessaly, Western Macedonia) as well as in the mountainous central parts of Peloponnese – including parts of the regional units of Achaea, Arcadia and Laconia – feature an Alpine climate with heavy snowfalls. The inland parts of northern Greece, in Central Macedonia and East Macedonia and Thrace feature a temperate climate with cold, damp winters and hot, dry summers with frequent thunderstorms. Snowfalls occur every year in the mountains and northern areas, and brief snowfalls are not unknown even in low-lying southern areas, such as Athens.[157]  Biodiversity Main article: Wildlife of Greece  Mount Olympus is the highest mountain in Greece and mythical abode of the Gods of Olympus Phytogeographically, Greece belongs to the Boreal Kingdom and is shared between the East Mediterranean province of the Mediterranean Region and the Illyrian province of the Circumboreal Region. According to the World Wide Fund for Nature and the European Environment Agency, the territory of Greece can be subdivided into six ecoregions: the Illyrian deciduous forests, Pindus Mountains mixed forests, Balkan mixed forests, Rhodope montane mixed forests, Aegean and Western Turkey sclerophyllous and mixed forests, and Crete Mediterranean forests.[158] It had a 2018 Forest Landscape Integrity Index mean score of 6.6/10, ranking it 70th globally out of 172 countries.[159]  Politics Main article: Politics of Greece  The building of the Hellenic Parliament (Old Royal Palace) in central Athens.  Count Ioannis Kapodistrias, first governor, founder of the modern Greek State, and distinguished European diplomat Greece is a unitary parliamentary republic.[160] The current Constitution was drawn up and adopted by the Fifth Revisionary Parliament of the Hellenes and entered into force in 1975 after the fall of the military junta of 1967–1974. It has been revised three times since, in 1986, 2001, 2008 and 2019. The Constitution, which consists of 120 articles, provides for a separation of powers into executive, legislative, and judicial branches, and grants extensive specific guarantees (further reinforced in 2001) of civil liberties and social rights.[161][162] Women's suffrage was guaranteed with an amendment to the 1952 Constitution.  The nominal head of state is the President of the Republic, who is elected by the Parliament for a five-year term.[160] According to the Constitution, executive power is exercised by the President and the Government.[160] However, the Constitutional amendment of 1986 curtailed the President's duties and powers to a significant extent, rendering the position largely ceremonial; most political power is thus vested in the Prime Minister, Greece's head of government.[163] The position is filled by the current leader of the political party that can obtain a vote of confidence by the Parliament. The President of the Republic formally appoints the Prime Minister and, on his recommendation, appoints and dismisses the other members of the Cabinet.[160]  Legislative powers are exercised by a 300-member elective unicameral Parliament.[160] Statutes passed by the Parliament are promulgated by the President of the Republic.[160] Parliamentary elections are held every four years, but the President of the Republic is obliged to dissolve the Parliament earlier on the proposal of the Cabinet, in view of dealing with a national issue of exceptional importance.[160] The President is also obliged to dissolve the Parliament earlier, if the opposition manages to pass a motion of no confidence.[160] The voting age is 17.[164]  According to a 2016 report by the OECD, Greeks display a moderate level of civic participation compared to most other developed countries; voter turnout was 64 percent during recent elections, lower than the OECD average of 69 percent.[165]  Political parties  This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed. (October 2017) (Learn how and when to remove this template message) Main article: Political parties of Greece  Kyriakos Mitsotakis, Prime Minister since 2019 Since the restoration of democracy, the Greek party system was dominated by the liberal-conservative New Democracy (ND) and the social-democratic Panhellenic Socialist Movement (PASOK).[g] Other parties represented in the Hellenic Parliament include the Coalition of the Radical Left (SYRIZA), the Communist Party of Greece (KKE), Greek Solution and MeRA25.  PASOK and New Democracy largely alternated in power until the outbreak of the government-debt crisis in 2009. From that time, the two major parties, New Democracy and PASOK, experienced a sharp decline in popularity.[166][167][168][169][170] In November 2011, the two major parties joined the smaller Popular Orthodox Rally in a grand coalition, pledging their parliamentary support for a government of national unity headed by former European Central Bank vice-president Lucas Papademos.[171] Panos Kammenos voted against this government and he split off from ND forming the right-wing populist Independent Greeks.  The coalition government led the country to the parliamentary elections of May 2012. The power of the traditional Greek political parties, PASOK and New Democracy, declined from 43% to 13% and from 33% to 18%, respectively. The left-wing party of SYRIZA became the second major party, with an increase from 4% to 16%. No party could form a sustainable government, which led to the parliamentary elections of June 2012. The result of the second elections was the formation of a coalition government composed of New Democracy (29%), PASOK (12%) and Democratic Left (6%) parties.  SYRIZA has since overtaken PASOK as the main party of the centre-left .[172] Alexis Tsipras led SYRIZA to victory in the general election held on 25 January 2015, falling short of an outright majority in Parliament by just two seats.[173] The following morning, Tsipras reached an agreement with Independent Greeks party to form a coalition, and he was sworn in as Prime Minister of Greece.[174] Tsipras called snap elections in August 2015, resigning from his post, which led to a month-long caretaker administration headed by judge Vassiliki Thanou-Christophilou, Greece's first female prime minister.[175] In the September 2015 general election, Alexis Tsipras led SYRIZA to another victory, winning 145 out of 300 seats[176] and re-forming the coalition with the Independent Greeks.[177] However, he was defeated in the July 2019 general election by Kyriakos Mitsotakis who leads New Democracy.[178] On 7 July 2019, Kyriakos Mitsotakis was sworn in as the new Prime Minister of Greece. He formed a centre-right government after the landslide victory of his New Democracy party.[179]  Foreign relations Main article: Foreign relations of Greece  Representation through:[180]   embassy   embassy in another country   general consulate   no representation   Greece Greece's foreign policy is conducted through the Ministry of Foreign Affairs and its head, the Minister for Foreign Affairs, currently Nikos Dendias. Officially, the main aims of the Ministry are to represent Greece before other states and international organizations;[181] safeguard the interests of the Greek state and of its citizens abroad;[181] promote Greek culture;[181] foster closer relations with the Greek diaspora;[181] and encourage international cooperation.[181]  Following the resolution of the Macedonia naming dispute with the Prespa Agreement in 2018, the Ministry identifies two remaining issues of particular importance to the Greek state: Turkish challenges to Greek sovereignty rights in the Aegean Sea and corresponding airspace and the Cyprus dispute involving the Turkish occupation of Northern Cyprus.[182]  There is a long-standing conflict between Turkey and Greece over natural resources in the eastern Mediterranean. Turkey doesn't recognize a legal continental shelf and exclusive economic zone around the Greek islands.[183]  Additionally, due to its political and geographical proximity to Europe, Asia, the Middle East and Africa, Greece is a country of significant geostrategic importance, which it has leveraged to develop a regional policy to help promote peace and stability in the Balkans, the Mediterranean, and the Middle East.[184] This has accorded the country middle power status in global affairs.[185]  Greece is a member of numerous international organizations, including the Council of Europe, the European Union, the Union for the Mediterranean, the North Atlantic Treaty Organization, the Organisation internationale de la francophonie and the United Nations, of which it is a founding member.  Law and justice Main articles: Judicial system of Greece and Law enforcement in Greece The Judiciary is independent of the executive and the legislature and comprises three Supreme Courts: the Court of Cassation (Άρειος Πάγος), the Council of State (Συμβούλιο της Επικρατείας) and the Court of Auditors (Ελεγκτικό Συνέδριο). The Judiciary system is also composed of civil courts, which judge civil and penal cases and administrative courts, which judge disputes between the citizens and the Greek administrative authorities.  The Hellenic Police (Greek: Ελληνική Αστυνομία) is the national police force of Greece. It is a very large agency with its responsibilities ranging from road traffic control to counter-terrorism. It was established in 1984 under Law 1481/1-10-1984 (Government Gazette 152 A) as the result of the fusion of the Gendarmerie (Χωροφυλακή, Chorofylaki) and the Cities Police (Αστυνομία Πόλεων, Astynomia Poleon) forces.[186]  Military  This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed. (October 2017) (Learn how and when to remove this template message) Main article: Military of Greece  The Greek-made frigate Psara used by the Hellenic Navy  Boeing AH-64A Apache used by the Hellenic Army Aviation  An F-16 Fighting Falcon, the main combat aircraft of the Hellenic Air Force, during an airshow  A Leopard 2A6 HEL of the Hellenic Army on parade in Athens The Hellenic Armed Forces are overseen by the Hellenic National Defense General Staff (Greek: Γενικό Επιτελείο Εθνικής Άμυνας – ΓΕΕΘΑ), with civilian authority vested in the Ministry of National Defence. It consists of three branches:  Hellenic Army (Ellinikos Stratos, ES) Hellenic Navy (Elliniko Polemiko Navtiko, EPN) Hellenic Air Force (Elliniki Polemiki Aeroporia, EPA) Moreover, Greece maintains the Hellenic Coast Guard for law enforcement at sea, search and rescue, and port operations. Though it can support the navy during wartime, it resides under the authority of the Ministry of Shipping.  Greek military personnel total 364,050, of whom 142,700 are active and 221,350 are reserve. Greece ranks 28th in the world in the number of citizens serving in the armed forces. Mandatory military service is nine months for the Army and one year for the Navy and Air Force.[187] Additionally, Greek males between the ages of 18 and 60 who live in strategically sensitive areas may be required to serve part-time in the National Guard.  As a member of NATO, the Greek military participates in exercises and deployments under the auspices of the alliance, although its involvement in NATO missions is minimal.[188] Greece spends over US$7 billion annually on its military, or 2.3 percent of GDP, the 24th-highest in the world in absolute terms, the seventh-highest on a per capita basis, and the second-highest in NATO after the United States. Moreover, Greece is one of only five NATO countries to meet or surpass the minimum defence spending target of 2 percent of GDP.  Administrative divisions Main article: Administrative divisions of Greece Since the Kallikratis programme reform entered into effect on 1 January 2011, Greece has consisted of 13 regions subdivided into a total of 325, from 2019 232 (Cleisthenes programme), municipalities. The 54 old prefectures and prefecture-level administrations have been largely retained as sub-units of the regions. Seven decentralised administrations group one to three regions for administrative purposes on a regional basis. There is also one autonomous area, Mount Athos (Greek: Agio Oros, "Holy Mountain"), which borders the region of Central Macedonia.  Map	No.	Region	Capital	Area (km2)	Area (sq. mi.)	Population[189]	GDP (bn)[190] Peripheries of Greece numbered.svg 1	Attica	Athens	3,808.10	1,470.32	3,828,434	€83.469 2	Central Greece	Lamia	15,549.31	6,003.62	547,390	€7.926 3	Central Macedonia	Thessaloniki	18,810.52	7,262.78	1,882,108	€23.850 4	Crete	Heraklion	8,259	3,189	623,065	€8.654 5	East Macedonia and Thrace	Komotini	14,157.76	5,466.34	608,182	€6.709 6	Epirus	Ioannina	9,203.22	3,553.38	336,856	€3.843 7	Ionian Islands	Corfu	2,306.94	890.71	207,855	€3.064 8	North Aegean	Mytilene	3,835.91	1,481.05	199,231	€2.412 9	Peloponnese	Tripoli	15,489.96	5,980.71	577,903	€7.683 10	South Aegean	Ermoupoli	5,285.99	2,040.93	309,015	€5.888 11	Thessaly	Larissa	14,036.64	5,419.58	732,762	€9.006 12	West Greece	Patras	11,350.18	4,382.33	679,796	€7.847 13	West Macedonia	Kozani	9,451	3,649	283,689	€3.849 No.	Autonomous state	Capital	Area (km2)	Area (sq. mi.)	Population	GDP (bn) (14)	Mount Athos	Karyes	390	151	1,830	N/A Economy Main articles: Economy of Greece and List of Greek subdivisions by GDP Introduction  A proportional representation of Greece exports, 2019 According to World Bank statistics for the year 2013, the economy of Greece is the 43rd largest by nominal gross domestic product at $242 billion[191] and 53rd largest by purchasing power parity (PPP) at $284 billion.[192] Additionally, Greece is the 15th largest economy in the 27-member European Union.[193] In terms of per capita income, Greece is ranked 41st or 47th in the world at $18,168 and $29,045 for nominal GDP and PPP respectively. The Greek economy is classified as advanced[194][195][196][197][198] and high-income.[199][197]  Graphical depiction of Greece's product exports in percent for 2018. Graphical depiction of Greece's product exports (%) in 2018 Greece is a developed country with a high standard of living and a high ranking in the Human Development Index.[200][201][202] Its economy mainly comprises the service sector (85.0%) and industry (12.0%), while agriculture makes up 3.0% of the national economic output.[203] Important Greek industries include tourism (with 14.9 million[204] international tourists in 2009, it is ranked as the 7th most visited country in the European Union[204] and 16th in the world[204] by the United Nations World Tourism Organization) and merchant shipping (at 16.2%[205] of the world's total capacity, the Greek merchant marine is the largest in the world[205]), while the country is also a considerable agricultural producer (including fisheries) within the union.  Greek unemployment stood at 21.7% in April 2017.[206] The youth unemployment rate (42.3% in March 2018) is extremely high compared to EU standards.[207]  With an economy larger than all the other Balkan economies combined, Greece is the largest economy in the Balkans,[208][209][210] and an important regional investor.[208][209] Greece is the number-two foreign investor of capital in Albania, the number-three foreign investor in Bulgaria, at the top-three of foreign investors in Romania and Serbia and the most important trading partner and largest foreign investor of North Macedonia. Greek banks open a new branch somewhere in the Balkans on an almost weekly basis.[211][212][213] The Greek telecommunications company OTE has become a strong investor in Yugoslavia and other Balkan countries.[211]  Greece was a founding member of the Organisation for Economic Co-operation and Development (OECD) and the Organization of the Black Sea Economic Cooperation (BSEC). In 1979 the accession of the country in the European Communities and the single market was signed, and the process was completed in 1982. Greece was accepted into the Economic and Monetary Union of the European Union on 19 June 2000, and in January 2001 adopted the Euro as its currency, replacing the Greek drachma at an exchange rate of 340.75 drachma to the Euro.[214] Greece is also a member of the International Monetary Fund and the World Trade Organization, and is ranked 24th on the KOF Globalization Index for 2013.  Debt crisis (2010–2018) Main article: Greek government-debt crisis  Greece's debt percentage since 1977, compared to the average of the Eurozone The Greek economy had fared well for much of the 20th century, with high growth rates and low public debt.[215] Even until the eve of the Financial crisis of 2007–2008, it featured high rates of growth, which, however, were coupled with high structural deficits, thus maintaining a (roughly unchanged throughout this period) public debt to GDP ratio of just over 100%.[215] The Greek crisis was triggered by the turmoil of the 2007–2009 Great Recession, which led the budget deficits of several Western nations to reach or exceed 10% of GDP.[215] In Greece's case, the high budget deficit (which, after several corrections and revisions, was revealed that it had been allowed to reach 10.2% and 15.1% of GDP in 2008 and 2009, respectively) was coupled with a high public debt to GDP ratio (relatively stable, at just over 100% until 2007 - as calculated after all corrections). Thus, the country appeared to lose control of its public debt to GDP ratio, which already reached 127% of GDP in 2009.[216] In addition, being a member of the Eurozone, the country had essentially no autonomous monetary policy flexibility. Finally, there was an effect of controversies about Greek statistics (due to the aforementioned drastic budget deficit revisions which led to an increase in the calculated value of the Greek public debt by about 10%, i.e., a public debt to GDP of about 100% until 2007), while there have been arguments about a possible effect of media reports. Consequently, Greece was "punished" by the markets which increased borrowing rates, making it impossible for the country to finance its debt since early 2010.  The above revisions were largely connected with the fact that in the years before the crisis Goldman Sachs, JPMorgan Chase, and numerous other banks had developed financial products which enabled the governments of Greece, Italy, and many other European countries to hide their borrowing.[217][218][219][220][221][222][223][224][225] Dozens of similar agreements were concluded across Europe whereby banks supplied cash in advance in exchange for future payments by the governments involved; in turn, the liabilities of the involved countries were "kept off the books".[225][226][227][228][229][230] These conditions had enabled Greece as well as other European governments to spend beyond their means, while meeting the deficit targets set out in the Maastricht Treaty.[230][225][231]  In May 2010, the Greece's deficit was again revised and estimated to be 13.6%[232] which was the second highest in the world relative to GDP, with Iceland in first place at 15.7% and the United Kingdom in third with 12.6%.[233] Public debt was forecast, according to some estimates, to hit 120% of GDP in the same year,[234] causing a crisis of confidence in Greece's ability pay back loans.  To avert a sovereign default, Greece, the other Eurozone members, and the International Monetary Fund agreed on a rescue package which involved giving Greece an immediate €45 billion in loans, with additional funds to follow, totaling €110 billion.[235][236] To secure the funding, Greece was required to adopt harsh austerity measures to bring its deficit under control.[237] A second bail-out amounting to €130 billion ($173 billion) was agreed in 2012, subject to strict conditions, including financial reforms and further austerity measures.[238] A debt haircut was also agreed as part of the deal.[238] Greece achieved a primary government budget surplus in 2013, while in April 2014, it returned to the global bond market. Greece returned to growth after six years of economic decline in the second quarter of 2014,[239] and was the Eurozone's fastest-growing economy in the third quarter.[240] A third bailout was agreed in July 2015, after a confrontation with the newly elected government of Alexis Tsipras.  There was a 25% drop in Greece's GDP, connected with the bailout programmes.[215][241] This had a critical effect: the Debt-to-GDP ratio, the key factor defining the severity of the crisis, would jump from its 2009 level of 127% to about 170%, solely due to the shrinking economy.[citation needed] In a 2013 report, the IMF admitted that it had underestimated the effects of so extensive tax hikes and budget cuts on the country's GDP and issued an informal apology.[242][243][244] The Greek programmes imposed a very rapid improvement in structural primary balance (at least two times faster than for other Eurozone bailed-out countries[245]). The policies have been blamed for worsening the crisis,[246][247] while Greece's president, Prokopis Pavlopoulos, stressed the creditors' share in responsibility for the depth of the crisis.[248][249] Greek Prime Minister, Alexis Tsipras, asserted that errors in the design of the first two programmes which led to a loss of 25% of the Greek economy due to the harsh imposition of excessive austerity.[241]  Between 2009 and 2017 the Greek government debt rose from €300 bn to €318 bn, i.e. by only about 6% (thanks, in part, to the 2012 debt restructuring);[216][250] however, during the same period, the critical debt-to-GDP ratio shot up from 127% to 179%[216] basically due to the severe GDP drop during the handling of the crisis.[215]  Greece's bailouts successfully ended (as declared) on 20 August 2018.[251]  Agriculture Main article: Agriculture in Greece  Sun-drying of Zante currant on Zakynthos In 2010, Greece was the European Union's largest producer of cotton (183,800 tons) and pistachios (8,000 tons)[252] and ranked second in the production of rice (229,500 tons)[252] and olives (147,500 tons),[253] third in the production of figs (11,000 tons),[253] almonds (44,000 tons),[253] tomatoes (1,400,000 tons),[253] and watermelons (578,400 tons)[253] and fourth in the production of tobacco (22,000 tons).[252] Agriculture contributes 3.8% of the country's GDP and employs 12.4% of the country's labor force.  Greece is a major beneficiary of the Common Agricultural Policy of the European Union. As a result of the country's entry to the European Community, much of its agricultural infrastructure has been upgraded and agricultural output increased. Between 2000 and 2007, organic farming in Greece increased by 885%, the highest change percentage in the EU.  Energy Main article: Energy in Greece  Solar-power generation potential in Greece Electricity production in Greece is dominated by the state-owned Public Power Corporation (known mostly by its acronym ΔΕΗ, transliterated as DEI). In 2009 DEI supplied for 85.6% of all electric energy demand in Greece,[254] while the number fell to 77.3% in 2010.[254] Almost half (48%) of DEI's power output is generated using lignite, a drop from the 51.6% in 2009.[254]  Twelve percent of Greece's electricity comes from hydroelectric power plants[255] and another 20% from natural gas.[255] Between 2009 and 2010, independent companies' energy production increased by 56%,[254] from 2,709 Gigawatt hour in 2009 to 4,232 GWh in 2010.[254]  In 2012, renewable energy accounted for 13.8% of the country's total energy consumption,[256] a rise from the 10.6% it accounted for in 2011,[256] a figure almost equal to the EU average of 14.1% in 2012.[256] 10% of the country's renewable energy comes from solar power,[257] while most comes from biomass and waste recycling.[257] In line with the European Commission's Directive on Renewable Energy, Greece aims to get 18% of its energy from renewable sources by 2020.[258]  In 2013, according to the independent power transmission operator in Greece (ΑΔΜΗΕ) more than 20% of the electricity in Greece has been produced from renewable energy sources and hydroelectric powerplants. This percentage in April reached 42%. Greece currently does not have any nuclear power plants in operation; however, in 2009 the Academy of Athens suggested that research in the possibility of Greek nuclear power plants begin.[259]  Maritime industry Main articles: Greek shipping and List of ports in Greece See also: Economy of Greece » Maritime industry  Greek companies control 16.2% of the world's total merchant fleet[citation needed] making it the largest in the world. They are ranked in the top 5 for all kinds of ships, including first for tankers and bulk carriers. The shipping industry has been a key element of Greek economic activity since ancient times.[260] Shipping remains one of the country's most important industries, accounting for 4.5 percent of GDP, employing about 160,000 people (4 percent of the workforce), and representing a third of the trade deficit.[261]  According to a 2011 report by the United Nations Conference on Trade and Development, the Greek Merchant Navy is the largest in the world at 16.2 percent of total global capacity,[205] up from 15.96 percent in 2010[262] but below the peak of 18.2 percent in 2006.[263] The country's merchant fleet ranks first in total tonnage (202 million dwt),[205] fourth in total number of ships (at 3,150), first in both tankers and dry bulk carriers, fourth in the number of containers, and fifth in other ships.[264] However, today's fleet roster is smaller than an all-time high of 5,000 ships in the late 1970s.[260] Additionally, the total number of ships flying a Greek flag (includes non-Greek fleets) is 1,517, or 5.3 percent of the world's dwt (ranked fifth globally).[262]  During the 1960s, the size of the Greek fleet nearly doubled, primarily through the investment undertaken by the shipping magnates, Aristotle Onassis and Stavros Niarchos.[265] The basis of the modern Greek maritime industry was formed after World War II when Greek shipping businessmen were able to amass surplus ships sold to them by the U.S. government through the Ship Sales Act of the 1940s.[265]  Greece has a significant shipbuilding and ship maintenance industry. The six shipyards around the port of Piraeus are among the largest in Europe.[266] In recent years, Greece has also become a leader in the construction and maintenance of luxury yachts.[267]  Tourism Main article: Tourism in Greece  Santorini, a popular tourist destination, is ranked as the world's top island in many travel magazines and sites.[268][269] Tourism has been a key element of the economic activity in the country and one of the country's most important sectors, contributing 20.6% of the gross domestic product as of 2018.[270] Greece welcomed over 28 million visitors in 2016,[271] which is an increase from the 26.5 million tourists it welcomed in 2015 and the 19.5 million in 2009,[272] and the 17.7 million tourists in 2007,[273] making Greece one of the most visited countries in Europe in the recent years.  The vast majority of visitors in Greece in 2007 came from the European continent, numbering 12.7 million,[274] while the most visitors from a single nationality were those from the United Kingdom, (2.6 million), followed closely by those from Germany (2.3 million).[274] In 2010, the most visited region of Greece was that of Central Macedonia, with 18% of the country's total tourist flow (amounting to 3.6 million tourists), followed by Attica with 2.6 million and the Peloponnese with 1.8 million.[272] Northern Greece is the country's most-visited geographical region, with 6.5 million tourists, while Central Greece is second with 6.3 million.[272]  In 2010, Lonely Planet ranked Greece's northern and second-largest city of Thessaloniki as the world's fifth-best party town worldwide, comparable to other cities such as Dubai and Montreal.[275] In 2011, Santorini was voted as "The World's Best Island" in Travel + Leisure.[276] Its neighboring island Mykonos, came in fifth in the European category.[276] There are 18 UNESCO World Heritage Sites in Greece,[277] and Greece is ranked 16th in the world in terms of total sites. 14 further sites are on the tentative list, awaiting nomination.[277]   Panoramic view of the old Corfu City, a UNESCO World Heritage Site, as seen from the Old Fortress. The Bay of Garitsa is to the left and the port of Corfu is just visible on the top right. Spianada Square is in the foreground. Transport  This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (October 2017) (Learn how and when to remove this template message) Main article: Transport in Greece  The Rio–Antirrio bridge connects mainland Greece to the Peloponnese. Since the 1980s, the road and rail network of Greece has been significantly modernised. Important works include the A2 (Egnatia Odos) motorway, that connects northwestern Greece (Igoumenitsa) with northern Greece (Thessaloniki) and northeastern Greece (Kipoi); the Rio–Antirrio bridge, the longest suspension cable bridge in Europe (2,250 m (7,382 ft) long), connecting the Peloponnese (Rio, 7 km (4 mi) from Patras) with Aetolia-Akarnania (Antirrio) in western Greece.  Also completed are the A5 (Ionia Odos) motorway that connects northwestern Greece (Ioannina) with western Greece (Antirrio); the last sections of the A1 motorway, connecting Athens to Thessaloniki and Evzonoi in northern Greece; as well as the A8 motorway (part of the Olympia Odos) in Peloponnese, connecting Athens to Patras. The remaining section of Olympia Odos, connecting Patras with Pyrgos, is under planning.  Other important projects that are currently underway, include the construction of the Thessaloniki Metro.  The Athens Metropolitan Area in particular is served by some of the most modern and efficient transport infrastructure in Europe, such as the Athens International Airport, the privately run A6 (Attiki Odos) motorway network and the expanded Athens Metro system.  Most of the Greek islands and many main cities of Greece are connected by air mainly from the two major Greek airlines, Olympic Air and Aegean Airlines. Maritime connections have been improved with modern high-speed craft, including hydrofoils and catamarans.  Railway connections play a somewhat lesser role in Greece than in many other European countries, but they too have also been expanded, with new suburban/commuter rail connections, serviced by Proastiakos around Athens, towards its airport, Kiato and Chalkida; around Thessaloniki, towards the cities of Larissa and Edessa; and around Patras. A modern intercity rail connection between Athens and Thessaloniki has also been established, while an upgrade to double lines in many parts of the 2,500 km (1,600 mi) network is underway; along with a new double track, standard gauge railway between Athens and Patras (replacing the old metre-gauge Piraeus–Patras railway) which is currently under construction and opening in stages.[278] International railway lines connect Greek cities with the rest of Europe, the Balkans and Turkey.  Telecommunications Main article: Telecommunications in Greece Modern digital information and communication networks reach all areas. There are over 35,000 km (21,748 mi) of fiber optics and an extensive open-wire network. Broadband internet availability is widespread in Greece: there were a total of 2,252,653 broadband connections as of early 2011, translating to 20% broadband penetration.[279] According to 2017 data, around 82% of the general population used the internet regularly.[280]  Internet cafés that provide net access, office applications and multiplayer gaming are also a common sight in the country, while mobile internet on 3G and 4G- LTE cellphone networks and Wi-Fi connections can be found almost everywhere.[281] 3G/4G mobile internet usage has been on a sharp increase in recent years. Based on 2016 data 70% of Greek internet users have access via 3G/4G mobile.[280] The United Nations International Telecommunication Union ranks Greece among the top 30 countries with a highly developed information and communications infrastructure.[282]  Science and technology  This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed. (September 2018) (Learn how and when to remove this template message) Main article: List of Greek inventions and discoveries  Thessaloniki Science Center and Technology Museum  Georgios Papanikolaou, a pioneer in cytopathology and early cancer detection The General Secretariat for Research and Technology of the Ministry of Development and Competitiveness is responsible for designing, implementing and supervising national research and technological policy. In 2017, spending on research and development (R&D) reached an all-time high of €2 billion, equal to 1.14 percent of GDP.[283]  Although lower than the EU average of 1.93 percent, between 1990 and 1998, total R&D expenditure in Greece enjoyed the third-highest increase in Europe, after Finland and Ireland. Greece was ranked 43rd in the Global Innovation Index in 2020, down from 41st in 2019.[284][285][286][287] Because of its strategic location, qualified workforce, and political and economic stability, many multinational companies such as Ericsson, Siemens, Motorola, Coca-Cola, and Tesla have their regional R&D headquarters in Greece.[288]  Greece has several major technology parks with incubator facilities and has been a member of the European Space Agency (ESA) since 2005.[289] Cooperation between ESA and the Hellenic National Space Committee began in 1994 with the signing of the first cooperation agreement. After applying for full membership in 2003, Greece became the ESA's sixteenth member on 16 March 2005. The country participates in the ESA's telecommunication and technology activities and the Global Monitoring for Environment and Security Initiative.  The National Centre of Scientific Research "Demokritos" was founded in 1959. The original objective of the center was the advancement of nuclear research and technology. Today, its activities cover several fields of science and engineering.  Greece has one of the highest rates of tertiary enrollment in the world,[290] while Greeks are well represented in academia worldwide; numerous leading Western universities employ a disproportionately high number of Greek faculty.[291] Greek scientific publications have grown significantly in terms of research impact, surpassing both the EU and global average from 2012 to 2016.[292]  Notable Greek scientists of modern times include Georgios Papanikolaou (inventor of the Pap test), mathematician Constantin Carathéodory (known for the Carathéodory theorems and Carathéodory conjecture), astronomer E. M. Antoniadi, archaeologists Ioannis Svoronos, Valerios Stais, Spyridon Marinatos, Manolis Andronikos (discovered the tomb of Philip II of Macedon in Vergina), Indologist Dimitrios Galanos, botanist Theodoros G. Orphanides, such as Michael Dertouzos, Nicholas Negroponte, John Argyris, John Iliopoulos (2007 Dirac Prize for his contributions on the physics of the charm quark, a major contribution to the birth of the Standard Model, the modern theory of Elementary Particles), Joseph Sifakis (2007 Turing Award, the "Nobel Prize" of Computer Science), Christos Papadimitriou (2002 Knuth Prize, 2012 Gödel Prize), Mihalis Yannakakis (2005 Knuth Prize) and physicist Dimitri Nanopoulos.  Demographics Main article: Demographics of Greece  Hermoupolis, on the island of Syros, is the capital of the Cyclades. According to the official statistical body of Greece, the Hellenic Statistical Authority (ELSTAT), the country's total population in 2011 was 10,816,286.[9] Eurostat places the current population at 10.7 million in 2018.[293]  Greek society has changed rapidly over the last several decades, coinciding with the wider European trend of declining fertility and rapid aging. The birth rate in 2003 stood at 9.5 per 1,000 inhabitants, significantly lower than the rate of 14.5 per 1,000 in 1981. At the same time, the mortality rate increased slightly from 8.9 per 1,000 inhabitants in 1981 to 9.6 per 1,000 inhabitants in 2003. Estimates from 2016 show the birth rate decreasing further still to 8.5 per 1,000 and mortality climbing to 11.2 per 1,000.[294]   Population pyramid of Greece in 2017 The fertility rate of 1.41 children per woman is well below the replacement rate of 2.1, and is one of the lowest in the world, considerably below the high of 5.47 children born per woman in 1900.[295] Subsequently, Greece's median age is 44.2 years, the seventh-highest in the world.[296] In 2001, 16.71 percent of the population were 65 years old and older, 68.12 percent between the ages of 15 and 64 years old, and 15.18 percent were 14 years old and younger.[297] By 2016, the proportion of the population age 65 and older had risen to 20.68 percent, while the proportion of those aged 14 and younger declined to slightly below 14 percent.  Marriage rates began declining from almost 71 per 1,000 inhabitants in 1981 until 2002, only to increase slightly in 2003 to 61 per 1,000 and then fall again to 51 in 2004.[297] Moreover, divorce rates have seen an increase from 191.2 per 1,000 marriages in 1991 to 239.5 per 1,000 marriages in 2004.[297]  As a result of these trends, the average Greek household is smaller and older than in previous generations. The economic crisis has exacerbated this development, with 350,000-450,000 Greeks, predominantly young adults, emigrating since 2010.[298]  Cities See also: List of cities in Greece Almost two-thirds of the Greek people live in urban areas. Greece's largest and most influential metropolitan centres are those of Athens and Thessaloniki—that latter commonly referred to as the symprotévousa (συμπρωτεύουσα, lit. 'co-capital'[299])—with metropolitan populations of approximately 4 million and 1 million inhabitants respectively. Other prominent cities with urban populations above 100,000 inhabitants include Patras, Heraklion, Larissa, Volos, Rhodes, Ioannina, Agrinio, Chania, and Chalcis.[300]  The table below lists the largest cities in Greece, by population contained in their respective contiguous built up urban areas, which are either made up of many municipalities, evident in the cases of Athens and Thessaloniki, or are contained within a larger single municipality, case evident in most of the smaller cities of the country. The results come from the preliminary figures of the population census that took place in Greece in May 2011.    vte Largest cities or towns in Greece Hellenic Statistical Authority 2011 census[301] Rank	Name	Region	Pop.	Rank	Name	Region	Pop.	 Athens Athens Thessaloniki Thessaloniki	1	Athens	Attica	3,090,508	11	Alexandroupoli	Eastern Macedonia and Thrace	57,812	Patras Patras Larissa Larissa 2	Thessaloniki	Central Macedonia	824,676	12	Xanthi	Eastern Macedonia and Thrace	56,122 3	Patras	Western Greece	167,446	13	Katerini	Central Macedonia	55,997 4	Larissa	Thessaly	144,651	14	Kalamata	Peloponnese	54,100 5	Heraklion	Crete	140,730	15	Kavala	Eastern Macedonia and Thrace	54,027 6	Volos	Thessaly	86,046	16	Chania	Crete	53,910 7	Ioannina	Epirus	65,574	17	Lamia	Central Greece	52,006 8	Trikala	Thessaly	61,653	18	Komotini	Eastern Macedonia and Thrace	50,990 9	Chalcis	Central Greece	59,125	19	Rhodes	South Aegean	49,541 10	Serres	Central Macedonia	58,287	20	Agrinio	Western Greece	46,899  Religion Main articles: Religion in Greece, Greek Orthodox Church, and Church of Greece See also: Muslim minority of Greece, Hellenismos, Ancient Greek religion, and Romaniote Jews Religiosity in Greece (2017)[5]    Eastern Orthodoxy (90%)   Other Christians (exc.Catholics) (3%)   Irreligion (4%)   Islam (2%)   Other religions (inc.Catholics) (1%) The Greek Constitution recognises Eastern Orthodoxy as the 'prevailing' faith of the country, while guaranteeing freedom of religious belief for all.[160][302] The Greek government does not keep statistics on religious groups and censuses do not ask for religious affiliation. According to the U.S. State Department, an estimated 97% of Greek citizens identify themselves as Eastern Orthodox, belonging to the Greek Orthodox Church,[303] which uses the Byzantine rite and the Greek language, the original language of the New Testament. The administration of the Greek territory is shared between the Church of Greece and the Patriarchate of Constantinople.   Our Lady of Tinos In a 2010 Eurostat–Eurobarometer poll, 79% of Greek citizens responded that they "believe there is a God".[304] According to other sources, 15.8% of Greeks describe themselves as "very religious", which is the highest among all European countries. The survey also found that just 3.5% never attend a church, compared to 4.9% in Poland and 59.1% in the Czech Republic.[305]  Estimates of the recognised Greek Muslim minority, which is mostly located in Thrace, range around 100,000,[303][306] (about 1% of the population). Some of the Albanian immigrants to Greece come from a nominally Muslim background, although most are secular in orientation.[307] Following the 1919–1922 Greco-Turkish War and the 1923 Treaty of Lausanne, Greece and Turkey agreed to a population transfer based on cultural and religious identity. About 500,000 Muslims from Greece, predominantly those defined as Turks, but also Greek Muslims like the Vallahades of western Macedonia, were exchanged with approximately 1.5 million Greeks from Turkey. However, many refugees who settled in former Ottoman Muslim villages in Central Macedonia, and were defined as Christian Orthodox Caucasus Greeks, arrived from the former Russian Transcaucasus province of Kars Oblast, after it had been retroceded to Turkey prior to the official population exchange.[308]  Judaism has been present in Greece for more than 2,000 years. The ancient community of Greek Jews are called Romaniotes, while the Sephardi Jews were once a prominent community in the city of Thessaloniki, numbering some 80,000, or more than half of the population, by 1900.[309] However, after the German occupation of Greece and the Holocaust during World War II, is estimated to number around 5,500 people.[303][306]  The Roman Catholic community is estimated to be around 250,000[303][306] of which 50,000 are Greek citizens.[303] Their community is nominally separate from the smaller Greek Byzantine Catholic Church, which recognises the primacy of the Pope but maintains the liturgy of the Byzantine Rite.[310] Old Calendarists account for 500,000 followers.[306] Protestants, including the Greek Evangelical Church and Free Evangelical Churches, stand at about 30,000.[303][306] Other Christian minorities, such as Assemblies of God, International Church of the Foursquare Gospel and various Pentecostal churches of the Greek Synod of Apostolic Church total about 12,000 members.[311] The independent Free Apostolic Church of Pentecost is the biggest Protestant denomination in Greece with 120 churches.[312] There are no official statistics about Free Apostolic Church of Pentecost, but the Orthodox Church estimates the followers as 20,000.[313] The Jehovah's Witnesses report having 28,874 active members.[314]  Since 2017, Hellenic Polytheism, or Helenism has been legally recognised as an actively practiced religion in Greece,[315] with estimates of 2,000 active practitioners and an additional 100,000 "sympathisers".[316][317][318] Hellenism refers to various religious movements that continue, revive, or reconstruct ancient Greek religious practices.  Languages  This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed. (October 2017) (Learn how and when to remove this template message) Main articles: Greek language, Languages of Greece, and Minorities in Greece  Regions with a traditional presence of languages other than Greek. Today, Greek is the dominant language throughout the country.[319][320][321][322][323][324] The first textual evidence of the Greek language dates back to 15th century BC and the Linear B script which is associated with the Mycenaean Civilization. Greek was a widely spoken lingua franca in the Mediterranean world and beyond during Classical Antiquity, and would eventually become the official parlance of the Byzantine Empire.  During the 19th and 20th centuries there was a major dispute known as the Greek language question, on whether the official language of Greece should be the archaic Katharevousa, created in the 19th century and used as the state and scholarly language, or the Dimotiki, the form of the Greek language which evolved naturally from Byzantine Greek and was the language of the people. The dispute was finally resolved in 1976, when Dimotiki was made the only official variation of the Greek language, and Katharevousa fell to disuse.  Greece is today relatively homogeneous in linguistic terms, with a large majority of the native population using Greek as their first or only language. Among the Greek-speaking population, speakers of the distinctive Pontic dialect came to Greece from Asia Minor after the Greek genocide and constitute a sizable group. The Cappadocian dialect came to Greece due to the genocide as well, but is endangered and is barely spoken now. Indigenous Greek dialects include the archaic Greek spoken by the Sarakatsani, traditionally transhument mountain shepherds of Greek Macedonia and other parts of Northern Greece. The Tsakonian language, a distinct Greek language deriving from Doric Greek instead of Koine Greek, is still spoken in some villages in the southeastern Peloponnese.  The Muslim minority in Thrace, which amounts to approximately 0.95% of the total population, consists of speakers of Turkish, Bulgarian (Pomaks)[324] and Romani. Romani is also spoken by Christian Roma in other parts of the country. Further minority languages have traditionally been spoken by regional population groups in various parts of the country. Their use has decreased radically in the course of the 20th century through assimilation with the Greek-speaking majority.  Today they are only maintained by the older generations and are on the verge of extinction. This goes for the Arvanites, an Albanian-speaking group mostly located in the rural areas around the capital Athens, and for the Aromanians and Megleno-Romanians, also known as "Vlachs", whose language is closely related to Romanian and who used to live scattered across several areas of mountainous central Greece. Members of these groups usually identify ethnically as Greek[325] and are today all at least bilingual in Greek.  Near the northern Greek borders there are also some Slavic–speaking groups, locally known as Slavomacedonian-speaking, most of whose members identify ethnically as Greeks. It is estimated that after the population exchanges of 1923, Macedonia had 200,000 to 400,000 Slavic speakers.[326] The Jewish community in Greece traditionally spoke Ladino (Judeo-Spanish), today maintained only by a few thousand speakers. Other notable minority languages include Armenian, Georgian, and the Greco-Turkic dialect spoken by the Urums, a community of Caucasus Greeks from the Tsalka region of central Georgia and ethnic Greeks from southeastern Ukraine who arrived in mainly Northern Greece as economic migrants in the 1990s.  Migration Main articles: Greek diaspora and Immigration to Greece  A map of the fifty countries with the largest Greek diaspora communities. Throughout the 20th century, millions of Greeks migrated to the United States, United Kingdom, Australia, Canada, and Germany, creating a large Greek diaspora. Net migration started to show positive numbers from the 1970s, but until the beginning of the 1990s, the main influx was that of returning Greek migrants or of Pontic Greeks and others from Russia, Georgia, Turkey the Czech Republic, and elsewhere in the former Soviet Bloc.[327]  A study from the Mediterranean Migration Observatory maintains that the 2001 census recorded 762,191 persons residing in Greece without Greek citizenship, constituting around 7% of the total population. Of the non-citizen residents, 48,560 were EU or European Free Trade Association nationals and 17,426 were Cypriots with privileged status. The majority come from Eastern European countries: Albania (56%), Bulgaria (5%) and Romania (3%), while migrants from the former Soviet Union (Georgia, Russia, Ukraine, Moldova, etc.) comprise 10% of the total.[328] Some of the immigrants from Albania are from the Greek minority in Albania centred on the region of Northern Epirus. In addition, the total Albanian national population which includes temporary migrants and undocumented persons is around 600,000.[329]  The 2011 census recorded 9,903,268 Greek citizens (91,56%), 480,824 Albanian citizens (4,44%), 75,915 Bulgarian citizens (0,7%), 46,523 Romanian citizenship (0,43%), 34,177 Pakistani citizens (0,32%), 27,400 Georgian citizens (0,25%) and 247,090 people had other or unidentified citizenship (2,3%).[330] 189,000 people of the total population of Albanian citizens were reported in 2008 as ethnic Greeks from Southern Albania, in the historical region of Northern Epirus.[327]  The greatest cluster of non-EU immigrant population are the larger urban centers, especially the Municipality of Athens, with 132,000 immigrants comprising 17% of the local population, and then Thessaloniki, with 27,000 immigrants reaching 7% of the local population. There is also a considerable number of co-ethnics that came from the Greek communities of Albania and the former Soviet Union.[327]  Greece, together with Italy and Spain, is a major entry point for illegal immigrants trying to enter the EU. Illegal immigrants entering Greece mostly do so from the border with Turkey at the Evros River and the islands of the eastern Aegean across from Turkey (mainly Lesbos, Chios, Kos, and Samos). In 2012, the majority of illegal immigrants entering Greece came from Afghanistan, followed by Pakistanis and Bangladeshis.[331] In 2015, arrivals of refugees by sea had increased dramatically mainly due to the ongoing Syrian civil war. There were 856,723 arrivals by sea in Greece, an almost fivefold increase to the same period of 2014, of which the Syrians represent almost 45%.[332] The majority of refugees and migrants use Greece as a transit country, while their intended destinations are northern European Nations such as Austria, Germany and Sweden.[333][334]  Education Main article: Education in Greece  This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed. (October 2017) (Learn how and when to remove this template message)  The Academy of Athens is Greece's national academy and the highest research establishment in the country.  The Ionian Academy in Corfu, the first academic institution of modern Greece. Greeks have a long tradition of valuing and investing in paideia (education), which was upheld as one of the highest societal values in the Greek and Hellenistic world. The first European institution described as a university was founded in fifth-century Constantinople and continued operating in various incarnations until the city's fall to the Ottomans in 1453.[335] The University of Constantinople was Christian Europe's first secular institution of higher learning,[336] and by some measures was the world's first university.[335]  Compulsory education in Greece comprises primary schools (Δημοτικό Σχολείο, Dimotikó Scholeio) and gymnasium (Γυμνάσιο). Nursery schools (Παιδικός σταθμός, Paidikós Stathmós) are popular but not compulsory. Kindergartens (Νηπιαγωγείο, Nipiagogeío) are now compulsory for any child above four years of age. Children start primary school aged six and remain there for six years. Attendance at gymnasia starts at age 12 and lasts for three years.  Greece's post-compulsory secondary education consists of two school types: unified upper secondary schools (Γενικό Λύκειο, Genikό Lykeiό) and technical–vocational educational schools (Τεχνικά και Επαγγελματικά Εκπαιδευτήρια, "TEE"). Post-compulsory secondary education also includes vocational training institutes (Ινστιτούτα Επαγγελματικής Κατάρτισης, "IEK") which provide a formal but unclassified level of education. As they can accept both Gymnasio (lower secondary school) and Lykeio (upper secondary school) graduates, these institutes are not classified as offering a particular level of education.  According to the Framework Law (3549/2007), Public higher education "Highest Educational Institutions" (Ανώτατα Εκπαιδευτικά Ιδρύματα, Anótata Ekpaideytiká Idrýmata, "ΑΕΙ") consists of two parallel sectors:the university sector (Universities, Polytechnics, Fine Arts Schools, the Open University) and the Technological sector (Technological Education Institutions (TEI) and the School of Pedagogic and Technological Education). There are also State Non-University Tertiary Institutes offering vocationally oriented courses of shorter duration (2 to 3 years) which operate under the authority of other Ministries. Students are admitted to these Institutes according to their performance at national level examinations taking place after completion of the third grade of Lykeio. Additionally, students over twenty-two years old may be admitted to the Hellenic Open University through a form of lottery. The Capodistrian University of Athens is the oldest university in the eastern Mediterranean.  The Greek education system also provides special kindergartens, primary, and secondary schools for people with special needs or difficulties in learning. There are also specialist gymnasia and high schools offering musical, theological, and physical education.  Seventy-two percent of Greek adults aged 25–64 have completed upper secondary education, which is slightly less than the OECD average of 74 percent. The average Greek pupil scored 458 in reading literacy, maths and science in the OECD's 2015 Programme for International Student Assessment (PISA). This score is lower than the OECD average of 486. On average, girls outperformed boys by 15 points, much more than the average OECD gap of two points.[337]  Healthcare system Main article: Health care in Greece Greece has universal health care. The system is mixed, combining a national health service with social health insurance (SHI). 2000 World Health Organization report, its health care system ranked 14th in overall performance of 191 countries surveyed.[338] In a 2013 Save the Children report, Greece was ranked the 19th out of 176 countries for the state of mothers and newborn babies.[339] In 2010, there were 138 hospitals with 31,000 beds, but in 2011, the Ministry of Health announced plans to decrease the number to 77 hospitals with 36,035 beds to reduce expenses and further enhance healthcare standards.[340] However, as of 2014, there were 124 public hospitals, of which 106 were general hospitals and 18 specialised hospitals, with a total capacity of about 30,000 beds.[341]  Greece's healthcare expenditures as a percentage of GDP were 9.6% in 2007, just above the OECD average of 9.5%.[342] By 2015, spending declined to 8.4% of GDP (compared with the EU average of 9.5%), a decline of one-fifth since 2010. Nevertheless, the country maintains the highest doctor-to-population ratio of any OECD country[342] and the highest doctor-to-patient ratio in the EU.[343]  Life expectancy in Greece is among the highest in the world; a 2011 OECD report placed it at 80.3 years, above the OECD average of 79.5,[342] while a more recent 2017 study found life expectancy in 2015 to be 81.1 years, slightly above the EU average of 80.6.[343] The island of Icaria has the highest percentage of nonagenarians in the world; approximately 33% of islanders are 90 or older.[344] Icaria is subsequently classified as a "blue zone", a region where people allegedly live longer than average and have lower rates of cancer, heart disease, or other chronic illnesses.[345]  The 2011 OECD report showed that Greece had the largest percentage of adult daily smokers of any of the 34 OECD members.[342] The country's obesity rate is 18.1%, which is above the OECD average of 15.1%, but considerably lower than the American rate of 27.7%.[342] In 2008, Greece had the highest rate of perceived good health in the OECD, at 98.5%.[346] Infant mortality, with a rate of 3.6 deaths per 1,000 live births, was below the 2007 OECD average of 4.9.[342]  Culture Main articles: Culture of Greece, Greeks, and List of Greeks  The Ancient Theatre of Epidaurus, still used for theatrical plays. The culture of Greece has evolved over thousands of years, beginning in Mycenaean Greece and continuing most notably into Classical Greece, through the influence of the Roman Empire and its Greek Eastern continuation, the Eastern Roman or Byzantine Empire. Other cultures and nations, such as the Latin and Frankish states, the Ottoman Empire, the Venetian Republic, the Genoese Republic, and the British Empire have also left their influence on modern Greek culture, although historians credit the Greek War of Independence with revitalising Greece and giving birth to a single, cohesive entity of its multi-faceted culture.  In ancient times, Greece was the birthplace of Western culture.[347][32] Modern democracies owe a debt to Greek beliefs in government by the people, trial by jury, and equality under the law. The ancient Greeks pioneered in many fields that rely on systematic thought, including logic, biology, geometry, geography, medicine, history,[348] philosophy,[349] physics and mathematics.[350] They introduced such important literary forms as epic and lyric poetry, history, tragedy, comedy and drama. In their pursuit of order and proportion, the Greeks created an ideal of beauty that strongly influenced Western art.[351]  Visual arts  This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed. (October 2017) (Learn how and when to remove this template message) See also: Greek art, Byzantine art, and Modern Greek art  Close-up of the Charioteer of Delphi, a celebrated statue from the 5th century BC. Artistic production in Greece began in the prehistoric pre-Greek Cycladic and the Minoan civilizations, both of which were influenced by local traditions and the art of ancient Egypt.[352]  There were several interconnected traditions of painting in ancient Greece. Due to their technical differences, they underwent somewhat differentiated developments. Not all painting techniques are equally well represented in the archaeological record. The most respected form of art, according to authors like Pliny or Pausanias, were individual, mobile paintings on wooden boards, technically described as panel paintings. Also, the tradition of wall painting in Greece goes back at least to the Minoan and Mycenaean Bronze Age, with the lavish fresco decoration of sites like Knossos, Tiryns and Mycenae. Much of the figural or architectural sculpture of ancient Greece was painted colourfully. This aspect of Greek stonework is described as polychrome.  Ancient Greek sculpture was composed almost entirely of marble or bronze; with cast bronze becoming the favoured medium for major works by the early 5th century. Both marble and bronze are easy to form and very durable. Chryselephantine sculptures, used for temple cult images and luxury works, used gold, most often in leaf form and ivory for all or parts (faces and hands) of the figure, and probably gems and other materials, but were much less common, and only fragments have survived. By the early 19th century, the systematic excavation of ancient Greek sites had brought forth a plethora of sculptures with traces of notably multicolored surfaces. It was not until published findings by German archaeologist Vinzenz Brinkmann in the late 20th century, that the painting of ancient Greek sculptures became an established fact.[353]  The art production continued also during the Byzantine era. The most salient feature of this new aesthetic was its "abstract", or anti-naturalistic character. If classical art was marked by the attempt to create representations that mimicked reality as closely as possible, Byzantine art seems to have abandoned this attempt in favour of a more symbolic approach. The Byzantine painting concentrated mainly on icons and hagiographies. The Macedonian art (Byzantine) was the artistic expression of Macedonian Renaissance, a label sometimes used to describe the period of the Macedonian dynasty of the Byzantine Empire (867–1056), especially the 10th century, which some scholars have seen as a time of increased interest in classical scholarship and the assimilation of classical motifs into Christian artwork.  Post Byzantine art schools include the Cretan School and Heptanese School. The first artistic movement in the Greek Kingdom can be considered the Greek academic art of the 19th century (Munich School). Notable modern Greek painters include Nikolaos Gyzis, Georgios Jakobides, Theodoros Vryzakis, Nikiforos Lytras, Konstantinos Volanakis, Nikos Engonopoulos and Yannis Tsarouchis, while some notable sculptors are Pavlos Prosalentis, Ioannis Kossos, Leonidas Drosis, Georgios Bonanos and Yannoulis Chalepas.  Architecture  This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (October 2017) (Learn how and when to remove this template message) See also: Ancient Greek architecture, Byzantine architecture, and Modern Greek architecture  Towerhouses of Vatheia in Mani peninsula. The architecture of ancient Greece was produced by the ancient Greeks (Hellenes), whose culture flourished on the Greek mainland, the Aegean Islands and their colonies, for a period from about 900 BC until the 1st century AD, with the earliest remaining architectural works dating from around 600 BC. The formal vocabulary of ancient Greek architecture, in particular the division of architectural style into three defined orders: the Doric Order, the Ionic Order and the Corinthian Order, was to have profound effect on Western architecture of later periods.  Byzantine architecture is the architecture promoted by the Byzantine Empire, also known as the Eastern Roman Empire, which dominated Greece and the Greek speaking world during the Middle Ages. The empire endured for more than a millennium, dramatically influencing Medieval architecture throughout Europe and the Near East, and becoming the primary progenitor of the Renaissance and Ottoman architectural traditions that followed its collapse.  After the Greek Independence, the modern Greek architects tried to combine traditional Greek and Byzantine elements and motives with the western European movements and styles. Patras was the first city of the modern Greek state to develop a city plan. In January 1829, Stamatis Voulgaris, a Greek engineer of the French army, presented the plan of the new city to the Governor Kapodistrias, who approved it. Voulgaris applied the orthogonal rule in the urban complex of Patras.[354]  Two special genres can be considered the Cycladic architecture, featuring white-coloured houses, in the Cyclades and the Epirotic architecture in the region of Epirus.[355][356] Important is also the influence of the Venetian style in the Ionian islands and the "Mediterranean style" of Florestano Di Fausto (during the years of the fascist regime) in the Dodecanese islands.[357]  After the establishment of the Greek Kingdom, the architecture of Athens and other cities was mostly influenced by the Neoclassical architecture. For Athens, the first King of Greece, Otto of Greece, commissioned the architects Stamatios Kleanthis and Eduard Schaubert to design a modern city plan fit for the capital of a state. As for Thessaloniki, after the fire of 1917, the government ordered for a new city plan under the supervision of Ernest Hébrard. Other modern Greek architects include Anastasios Metaxas, Lysandros Kaftanzoglou, Panagis Kalkos, Ernst Ziller, Xenophon Paionidis, Dimitris Pikionis and Georges Candilis.  Theatre  This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed. (October 2017) (Learn how and when to remove this template message) See also: Theatre of ancient Greece and Modern Greek theatre  Nobile Teatro di San Giacomo di Corfù, the first theatre and opera house of modern Greece. Theatre in its western form was born in Greece.[358] The city-state of Classical Athens, which became a significant cultural, political, and military power during this period, was its centre, where it was institutionalised as part of a festival called the Dionysia, which honoured the god Dionysus. Tragedy (late 6th century BC), comedy (486 BC), and the satyr play were the three dramatic genres to emerge there.  During the Byzantine period, the theatrical art was heavily declined. According to Marios Ploritis, the only form survived was the folk theatre (Mimos and Pantomimos), despite the hostility of the official state.[359] Later, during the Ottoman period, the main theatrical folk art was the Karagiozis. The renaissance which led to the modern Greek theatre, took place in the Venetian Crete. Significal dramatists include Vitsentzos Kornaros and Georgios Chortatzis.  The modern Greek theatre was born after the Greek independence, in the early 19th century, and initially was influenced by the Heptanesean theatre and melodrama, such as the Italian opera. The Nobile Teatro di San Giacomo di Corfù was the first theatre and opera house of modern Greece and the place where the first Greek opera, Spyridon Xyndas' The Parliamentary Candidate (based on an exclusively Greek libretto) was performed. During the late 19th and early 20th century, the Athenian theatre scene was dominated by revues, musical comedies, operettas and nocturnes and notable playwrights included Spyridon Samaras, Dionysios Lavrangas, Theophrastos Sakellaridis and others.  The National Theatre of Greece was opened in 1900 as Royal Theatre.[360] Notable playwrights of the modern Greek theatre include Gregorios Xenopoulos, Nikos Kazantzakis, Pantelis Horn, Alekos Sakellarios and Iakovos Kambanelis, while notable actors include Cybele Andrianou, Marika Kotopouli, Aimilios Veakis, Orestis Makris, Katina Paxinou, Manos Katrakis and Dimitris Horn. Significant directors include Dimitris Rontiris, Alexis Minotis and Karolos Koun.  Literature  This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (October 2017) (Learn how and when to remove this template message) Main articles: Greek literature, Byzantine literature, and Modern Greek literature  Parnassos Literary Society, painted by Georgios Roilos (Kostis Palamas is at the center) Greek literature can be divided into three main categories: Ancient, Byzantine and modern Greek literature.[361]  Athens is considered the birthplace of Western literature.[362] At the beginning of Greek literature stand the two monumental works of Homer: the Iliad and the Odyssey. Though dates of composition vary, these works were fixed around 800 BC or after. In the classical period many of the genres of western literature became more prominent. Lyrical poetry, odes, pastorals, elegies, epigrams; dramatic presentations of comedy and tragedy; historiography, rhetorical treatises, philosophical dialectics, and philosophical treatises all arose in this period. The two major lyrical poets were Sappho and Pindar. The Classical era also saw the dawn of drama.  Of the hundreds of tragedies written and performed during the classical age, only a limited number of plays by three authors have survived: those of Aeschylus, Sophocles, and Euripides. The surviving plays by Aristophanes are also a treasure trove of comic presentation, while Herodotus and Thucydides are two of the most influential historians in this period. The greatest prose achievement of the 4th century was in philosophy with the works of the three great philosophers.  Byzantine literature refers to literature of the Byzantine Empire written in Atticizing, Medieval and early Modern Greek, and it is the expression of the intellectual life of the Byzantine Greeks during the Christian Middle Ages. Although popular Byzantine literature and early Modern Greek literature both began in the 11th century, the two are indistinguishable.[363]     Constantine P. Cavafy, whose work was inspired mainly by the Hellenistic past, while Odysseas Elytis (centre) and Giorgos Seferis (right) were representatives of the Generation of the '30s and Nobel laureates in Literature. Modern Greek literature refers to literature written in common Modern Greek, emerging from late Byzantine times in the 11th century. The Cretan Renaissance poem Erotokritos is considered the masterpiece of this period of Greek literature. It is a verse romance written around 1600 by Vitsentzos Kornaros (1553–1613). Later, during the period of Greek enlightenment (Diafotismos), writers such as Adamantios Korais and Rigas Feraios prepared with their works the Greek Revolution (1821–1830).  Leading figures of modern Greek literature include Dionysios Solomos, Andreas Kalvos, Angelos Sikelianos, Emmanuel Rhoides, Demetrius Vikelas, Kostis Palamas, Penelope Delta, Yannis Ritsos, Alexandros Papadiamantis, Nikos Kazantzakis, Andreas Embeirikos, Kostas Karyotakis, Gregorios Xenopoulos, Constantine P. Cavafy, Nikos Kavvadias, Kostas Varnalis and Kiki Dimoula. Two Greek authors have been awarded the Nobel Prize in Literature: George Seferis in 1963 and Odysseas Elytis in 1979.  Philosophy Main articles: Ancient Greek philosophy and Modern Greek Enlightenment  A statue of Plato in Athens. Most western philosophical traditions began in Ancient Greece in the 6th century BC. The first philosophers are called "Presocratics," which designates that they came before Socrates, whose contributions mark a turning point in western thought. The Presocratics were from the western or the eastern colonies of Greece and only fragments of their original writings survive, in some cases merely a single sentence.  A new period of philosophy started with Socrates. Like the Sophists, he rejected entirely the physical speculations in which his predecessors had indulged, and made the thoughts and opinions of people his starting-point. Aspects of Socrates were first united from Plato, who also combined with them many of the principles established by earlier philosophers, and developed the whole of this material into the unity of a comprehensive system.  Aristotle of Stagira, the most important disciple of Plato, shared with his teacher the title of the greatest philosopher of antiquity. But while Plato had sought to elucidate and explain things from the supra-sensual standpoint of the forms, his pupil preferred to start from the facts given to us by experience. Except from these three most significant Greek philosophers other known schools of Greek philosophy from other founders during ancient times were Stoicism, Epicureanism, Skepticism and Neoplatonism.[364]  Byzantine philosophy refers to the distinctive philosophical ideas of the philosophers and scholars of the Byzantine Empire, especially between the 8th and 15th centuries. It was characterised by a Christian world-view, but one which could draw ideas directly from the Greek texts of Plato, Aristotle, and the Neoplatonists.  On the eve of the Fall of Constantinople, Gemistus Pletho tried to restore the use of the term "Hellene" and advocated the return to the Olympian Gods of the ancient world. After 1453 a number of Greek Byzantine scholars who fled to western Europe contributed to the Renaissance.  In modern period, Diafotismos (Greek: Διαφωτισμός, "enlightenment", "illumination") was the Greek expression of the Age of Enlightenment and its philosophical and political ideas. Some notable representatives were Adamantios Korais, Rigas Feraios and Theophilos Kairis.  Other modern era Greek philosophers or political scientists include Cornelius Castoriadis, Nicos Poulantzas and Christos Yannaras.  Music and dances  This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed. (October 2017) (Learn how and when to remove this template message) Main article: Music of Greece  Cretan dancers of traditional folk music  Rebetes in Karaiskaki, Piraeus (1933). Left Markos Vamvakaris with bouzouki. Greek vocal music extends far back into ancient times where mixed-gender choruses performed for entertainment, celebration and spiritual reasons. Instruments during that period included the double-reed aulos and the plucked string instrument, the lyre, especially the special kind called a kithara. Music played an important role in the education system during ancient times. Boys were taught music from the age of six. Later influences from the Roman Empire, Middle East, and the Byzantine Empire also had effect on Greek music.  While the new technique of polyphony was developing in the West, the Eastern Orthodox Church resisted any type of change. Therefore, Byzantine music remained monophonic and without any form of instrumental accompaniment. As a result, and despite certain attempts by certain Greek chanters (such as Manouel Gazis, Ioannis Plousiadinos or the Cypriot Ieronimos o Tragoudistis), Byzantine music was deprived of elements of which in the West encouraged an unimpeded development of art. However, this method which kept music away from polyphony, along with centuries of continuous culture, enabled monophonic music to develop to the greatest heights of perfection. Byzantium presented the monophonic Byzantine chant; a melodic treasury of inestimable value for its rhythmical variety and expressive power.  Along with the Byzantine (Church) chant and music, the Greek people also cultivated the Greek folk song (Demotiko) which is divided into two cycles, the akritic and klephtic. The akritic was created between the 9th and 10th centuries and expressed the life and struggles of the akrites (frontier guards) of the Byzantine empire, the most well known being the stories associated with Digenes Akritas. The klephtic cycle came into being between the late Byzantine period and the start of the Greek War of Independence. The klephtic cycle, together with historical songs, paraloghes (narrative song or ballad), love songs, mantinades, wedding songs, songs of exile and dirges express the life of the Greeks. There is a unity between the Greek people's struggles for freedom, their joys and sorrow and attitudes towards love and death.   Mikis Theodorakis was one of the most popular and significant Greek composers The Heptanesean kantádhes (καντάδες 'serenades'; sing.: καντάδα) became the forerunners of the Greek modern urban popular song, influencing its development to a considerable degree. For the first part of the next century, several Greek composers continued to borrow elements from the Heptanesean style. The most successful songs during the period 1870–1930 were the so-called Athenian serenades, and the songs performed on stage (επιθεωρησιακά τραγούδια 'theatrical revue songs') in revue, operettas and nocturnes that were dominating Athens' theater scene.  Rebetiko, initially a music associated with the lower classes, later (and especially after the population exchange between Greece and Turkey) reached greater general acceptance as the rough edges of its overt subcultural character were softened and polished, sometimes to the point of unrecognizability. It was the base of the later laïkó (song of the people). The leading performers of the genre include Vassilis Tsitsanis, Grigoris Bithikotsis, Stelios Kazantzidis, George Dalaras, Haris Alexiou and Glykeria.  Regarding the classical music, it was through the Ionian islands (which were under western rule and influence) that all the major advances of the western European classical music were introduced to mainland Greeks. The region is notable for the birth of the first School of modern Greek classical music (Heptanesean or Ionian School, Greek: Επτανησιακή Σχολή), established in 1815. Prominent representatives of this genre include Nikolaos Mantzaros, Spyridon Xyndas, Spyridon Samaras and Pavlos Carrer. Manolis Kalomiris is considered the founder of the Greek National School of Music.  In the 20th century, Greek composers have had a significant impact on the development of avant garde and modern classical music, with figures such as Iannis Xenakis, Nikos Skalkottas, and Dimitri Mitropoulos achieving international prominence. At the same time, composers and musicians such as Mikis Theodorakis, Manos Hatzidakis, Eleni Karaindrou, Vangelis and Demis Roussos garnered an international following for their music, which include famous film scores such as Zorba the Greek, Serpico, Never on Sunday, America America, Eternity and a Day, Chariots of Fire, Blade Runner, among others. Greek American composers known for their film scores include also Yanni and Basil Poledouris. Notable Greek opera singers and classical musicians of the 20th and 21st century include Maria Callas, Nana Mouskouri, Mario Frangoulis, Leonidas Kavakos, Dimitris Sgouros and others.  During the dictatorship of the Colonels, the music of Mikis Theodorakis was banned by the junta and the composer was jailed, internally exiled, and put in a concentration camp,[365] before finally being allowed to leave Greece due to international reaction to his detention. Released during the junta years, Anthrope Agapa, ti Fotia Stamata (Make Love, Stop the Gunfire), by the pop group Poll is considered the first anti-war protest song in the history of Greek rock.[366] The song was echoing the hippie slogan Make love, not war and was inspired directly by the Vietnam War, becoming a "smash hit" in Greece.[367]  Greece participated in the Eurovision Song Contest 35 times after its debut at the 1974 Contest. In 2005, Greece won with the song "My Number One", performed by Greek-Swedish singer Elena Paparizou. The song received 230 points with 10 sets of 12 points from Belgium, Bulgaria, Hungary, the United Kingdom, Turkey, Albania, Cyprus, Serbia & Montenegro, Sweden and Germany and also became a smash hit in different countries and especially in Greece. The 51st Eurovision Song Contest was held in Athens at the Olympic Indoor Hall of the Athens Olympic Sports Complex in Maroussi, with hosted by Maria Menounos and Sakis Rouvas.  Cuisine Main articles: Greek cuisine and Greek wine  A Greek salad, with feta and olives. Greek cuisine is characteristic of the healthy Mediterranean diet, which is epitomised by dishes of Crete.[368] Greek cuisine incorporates fresh ingredients into a variety of local dishes such as moussaka, pastitsio, classic Greek salad, fasolada, spanakopita and souvlaki. Some dishes can be traced back to ancient Greece like skordalia (a thick purée of walnuts, almonds, crushed garlic and olive oil), lentil soup, retsina (white or rosé wine sealed with pine resin) and pasteli (candy bar with sesame seeds baked with honey). Throughout Greece people often enjoy eating from small dishes such as meze with various dips such as tzatziki, grilled octopus and small fish, feta cheese, dolmades (rice, currants and pine kernels wrapped in vine leaves), various pulses, olives and cheese. Olive oil is added to almost every dish.  Some sweet desserts include melomakarona, diples and galaktoboureko, and drinks such as ouzo, metaxa and a variety of wines including retsina. Greek cuisine differs widely from different parts of the mainland and from island to island. It uses some flavorings more often than other Mediterranean cuisines: oregano, mint, garlic, onion, dill and bay laurel leaves. Other common herbs and spices include basil, thyme and fennel seed. Many Greek recipes, especially in the northern parts of the country, use "sweet" spices in combination with meat, for example cinnamon and cloves in stews.  Cinema  This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed. (October 2017) (Learn how and when to remove this template message) Main article: Greek cinema Cinema first appeared in Greece in 1896, but the first actual cine-theatre was opened in 1907 in Athens. In 1914, the Asty Films Company was founded and the production of long films began. Golfo (Γκόλφω), a well known traditional love story, is considered the first Greek feature film, although there were several minor productions such as newscasts before this. In 1931, Orestis Laskos directed Daphnis and Chloe (Δάφνις και Χλόη), containing one of the first nude scene in the history of European cinema; it was also the first Greek movie which was played abroad. In 1944, Katina Paxinou was honoured with the Best Supporting Actress Academy Award for For Whom the Bell Tolls.   Theodoros Angelopoulos, winner of the Palme d'Or in 1998, notable director in the history of the European cinema The 1950s and early 1960s are considered by many to be a "golden age" of Greek cinema. Directors and actors of this era were recognised as important figures in Greece and some gained international acclaim: George Tzavellas, Irene Papas, Melina Mercouri, Mihalis Kakogiannis, Alekos Sakellarios, Nikos Tsiforos, Iakovos Kambanelis, Katina Paxinou, Nikos Koundouros, Ellie Lambeti and others. More than sixty films per year were made, with the majority having film noir elements. Some notable films include The Drunkard (1950, directed by George Tzavellas), The Counterfeit Coin (1955, by Giorgos Tzavellas), Πικρό Ψωμί (1951, by Grigoris Grigoriou), O Drakos (1956, by Nikos Koundouros), Stella (1955, directed by Cacoyannis and written by Kampanellis), Woe to the Young (1961, by Alekos Sakellarios), Glory Sky (1962, by Takis Kanellopoulos) and The Red Lanterns (1963, by Vasilis Georgiadis)  Cacoyannis also directed Zorba the Greek with Anthony Quinn which received Best Director, Best Adapted Screenplay and Best Film nominations. Finos Film also contributed in this period with movies such as Λατέρνα, Φτώχεια και Φιλότιμο, Madalena, I theia ap' to Chicago, Το ξύλο βγήκε από τον Παράδεισο and many more.  During the 1970s and 1980s, Theo Angelopoulos directed a series of notable and appreciated movies. His film Eternity and a Day won the Palme d'Or and the Prize of the Ecumenical Jury at the 1998 Cannes Film Festival.  There are also internationally renowned filmmakers in the Greek diaspora, such as the Greek-French Costa-Gavras and the Greek-Americans Elia Kazan, John Cassavetes and Alexander Payne.  More recently Yorgos Lanthimos (film and stage director, producer, and screenwriter) has received four Academy Award nominations for his work, including Best Foreign Language Film for Dogtooth (2009), Best Original Screenplay for The Lobster (2015), and Best Picture and Best Director for The Favourite (2018).  Sports Main article: Sports in Greece  Spyridon Louis entering the Panathenaic Stadium at the end of the marathon; 1896 Summer Olympics.  Angelos Charisteas scoring Greece's winning goal in the UEFA Euro 2004 Final Greece is the birthplace of the ancient Olympic Games, first recorded in 776 BC in Olympia, and hosted the modern Olympic Games twice, the inaugural 1896 Summer Olympics and the 2004 Summer Olympics. During the parade of nations, Greece is always called first, as the founding nation of the ancient precursor of modern Olympics. The nation has competed at every Summer Olympic Games, one of only four countries to have done so. Having won a total of 110 medals (30 gold, 42 silver and 38 bronze), Greece is ranked 32nd by gold medals in the all-time Summer Olympic medal count. Their best ever performance was in the 1896 Summer Olympics, when Greece finished second in the medal table with 10 gold medals.  The Greek national football team, ranking 12th in the world in 2014 (and having reached a high of 8th in the world in 2008 and 2011),[369] were crowned European Champions in Euro 2004 in one of the biggest upsets in the history of the sport.[370] The Greek Super League is the highest professional football league in the country, comprising sixteen teams. The most successful are Olympiacos, Panathinaikos, and AEK Athens.  The Greek national basketball team has a decades-long tradition of excellence in the sport, being considered among the world's top basketball powers. As of 2012, it ranked 4th in the world and 2nd in Europe.[371] They have won the European Championship twice in 1987 and 2005,[372] and have reached the final four in two of the last four FIBA World Championships, taking the second place in the world in 2006 FIBA World Championship, after a 101–95 win against Team USA in the tournament's semifinal. The domestic top basketball league, A1 Ethniki, is composed of fourteen teams. The most successful Greek teams are Panathinaikos, Olympiacos, Aris Thessaloniki, AEK Athens and P.A.O.K. Greek basketball teams are the most successful in European basketball the last 25 years, having won 9 Euroleagues since the establishment of the modern era Euroleague Final Four format in 1988, while no other nation has won more than 4 Euroleague championships in this period. Besides the 9 Euroleagues, Greek basketball teams (Panathinaikos, Olympiacos, Aris Thessaloniki, AEK Athens, P.A.O.K, Maroussi) have won 3 Triple Crowns, 5 Saporta Cups, 2 Korać Cups and 1 FIBA Europe Champions Cup. After the 2005 European Championship triumph of the Greek national basketball team, Greece became the reigning European Champion in both football and basketball.   The Greek national basketball team in 2008. Twice European champions (1987 and 2005) and second in the world in 2006 The Greece women's national water polo team have emerged as one of the leading powers in the world, becoming World Champions after their gold medal win against the hosts China at the 2011 World Championship. They also won the silver medal at the 2004 Summer Olympics, the gold medal at the 2005 World League and the silver medals at the 2010 and 2012 European Championships. The Greece men's national water polo team became the third best water polo team in the world in 2005, after their win against Croatia in the bronze medal game at the 2005 World Aquatics Championships in Canada. The domestic top water polo leagues, Greek Men's Water Polo League and Greek Women's Water Polo League are considered amongst the top national leagues in European water polo, as its clubs have made significant success in European competitions. In men's European competitions, Olympiacos has won the Champions League,[373] the European Super Cup and the Triple Crown in 2002[374] becoming the first club in water polo history to win every title in which it has competed within a single year (National championship, National cup, Champions League and European Super Cup),[375] while NC Vouliagmeni has won the LEN Cup Winners' Cup in 1997. In women's European competitions, Greek water polo teams (NC Vouliagmeni, Glyfada NSC, Olympiacos, Ethnikos Piraeus) are amongst the most successful in European water polο, having won 4 LEN Champions Cups, 3 LEN Trophies and 2 European Supercups.  The Greek men's national volleyball team has won two bronze medals, one in the European Volleyball Championship and another one in the Men's European Volleyball League, a 5th place in the Olympic Games and a 6th place in the FIVB Volleyball Men's World Championship. The Greek league, the A1 Ethniki, is considered one of the top volleyball leagues in Europe and the Greek clubs have had significant success in European competitions. Olympiacos is the most successful volleyball club in the country having won the most domestic titles and being the only Greek club to have won European titles; they have won two CEV Cups, they have been CEV Champions League runners-up twice and they have played in 12 Final Fours in the European competitions, making them one of the most traditional volleyball clubs in Europe. Iraklis have also seen significant success in European competitions, having been three times runners-up of the CEV Champions League.  In handball, AC Diomidis Argous is the only Greek club to have won a European Cup.  Apart from these, cricket is relatively popular in Corfu.  Mythology Main article: Greek mythology The numerous gods of the ancient Greek religion as well as the mythical heroes and events of the ancient Greek epics (The Odyssey and The Iliad) and other pieces of art and literature from the time make up what is nowadays colloquially referred to as Greek mythology. Apart from serving a religious function, the mythology of the ancient Greek world also served a cosmological role as it was meant to try to explain how the world was formed and operated.  The principal gods of the ancient Greek religion were the Dodekatheon, or the Twelve Gods, who lived on the top of Mount Olympus. The most important of all ancient Greek gods was Zeus, the king of the gods, who was married to his sister, Hera. The other Greek gods that made up the Twelve Olympians were Ares, Poseidon, Athena, Demeter, Dionysus, Apollo, Artemis, Aphrodite, Hephaestus, and Hermes. Apart from these twelve gods, Greeks also had a variety of other mystical beliefs, such as nymphs and other magical creatures.  Public holidays and festivals Main article: Public holidays in Greece  Procession in honor of the Assumption of Virgin Mary (15 August) According to Greek law, every Sunday of the year is a public holiday. Since the late '70s, Saturday also is a non-school and not working day. In addition, there are four mandatory official public holidays: 25 March (Greek Independence Day), Easter Monday, 15 August (Assumption or Dormition of the Holy Virgin), and 25 December (Christmas). 1 May (Labour Day) and 28 October (Ohi Day) are regulated by law as being optional but it is customary for employees to be given the day off. There are, however, more public holidays celebrated in Greece than are announced by the Ministry of Labour each year as either obligatory or optional. The list of these non-fixed national holidays rarely changes and has not changed in recent decades, giving a total of eleven national holidays each year.  In addition to the national holidays, there are public holidays that are not celebrated nationwide, but only by a specific professional group or a local community. For example, many municipalities have a "Patron Saint" parallel to "Name Days", or a "Liberation Day". On such days it is customary for schools to take the day off.  Notable festivals, beyond the religious fests, include Patras Carnival, Athens Festival and various local wine festivals. The city of Thessaloniki is also home of a number of festivals and events. The Thessaloniki International Film Festival is one of the most important film festivals in Southern Europe.[376]  See also flag	Greece portal 	Ancient Greece portal Outline of Greece Outline of ancient Greece Index of Greece-related articles Notes  The Church of Greece is recognized by the Greek Constitution as the prevailing religion in Greece,[2] and is the only country in the world where Eastern Orthodoxy is clearly recognized as a state religion.[3]  Greek: Ελληνική Δημοκρατία, romanized: Elliniki Dimokratia, [eliniˈci ðimokraˈti.a]  See:[14][15][16][17][18][19][20][21]  See:[30][31][32]  On 14 August 1974 Greek forces withdrew from the integrated military structure of NATO in protest at the Turkish occupation of northern Cyprus; Greece rejoined NATO in 1980.  See:[145][146][147][148][149]  For a diachronic analysis of the Greek party system see Pappas 2003, pp. 90–114, who distinguishes three distinct types of party system which developed in consecutive order, namely, a predominant-party system (from 1952 to 1963), a system of polarised pluralism (between 1963 and 1981), and a two-party system (since 1981). References Citations  [1]  [2] The Constitution of Greece: Section II Relations of Church and State: Article 3, Hellenic Resources network.  Enyedi, Zsolt; Madeley, John T.S. (2 August 2004). Church and State in Contemporary Europe. Routledge. p. 228. ISBN 9781135761417. Both as a state church and as a national church, the Orthodox Church of Greece has a lot in common with Protestant state churches, and even with Catholicism in some countries.  [3]  "Religious Belief and National Belonging in Central and Eastern Europe". Pew Research Center. 10 May 2017. Retrieved 9 September 2017.  "Country Comparison: Area". The World Factbook. Central Intelligence Agency. Retrieved 7 January 2013.  "Surface water and surface water change". Organisation for Economic Co-operation and Development (OECD). Retrieved 11 October 2020.  "Statistics - ELSTAT". www.statistics.gr. Retrieved 30 April 2021.  Απογραφή Πληθυσμού – Κατοικιών 2011. ΜΟΝΙΜΟΣ Πληθυσμός [Results of Population-Housing Census 2011 concerning the permanent population of the country] (PDF) (in Greek). 20 March 2014. Retrieved 25 October 2016.  "Announcement of the results of the 2011 Population Census for the Resident Population" (PDF). Hellenic Statistical Authority. 28 December 2012. Archived from the original (PDF) on 13 November 2013. Retrieved 24 August 2013.  "Report for Selected Countries and Subjects: October 2020". IMF. 15 October 2019.  "Gini coefficient of equivalised disposable income – EU-SILC survey". ec.europa.eu. Eurostat. Retrieved 9 August 2021.  Human Development Report 2020 The Next Frontier: Human Development and the Anthropocene (PDF). United Nations Development Programme. 15 December 2020. pp. 343–346. ISBN 978-92-1-126442-5. Retrieved 16 December 2020.  "The Strategic Importance of Greece". geopoliticalfutures.com. 5 April 2016. Retrieved 6 March 2017.  "The Geopolitics of Greece: "One cannot afford anymore to manage the Greek crisis without due consideration of its geopolitical consequences"". janelanaweb.com. Archived from the original on 7 March 2017. Retrieved 6 March 2017.  "The Geostrategic Value of Greece and Sweden in the Current Struggle between Russia and NATO". atlanticcouncil.org. 19 December 2015. Retrieved 6 March 2017.  Kitsikis, Dimitri. "The Geopolitical Importance of Greece through the Ages". academia.edu. Retrieved 6 March 2017.  "The Role of Greece in the Geostrategic Chessboard of Natural Gas". naturalgasworld.com. Retrieved 6 March 2017.  "Geopolitical Consequences Of 'Grexit' Would Be Huge". bmiresearch.com. Retrieved 6 March 2017.  "Greece can still be a geopolitical asset for the EU". europesworld.org. Archived from the original on 11 January 2017. Retrieved 6 March 2017.  "Greece and NATO: a long lasting relationship". nato.int. Retrieved 6 March 2017.  "Government and Politics". Ministry of Foreign Affairs. Archived from the original on 27 December 2019. Retrieved 28 April 2020.  Eugene N. Borza (1992). In the Shadow of Olympus: The Emergence of Macedon. Princeton University Press. p. 58. ISBN 978-0-691-00880-6.  Zimmer, Carl (10 July 2019). "A Skull Bone Discovered in Greece May Alter the Story of Human Prehistory - The bone, found in a cave, is the oldest modern human fossil ever discovered in Europe. It hints that humans began leaving Africa far earlier than once thought". The New York Times. Retrieved 11 July 2019.  Staff (10 July 2019). "'Oldest remains' outside Africa reset human migration clock". Phys.org. Retrieved 10 July 2019.  Harvati, Katerina; et al. (10 July 2019). "Apidima Cave fossils provide earliest evidence of Homo sapiens in Eurasia". Nature. 571 (7766): 500–504. doi:10.1038/s41586-019-1376-z. PMID 31292546. S2CID 195873640.  Douka, K.; Perles, C.; Valladas, H.; Vanhaeren, M.; Hedges, R.E.M. (2011). "Franchthi Cave revisited: the age of the Aurignacian in south-eastern Europe". Antiquity Magazine: 1133.  Perlès, Catherine (2001). The Early Neolithic in Greece: The First Farming Communities in Europe. Cambridge University Press. p. 1. ISBN 9780521000277.  Pullen, David (2008). "The Cambridge Companion to the Aegean Bronze Age". Cambridge Univ. Press.  Ricardo Duchesne (7 February 2011). The Uniqueness of Western Civilization. BRILL. p. 297. ISBN 978-90-04-19248-5. The list of books which have celebrated Greece as the "cradle" of the West is endless; two more examples are Charles Freeman's The Greek Achievement: The Foundation of the Western World (1999) and Bruce Thornton's Greek Ways: How the Greeks Created Western Civilization (2000)  Chiara Bottici; Benoît Challand (11 January 2013). The Myth of the Clash of Civilizations. Routledge. p. 88. ISBN 978-1-136-95119-0. The reason why even such a sophisticated historian as Pagden can do it is that the idea that Greece is the cradle of civilisation is so much rooted in western minds and school curicula as to be taken for granted.  William J. Broad (2007). The Oracle: Ancient Delphi and the Science Behind Its Lost Secrets. Penguin Publishing Group. p. 120. ISBN 978-0-14-303859-7. In 1979, a friend of de Boer's invited him to join a team of scientists that was going to Greece to assess the suitability of the ... But the idea of learning more about Greece – the cradle of Western civilization, a fresh example of tectonic forces at ...  Slomp, Hans (30 September 2011). Europe, A Political Profile: An American Companion to European Politics: An American Companion to European Politics. ABC-CLIO. p. 50. ISBN 978-0-313-39182-8. Retrieved 5 December 2012. Greek Culture and Democracy. As the cradle of Western civilization, Greece long ago discovered the value and beauty of the individual human being. Around 500 BC, Greece  Bulliet, Richard W; Kyle Crossley, Pamela; Headrick, Daniel R; Johnson, Lyman L; Hirsch, Steven W (21 February 2007). The Earth and Its Peoples: A Global History to 1550. Cengage. p. 95. ISBN 978-0-618-77150-9. Retrieved 5 December 2012. The emergence of the Minoan civilization on the island of Crete and the Mycenaean civilization of Greece is another... was home to the first European civilization to have complex political and social structures and advanced technologies  Pomeroy, Sarah B (1999). Ancient Greece: A Political, Social, and Cultural History. Oxford University Press. ISBN 978-0-19-509742-9. Retrieved 5 December 2012. Written by four leading authorities on the classical world, here is a new history of ancient Greece that dynamically presents a generation of new scholarship on the birthplace of Western civilization.  Frucht, Richard C (31 December 2004). Eastern Europe: An Introduction to the People, Lands, and Culture. ABC-CLIO. p. 847. ISBN 978-1-57607-800-6. Retrieved 5 December 2012. People appear to have first entered Greece as hunter-gatherers from southwest Asia about 50,000 years... of Bronze Age culture and technology laid the foundations for the rise of Europe's first civilization, Minoan Crete  Sansone, David (2011). Ancient Greek civilization. Wiley. p. 5. ISBN 9781444358773.  World and Its Peoples. Marshall Cavendish. September 2009. p. 1458. ISBN 978-0-7614-7902-4. Retrieved 5 December 2012. Greece was home to the earliest European civilizations, the Minoan civilization of Crete, which developed around 2000 BC, and the Mycenaean civilization on the Greek mainland, which emerged about 400 years later. The ancient Minoan  Drews, Robert (1995). The End of the Bronze Age: Changes in Warfare and the Catastrophe Ca. 1200 BC. Princeton University Press. p. 3. ISBN 0691025916.  Beckman, Gary M.; Bryce, Trevor R.; Cline, Eric H. (2012). "Writings from the Ancient World: The Ahhiyawa Texts" (PDF). Writings from the Ancient World. Atlanta: Society of Biblical Literature: 6. ISSN 1570-7008.  Kelder, Jorrit M. (2010). The Kingdom of Mycenae: A Great Kingdom in the Late Bronze Age Aegean. academia.edu. Bethesda, MD: CDL Press. pp. 45, 86, 108. Retrieved 18 March 2015.  Short, John R (1987). An Introduction to Urban Geography. Routledge. p. 10. ISBN 9780710203724.  Vidal-Naquet, Pierre. Le monde d'Homère (The World of Homer), Perrin (2000), p. 19.  D.C.H. Rieu's introduction to The Odyssey (Penguin, 2003), p. xi.  Dunn, John (1994). Democracy: the unfinished journey 508 BC – 1993 AD. Oxford University Press. ISBN 978-0-19-827934-1.  Raaflaub, Kurt A; Ober, Josiah; Wallace, Robert W (2007). Origin of Democracy in Ancient Greece. University of California Press. ISBN 978-0-520-24562-4.  Joseph Roisman, Ian Worthington. "A companion to Ancient Macedonia" John Wiley & Sons, 2011. ISBN 144435163X pp 135–138, p 343  Robin Waterfield (19 April 2018). Creators, Conquerors, and Citizens: A History of Ancient Greece. Oxford University Press. p. 148. ISBN 978-0-19-872788-0. They formed an alliance, which we call the Hellenic League, and bound themselves not just to repel the Persians, but to help one another whatever particular enemy threatened the freedom of the Greek cities. This was a real acknowledgment of a shared Greekness, and a first attempt to unify the Greek states under such a banner.  John Van Antwerp Fine (1983). The Ancient Greeks: A Critical History. Harvard University Press. p. 297. ISBN 978-0-674-03314-6. This Hellenic League – the first union of Greek states since the mythical times of the Trojan War – was the instrument through which the Greeks organised their successful resistance to Persia.  Barry Strauss (16 August 2005). The Battle of Salamis: The Naval Encounter That Saved Greece – and Western Civilization. Simon and Schuster. pp. 1–11. ISBN 978-0-7432-7453-1.  Willner, Mark; Hero, George; Wiener, Jerry; Hero, George A. (2006). Global History Volume One: The Ancient World to the Age of Revolution. Barron's Educational Series. p. 79. ISBN 9780764158117.  Walbank, Frank W. (26 August 2010). Selected Papers: Studies in Greek and Roman History and Historiography. Cambridge University Press. p. 1. ISBN 9780521136808. Retrieved 8 September 2018.  Brice, Lee L. (17 October 2012). Greek Warfare: From the Battle of Marathon to the Conquests of Alexander the Great. ABC-CLIO. p. 5. ISBN 9781610690706.  Ian Morris (December 2005). "The growth of Greek cities in the first millennium BC" (PDF). Princeton University.  John Ferguson. "Hellenistic Age: Ancient Greek history". Online Encyclopædia Britannica. Retrieved 29 April 2012.  Kosso, Cynthia; Scott, Anne (2009). The Nature and Function of Water, Baths, Bathing, and Hygiene from Antiquity Through the Renaissance. Brill. p. 51. ISBN 978-9004173576.  Spielvogel, Jackson (2005). Western Civilization. I: To 1715. Thomson Wadsworth. pp. 89–90. ISBN 978-0-534-64603-5.  Flower, Harriet, ed. (2004). The Roman Republic. pp. 248, 258. ISBN 978-0-521-00390-2.  "Antigonid dynasty". Britannica (online ed.). 2008.  Ward, Allen Mason; et al. (2003). A history of the Roman people. p. 276. ISBN 978-0-13-038480-5.  Zoch, Paul (2000). Ancient Rome: An Introductory History. p. 136. ISBN 978-0-8061-3287-7. Retrieved 29 April 2012.  Ferguson, Everett (2003). Backgrounds of Early Christianity. pp. 617–18. ISBN 978-0-8028-2221-5.  Dunstan, William (2011). Ancient Rome. p. 500. ISBN 978-0-7425-6834-1. Retrieved 29 April 2012.  Milburn, Robert (1992). Early Christian Art and Architecture. p. 158. ISBN 9780520074125. Retrieved 29 April 2012.  Gerard Friell; Peabody Professor of North American Archaeology and Ethnography Emeritus Stephen Williams; Stephen Williams (8 August 2005). Theodosius: The Empire at Bay. Routledge. p. 105. ISBN 978-1-135-78262-7.  Tony Perrottet (8 June 2004). The Naked Olympics: The True Story of the Ancient Games. Random House Digital, Inc. pp. 190–. ISBN 978-1-58836-382-4. Retrieved 1 April 2013.  James Allan Stewart Evans (January 2005). The Emperor Justinian and the Byzantine Empire. Greenwood Publishing Group. pp. 65–70. ISBN 978-0-313-32582-3.  J. F. Haldon (1990). Byzantium in the Seventh Century: The Transformation of a Culture. Cambridge University Press. p. 329. ISBN 978-0-521-31917-1.  Makrides, Nikolaos (2009). Hellenic Temples and Christian Churches: A Concise History of the Religious Cultures of Greece from Antiquity to the Present. NYU Press. p. 206. ISBN 978-0-8147-9568-2. Retrieved 29 April 2012.  Jeffreys, Elizabeth, ed. (2008). The Oxford Handbook of Byzantine Studies. p. 4. ISBN 978-0-19-925246-6.  Fine 1991, pp. 35–6.  Fine 1991, pp. 63–6.  Gregory, TE (2010). A History of Byzantium. Wiley-Blackwell. p. 169. It is now generally agreed that the people who lived in the Balkans after the Slavic "invasions" were probably for the most part the same as those who had lived there earlier, although the creation of new political groups and arrival of small immigrants caused people to look at themselves as distinct from their neighbors, including the Byzantines.  Richard M. Rothaus (2000). Corinth, the First City of Greece: An Urban History of Late Antique Cult and Religion. BRILL. p. 10. ISBN 978-90-04-10922-3.  Geanakoplos, Deno John (1984). Byzantium: Church, Society, and Civilization Seen Through Contemporary Eyes. University of Chicago Press. ISBN 9780226284606.  "Greece During the Byzantine Period: Byzantine recovery". Online. Encyclopædia Britannica. Retrieved 28 April 2012.  Fine 1991, pp. 79–83.  "Greece during the Byzantine period (c. AD 300 – c. 1453), Population and languages, Emerging Greek identity". Encyclopædia Britannica. 2008. Online Edition.  "Greece During the Byzantine Period: Results of the Fourth Crusade". Online Encyclopædia Britannica. Retrieved 28 April 2012.  "Greece During the Byzantine Period: The islands". Online Encyclopædia Britannica. Retrieved 14 May 2012.  Vasiliev, Alexander A. (1964). History of the Byzantine Empire, 324–1453. University of Wisconsin Press. p. 582. ISBN 9780299809256.  Moles, Ian (1969). "Nationalism and Byzantine Greece". Greek, Roman and Byzantine Studies: 102. Greek nationalism, in other words, was articulated as the boundaries of Byzantium shrank... the Palaeologian restoration that the two words are brought into definite and cognate relationship with 'nation' (Έθνος).  Steven Runciman; Sir Steven Runciman (24 October 1985). The Great Church in Captivity: A Study of the Patriarchate of Constantinople from the Eve of the Turkish Conquest to the Greek War of Independence. Cambridge University Press. p. 120. ISBN 978-0-521-31310-0. By the fifteenth century most Byzantine intellectuals alluded to themselves as Hellenes. John Argyropoulus even calls the Emperor 'Emperor of the Hellenes' and describes the last wars of Byzantium as a struggle for the freedom of Hellas.  Jane Perry Clark Carey; Andrew Galbraith Carey (1968). The Web of Modern Greek Politics. Columbia University Press. p. 33. ISBN 9780231031707. By the end of the fourteenth century the Byzantine emperor was often called "Emperor of the Hellenes"  Hilsdale, Cecily J. (2014). Byzantine Art and Diplomacy in an Age of Decline. Cambridge University Press. pp. 82–83. ISBN 9781107729384.  "Greece During the Byzantine Period: Serbian and Ottoman advances". Online Encyclopædia Britannica. Retrieved 28 April 2012.  "Greece During the Byzantine Period: The Peloponnese advances". Online Encyclopædia Britannica. Retrieved 28 April 2012.  Norwich, John Julius (1997). A Short History of Byzantium. Vintage Books. p. xxi. ISBN 978-0-679-77269-9.  Nondas Stamatopoulos (1993). Old Corfu: history and culture. N. Stamatopoulos. pp. 164–165. ISBN 9789608403000. Retrieved 6 April 2013. Again, during the first great siege of Corfu by the Turks in 1537, Angelocastro ... and After a siege lasting a year the invaders were finally driven away by the defenders of the fortress who were helped by the inhabitants of the neighbouring villages. In 1571, when they once more invaded Corfu, the Turks again unsuccessfully attacked, Angelocastro, where 4,000 people had taken refuge. During the second great siege of the city by the Turks in 1716, Angelokastro once again served  Clogg 1992, p. 10.  Clogg, 1992 & page 23.  Kourvetaris, George; Dobratz, Betty (1987). A profile of modern Greece: in search of identity. Clarendon Press. p. 33. ISBN 9780198275510.  Clogg 1992, p. 14.  Clogg 1992.  Harrington, Lyn (1968). Greece and the Greeks. T Nelson. p. 124., 221 pp.  Stokes, Jamie; Gorman, Anthony (2010). Encyclopedia of the Peoples of Africa and the Middle East. Infobase. p. 256. ISBN 978-1-4381-2676-0.  Clogg 1992, p. 27.  Clogg 1992, p. 31.  Katsiaridi-Hering, Olga (2009). "La famiglia nell'economia europea, secc. XIII-XVIII". Atti della "quarantesima Settimana di studi," 6–10 Aprile 2008. Istituto internazionale di storia economica F. Datini. Simonetta Cavaciocchi. Firenze University Press. p. 410. ISBN 978-88-8453-910-6.  Hatzopoulos 2009, pp. 81–3.  Hatzopoulos 2009. For the crisis of maritime trade from 1815 onwards, see Kremmydas 1977 and Kremmydas 2002.  Brewer, D. The Greek War of Independence: The Struggle for Freedom from Ottoman Oppression and the Birth of the Modern Greek Nation. Overlook Press, 2001, ISBN 1-58567-172-X, pp. 235–36.  Tucker, Spencer C. (2009). A Global Chronology of Conflict: From the Ancient World to the Modern Middle East. ABC-CLIO. p. 1140. ISBN 9781851096725.  "The Chios Massacre Of 1822". Queens Gazette. Archived from the original on 11 November 2018. Retrieved 11 November 2018.  Klose, Fabian (2016). The Emergence of Humanitarian Intervention: Ideas and Practice... Clays. p. 175. ISBN 9781107075511. Retrieved 6 August 2017.  Willert, Trine Stauning (4 September 2018). The New Ottoman Greece in History and Fiction. Springer. pp. 71–100. ISBN 978-3-319-93849-3.  "Otto". Encyclopedia Britannica. Retrieved 1 September 2018.  Jong, M. de; Lalenis, K.; Mamadouh, V. D. (31 December 2002). The Theory and Practice of Institutional Transplantation: Experiences with the Transfer of Policy Institutions. Springer Science & Business Media. p. 71. ISBN 9781402011085.  Hodge, Carl Cavanagh (2008). Encyclopedia of the Age of Imperialism, 1800-1914. Greenwood Publishing Group. p. 291. ISBN 9780313043413. Retrieved 9 September 2018.  Great Greek Encyclopedia, p. 50-51.  Roudometof, Victor (2001). Nationalism, Globalization, and Orthodoxy: The Social Origins of Ethnic Conflict in the Balkans. Greenwood Publishing Group. pp. 101–113. ISBN 9780313319495.  Wynn, Martin (1984). Planning and Urban Growth in Southern Europe. Mansell. p. 6. ISBN 9780720116083.  Great Greek Encyclopedia, p. 239, "Διὰ τοῦ Συντάγματος τοῦ 1864 καθιερώθει ὡς πολίτευμα διὰ τὴν Ἑλλάδα ἡ κοινοβουλευτικὴ μοναρχία, ἣ, ὅπως ἄλλως ἐχαρακτηρίσθη, ἡ «βασιλευομένη δημοκρατία» ἣ «δημοκρατικὴ βασιλεία»" [Through the Constitution of 1864, constitutional monarchy, or, as it had been described, "crowned democracy", or "democratic monarchy", was consolidated as the form of government in Greece].  "Constitutional History". hellenicparliament.gr. Hellenic Parliament. Retrieved 4 September 2018. The revolt marked the end of constitutional monarchy and the beginning of a crowned democracy with George-Christian-Wilhelm of the Schleswig-Holstein-Sønderburg-Glücksburg dynasty as monarch.  Greece Country Study Guide: Strategic Information and Developments. International Business Publications, USA. 3 March 2012. p. 131. ISBN 978-1-4387-7447-3. In 1862, however, a revolt brought about important changes in the political system that led to the so-called "crowned democracy", i.e. a kingdom with a democratic government.  "Constitutional History". hellenicparliament.gr. Hellenic Parliament. Retrieved 4 September 2018.  Livanios 1999, pp. 195–6, Koliopoulos & Veremis 2002, pp. 280–1, Kostopoulos 2011.  Mazower 1992, pp. 886, 890–3, 895–900, 904  Matthew J. Gibney, Randall Hansen. (2005). Immigration and Asylum: from 1900 to the Present, Volume 3. ABC-CLIO. p. 377. ISBN 978-1-57607-796-2. The total number of Christians who fled to Greece was probably in the region of I.2 million with the main wave occurring in 1922 before the signing of the convention. According to the official records of the Mixed Commission set up to monitor the movements, the Greeks who were transferred after 1923 numbered 189,916 and the number of Muslims expelled to Turkey was 355,635 (Ladas I932, 438–439), but using the same source Eddy 1931, 201 states that the post-1923 exchange involved 192,356 Greeks from Turkey and 354,647 Muslims from Greece.  Sofos, Spyros A.; Özkirimli, Umut (2008). Tormented by History: Nationalism in Greece and Turkey. C Hurst & Co Publishers Ltd. pp. 116–117. ISBN 978-1-85065-899-3.  Schaller, Dominik J; Zimmerer, Jürgen (2008). "Late Ottoman genocides: the dissolution of the Ottoman Empire and Young Turkish population and extermination policies – introduction". Journal of Genocide Research. 10 (1): 7–14. doi:10.1080/14623520801950820. S2CID 71515470.  "Genocide Resolution approved by Swedish Parliament". News.AM., containing both the IAGS and the Swedish resolutions.  Gaunt, David. Massacres, Resistance, Protectors: Muslim-Christian Relations in Eastern Anatolia during World War I. Piscataway, NJ: Gorgias Press, 2006.  Hedges, Chris (17 September 2000). "A Few Words in Greek Tell of a Homeland Lost". The New York Times.  Rummel, RJ (1998). "The Holocaust in Comparative and Historical Perspective". Idea Journal of Social Issues. 3 (2).  Annette Grossbongardt (28 November 2006). "Christians in Turkey: The Diaspora Welcomes the Pope". Der Spiegel.  Howland, Charles P. "Greece and Her Refugees", Foreign Affairs, The Council on Foreign Relations. July 1926.  Hagen, Fleischer (2006). "Authoritarian Rule in Greece (1936–1974) and Its Heritage". Totalitarian and Authoritarian Regimes in Europe: Legacies and Lessons from the Twentieth Century. New York/Oxford: Berghahn. p. 237.  Pilavios, Konstantinos (Director); Tomai, Fotini (Texts & Presentation) (25 October 2010). The Heroes Fight like Greeks – Greece during the Second World War (in Greek). Athens: Service of Diplomatic and Historical Archives of the Greek Ministry of Foreign Affairs. Event occurs at 51 sec. Retrieved 28 October 2010.  Fafalios and Hadjipateras, p. 157  Hitler, Adolf (11 December 1941). Address to the Reichstag  – via Wikisource.  "Greek history since World War I". Encyclopædia Britannica.  Mazower (2001), p. 155  Knopp (2009), p. 193  Chomsky, Noam (1994). World Orders, Old And New. Pluto Press London.  Mazower, Mark. After the War was Over.  Baten, Jörg (2016). A History of the Global Economy. From 1500 to the Present. Cambridge University Press. p. 51, Figure 2.3 "Numeracy in selected Balkan and Caucasus countries", based on data from Crayen and Baten (2010). ISBN 978-1-107-50718-0.  History, Editorial Consultant: Adam Hart-Davis. Dorling Kindersley. ISBN 978-1-85613-062-2.  "Greece". European Union. Retrieved 7 April 2007.  Baten, Jörg (2016). A History of the Global Economy. From 1500 to the Present. Cambridge University Press. p. 66. ISBN 978-1-107-50718-0.  "Greece elections: Centre-right regains power under Kyriakos Mitsotakis". BBC News. 8 July 2019. Retrieved 27 May 2021.  "Greece swears in first female president". www.aljazeera.com.  "The World Factbook – Central Intelligence Agency". cia.gov. Retrieved 10 November 2017.  "UNITED NATIONS GROUP OF EXPERTS ON GEOGRAPHICAL NAMES: Working Paper No. 48" (PDF). UN. 2006. Retrieved 2 September 2015.  Chrēstos G. Kollias; Gülay Günlük-Şenesen; Gülden Ayman (2003). Greece and Turkey in the 21st Century: Conflict Or Cooperation: a Political Economy Perspective. Nova Publishers. p. 10. ISBN 978-1-59033-753-0. Retrieved 12 April 2013. Greece's Strategic Position in the Balkans And Eastern Mediterranean Greece is located at the crossroads of three continents (Europe, Asia and Africa). It is an integral part of the Balkans (where it is the only country that is a member of the ...)  Christina Bratt Paulston; Scott F. Kiesling; Elizabeth S. Rangel (13 February 2012). The Handbook of Intercultural Discourse and Communication. John Wiley & Sons. p. 292. ISBN 978-1-4051-6272-2. Retrieved 12 April 2013. Introduction Greece and Turkey are situated at the crossroads of Europe, Asia, the Middle East and Africa, and their inhabitants have had a long history of cultural interaction even though their languages are neither genetically nor typologically ...  Caralampo Focas (2004). Transport Issues And Problems in Southeastern Europe. Ashgate Publishing, Ltd. p. 114. ISBN 978-0-7546-1970-3. Retrieved 12 April 2013. Greece itself shows a special geopolitical importance as it is situated at the crossroads of three continents – Europe, Asia and Africa – and can be therefore considered as a natural bridge between Europe and the Middle East  Centre for Economic Policy Research (Great Britain) (2005). European Migration: What Do We Know?. Oxford University Press. p. 337. ISBN 978-0-19-925735-5. Introduction Migration movements from and to, or via Greece, are an age-old phenomenon. Situated at the crossroads of three continents (Europe, Asia, and Africa), Greece has been, at different historical times, both a labour...  Sladjana Petkovic; Howard Williamson (21 July 2015). Youth policy in Greece: Council of Europe international review. Council of Europe. p. 48. ISBN 978-92-871-8181-7. As reports from the GSY (2007) show, young people have the opportunity to become acquainted with many diverse civilisations and cultures, through Greece's strategic location at the crossroads of Europe, Asia, and Africa. Accordingly, many ...  "The World Fact Book – Field Listing :: Coastline". Central Intelligence Agency. Retrieved 17 March 2011.  "Statistical Yearbook of Greece 2009 & 2010" (PDF). Hellenic Statistical Authority. p. 27. Archived from the original (PDF) on 13 December 2013.  "Olympus the First National Park". Management Agency of Olympus National Park. 2008. Archived from the original on 14 January 2017. Retrieved 5 December 2015.  Guinness World Records 2005: Special 50th Anniversary Edition. Guinness World Records. 2004. p. 52. ISBN 978-1-892051-22-6.  Marker, Sherry; Bowman, John; Kerasiotis, Peter; Sarna, Heidi (2010). Frommer's Greek Islands. John Wiley & Sons. p. 12. ISBN 978-0-470-52664-4.  "The Climate of Greece". Hellenic National Meteorological Service. Retrieved 3 December 2019.  "Climate Atlas of Greece" (PDF). Hellenic National Meteorological Service. Archived from the original (PDF) on 21 September 2017. Retrieved 30 December 2019.  "Greece - Climate". Encyclopedia Britannica. Retrieved 21 June 2020.  Dinerstein, Eric; Olson, David; Joshi, Anup; Vynne, Carly; Burgess, Neil D.; Wikramanayake, Eric; Hahn, Nathan; Palminteri, Suzanne; Hedao, Prashant; Noss, Reed; Hansen, Matt; Locke, Harvey; Ellis, Erle C; Jones, Benjamin; Barber, Charles Victor; Hayes, Randy; Kormos, Cyril; Martin, Vance; Crist, Eileen; Sechrest, Wes; Price, Lori; Baillie, Jonathan E. M.; Weeden, Don; Suckling, Kierán; Davis, Crystal; Sizer, Nigel; Moore, Rebecca; Thau, David; Birch, Tanya; Potapov, Peter; Turubanova, Svetlana; Tyukavina, Alexandra; de Souza, Nadia; Pintea, Lilian; Brito, José C.; Llewellyn, Othman A.; Miller, Anthony G.; Patzelt, Annette; Ghazanfar, Shahina A.; Timberlake, Jonathan; Klöser, Heinz; Shennan-Farpón, Yara; Kindt, Roeland; Lillesø, Jens-Peter Barnekow; van Breugel, Paulo; Graudal, Lars; Voge, Maianna; Al-Shammari, Khalaf F.; Saleem, Muhammad (2017). "An Ecoregion-Based Approach to Protecting Half the Terrestrial Realm". BioScience. 67 (6): 534–545. doi:10.1093/biosci/bix014. ISSN 0006-3568. PMC 5451287. PMID 28608869.  Grantham, H. S.; Duncan, A.; Evans, T. D.; Jones, K. R.; Beyer, H. L.; Schuster, R.; Walston, J.; Ray, J. C.; Robinson, J. G.; Callow, M.; Clements, T.; Costa, H. M.; DeGemmis, A.; Elsen, P. R.; Ervin, J.; Franco, P.; Goldman, E.; Goetz, S.; Hansen, A.; Hofsvang, E.; Jantz, P.; Jupiter, S.; Kang, A.; Langhammer, P.; Laurance, W. F.; Lieberman, S.; Linkie, M.; Malhi, Y.; Maxwell, S.; Mendez, M.; Mittermeier, R.; Murray, N. J.; Possingham, H.; Radachowsky, J.; Saatchi, S.; Samper, C.; Silverman, J.; Shapiro, A.; Strassburg, B.; Stevens, T.; Stokes, E.; Taylor, R.; Tear, T.; Tizard, R.; Venter, O.; Visconti, P.; Wang, S.; Watson, J. E. M. (2020). "Anthropogenic modification of forests means only 40% of remaining forests have high ecosystem integrity - Supplementary Material". Nature Communications. 11 (1): 5978. doi:10.1038/s41467-020-19493-3. ISSN 2041-1723. PMC 7723057. PMID 33293507.  "Syntagma" (PDF) (in Greek). Archived from the original (PDF) on 25 September 2007. Retrieved 2 August 2009.  Dagtoglou 1991, p. 21.  Venizelos 2002, pp. 131–32, 165–72.  Mavrias 2002, pp. 477–78, 486–87  Εφημερίδα της Κυβερνήσεως τη Ελληνικής Δημοκρατίας [Government Gazette of the Hellenic Republic] (in Greek), A, Athens: National Publishing House, 27 July 2016, retrieved 12 February 2019  "OECD Better Life Index -Greece". w.oecdbetterlifeindex.org. OECD. Retrieved 20 February 2018.  "Πολιτική Συγκυρία & Διακυβέρνηση" [Political climate & governance] (PDF). GR: VPRC. 22 December 2011. Archived from the original (PDF) on 25 April 2012. Retrieved 22 December 2011.  "Πολιτική Συγκυρία & Διακυβέρνηση" [Political conjuncture & governance] (PDF). VPRC. GR. 26 January 2012. Retrieved 26 January 2012.  "Πανελλαδικη Ερευνα για την ET3" (PDF). To The Point. GR. 29 January 2012. Retrieved 29 January 2012.  "Ερευνα της Pulse RC για το Ποντικι" (PDF). GR: Pulse RC. 2 February 2012. Retrieved 2 February 2012 – via Ek logika.  "Πολιτικό Βαρόμετρο 99" [Political barometer] (PDF). Public Issue. Ek logika. 7 February 2012. Retrieved 7 February 2011.  "Lucas Papademos named as new Greek prime minister". BBC News. 10 November 2011. Retrieved 10 November 2011.  Katsourides, Yiannos (22 September 2016). Radical Left Parties in Government: The Cases of SYRIZA and AKEL. Springer. p. 94. ISBN 9781137588418.  "Greece election: Anti-austerity Syriza wins election". BBC News. 26 January 2015.  GMT, Graeme Wearden until 4 15pm; Tran (now), Mark (26 January 2015). "Alexis Tsipras sworn in as new Greek prime minister – as it happened". The Guardian – via www.theguardian.com.  K, D. "Vassiliki Thanou-Christophilou became Greece's first female Prime Minister | Economy Watch".  "Greece election: Alexis Tsipras hails 'victory of the people'". BBC News. 21 September 2015.  "Greek Finance Minister Tsakalotos takes key role in Tsipras' new cabinet | DW | 23.09.2015". DW.COM.  "Greek elections: landslide victory for centre-right New Democracy party". the Guardian. 7 July 2019.  "New era as Mitsotakis is sworn in as Greece's new PM". www.aljazeera.com.  Αρχές του Εξωτερικού [Missions Abroad] (in Greek). Hellenic Republic Ministry of Foreign Affairs. Archived from the original on 21 May 2011. Retrieved 2 July 2011.  "Mission and Competences". Ministry for Foreign Affairs. Retrieved 23 February 2012.  "Foreign Policy Issues". Ministry for Foreign Affairs. Retrieved 23 February 2012.  "Turkey threatens Greece over disputed Mediterranean territorial claims". Deutsche Welle. 5 September 2020.  "Regional Policy". Ministry for Foreign Affairs. Retrieved 23 February 2012.  Thanos Veremēs (1997)The Military in Greek Politics "Black Rose Books"  Law 1481/1 October 1984, Official Journal of the Hellenic Republic, A-152  "The World Factbook -- Greece". Central Intelligence Agency. Retrieved 19 July 2017.  Dempsey, Judy. "EU and NATO Look on at Greece's Pampered Armed Forces". Carnegie Europe. Retrieved 19 July 2017.  "Πίνακας 1: Προσωρινά αποτελέσματα του Μόνιμου Πληθυσμού της Ελλάδος" (PDF). National Statistical Service. 22 July 2011.  "Regional GDP per capita ranged from 29% to 611% of the EU average in 2016". Eurostat. 2016. Retrieved 5 October 2018.  "Gross domestic product 2013". World Bank. 14 February 2015. Retrieved 14 February 2015.  "Gross domestic product 2013, PPP". World Bank. 14 February 2015. Retrieved 14 February 2015.  "Gross domestic product at market prices (tec00001)". Eurostat. Archived from the original on 14 August 2012. Retrieved 22 February 2012.  "World Economic Outlook" (PDF). International Monetary Fund. Retrieved 23 February 2012.  "Groups and Aggregates Information". World Economic Outlook Database. International Monetary Fund. April 2013. Retrieved 10 September 2013.  "Appendix B: International Organizations and Groups". The World Factbook. Central Intelligence Agency. Retrieved 10 September 2013.  "Country and Lending Groups - Data". World Bank. Archived from the original on 18 March 2011. Retrieved 3 August 2017.  "WEO Groups and Aggregates Information". World Economic Outlook Database. Washington, D.C.: International Monetary Fund. 8 April 2014. Retrieved 2 August 2014.  "Country and Lending Groups". Washington, D.C.: World Bank. Retrieved 2 August 2014.  The world's best countries: 2010 index, Newsweek. Accessed on line 15 August 2010.  "The lottery of life". The Economist. London. 21 November 2012. Retrieved 2 August 2014.  "Table 1: Human Development Index and its components". Human Development Report 2014. New York: United Nations Development Programme. 24 July 2014. Retrieved 2 August 2014.  "Gross Added Value by Industry (A17; Years 2000–2011)". Piraeus: Hellenic Statistical Authority. Archived from the original on 13 November 2012. Retrieved 22 March 2012.  "UNWTO World Tourism Barometer" (PDF). United Nations World Tourism Organization. Archived from the original (PDF) on 3 September 2015. Retrieved 22 February 2012.  "Review of Maritime Transport 2011" (PDF). United Nations. 2011. Retrieved 17 February 2012.  "Euro area unemployment rate at 11%". Eurostat. Archived (PDF) from the original on 31 July 2017.  "Youth unemployment rate in EU member states as of March 2018". Statista.  Likmeta, Besar; BIRN, Gjirokastra (11 July 2012). "Albania Eyes New Markets as Greek Crisis Hits Home Businesses affected by the economic downturn in Greece are seeking new markets in the West, hoping that a cheap and qualified labour force will draw fresh clients". Balkan Insight. Retrieved 18 April 2014. Greece is the Balkan region's largest economy and has been an important investor in Southeast Europe over the past decade  Keridis, Dimitris (3 March 2006). "Greece and the Balkans: From Stabilization to Growth" (lecture). Montreal, QC, CA: Hellenic Studies Unit at Concordia University. Greece has a larger economy than all the Balkan countries combined. Greece is also an important regional investor  Prof. Nicholas Economides Stern School of Business, New York University & Haas School of Business, UC Berkeley. "The Greek and EU Crisis for non-economists" (PDF). Largest economy than all rest of Balkans combined  Imogen Bell (2002). Central and South-Eastern Europe: 2003. Routledge. p. 282. ISBN 978-1-85743-136-0. Retrieved 27 May 2013. show that Greece has become the largest investor into Macedonia (FYRM), while Greek companies such as OTE have also developed strong presences in countries of the former Yugoslavia and other Balkan countries.  Mustafa Aydin; Kostas Ifantis (28 February 2004). Turkish-Greek Relations: The Security Dilemma in the Aegean. Taylor & Francis. pp. 266–267. ISBN 978-0-203-50191-7. Retrieved 27 May 2013. second largest investor of foreign capital in Albania, and the third largest foreign investor in Bulgaria. Greece is the most important trading partner of the Former Yugoslav Republic of Macedonia.  Wayne C. Thompson (9 August 2012). Western Europe 2012. Stryker Post. p. 283. ISBN 978-1-61048-898-3. Retrieved 27 May 2013. Greeks are already among the three largest investors in Bulgaria, Romania and Serbia, and overall Greek investment in the ... Its banking sector represents 16% of banking activities in the region, and Greek banks open a new branch in a Balkan country almost weekly.  "Fixed Euro conversion rates". European Central Bank. Retrieved 23 February 2012.  "2010-2018 Greek Debt Crisis and Greece's Past: Myths, Popular Notions and Implications". Academia.edu. Retrieved 14 October 2018.  "Eurostat (Government debt data)". Eurostat. Retrieved 5 September 2018.  "Greece not alone in exploiting EU accounting flaws". Reuters. 22 February 2010. Retrieved 20 August 2010.  "Greece is far from the EU's only joker". Newsweek. 19 February 2010. Retrieved 16 May 2011.  "The Euro PIIGS out". Librus Magazine. 22 October 2010. Archived from the original on 20 August 2011. Retrieved 17 May 2011.  "'Creative accounting' masks EU budget deficit problems". Sunday Business. 26 June 2005. Archived from the original on 15 May 2013. Retrieved 17 May 2011.  "How Europe's governments have enronized their debts". Euromoney. September 2005. Retrieved 1 January 2014.  "How Italy shrank its deficit". Euromoney. 1 December 2001. Retrieved 30 August 2017.  "Italy faces restructured derivatives hit". Financial Times. 25 June 2013. Retrieved 7 January 2019.  "Rehn: No Other State Will Need a Bail-Out". EU Observer. Retrieved 6 May 2010.  "Greece Paid Goldman $300 Million To Help It Hide Its Ballooning Debts". Business Insider. Archived from the original on 20 April 2010. Retrieved 6 May 2010.  LOUISE STORY; LANDON THOMAS Jr; NELSON D. SCHWARTZ (13 February 2010). "Global Business: Wall St. Helped to Mask Debt Fueling Europe's Crisis". The New York Times. In dozens of deals across the Continent, banks provided cash upfront in return for government payments in the future, with those liabilities then left off the books. Greece, for example, traded away the rights to airport fees and lottery proceeds in years to come.  Nicholas Dunbar; Elisa Martinuzzi (5 March 2012). "Goldman Secret Greece Loan Shows Two Sinners as Client Unravels". Bloomberg L.P. Greece actually executed the swap transactions to reduce its debt-to-gross-domestic-product ratio because all member states were required by the Maastricht Treaty to show an improvement in their public finances," Laffan said in an e-mail. "The swaps were one of several techniques that many European governments used to meet the terms of the treaty."  Edmund Conway Economics (15 February 2010). "Did Goldman Sachs help Britain hide its debts too?". The Telegraph. London. Archived from the original on 18 February 2010. One of the more intriguing lines from that latter piece says: "Instruments developed by Goldman Sachs, JPMorgan Chase and a wide range of other banks enabled politicians to mask additional borrowing in Greece, Italy and possibly elsewhere." So, the obvious question goes, what about the UK? Did Britain hide its debts? Was Goldman Sachs involved? Should we panic?  Elena Moya (16 February 2010). "Banks that inflated Greek debt should be investigated, EU urges". The Guardian. "These instruments were not invented by Greece, nor did investment banks discover them just for Greece," said Christophoros Sardelis, who was chief of Greece's debt management agency when the contracts were conducted with Goldman Sachs.Such contracts were also used by other European countries until Eurostat, the EU's statistic agency, stopped accepting them later in the decade. Eurostat has also asked Athens to clarify the contracts.  Beat Balzli (8 February 2010). "Greek Debt Crisis: How Goldman Sachs Helped Greece to Mask its True Debt". Der Spiegel. Retrieved 29 October 2013. This credit disguised as a swap didn't show up in the Greek debt statistics. Eurostat's reporting rules don't comprehensively record transactions involving financial derivatives. "The Maastricht rules can be circumvented quite legally through swaps," says a German derivatives dealer. In previous years, Italy used a similar trick to mask its true debt with the help of a different US bank.  Story, Louise; Thomas Jr, Landon; Schwartz, Nelson D. (14 February 2010). "Wall St. Helped To Mask Debt Fueling Europe's Crisis". The New York Times. Retrieved 6 May 2010.  "Papandreou Faces Bond Rout as Budget Worsens, Workers Strike". Bloomberg L.P. 22 April 2010. Archived from the original on 23 June 2011. Retrieved 2 May 2010.  Staff (19 February 2010). "Britain's Deficit Third Worst in the World, Table". The Daily Telegraph. London. Retrieved 5 August 2011.  Melander, Ingrid; Papchristou, Harry (5 November 2009). "Greek Debt To Reach 120.8 Pct of GDP in '10 – Draft". Reuters. Retrieved 5 August 2011.  Thesing, Gabi; Krause-Jackson, Flavia (3 May 2010). "Greece Faces 'Unprecedented' Cuts as $159B Rescue Nears". Bloomberg. Retrieved 6 May 2010.  Kerin Hope (2 May 2010). "EU Puts Positive Spin on Greek Rescue". Financial Times. Retrieved 6 May 2010.  Newman, Rick (3 November 2011). "Lessons for Congress From the Chaos in Greece". US News. Archived from the original on 4 November 2011. Retrieved 3 November 2011.  "Q&A: Greek debt". BBC News Online. Retrieved 14 May 2012.  Bensasson, Marcus (4 November 2014). "Greece exited recession in second quarter, says EU Commission". Kathimerini. Retrieved 4 November 2014.  "Greek growth rates put Germany, eurozone to shame". MarketWatch. 14 November 2014. Retrieved 16 November 2014.  "Tsipras says Greece won't go back to old spending ways". 27 June 2018. Retrieved 30 July 2018.  "IMF 'to admit mistakes' in handling Greek debt crisis and bailout (The Guardian)". 5 June 2013. Retrieved 22 June 2018.  "For hard-hit Greeks, IMF mea culpa comes too late (Reuters)". 6 June 2013. Retrieved 22 June 2018.  "IMF admits disastrous love affair with the euro and apologises for the immolation of Greece (The Telegraph)". 29 July 2016. Retrieved 22 June 2018.  "Should other Eurozone programme countries worry about a reduced Greek primary surplus target?". 25 February 2015. Retrieved 28 May 2017.  "Why Three Rescues Didn't Solve Greece's Debt Problem (Bloomberg)". 18 June 2018. Retrieved 22 June 2018.  "Will the IMF Apologize to Greece ? (WSJ)". 15 June 2014. Retrieved 22 June 2018.  "Debt deal exceeded market expectations, Tsipras says (Kathimerini)". 22 June 2018. Retrieved 22 June 2018.  "Pavlopoulos to Moscovici: the mistakes that led to painful sacrifices for the Greek people should not be repeated (Kathimerini, in Greek))". 3 July 2018. Retrieved 30 July 2018.  "Eurostat (2017 Government debt data)". Eurostat. 24 April 2018. Retrieved 5 September 2018.  "Greece exits final bailout successfully: ESM". Reuters. 20 August 2018. Retrieved 31 August 2018.  "Crops products (excluding fruits and vegetables) (annual data)". Eurostat. Archived from the original on 6 October 2014. Retrieved 19 October 2011.  "Fruits and vegetables (annual data)". Eurostat. Retrieved 19 October 2011.  "Public Power Corporation S.A. Financial Report (January 1, 2010 – December 31, 2010)" (PDF). Public Power Corporation of Greece. 2010. Retrieved 24 October 2011.  "Energy". Invest in Greece Agency. Archived from the original on 20 August 2011. Retrieved 26 October 2011.  "Share of renewable energy in gross final energy consumption %". Eurostat. 2008. Retrieved 24 October 2011.  "Sustainable development in the European Union" (PDF). Eurostat. 2009. Archived from the original (PDF) on 26 August 2011. Retrieved 24 October 2011.  "Renewable energy – Targets by 2020". Eurostat. Retrieved 24 October 2011.  "Πορίσματα της Ομάδας Εργασίας της Επιτροπής Ενέργειας της Ακαδημίας Αθηνών επί του θέματος "Πυρηνική Ενέργεια και Ενεργειακές Ανάγκες της Ελλάδος"" (PDF). Academy of Athens. Archived from the original (PDF) on 22 November 2011. Retrieved 24 October 2011.  Polemis, Spyros M. "The History of Greek Shipping". greece.org. Retrieved 9 April 2007.  Press release (11 May 2006). "Greek Shipping Is Modernized To Remain a Global Leader and Expand Its Contribution to the Greek Economy". National Bank of Greece. Archived from the original on 31 August 2007. Retrieved 8 April 2007.  "Review of Maritime Transport 2010" (PDF). United Nations. 2010. Retrieved 10 August 2011.  "Review of Maritime Transport 2006" (PDF). United Nations. 2006. Archived from the original (PDF) on 28 July 2011. Retrieved 10 August 2011.  "Top 15 Ranking of World Merchant Fleet by Country of Owner, Year-End 2006". U.S. Bureau of Transportation Statistics. 2001. Archived from the original on 29 October 2013. Retrieved 11 June 2013.  Engber, Daniel (17 August 2005). "So Many Greek Shipping Magnates..." Slate. Retrieved 5 August 2011.  Jill Dubois; Xenia Skoura; Olga Gratsaniti (2003). Greece. Marshall Cavendish. p. 42. ISBN 978-0-7614-1499-5. Retrieved 14 April 2013. Greek ships make up 70 percent of the European Union's total merchant fleet. Greece has a large shipbuilding and ship refitting industry. Its six shipyards near Piraeus are among the biggest in Europe. As Greek ships primarily transport ...  "Mega yacht owners choose Greece for construction and maintenance, Ilias Bellos | Kathimerini". www.ekathimerini.com.  "2011 World's Best Awards". Travel+Leisure. Archived from the original on 12 July 2011. Retrieved 16 July 2011.  "World's Best Islands". BBC. Retrieved 1 December 2011.  Chloe Wynne. "Greek tourism sector growing over three times faster than wider economy says new WTTC research". WTTC. Retrieved 21 April 2019.  ""Έσπασε τα κοντέρ" ο ελληνικός τουρισμός το 2016". Newsbeast.gr. 20 January 2017. Retrieved 3 August 2017.  "Nights spent in tourist accommodation establishments – regional – annual data". Eurostat. 2010. Retrieved 10 August 2011.  "Tourism" (PDF). Eurostat. 2010. Archived from the original (PDF) on 16 May 2011. Retrieved 10 August 2011.  02. Αφίξεις αλλοδαπών από το εξωτερικό κατά υπηκοότητα και μέσο ταξιδίου ( Δεκέμβριος 2007 ) [02. Arrivals of foreigners from abroad by nationality and means of travel (December 2007)] (PDF) (in Greek). Hellenic National Statistics Agency. December 2007. Archived from the original (PDF) on 14 November 2010. Retrieved 10 August 2011.  "Ultimate party cities". Lonely Planet. Retrieved 10 August 2011.  "World's Best Awards – Islands". Travel + Leisure. Archived from the original on 12 July 2011. Retrieved 10 August 2011.  "Greece Properties inscribed on the World Heritage List (17)". Unesco.  ERGOSE - Investment Program, 30 March 2016  Το 20% του πληθυσμού πλησιάζει η διείσδυση της ευρυζωνικότητας στην Ελλάδα [20% of the population approaching broadband penetration in Greece] (in Greek). in.gr. 2 May 2011. Retrieved 18 April 2014.  "Το 81,8 των Ελληνων σερφαρει στο ιντερνετ" [81.8% of Greeks surf the Internet]. Kathimerini.gr. Retrieved 28 October 2016.  "Finding Free WiFi Internet in the Greek Islands". Open Journey. 29 June 2011. Retrieved 20 August 2011.  "ICT Development Index (IDI), 2010 and 2008" (PDF). The United Nations Telecommunication Union|International Telecommunication Union. Retrieved 22 July 2012. p. 15.  "R&D spending in Greece reached a record high in 2017". www.greeknewsagenda.gr. Retrieved 3 August 2019.  "Release of the Global Innovation Index 2020: Who Will Finance Innovation?". www.wipo.int. Retrieved 2 September 2021.  "Global Innovation Index 2019". www.wipo.int. Retrieved 2 September 2021.  "RTD - Item". ec.europa.eu. Retrieved 2 September 2021.  "Global Innovation Index". INSEAD Knowledge. 28 October 2013. Retrieved 2 September 2021.  Lambert, Fred (24 February 2018). "Tesla is building an electric motor R&D group in Greece to tap into strong local electrical engineering talent". Electrek.co.  "Greece becomes 16th ESA Member State". ESA. 22 March 2005. Retrieved 15 May 2012.  "School enrollment, tertiary (% gross) - Country Ranking". indexmundi.com. Index Mundi. Retrieved 26 February 2018.  "University reforms in Greece face student protests". The Economist. 6 July 2006. Archived from the original on 7 December 2008. Retrieved 19 December 2008.  "Greek scientific publications increase their impact". greeknewsagenda.gr. Retrieved 15 May 2020.  "Visualisations - Eurostat". ec.europa.eu. Retrieved 3 August 2019.  "The World Factbook". Central Intelligence Agency. Retrieved 19 July 2017.  Max Roser (2014), "Total Fertility Rate around the world over the last centuries", Our World in Data, Gapminder Foundation, archived from the original on 7 August 2018, retrieved 7 May 2019  "World Factbook EUROPE : GREECE", The World Factbook, 12 July 2018  "Greece in Numbers" (PDF). Hellenic Statistical Authority. 2006. Archived from the original (PDF) on 7 July 2004. Retrieved 14 December 2007.  Hope, Kerin (16 August 2018). "Greece brain drain hampers recovery from economic crisis". Financial Times. Retrieved 3 August 2019.  Harry Coccossis; Yannis Psycharis (2008). Regional analysis and policy: the Greek experience. ISBN 9783790820867. Retrieved 19 August 2011.  "Athena 2001 Census". National Statistical Service of Greece. Archived from the original on 17 January 2008. Retrieved 14 December 2007.  Official Final Census Results, 2011. "Announcement on the Publication of Revised 2011 Census Tables". statistics.gr. Hellenic Statistical Authority.  "The Constitution of Greece". Hellenic Resources Network.  "Greece". International Religious Freedom Report 2007. United States Department of State, Bureau of Democracy, Human Rights, and Labor. 15 September 2006. Retrieved 14 April 2007.  "Special Eurobarometer, biotechnology; Fieldwork: January–February 2010" (PDF). October 2010. p. 204. Archived from the original (PDF) on 15 December 2010.  "Dagens ESS: Religiøsitet og kirkebesøk" [Today ESS: Religiosity and church visits] (in Norwegian). Forskning. 11 October 2005. Retrieved 11 September 2010.  Ktistakis, Ioannis; Sitaropoulos, Nicholas (22 June 2004). "Executive Summary Discrimination on the Grounds of Religion and Belief Greece" (PDF). European Commission. Archived from the original (PDF) on 5 June 2007. Retrieved 14 April 2007.  "Greece". United States Department of State. 26 August 2005. Retrieved 6 January 2009.  "Turkey – Population". Countrystudies.us. US: Library of Congress.  The Guardian, Thessaloniki’s Jews: 'We can’t let this be forgotten; if it’s forgotten, it will die'  Leustean, Lucian N. (2014). "Eastern Christianity and Politics in the Twenty-First Century: an Overview" in Lucian N. Leustean (editor), Eastern Christianity and Politics in the Twenty-First Century, pp. 1-20. New York: Routledge. ISBN 978-0-415-68490-3, pp 8-9.  "Synod of Apostolic Church of Christ". Pentecost. Archived from the original on 16 December 2004. Retrieved 22 March 2009.  "Christianity Ministries" (in Greek). christianity.gr. Archived from the original on 30 May 2005. Retrieved 22 March 2009.  Ελευθέρα Αποστολική Εκκλησία της Πεντηκοστής [Free Apostolic Church of Pentecost] (in Greek). egolpio.com. Archived from the original on 2 December 2008. Retrieved 22 March 2009.  "2014 Yearbook of Jehovah's Witnesses" (PDF). Watchtower Bible and Tract Society of New York, Inc. 2014. pp. 178–187. Archived from the original (PDF) on 31 December 2014. Retrieved 31 December 2014.  "Hellenism legally recognized as religion in Greece". wildhunt.org. Retrieved 9 April 2017.  "Newstatesman – The ancient Gods of Greece are not extinct". Archived from the original on 2 December 2008.  "Modern Athenians fight for the right to worship the ancient Greek gods". The Daily Telegraph. Archived from the original on 1 September 2004.  "Helena Smith on why some Greeks are worshipping the ancient gods". The Guardian. London.  "Languages of Greece". Ethnologue. Summer institute of Linguistics. Retrieved 19 December 2010.  "Euromosaic - Le [slavo]macédonien / bulgare en Grèce". www.uoc.edu. Archived from the original on 4 March 2016. Retrieved 8 February 2019.  "Euromosaic - L'arvanite / albanais en Grèce". www.uoc.edu. Archived from the original on 2 July 2019. Retrieved 8 February 2019.  "Euromosaic - Le valaque (aromoune, aroumane) en Grèce". www.uoc.edu. Archived from the original on 3 March 2016. Retrieved 8 February 2019.  "Turkish The Turkish language in Education in Greece" (PDF). mercator-research.eu.  Trudgill 2000.  "Minority Rights Group, Greece, Report about Compliance with the Principles of the Framework Convention for the Protection of National Minorities (along guidelines for state reports according to Article 25.1 of the Convention)". Greek Helsinki Monitor. 8 September 1999. Archived from the original on 11 January 2012. Retrieved 27 December 2011.  Roudometof, Victor; Robertson, Roland (2001). Nationalism, Globalization, and Orthodoxy – The Social Origins of Ethnic Conflict in the Balkans. Westport, Connecticut: Greenwood. p. 186. ISBN 978-0-313-31949-5.  Triandafyllidou, Anna. "Migration and Migration Policy in Greece" Archived 23 September 2013 at the Wayback Machine. Critical Review and Policy Recommendations. Hellenic Foundation for European and Foreign Policy. No. 3, April 2009  Kasimis, Charalambos; Kassimi, Chryssa (June 2004). "Greece: A History of Migration". Migration Information Source.  Managing Migration: The Promise of Cooperation. By Philip L. Martin, Susan Forbes Martin, Patrick Weil  "Announcement of the demographic and social characteristics of the Resident Population of Greece according to the 2011 Population" (PDF) (Press release). Greek National Statistics Agency. 23 August 2013. p. 9. Archived from the original (PDF) on 25 December 2013. Retrieved 3 June 2014.  "In crisis, Greece rounds up immigrants – Associated Press". The Guardian. London. 22 August 2012. Retrieved 11 June 2013.  "Refugees/Migrants Emergency Response – Mediterranean, Greece". UNHCR. 13 February 2016. Retrieved 20 February 2016.  "Migrant crisis: Migration to Europe explained in seven charts". BBC News. 4 March 2016. Retrieved 7 June 2017.  Simpson, John (24 December 2015). "This migrant crisis is different from all others". BBC News. Retrieved 7 June 2017.  "Jerome Bump, University of Constantinople". The Origin of Universities. University of Texas at Austin. Archived from the original on 20 February 2009. Retrieved 19 December 2008.  Tatakes, Vasileios N.; Moutafakis, Nicholas J. (2003). Byzantine Philosophy. Hackett Publishing. p. 189. ISBN 978-0-87220-563-5.  "OECD Better Life Index - Greece". oecdbetterlifeindex.org. OECD. Retrieved 20 February 2018.  "Health Systems: Improving Performance" (PDF). World Health Report. World Health Organization. 2000. Retrieved 22 July 2011.  "State of the World's Mothers 2013". Save the Children. 2013. Retrieved 7 May 2013.  Προταση Λειτουργικων Αναδιαταξεων Μοναδων Υγειασ Εσυ [Proposals for functional rearrangements of the NHS health units] (in Greek). Ethnos. 1 July 2011. Archived from the original (PDF) on 21 May 2012. Retrieved 23 March 2016.  Hellenic Statistical Authority, 2018  "How Does Greece Compare" (PDF). Health Data. Organisation for Economic Co-operation and Development. 2011. Archived from the original (PDF) on 2 September 2009. Retrieved 22 July 2011.  Economou C, Kaitelidou D, Karanikolos M, Maresso A. Greece: Health system review. Health Systems in Transition, 2017; 19(5):1–192.  "The Island Where People Live Longer". NPR. 2 May 2009. Retrieved 6 April 2013. Buettner and a team of demographers work with census data to identify blue zones around the world. They found Icaria had the highest percentage of 90-year-olds anywhere on the planet — nearly 1 out of 3 people make it to their 90s.  DAN BUETTNER (24 October 2012). "The Island Where People Forget to Die". The New York Times. Retrieved 6 April 2013.  "Perceived Health Status". Organisation for Economic Co-operation and Development. Retrieved 22 July 2011.  Mazlish, Bruce. Civilization And Its Contents. Stanford University Press, 2004. p. 3. Web. 25 June 2012.  Myres, John. Herodotus, Father of History. Oxford: Clarendon Press, 1953. Web. 25 June 2012.  Copleston, Frederick. History of Philosophy, Volume 1.  Thomas Heath (1981). A History of Greek Mathematics. Courier Dover Publications. p. 1. ISBN 978-0-486-24073-2. Retrieved 19 August 2013.  Peter Krentz, PhD, W. R. Grey Professor of History, Davidson College. "Greece, Ancient." World Book Advanced. World Book, 2012. Web. 8 July 2012.  "Egypt the Birthplace of Greek Decorative Art". digital.library.upenn.edu.  Gurewitsch, Matthew (July 2008). "True Colors". Smithsonian: 66–71.  Παύλος Κυριαζής, «Σταμάτης Βούλγαρης. Ο αγωνιστής, ο πολεοδόμος, ο άνθρωπος», στο: Συλλογικό, Πρώτοι Έλληνες τεχνικοί επιστήμονες περιόδου απελευθέρωσης, εκδ. Τεχνικό Επιμελητήριο Ελλάδος, Αθήνα, 1976, σελ.158  "23 Best Examples of Cycladic Architecture". 23 April 2015.  "Architecture of Epirus, Greece - Greeka.com". Greekacom.  Anderson, Sean (2010). "The Light and the Line: Florestano Di Fausto and the Politics of 'Mediterraneità'". California Italian Studies. doi:10.5070/C311008864.  Brockett, Oscar G. (1991) History of the Theatre (sixth edition). Boston; London: Allyn & Bacon.  "Culture e-Magazine – Free eBooks – WebTV " Τo Θέατρο στο Βυζάντιο και την Οθωμανική περίοδο". 24grammata.com. 18 March 2012. Retrieved 23 April 2014.  "ΓΝΩΡΙΣΤΕ ΜΑΣ - Εθνικό Θέατρο". n-t.gr.  Encyclopædia Britannica - "Greek literature: Byzantine literature"  Carol Strickland (2007). The Illustrated Timeline of Western Literature: A Crash Course in Words & Pictures. Sterling Publishing Company, Inc. p. 2. ISBN 978-1-4027-4860-8. Although the first writing originates in the cradle of civilization along Middle Eastern rivers – the Tigris, Euphrates, and Nile – the true cradle of Western literature is Athens. As the poet Percy Bysshe Shelley says, "We are all Greeks."  "The Modern Greek language in its relation to Ancient Greek", E. M. Geldart  "Ancient Greek Philosophy". Internet encyclopedia of philosophy. Retrieved 23 March 2016.  Thomas S. Hischak (16 April 2015). The Encyclopedia of Film Composers. Rowman & Littlefield Publishers. p. 664. ISBN 978-1-4422-4550-1.  "Kostas Tournas". europopmusic.eu. Retrieved 10 March 2013.  Kostis Kornetis (30 November 2013). Children of the Dictatorship: Student Resistance, Cultural Politics and the 'Long 1960s' in Greece. Berghahn Books. p. 190. ISBN 978-1-78238-001-6.  Edelstein, Sari (22 October 2010). Food, Cuisine, and Cultural Competency for Culinary, Hospitality, and Nutrition Professionals. Jones & Bartlett. pp. 147–49. ISBN 978-0-7637-5965-0. Retrieved 27 December 2011.  "World Rankings". FIFA. July 2009. Retrieved 23 July 2009.  McNulty, Phil (4 July 2004). "Greece Win Euro 2004". News. BBC. Retrieved 7 May 2007.  "Ranking Men after Olympic Games: Tournament Men (2008)". International Basketball Federation. August 2008. Retrieved 24 August 2008.  Wilkinson, Simon (26 September 2005). "Greece Tops Germany for Euro Title". ESPN. Retrieved 7 May 2007.  Όταν η Ευρώπη υποκλίθηκε στον Ολυμπιακό (in Greek). onsports.gr. Retrieved 14 June 2012.  Σαν σήμερα κοκκίνησε τον Δούναβη, Πρωταθλητής Ευρώπης στο πόλο ο Θρύλος (in Greek). newsnow.gr. Retrieved 11 January 2013.  Έγραψε ιστορία ο Θρύλος (in Greek). sport.gr. Archived from the original on 13 December 2013. Retrieved 18 December 2012.   Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more Greek language From Wikipedia, the free encyclopedia Jump to navigationJump to search For the Greek language used during particular eras, see Proto-Greek language, Mycenaean Greek, Ancient Greek, Koine Greek, Medieval Greek, and Modern Greek. Greek ελληνικά Pronunciation	[eliniˈka] Native to	 Greece (official) Cyprus (official) Italy Egypt Turkey southern Albania Ethnicity	Greeks Native speakers	13.5 million (2012)[1] Language family	 Indo-European Hellenic Greek Early form	 Proto-Greek Dialects	 Ancient dialects Modern dialects Writing system	Greek alphabet Language codes ISO 639-1	el ISO 639-2	gre (B) ell (T) ISO 639-3	Variously: ell – Modern Greek grc – Ancient Greek cpg – Cappadocian Greek gmy – Mycenaean Greek pnt – Pontic tsd – Tsakonian yej – Yevanic Glottolog	gree1276 Linguasphere	 56-AAA-a 56-AAA-aa to -am (varieties) Idioma Griego.PNG Areas where Modern Greek is spoken (in dark blue those areas where it is the official language).(The map does not indicate where the language is majority or minority.) This article contains IPA phonetic symbols. Without proper rendering support, you may see question marks, boxes, or other symbols instead of Unicode characters. For an introductory guide on IPA symbols, see Help:IPA. Greek (Modern Greek: Ελληνικά, romanized: Elliniká; Ancient Greek: Ἑλληνική, romanized: Hellēnikḗ) is an independent branch of the Indo-European family of languages, native to Greece, Cyprus, Albania, and the other parts of the Balkans, the Black Sea coast, and the Eastern Mediterranean. It has the longest documented history of any living Indo-European language, spanning at least 3,400 years of written records.[2] Its writing system is the Greek alphabet, which has been used for over 2,600 years; previously, Greek was recorded in writing systems such as Linear B and the Cypriot syllabary.[3] The alphabet arose from the Phoenician script and was in turn the basis of the Latin, Cyrillic, Armenian, Coptic, Gothic, and many other writing systems.  The Greek language holds an important place in the history of the Western world.[4] Beginning with the epics of Homer, ancient Greek literature includes many works of lasting importance in the European canon. Greek is also the language in which many of the foundational texts in science and philosophy were originally composed. The New Testament of the Christian Bible was also originally written in Greek.[5][6] Together with the Latin texts and traditions of the Roman world, the Greek texts and Greek societies of antiquity constitute the objects of study of the discipline of Classics.  During antiquity, Greek was by far the most widely spoken lingua franca in the Mediterranean world. It eventually became the official language of the Byzantine Empire and developed into Medieval Greek.[7] In its modern form, Greek is the official language of Greece and Cyprus and one of the 24 official languages of the European Union. It is spoken by at least 13.5 million people today in Greece, Cyprus, Italy, Albania, Turkey, and the many other countries of the Greek diaspora.  Greek roots have been widely used for centuries and continue to be widely used to coin new words in other languages; Greek and Latin are the predominant sources of international scientific vocabulary.   Idealised portrayal of the author Homer  Contents 1	History 1.1	Periods 1.2	Diglossia 1.3	Historical unity 2	Geographic distribution 2.1	Official status 3	Characteristics 3.1	Phonology 3.2	Morphology 3.2.1	Nouns and adjectives 3.2.2	Verbs 3.3	Syntax 3.4	Vocabulary 3.5	Greek loanwords in other languages 4	Classification 5	Writing system 5.1	Linear B 5.2	Cypriot syllabary 5.3	Greek alphabet 5.3.1	Diacritics 5.3.2	Punctuation 5.4	Latin alphabet 5.5	Hebrew alphabet 5.6	Arabic alphabet 6	See also 7	Notes 8	References 8.1	Citations 8.2	Sources 9	Further reading 10	External links History Main article: History of Greek Greek has been spoken in the Balkan peninsula since around the 3rd millennium BC,[8] or possibly earlier.[9] The earliest written evidence is a Linear B clay tablet found in Messenia that dates to between 1450 and 1350 BC,[10] making Greek the world's oldest recorded living language. Among the Indo-European languages, its date of earliest written attestation is matched only by the now-extinct Anatolian languages.  Periods  Proto-Greek-speaking area according to linguist Vladimir I. Georgiev The Greek language is conventionally divided into the following periods:  Proto-Greek: the unrecorded but assumed last ancestor of all known varieties of Greek. The unity of Proto-Greek would have ended as Hellenic migrants entered the Greek peninsula sometime in the Neolithic era or the Bronze Age.[note 1] Mycenaean Greek: the language of the Mycenaean civilization. It is recorded in the Linear B script on tablets dating from the 15th century BC onwards. Ancient Greek: in its various dialects, the language of the Archaic and Classical periods of the ancient Greek civilization. It was widely known throughout the Roman Empire. Ancient Greek fell into disuse in western Europe in the Middle Ages, but remained officially in use in the Byzantine world and was reintroduced to the rest of Europe with the Fall of Constantinople and Greek migration to western Europe. Koine Greek: The fusion of Ionian with Attic, the dialect of Athens, began the process that resulted in the creation of the first common Greek dialect, which became a lingua franca across the Eastern Mediterranean and Near East. Koine Greek can be initially traced within the armies and conquered territories of Alexander the Great and after the Hellenistic colonization of the known world, it was spoken from Egypt to the fringes of India. After the Roman conquest of Greece, an unofficial bilingualism of Greek and Latin was established in the city of Rome and Koine Greek became a first or second language in the Roman Empire. The origin of Christianity can also be traced through Koine Greek, because the Apostles used this form of the language to spread Christianity. It is also known as Hellenistic Greek, New Testament Greek, and sometimes Biblical Greek because it was the original language of the New Testament and the Old Testament was translated into the same language via the Septuagint.  Distribution of varieties of Greek in Anatolia, 1910. Demotic in yellow. Pontic in orange. Cappadocian Greek in green, with green dots indicating individual Cappadocian Greek villages.[11] Medieval Greek, also known as Byzantine Greek: the continuation of Koine Greek, up to the demise of the Byzantine Empire in the 15th century. Medieval Greek is a cover phrase for a whole continuum of different speech and writing styles, ranging from vernacular continuations of spoken Koine that were already approaching Modern Greek in many respects, to highly learned forms imitating classical Attic. Much of the written Greek that was used as the official language of the Byzantine Empire was an eclectic middle-ground variety based on the tradition of written Koine. Modern Greek (Neo-Hellenic):[12] Stemming from Medieval Greek, Modern Greek usages can be traced in the Byzantine period, as early as the 11th century. It is the language used by the modern Greeks, and, apart from Standard Modern Greek, there are several dialects of it. Diglossia Main article: Greek language question In the modern era, the Greek language entered a state of diglossia: the coexistence of vernacular and archaizing written forms of the language. What came to be known as the Greek language question was a polarization between two competing varieties of Modern Greek: Dimotiki, the vernacular form of Modern Greek proper, and Katharevousa, meaning 'purified', a compromise between Dimotiki and Ancient Greek, which was developed in the early 19th century, and was used for literary and official purposes in the newly formed Greek state. In 1976, Dimotiki was declared the official language of Greece, having incorporated features of Katharevousa and giving birth to Standard Modern Greek, which is used today for all official purposes and in education.[13]  Historical unity  The distribution of major modern Greek dialect areas The historical unity and continuing identity between the various stages of the Greek language are often emphasized. Although Greek has undergone morphological and phonological changes comparable to those seen in other languages, never since classical antiquity has its cultural, literary, and orthographic tradition been interrupted to the extent that one can speak of a new language emerging. Greek speakers today still tend to regard literary works of ancient Greek as part of their own rather than a foreign language.[14] It is also often stated that the historical changes have been relatively slight compared with some other languages. According to one estimation, "Homeric Greek is probably closer to Demotic than 12-century Middle English is to modern spoken English".[15]  Geographic distribution Further information: Greeks and Greek diaspora  Geographic distribution of Greek language in the Russian Empire (1897 census) Greek is spoken today by at least 13 million people, principally in Greece and Cyprus along with a sizable Greek-speaking minority in Albania near the Greek-Albanian border.[12] A significant percentage of Albania's population has some basic knowledge of the Greek language due in part to the Albanian wave of immigration to Greece in the 1980s and '90s. Prior to the Greco-Turkish War and the resulting population exchange in 1923 a very large population of Greek-speakers also existed in Turkey, though very few remain today.[2] A small Greek-speaking community is also found in Bulgaria near the Greek-Bulgarian border. Greek is also spoken worldwide by the sizable Greek diaspora which has notable communities in the United States, Australia, Canada, South Africa, Chile, Brazil, Argentina, Russia, Ukraine, the United Kingdom, and throughout the European Union, especially in Germany.  Historically, significant Greek-speaking communities and regions were found throughout the Eastern Mediterranean, in what are today Southern Italy, Turkey, Cyprus, Syria, Lebanon, Israel, Egypt, and Libya; in the area of the Black Sea, in what are today Turkey, Bulgaria, Romania, Ukraine, Russia, Georgia, Armenia, and Azerbaijan; and, to a lesser extent, in the Western Mediterranean in and around colonies such as Massalia, Monoikos, and Mainake. It was also used as a liturgical language in Christian Nubian kingdom of Makuria which was in modern day Sudan.[16]  Official status Greek, in its modern form, is the official language of Greece, where it is spoken by almost the entire population.[17] It is also the official language of Cyprus (nominally alongside Turkish).[18] Because of the membership of Greece and Cyprus in the European Union, Greek is one of the organization's 24 official languages.[19] Furthermore, Greek is officially recognized as official in Dropull and Himara (Albania), and as a minority language all over Albania.[20] It is also recognized as an official minority language in the regions of Apulia and Calabria in Italy. In the framework of the European Charter for Regional or Minority Languages, Greek is protected and promoted officially as a regional and minority language in Armenia, Hungary, Romania, and Ukraine.[21]  Characteristics See also: Ancient Greek grammar, Koine Greek grammar, and Modern Greek grammar The phonology, morphology, syntax, and vocabulary of the language show both conservative and innovative tendencies across the entire attestation of the language from the ancient to the modern period. The division into conventional periods is, as with all such periodizations, relatively arbitrary, especially because at all periods, Ancient Greek has enjoyed high prestige, and the literate borrowed heavily from it.  Phonology Main articles: Modern Greek phonology, Koine Greek phonology, and Ancient Greek phonology MENU0:00 Spoken Modern Greek Across its history, the syllabic structure of Greek has varied little: Greek shows a mixed syllable structure, permitting complex syllabic onsets but very restricted codas. It has only oral vowels and a fairly stable set of consonantal contrasts. The main phonological changes occurred during the Hellenistic and Roman period (see Koine Greek phonology for details):  replacement of the pitch accent with a stress accent. simplification of the system of vowels and diphthongs: loss of vowel length distinction, monophthongisation of most diphthongs and several steps in a chain shift of vowels towards /i/ (iotacism). development of the voiceless aspirated plosives /pʰ/ and /tʰ/ to the voiceless fricatives /f/ and /θ/, respectively; the similar development of /kʰ/ to /x/ may have taken place later (the phonological changes are not reflected in the orthography, and both earlier and later phonemes are written with φ, θ, and χ). development of the voiced plosives /b/, /d/, and /ɡ/ to their voiced fricative counterparts /β/ (later /v/), /ð/, and /ɣ/. Morphology In all its stages, the morphology of Greek shows an extensive set of productive derivational affixes, a limited but productive system of compounding[22] and a rich inflectional system. Although its morphological categories have been fairly stable over time, morphological changes are present throughout, particularly in the nominal and verbal systems. The major change in the nominal morphology since the classical stage was the disuse of the dative case (its functions being largely taken over by the genitive). The verbal system has lost the infinitive, the synthetically-formed future, and perfect tenses and the optative mood. Many have been replaced by periphrastic (analytical) forms.  Nouns and adjectives Pronouns show distinctions in person (1st, 2nd, and 3rd), number (singular, dual, and plural in the ancient language; singular and plural alone in later stages), and gender (masculine, feminine, and neuter), and decline for case (from six cases in the earliest forms attested to four in the modern language).[note 2] Nouns, articles, and adjectives show all the distinctions except for a person. Both attributive and predicative adjectives agree with the noun.  Verbs The inflectional categories of the Greek verb have likewise remained largely the same over the course of the language's history but with significant changes in the number of distinctions within each category and their morphological expression. Greek verbs have synthetic inflectional forms for:  Ancient Greek	Modern Greek Person	first, second and third	also second person formal Number	singular, dual and plural	singular and plural tense	present, past and future	past and non-past (future is expressed by a periphrastic construction) aspect	imperfective, perfective (traditionally called aorist) and perfect (sometimes also called perfective; see note about terminology)	imperfective and perfective/aorist (perfect is expressed by a periphrastic construction) mood	indicative, subjunctive, imperative and optative	indicative, subjunctive,[note 3] and imperative (other modal functions are expressed by periphrastic constructions) Voice	active, middle, and passive	active and medio-passive Syntax Many aspects of the syntax of Greek have remained constant: verbs agree with their subject only, the use of the surviving cases is largely intact (nominative for subjects and predicates, accusative for objects of most verbs and many prepositions, genitive for possessors), articles precede nouns, adpositions are largely prepositional, relative clauses follow the noun they modify and relative pronouns are clause-initial. However, the morphological changes also have their counterparts in the syntax, and there are also significant differences between the syntax of the ancient and that of the modern form of the language. Ancient Greek made great use of participial constructions and of constructions involving the infinitive, and the modern variety lacks the infinitive entirely (employing a raft of new periphrastic constructions instead) and uses participles more restrictively. The loss of the dative led to a rise of prepositional indirect objects (and the use of the genitive to directly mark these as well). Ancient Greek tended to be verb-final, but neutral word order in the modern language is VSO or SVO.  Vocabulary Modern Greek inherits most of its vocabulary from Ancient Greek, which in turn is an Indo-European language, but also includes a number of borrowings from the languages of the populations that inhabited Greece before the arrival of Proto-Greeks,[23] some documented in Mycenaean texts; they include a large number of Greek toponyms. The form and meaning of many words have evolved. Loanwords (words of foreign origin) have entered the language, mainly from Latin, Venetian, and Turkish. During the older periods of Greek, loanwords into Greek acquired Greek inflections, thus leaving only a foreign root word. Modern borrowings (from the 20th century on), especially from French and English, are typically not inflected; other modern borrowings are derived from South Slavic (Macedonian/Bulgarian) and Eastern Romance languages (Aromanian and Megleno-Romanian).  Greek loanwords in other languages Further information: English words of Greek origin Further information: Greek and Latin roots in English Greek words have been widely borrowed into other languages, including English. Example words include: mathematics, physics, astronomy, democracy, philosophy, athletics, theatre, rhetoric, baptism, evangelist, etc. Moreover, Greek words and word elements continue to be productive as a basis for coinages: anthropology, photography, telephony, isomer, biomechanics, cinematography, etc. Together with Latin words, they form the foundation of international scientific and technical vocabulary. For example, all words ending in –logy ("discourse"). There are many English words of Greek origin.[24][25]  Classification Greek is an independent branch of the Indo-European language family. The ancient language most closely related to it may be ancient Macedonian,[26] which most scholars suggest may have been a dialect of Greek itself,[27][28][29] but it is poorly attested and it is difficult to conclude. Independently of the Macedonian question, some scholars have grouped Greek into Graeco-Phrygian, as Greek and the extinct Phrygian share features that are not found in other Indo-European languages.[30] Among living languages, some Indo-Europeanists suggest that Greek may be most closely related to Armenian (see Graeco-Armenian) or the Indo-Iranian languages (see Graeco-Aryan), but little definitive evidence has been found for grouping the living branches of the family.[31] In addition, Albanian has also been considered somewhat related to Greek and Armenian by some linguists. If proven and recognized, the three languages would form a new Balkan sub-branch with other dead European languages.[32]  Writing system Greek alphabet alpha-omega.svg Greek alphabet Αα	Alpha	Νν	Nu Ββ	Beta	Ξξ	Xi Γγ	Gamma	Οο	Omicron Δδ	Delta	Ππ	Pi Εε	Epsilon	Ρρ	Rho Ζζ	Zeta	Σσς	Sigma Ηη	Eta	Ττ	Tau Θθ	Theta	Υυ	Upsilon Ιι	Iota	Φφ	Phi Κκ	Kappa	Χχ	Chi Λλ	Lambda	Ψψ	Psi Μμ	Mu	Ωω	Omega History Archaic local variants DigammaHetaSanKoppaSampiTsan DiacriticsLigatures Numerals ϛ (6)ϟ (90)ϡ (900) Use in other languages BactrianCopticAlbanian Related topics Use as scientific symbols Category Category vte See also: Greek Braille Linear B Main article: Linear B Linear B, attested as early as the late 15th century BC, was the first script used to write Greek.[33] It is basically a syllabary, which was finally deciphered by Michael Ventris and John Chadwick in the 1950s (its precursor, Linear A, has not been deciphered and most likely encodes a non-Greek language).[33] The language of the Linear B texts, Mycenaean Greek, is the earliest known form of Greek.[33]  Cypriot syllabary Main article: Cypriot syllabary  Greek inscription in Cypriot syllabic script Another similar system used to write the Greek language was the Cypriot syllabary (also a descendant of Linear A via the intermediate Cypro-Minoan syllabary), which is closely related to Linear B but uses somewhat different syllabic conventions to represent phoneme sequences. The Cypriot syllabary is attested in Cyprus from the 11th century BC until its gradual abandonment in the late Classical period, in favor of the standard Greek alphabet.[34]  Greek alphabet Main articles: Greek alphabet and Greek orthography  Ancient epichoric variants of the Greek alphabet from Euboea, Ionia, Athens, and Corinth comparing to modern Greek Greek has been written in the Greek alphabet since approximately the 9th century BC. It was created by modifying the Phoenician alphabet, with the innovation of adopting certain letters to represent the vowels. The variant of the alphabet in use today is essentially the late Ionic variant, introduced for writing classical Attic in 403 BC. In classical Greek, as in classical Latin, only upper-case letters existed. The lower-case Greek letters were developed much later by medieval scribes to permit a faster, more convenient cursive writing style with the use of ink and quill.  The Greek alphabet consists of 24 letters, each with an uppercase (majuscule) and lowercase (minuscule) form. The letter sigma has an additional lowercase form (ς) used in the final position:  upper case Α	Β	Γ	Δ	Ε	Ζ	Η	Θ	Ι	Κ	Λ	Μ	Ν	Ξ	Ο	Π	Ρ	Σ	Τ	Υ	Φ	Χ	Ψ	Ω lower case α	β	γ	δ	ε	ζ	η	θ	ι	κ	λ	μ	ν	ξ	ο	π	ρ	σ ς	τ	υ	φ	χ	ψ	ω Diacritics Main article: Greek diacritics In addition to the letters, the Greek alphabet features a number of diacritical signs: three different accent marks (acute, grave, and circumflex), originally denoting different shapes of pitch accent on the stressed vowel; the so-called breathing marks (rough and smooth breathing), originally used to signal presence or absence of word-initial /h/; and the diaeresis, used to mark the full syllabic value of a vowel that would otherwise be read as part of a diphthong. These marks were introduced during the course of the Hellenistic period. Actual usage of the grave in handwriting saw a rapid decline in favor of uniform usage of the acute during the late 20th century, and it has only been retained in typography.  After the writing reform of 1982, most diacritics are no longer used. Since then, Greek has been written mostly in the simplified monotonic orthography (or monotonic system), which employs only the acute accent and the diaeresis. The traditional system, now called the polytonic orthography (or polytonic system), is still used internationally for the writing of Ancient Greek.  Punctuation In Greek, the question mark is written as the English semicolon, while the functions of the colon and semicolon are performed by a raised point (•), known as the ano teleia (άνω τελεία). In Greek the comma also functions as a silent letter in a handful of Greek words, principally distinguishing ό,τι (ó,ti, 'whatever') from ότι (óti, 'that').[35]  Ancient Greek texts often used scriptio continua ('continuous writing'), which means that ancient authors and scribes would write word after word with no spaces or punctuation between words to differentiate or mark boundaries.[36] Boustrophedon, or bi-directional text, was also used in Ancient Greek.  Latin alphabet Greek has occasionally been written in the Latin script, especially in areas under Venetian rule or by Greek Catholics. The term Frankolevantinika / Φραγκολεβαντίνικα applies when the Latin script is used to write Greek in the cultural ambit of Catholicism (because Frankos / Φράγκος is an older Greek term for West-European dating to when most of (Roman Catholic Christian) West Europe was under the control of the Frankish Empire). Frankochiotika / Φραγκοχιώτικα (meaning 'Catholic Chiot') alludes to the significant presence of Catholic missionaries based on the island of Chios. Additionally, the term Greeklish is often used when the Greek language is written in a Latin script in online communications.[37]  The Latin script is nowadays used by the Greek-speaking communities of Southern Italy.  Hebrew alphabet The Yevanic dialect was written by Romaniote and Constantinopolitan Karaite Jews using the Hebrew Alphabet.[38]  Arabic alphabet Some Greek Muslims from Crete wrote their Cretan Greek in the Arabic alphabet. The same happened among Epirote Muslims in Ioannina. This usage is sometimes called aljamiado as when Romance languages are written in the Arabic alphabet.[39]  See also flag	Greece portal icon	Language portal Modern Greek Varieties of Modern Greek Medieval Greek Ancient Greek Ancient Greek dialects Hellenic languages List of Greek and Latin roots in English List of medical roots, suffixes and prefixes Notes  A comprehensive overview in J.T. Hooker's Mycenaean Greece (Hooker 1976, Chapter 2: "Before the Mycenaean Age", pp. 11–33 and passim); for a different hypothesis excluding massive migrations and favoring an autochthonous scenario, see Colin Renfrew's "Problems in the General Correlation of Archaeological and Linguistic Strata in Prehistoric Greece: The Model of Autochthonous Origin" (Renfrew 1973, pp. 263–276, especially p. 267) in Bronze Age Migrations by R.A. Crossland and A. Birchall, eds. (1973).  The four cases that are found in all stages of Greek are the nominative, genitive, accusative, and vocative. The dative/locative of Ancient Greek disappeared in the late Hellenistic period, and the instrumental case of Mycenaean Greek disappeared in the Archaic period.  There is no particular morphological form that can be identified as 'subjunctive' in the modern language, but the term is sometimes encountered in descriptions even if the most complete modern grammar (Holton et al. 1997) does not use it and calls certain traditionally-'subjunctive' forms 'dependent'. Most Greek linguists advocate abandoning the traditional terminology (Anna Roussou and Tasos Tsangalidis 2009, in Meletes gia tin Elliniki Glossa, Thessaloniki, Anastasia Giannakidou 2009 "Temporal semantics and polarity: The dependency of the subjunctive revisited", Lingua); see Modern Greek grammar for explanation. References Citations  Greek at Ethnologue (18th ed., 2015) Ancient Greek at Ethnologue (18th ed., 2015) Cappadocian Greek at Ethnologue (18th ed., 2015) Mycenaean Greek at Ethnologue (18th ed., 2015) Pontic at Ethnologue (18th ed., 2015) Tsakonian at Ethnologue (18th ed., 2015) (Additional references under 'Language codes' in the information box)  "Greek language". Encyclopædia Britannica. Encyclopædia Britannica, Inc. Retrieved 29 April 2014.  1922-, Adrados, Francisco Rodríguez (2005). A history of the Greek language : from its origins to the present. Leiden: Brill. ISBN 978-90-04-12835-4. OCLC 59712402.  A history of ancient Greek by Maria Chritē, Maria Arapopoulou, Centre for the Greek Language (Thessalonikē, Greece) pg 436 ISBN 0-521-83307-8  Kurt Aland, Barbara Aland The text of the New Testament: an introduction to the critical 1995 p52  Archibald Macbride Hunter Introducing the New Testament 1972 p9  Manuel, Germaine Catherine (1989). A study of the preservation of the classical tradition in the education, language, and literature of the Byzantine Empire. HVD ALEPH.  Renfrew 2003, p. 35; Georgiev 1981, p. 192.  Gray & Atkinson 2003, pp. 437–438; Atkinson & Gray 2006, p. 102.  "Ancient Tablet Found: Oldest Readable Writing in Europe". National Geographic Society. 30 March 2011. Retrieved 22 November 2013.  Dawkins & Halliday 1916.  "Greek". Ethnologue. Retrieved 12 April 2020.  Peter, Mackridge (1985). The modern Greek language : a descriptive analysis of standard modern Greek. Oxford [Oxfordshire]: Oxford University Press. ISBN 978-0-19-815770-0. OCLC 11134463.  Browning 1983.  Alexiou 1982, p. 161.  Welsby 2002, p. 239.  "Greece". The World Factbook. Central Intelligence Agency. Retrieved 23 January 2010.  "The Constitution of Cyprus, App. D., Part 1, Art. 3". Archived from the original on 7 April 2012. states that The official languages of the Republic are Greek and Turkish. However, the official status of Turkish is only nominal in the Greek-dominated Republic of Cyprus; in practice, outside Turkish-dominated Northern Cyprus, Turkish is little used; see A. Arvaniti (2006): Erasure as a Means of Maintaining Diglossia in Cyprus, San Diego Linguistics Papers 2: pp. 25–38 [27].  "The EU at a Glance – Languages in the EU". Europa. European Union. Retrieved 30 July 2010.  "Greek". Office of the High Commissioner for Human Rights. Archived from the original on 18 November 2008. Retrieved 8 December 2008.  "List of Declarations Made with Respect to Treaty No. 148". Council of Europe. Archived from the original on 10 April 2020. Retrieved 8 December 2008.  Ralli 2001, pp. 164–203.  Beekes 2009.  Scheler 1977.  "Πόσο "ελληνικές" είναι οι ξένες γλώσσες". NewsIt. 18 November 2019.  Hamp 2013, pp. 8–10, 13.  Crespo, Emilio (2018). "The Softening of Obstruent Consonants in the Macedonian Dialect". In Giannakis, Georgios K.; Crespo, Emilio; Filos, Panagiotis (eds.). Studies in Ancient Greek Dialects: From Central Greece to the Black Sea. Walter de Gruyter. p. 329. ISBN 978-3-11-053081-0.  Hatzopoulos, Miltiades B. (2018). "Recent Research in the Ancient Macedonian Dialect: Consolidation and New Perspectives". In Giannakis, Georgios K.; Crespo, Emilio; Filos, Panagiotis (eds.). Studies in Ancient Greek Dialects: From Central Greece to the Black Sea. Walter de Gruyter. p. 299. ISBN 978-3-11-053081-0.  Babiniotis 1992, pp. 29–40; Dosuna 2012, pp. 65–78.  Hammarström, Harald; Forkel, Robert; Haspelmath, Martin, eds. (2017). "Graeco-Phrygian". Glottolog 3.0. Jena, Germany: Max Planck Institute for the Science of Human History.  Renfrew 1990; Gamkrelidze & Ivanov 1990, pp. 110–116; Renfrew 2003, pp. 17–48; Gray & Atkinson 2003, pp. 435–439.  Holm 2008, pp. 628–636.  T., Hooker, J. (1980). Linear B : an introduction. Bristol: Bristol Classical Press. ISBN 978-0-906515-69-3. OCLC 7326206.  "Cypriot syllabary". Britannica Academic. Retrieved 1 August 2017.  Nicolas, Nick (2005). "Greek Unicode Issues: Punctuation". Archived from the original on 6 August 2012. Retrieved 7 October 2014.  Hugoe, Matthews Peter (March 2014). The concise Oxford dictionary of linguistics. Oxford University Press. (Third ed.). Oxford. ISBN 978-0-19-967512-8. OCLC 881847972.  Androutsopoulos 2009, pp. 221–249.  "Yevanic alphabet, pronunciation and language". www.omniglot.com. Retrieved 18 April 2020.  Kotzageorgis, Phokion (2010). Gruber, Christiane J.; Colby, Frederick Stephen (eds.). The Prophet's Ascension: Cross-cultural Encounters with the Islamic Mi'rāj Tales. Indiana University Press. p. 297. ISBN 978-0-253-35361-0. The element that makes this text a unicum is that it is written in Greek script. In the Ottoman Empire, the primary criterion for the selection of an alphabet in which to write was religion. Thus, people who did not speak—or even know—the official language of their religion used to write their religious texts in the languages that they knew, though in the alphabet where the sacred texts of that religion were written. Thus, the Grecophone Catholics of Chios wrote using the Latin alphabet, but in the Greek language (frangochiotika); the Turcophone Orthodox Christians of Cappadocia wrote their Turkish texts using the Greek alphabet (karamanlidika); and the Grecophone Muslims of the Greek peninsula wrote in Greek language using the Arabic alphabet (tourkogianniotika, tourkokretika). Our case is much stranger, since it is a quite early example for that kind of literature and because it is largely concerned with religious themes."; p. 306. The audience for the Greek Mi'rājnāma was most certainly Greek-speaking Muslims, in particular the so-called Tourkogianniotes (literally, the Turks of Jannina). Although few examples have been discovered as yet, it seems that these people developed a religious literature mainly composed in verse form. This literary form constituted the mainstream of Greek Aljamiado literature from the middle of the seventeenth century until the population exchange between Greece and Turkey in 1923. Tourkogianniotes were probably of Christian origin and were Islamized sometime during the seventeenth century. They did not speak any language other than Greek. Thus, even their frequency in attending mosque services did not provide them with the necessary knowledge about their faith. Given their low level of literacy, one important way that they could learn about their faith was to listen to religiously edifying texts such as the Greek Mi'rājnāma. Sources Alexiou, Margaret (1982). "Diglossia in Greece". In Haas, William (ed.). Standard Languages: Spoken and Written. Manchester: Manchester University Press. pp. 156–192. ISBN 978-0-389-20291-2. Androutsopoulos, Jannis (2009). "'Greeklish': Transliteration Practice and Discourse in a Setting of Computer-Mediated Digraphia" (PDF). In Georgakopoulou, Alexandra; Silk, Michael (eds.). Standard Languages and Language Standards: Greek, Past and Present. Aldershot: Ashgate Publishing Limited. pp. 221–249.[permanent dead link] Atkinson, Quentin D.; Gray, Russel D. (2006). "Chapter 8: How Old is the Indo-European Language Family? Illumination or More Moths to the Flame?". In Forster, Peter; Renfrew, Colin (eds.). Phylogenetic Methods and the Prehistory of Languages. Cambridge, England: McDonald Institute for Archaeological Research. pp. 91–109. ISBN 978-1-902937-33-5. Babiniotis, George (1992). "The Question of Mediae in Ancient Macedonian Greek Reconsidered". In Brogyanyi, Bela; Lipp, Reiner (eds.). Historical Philology: Greek, Latin and Romance. Amsterdam and Philadelphia: John Benjamins Publishing Company. pp. 29–40. ISBN 9789027277473. Beekes, Robert Stephen Paul (2009). Etymological Dictionary of Greek. Leiden and Boston: Brill. ISBN 978-90-04-17418-4. Browning, Robert (1983) [1969]. Medieval and Modern Greek. Cambridge, UK: Cambridge University Press. ISBN 978-0-521-23488-7. Dawkins, Richard McGillivray; Halliday, William Reginald (1916). Modern Greek in Asia Minor: A Study of Dialect of Silly, Cappadocia and Pharasa with Grammar, Texts, Translations and Glossary. Cambridge, England: Cambridge University Press. Dosuna, Julián Víctor Méndez (2012). "Ancient Macedonian as a Greek Dialect: A Critical Survey on Recent Work". In Giannakis, Georgios K. (ed.). Ancient Macedonia: Language, History and Culture (in Greek). Thessaloniki: Centre for the Greek Language. pp. 65–78. Gamkrelidze, Tamaz V.; Ivanov, Vyacheslav (March 1990). "The Early History of Indo-European Languages". Scientific American. 262 (3): 110–116. Bibcode:1990SciAm.262c.110G. doi:10.1038/scientificamerican0390-110. Archived from the original on 6 January 2014. Georgiev, Vladimir Ivanov (1981). Introduction to the History of the Indo-European Languages. Sofia: Bulgarian Academy of Sciences. ISBN 9789535172611. Gray, Russel D.; Atkinson, Quentin D. (2003). "Language-tree Divergence Times Support the Anatolian Theory of Indo-European Origin". Nature. 426 (6965): 435–439. Bibcode:2003Natur.426..435G. doi:10.1038/nature02029. PMID 14647380. S2CID 42340. Hamp, Eric P. (August 2013). "The Expansion of the Indo-European Languages: An Indo-Europeanist's Evolving View" (PDF). Sino-Platonic Papers. 239. Holm, Hans J. (2008). "The Distribution of Data in Word Lists and its Impact on the Subgrouping of Languages". In Preisach, Christine; Burkhardt, Hans; Schmidt-Thieme, Lars; Decker, Reinhold (eds.). Data Analysis, Machine Learning, and Applications. Proceedings of the 31st Annual Conference of the Gesellschaft für Klassifikation e.V., Albert-Ludwigs-Universität Freiburg, March 7–9, 2007. Berlin-Heidelberg: Springer-Verlag. pp. 628–636. ISBN 978-3-540-78246-9. Hooker, J.T. (1976). Mycenaean Greece. London: Routledge & Kegan Paul. ISBN 9780710083791. Jeffries, Ian (2002). Eastern Europe at the Turn of the Twenty-First Century: A Guide to the Economies in Transition. London and New York: Routledge (Taylor & Francis). ISBN 978-0-415-23671-3. Ralli, Angeliki (2001). Μορφολογία [Morphology] (in Greek). Athens: Ekdoseis Pataki. Renfrew, Colin (1973). "Problems in the General Correlation of Archaeological and Linguistic Strata in Prehistoric Greece: The Model of Autochthonous Origin". In Crossland, R. A.; Birchall, Ann (eds.). Bronze Age Migrations in the Aegean; Archaeological and Linguistic Problems in Greek Prehistory: Proceedings of the first International Colloquium on Aegean Prehistory, Sheffield. London: Gerald Duckworth and Company Limited. pp. 263–276. ISBN 978-0-7156-0580-6. Renfrew, Colin (2003). "Time Depth, Convergence Theory, and Innovation in Proto-Indo-European: 'Old Europe' as a PIE Linguistic Area". In Bammesberger, Alfred; Vennemann, Theo (eds.). Languages in Prehistoric Europe. Heidelberg: Universitätsverlag Winter GmBH. pp. 17–48. ISBN 978-3-8253-1449-1. Renfrew, Colin (1990) [1987]. Archaeology and Language: The Puzzle of Indo-European Origins. Cambridge: Cambridge University Press. ISBN 978-0-521-38675-3. Scheler, Manfred (1977). Der englische Wortschatz [English Vocabulary] (in German). Berlin: E. Schmidt. ISBN 978-3-503-01250-3. Tsitselikis, Konstantinos (2013). "A Surviving Treaty: The Lausanne Minority Protection in Greece and Turkey". In Henrard, Kristin (ed.). The Interrelation between the Right to Identity of Minorities and their Socio-economic Participation. Leiden and Boston: Martinus Nijhoff Publishers. pp. 287–315. ISBN 9789004244740. Further reading Allen, W. Sidney (1968). Vox Graeca – A Guide to the Pronunciation of Classical Greek. Cambridge, England: Cambridge University Press. ISBN 978-0-521-20626-6. Crosby, Henry Lamar; Schaeffer, John Nevin (1928). An Introduction to Greek. Boston, MA; New York, NY: Allyn and Bacon, Inc. Dionysius of Thrace. Bibliotheca Augustana Τέχνη Γραμματική [Art of Grammar] (in Greek). Holton, David; Mackridge, Peter; Philippaki-Warburton, Irene (1997). Greek: A Comprehensive Grammar of the Modern Language. London and New York: Routledge. ISBN 978-0-415-10002-1. Horrocks, Geoffrey (1997). Greek: A History of the Language and Its Speakers. London and New York: Longman Linguistics Library (Addison Wesley Longman Limited). ISBN 978-0-582-30709-4. Krill, Richard M. (1990). Greek and Latin in English Today. Wauconda, IL: Bolchazy-Carducci Publishers. ISBN 978-0-86516-241-9. Mallory, James P. (1997). "Greek Language". In Mallory, James P.; Adams, Douglas Q. (eds.). Encyclopedia of Indo-European Culture. Chicago, IL: Fitzroy Dearborn Publishers. pp. 240–246. ISBN 9781884964985. Newton, Brian (1972). The Generative Interpretation of Dialect: A Study of Modern Greek Phonology. Cambridge, England: Cambridge University Press. ISBN 978-0-521-08497-0. Sihler, Andrew L. (1995). New Comparative Grammar of Greek and Latin. New York, NY: Oxford University Press. ISBN 978-0-19-508345-3. Smyth, Herbert Weir; Messing, Gordon (1956) [1920]. Greek Grammar. Cambridge, MA: Harvard University Press. ISBN 978-0-674-36250-5. External links 	Standard Greek edition of Wikipedia, the free encyclopedia 	Pontic Greek edition of Wikipedia, the free encyclopedia 	Wikibooks has more on the topic of: Greek language 	For a list of words relating to Greek language, see the Greek language category of words in Wiktionary, the free dictionary. 	Ancient Greek test of Wikipedia at Wikimedia Incubator 	Wikimedia Commons has media related to Greek language. 	Wikivoyage has a phrasebook for Greek. General background Greek Language, Columbia Electronic Encyclopedia. The Greek Language and Linguistics Gateway, useful information on the history of the Greek language, application of modern Linguistics to the study of Greek, and tools for learning Greek. Aristotle University of Thessaloniki, The Greek Language Portal, a portal for Greek language and linguistic education. The Perseus Project has many useful pages for the study of classical languages and literatures, including dictionaries. Ancient Greek Tutorials, Berkeley Language Center of the University of California, Berkeley Language learning 	Wikiquote has quotations related to: Greek language Hellenistic Greek Lessons Greek-Language.com provides a free online grammar of Hellenistic Greek. komvos.edu.gr, a website for the support of people who are being taught the Greek language. New Testament Greek Three graduated courses designed to help students learn to read the Greek New Testament Books on Greek language that are taught at schools in Greece (page in Greek) Greek Swadesh list of basic vocabulary words (from Wiktionary's Swadesh list appendix) USA Foreign Service Institute Modern Greek basic course Aversa, Alan. "Greek Inflector". University of Arizona. Identifies the grammatical functions of all the words in sentences entered, using Perseus. Dictionaries Greek Lexical Aids, descriptions of both online lexicons (with appropriate links) and Greek Lexicons in Print. The Greek Language Portal, dictionaries of all forms of Greek (Ancient, Hellenistic, Medieval, Modern) scanned images from S. C. Woodhouse's English–Greek dictionary, 1910 Literature Center for Neo-Hellenic Studies, a non-profit organization that promotes modern Greek literature and culture Research lab of modern Greek philosophy, a large e-library of modern Greek texts/books vte Greek language vte Languages of Greece vte Languages of Cyprus vte Languages of Albania vte Languages of Turkey vte Languages of Italy vte Languages of Ukraine vte Greece Greece topics vte Ages of Greek c. 3rd millennium BC	c. 1600–1100 BC	c. 800–300 BC	c. 300 BC – AD 330	c. 330–1453	Since 1453 Proto-Greek  Mycenaean  Ancient  Koine  Medieval  Modern  Authority control: National libraries Edit this at Wikidata	 SpainJapan Categories: Greek languageFusional languagesGreek alphabetLanguages of AlbaniaLanguages of ApuliaLanguages of ArmeniaLanguages of CalabriaLanguages of CyprusLanguages of Georgia (country)Languages of GreeceLanguages of HungaryLanguages of RomaniaLanguages of SicilyLanguages of TurkeyLanguages of UkraineSubject–verb–object languages Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadEditView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikibooks Wikiquote Wikiversity Wikivoyage  Languages Български Deutsch Ελληνικά Français Македонски Ποντιακά Shqip Türkçe 中文 199 more Edit links This page was last edited on 5 October 2021, at 10:53 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki   Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more Page semi-protected Ancient Greek From Wikipedia, the free encyclopedia Jump to navigationJump to search This article is about the language. For ancient Greek population groups, see List of ancient Greek tribes. "Classical Greek" redirects here. For the culture, see Classical Greece. For other uses, see Greek (disambiguation).  This article needs additional citations for verification. Relevant discussion may be found on the talk page. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed. Find sources: "Ancient Greek" – news · newspapers · books · scholar · JSTOR (January 2019) (Learn how and when to remove this template message) Ancient Greek Ἑλληνική Hellēnikḗ Account of the construction of Athena Parthenos by Phidias.jpg Inscription about the construction of the statue of Athena Parthenos in the Parthenon, 440/439 BC Region	eastern Mediterranean Language family	 Indo-European Hellenic Ancient Greek Writing system	Greek alphabet Language codes ISO 639-2	grc ISO 639-3	grc (includes all pre-modern stages) Glottolog	anci1242 Homeric Greece-en.svg Map of Ancient (Homeric) Greece This article contains IPA phonetic symbols. Without proper rendering support, you may see question marks, boxes, or other symbols instead of Unicode characters. For an introductory guide on IPA symbols, see Help:IPA.  Beginning of Homer's Odyssey Ancient Greek includes the forms of the Greek language used in ancient Greece and the ancient world from around 1500 BC to 300 BC. It is often roughly divided into the following periods: Mycenaean Greek (c. 1400–1200 BC), Dark Ages (c. 1200–800 BC), the Archaic period (c. 800–500 BC), and the Classical period (c. 500–300 BC).[1]  Ancient Greek was the language of Homer and of fifth-century Athenian historians, playwrights, and philosophers. It has contributed many words to English vocabulary and has been a standard subject of study in educational institutions of the Western world since the Renaissance. This article primarily contains information about the Epic and Classical periods of the language.  From the Hellenistic period (c. 300 BC), Ancient Greek was followed by Koine Greek, which is regarded as a separate historical stage, although its earliest form closely resembles Attic Greek and its latest form approaches Medieval Greek. There were several regional dialects of Ancient Greek, of which Attic Greek developed into Koine.   Contents 1	Dialects 1.1	History 1.2	Related languages 2	Phonology 2.1	Differences from Proto-Indo-European 2.2	Phonemic inventory 2.2.1	Consonants 2.2.2	Vowels 3	Morphology 3.1	Augment 3.2	Reduplication 4	Writing system 5	Sample texts 6	Modern use 6.1	In education 6.2	Modern real-world usage 7	See also 8	Notes 9	References 10	Further reading 11	External links 11.1	Grammar learning 11.2	Classical texts Dialects Main article: Ancient Greek dialects Ancient Greek was a pluricentric language, divided into many dialects. The main dialect groups are Attic and Ionic, Aeolic, Arcadocypriot, and Doric, many of them with several subdivisions. Some dialects are found in standardized literary forms used in literature, while others are attested only in inscriptions.  There are also several historical forms. Homeric Greek is a literary form of Archaic Greek (derived primarily from Ionic and Aeolic) used in the epic poems, the Iliad and the Odyssey, and in later poems by other authors. Homeric Greek had significant differences in grammar and pronunciation from Classical Attic and other Classical-era dialects.  History Idioma griego antiguo.png Ancient Greek language The origins, early form and development of the Hellenic language family are not well understood because of a lack of contemporaneous evidence. Several theories exist about what Hellenic dialect groups may have existed between the divergence of early Greek-like speech from the common Proto-Indo-European language and the Classical period. They have the same general outline but differ in some of the detail. The only attested dialect from this period[a] is Mycenaean Greek, but its relationship to the historical dialects and the historical circumstances of the times imply that the overall groups already existed in some form.  Scholars assume that major ancient Greek period dialect groups developed not later than 1120 BC, at the time of the Dorian invasions—and that their first appearances as precise alphabetic writing began in the 8th century BC. The invasion would not be "Dorian" unless the invaders had some cultural relationship to the historical Dorians. The invasion is known to have displaced population to the later Attic-Ionic regions, who regarded themselves as descendants of the population displaced by or contending with the Dorians.  The Greeks of this period believed there were three major divisions of all Greek people – Dorians, Aeolians, and Ionians (including Athenians), each with their own defining and distinctive dialects. Allowing for their oversight of Arcadian, an obscure mountain dialect, and Cypriot, far from the center of Greek scholarship, this division of people and language is quite similar to the results of modern archaeological-linguistic investigation.  One standard formulation for the dialects is:[2]   Distribution of Greek dialects in Greece in the classical period.[3] Western group:    Doric proper   Northwest Doric   Achaean Doric Central group:    Aeolic   Arcado-Cypriot Eastern group:    Attic   Ionic  Distribution of Greek dialects in Magna Graecia (Southern Italy and Sicily) in the classical period. Western group:    Doric proper   Northwest Doric   Achaean Doric Eastern group:    Attic-Ionic West Group Northwest Greek Doric Aeolic Group Aegean/Asiatic Aeolic Thessalian Boeotian Ionic-Attic Group Attic Ionic Euboean and colonies in Italy Cycladic Asiatic Ionic Arcadocypriot Greek Arcadian Cypriot West vs. non-West Greek is the strongest-marked and earliest division, with non-West in subsets of Ionic-Attic (or Attic-Ionic) and Aeolic vs. Arcadocypriot, or Aeolic and Arcado-Cypriot vs. Ionic-Attic. Often non-West is called 'East Greek'.  Arcadocypriot apparently descended more closely from the Mycenaean Greek of the Bronze Age.  Boeotian had come under a strong Northwest Greek influence, and can in some respects be considered a transitional dialect. Thessalian likewise had come under Northwest Greek influence, though to a lesser degree.  Pamphylian Greek, spoken in a small area on the southwestern coast of Anatolia and little preserved in inscriptions, may be either a fifth major dialect group, or it is Mycenaean Greek overlaid by Doric, with a non-Greek native influence.  Regarding the speech of the ancient Macedonians diverse theories have been put forward, but the epigraphic activity and the archaeological discoveries in the Greek region of Macedonia during the last decades has brought to light documents, among which the first texts written in Macedonian, such as the Pella curse tablet, as Hatzopoulos and other scholars note.[4][5] Based on the conclusions drawn by several studies and findings such as Pella curse tablet, Emilio Crespo and other scholars suggest that ancient Macedonian was a Northwest Doric dialect,[6][7][5] which shares isoglosses with its neighboring Thessalian dialects spoken in northeastern Thessaly.[6][5]  Most of the dialect sub-groups listed above had further subdivisions, generally equivalent to a city-state and its surrounding territory, or to an island. Doric notably had several intermediate divisions as well, into Island Doric (including Cretan Doric), Southern Peloponnesus Doric (including Laconian, the dialect of Sparta), and Northern Peloponnesus Doric (including Corinthian).  The Lesbian dialect was Aeolic Greek.  All the groups were represented by colonies beyond Greece proper as well, and these colonies generally developed local characteristics, often under the influence of settlers or neighbors speaking different Greek dialects.  The dialects outside the Ionic group are known mainly from inscriptions, notable exceptions being:  fragments of the works of the poet Sappho from the island of Lesbos, in Aeolian, and the poems of the Boeotian poet Pindar and other lyric poets, usually in Doric. After the conquests of Alexander the Great in the late 4th century BC, a new international dialect known as Koine or Common Greek developed, largely based on Attic Greek, but with influence from other dialects. This dialect slowly replaced most of the older dialects, although the Doric dialect has survived in the Tsakonian language, which is spoken in the region of modern Sparta. Doric has also passed down its aorist terminations into most verbs of Demotic Greek. By about the 6th century AD, the Koine had slowly metamorphosed into Medieval Greek.  Related languages Main article: Phrygian language Phrygian is an extinct Indo-European language of West and Central Anatolia, which is considered by some linguists to have been closely related to Greek.[8][9][10] Among Indo-European branches with living descendants, Greek is often argued to have the closest genetic ties with Armenian[11] (see also Graeco-Armenian) and Indo-Iranian languages (see Graeco-Aryan).[12][13]  Phonology Differences from Proto-Indo-European Main article: Proto-Greek language Ancient Greek differs from Proto-Indo-European (PIE) and other Indo-European languages in certain ways. In phonotactics, ancient Greek words could end only in a vowel or /n s r/; final stops were lost, as in γάλα "milk", compared with γάλακτος "of milk" (genitive). Ancient Greek of the classical period also differed in both the inventory and distribution of original PIE phonemes due to numerous sound changes,[14] notably the following:  PIE *s became /h/ at the beginning of a word (debuccalization): Latin sex, English six, ancient Greek ἕξ /héks/. PIE *s was elided between vowels after an intermediate step of debuccalization: Sanskrit janasas, Latin generis (where s > r by rhotacism), Greek *genesos > *genehos > ancient Greek γένεος (/géneos/), Attic γένους (/génoːs/) "of a kind". PIE *y /j/ became /h/ (debuccalization) or /(d)z/ (fortition): Sanskrit yas, ancient Greek ὅς /hós/ "who" (relative pronoun); Latin iugum, English yoke, ancient Greek ζυγός /zygós/. PIE *w, which occurred in Mycenaean and some non-Attic dialects, was lost: early Doric ϝέργον /wérgon/, English work, Attic Greek ἔργον /érgon/. PIE and Mycenaean labiovelars changed to plain stops (labials, dentals, and velars) in the later Greek dialects: for instance, PIE *kʷ became /p/ or /t/ in Attic: Attic Greek ποῦ /pôː/ "where?", Latin quō; Attic Greek τίς /tís/, Latin quis "who?". PIE "voiced aspirated" stops *bʰ dʰ ǵʰ gʰ gʷʰ were devoiced and became the aspirated stops φ θ χ /pʰ tʰ kʰ/ in ancient Greek. Phonemic inventory Main article: Ancient Greek phonology The pronunciation of ancient Greek was very different from that of Modern Greek. Ancient Greek had long and short vowels; many diphthongs; double and single consonants; voiced, voiceless, and aspirated stops; and a pitch accent. In Modern Greek, all vowels and consonants are short. Many vowels and diphthongs once pronounced distinctly are pronounced as /i/ (iotacism). Some of the stops and glides in diphthongs have become fricatives, and the pitch accent has changed to a stress accent. Many of the changes took place in the Koine Greek period. The writing system of Modern Greek, however, does not reflect all pronunciation changes.  The examples below represent Attic Greek in the 5th century BC. Ancient pronunciation cannot be reconstructed with certainty, but Greek from the period is well documented, and there is little disagreement among linguists as to the general nature of the sounds that the letters represent.  Consonants Bilabial	Dental	Velar	Glottal Nasal	μ m	ν n	γ (ŋ)	 Plosive	voiced	β b	δ d	γ ɡ	 voiceless	π p	τ t	κ k	 aspirated	φ pʰ	θ tʰ	χ kʰ	 Fricative		σ s		h Trill		ρ r		 Lateral		λ l		 [ŋ] occurred as an allophone of /n/ that was used before velars and as an allophone of /ɡ/ before nasals. /r/ was probably voiceless when word-initial (written ῥ). /s/ was assimilated to [z] before voiced consonants.  Vowels Front	Back unrounded	rounded Close	ι i iː	υ y yː	 Close-mid	ε ει e eː		ο ου o oː Open-mid	η ɛː		ω ɔː Open		α a aː /oː/ raised to [uː], probably by the 4th century BC.  Morphology Main article: Ancient Greek grammar  Ostracon bearing the name of Cimon, Stoa of Attalos Greek, like all of the older Indo-European languages, is highly inflected. It is highly archaic in its preservation of Proto-Indo-European forms. In ancient Greek, nouns (including proper nouns) have five cases (nominative, genitive, dative, accusative, and vocative), three genders (masculine, feminine, and neuter), and three numbers (singular, dual, and plural). Verbs have four moods (indicative, imperative, subjunctive, and optative) and three voices (active, middle, and passive), as well as three persons (first, second, and third) and various other forms. Verbs are conjugated through seven combinations of tenses and aspect (generally simply called "tenses"): the present, future, and imperfect are imperfective in aspect; the aorist, present perfect, pluperfect and future perfect are perfective in aspect. Most tenses display all four moods and three voices, although there is no future subjunctive or imperative. Also, there is no imperfect subjunctive, optative or imperative. The infinitives and participles correspond to the finite combinations of tense, aspect, and voice.  Augment The indicative of past tenses adds (conceptually, at least) a prefix /e-/, called the augment. This was probably originally a separate word, meaning something like "then", added because tenses in PIE had primarily aspectual meaning. The augment is added to the indicative of the aorist, imperfect, and pluperfect, but not to any of the other forms of the aorist (no other forms of the imperfect and pluperfect exist).  The two kinds of augment in Greek are syllabic and quantitative. The syllabic augment is added to stems beginning with consonants, and simply prefixes e (stems beginning with r, however, add er). The quantitative augment is added to stems beginning with vowels, and involves lengthening the vowel:  a, ā, e, ē → ē i, ī → ī o, ō → ō u, ū → ū ai → ēi ei → ēi or ei oi → ōi au → ēu or au eu → ēu or eu ou → ou Some verbs augment irregularly; the most common variation is e → ei. The irregularity can be explained diachronically by the loss of s between vowels, or that of the letter w, which affected the augment when it was word-initial. In verbs with a preposition as a prefix, the augment is placed not at the start of the word, but between the preposition and the original verb. For example, προσ(-)βάλλω (I attack) goes to προσέβαλoν in the aorist. However compound verbs consisting of a prefix that is not a preposition retain the augment at the start of the word: αὐτο(-)μολῶ goes to ηὐτομόλησα in the aorist.  Following Homer's practice, the augment is sometimes not made in poetry, especially epic poetry.  The augment sometimes substitutes for reduplication; see below.  Reduplication Almost all forms of the perfect, pluperfect, and future perfect reduplicate the initial syllable of the verb stem. (Note that a few irregular forms of perfect do not reduplicate, whereas a handful of irregular aorists reduplicate.) The three types of reduplication are:  Syllabic reduplication: Most verbs beginning with a single consonant, or a cluster of a stop with a sonorant, add a syllable consisting of the initial consonant followed by e. An aspirated consonant, however, reduplicates in its unaspirated equivalent (see Grassmann's law). Augment: Verbs beginning with a vowel, as well as those beginning with a cluster other than those indicated previously (and occasionally for a few other verbs) reduplicate in the same fashion as the augment. This remains in all forms of the perfect, not just the indicative. Attic reduplication: Some verbs beginning with an a, e or o, followed by a sonorant (or occasionally d or g), reduplicate by adding a syllable consisting of the initial vowel and following consonant, and lengthening the following vowel. Hence er → erēr, an → anēn, ol → olōl, ed → edēd. This is not actually specific to Attic Greek, despite its name, but it was generalized in Attic. This originally involved reduplicating a cluster consisting of a laryngeal and sonorant, hence h₃l → h₃leh₃l → olōl with normal Greek development of laryngeals. (Forms with a stop were analogous.) Irregular duplication can be understood diachronically. For example, lambanō (root lab) has the perfect stem eilēpha (not *lelēpha) because it was originally slambanō, with perfect seslēpha, becoming eilēpha through compensatory lengthening.  Reduplication is also visible in the present tense stems of certain verbs. These stems add a syllable consisting of the root's initial consonant followed by i. A nasal stop appears after the reduplication in some verbs.[15]  Writing system Greek alphabet alpha-omega.svg Greek alphabet Αα	Alpha	Νν	Nu Ββ	Beta	Ξξ	Xi Γγ	Gamma	Οο	Omicron Δδ	Delta	Ππ	Pi Εε	Epsilon	Ρρ	Rho Ζζ	Zeta	Σσς	Sigma Ηη	Eta	Ττ	Tau Θθ	Theta	Υυ	Upsilon Ιι	Iota	Φφ	Phi Κκ	Kappa	Χχ	Chi Λλ	Lambda	Ψψ	Psi Μμ	Mu	Ωω	Omega History Archaic local variants DigammaHetaSanKoppaSampiTsan DiacriticsLigatures Numerals ϛ (6)ϟ (90)ϡ (900) Use in other languages BactrianCopticAlbanian Related topics Use as scientific symbols Category Category vte Main article: Greek orthography The earliest extant examples of ancient Greek writing (circa 1450 BC) are in the syllabic script Linear B. Beginning in the 8th century BC, however, the Greek alphabet became standard, albeit with some variation among dialects. Early texts are written in boustrophedon style, but left-to-right became standard during the classic period. Modern editions of ancient Greek texts are usually written with accents and breathing marks, interword spacing, modern punctuation, and sometimes mixed case, but these were all introduced later.  Sample texts The beginning of Homer's Iliad exemplifies the Archaic period of ancient Greek (see Homeric Greek for more details):  Μῆνιν ἄειδε, θεά, Πηληϊάδεω Ἀχιλῆος οὐλομένην, ἣ μυρί' Ἀχαιοῖς ἄλγε' ἔθηκε, πολλὰς δ' ἰφθίμους ψυχὰς Ἄϊδι προΐαψεν ἡρώων, αὐτοὺς δὲ ἑλώρια τεῦχε κύνεσσιν οἰωνοῖσί τε πᾶσι· Διὸς δ' ἐτελείετο βουλή· ἐξ οὗ δὴ τὰ πρῶτα διαστήτην ἐρίσαντε Ἀτρεΐδης τε ἄναξ ἀνδρῶν καὶ δῖος Ἀχιλλεύς.  The beginning of Apology by Plato exemplifies Attic Greek from the Classical period of ancient Greek:  Ὅτι μὲν ὑμεῖς, ὦ ἄνδρες Ἀθηναῖοι, πεπόνθατε ὑπὸ τῶν ἐμῶν κατηγόρων, οὐκ οἶδα· ἐγὼ δ' οὖν καὶ αὐτὸς ὑπ' αὐτῶν ὀλίγου ἐμαυτοῦ ἐπελαθόμην, οὕτω πιθανῶς ἔλεγον. Καίτοι ἀληθές γε ὡς ἔπος εἰπεῖν οὐδὲν εἰρήκασιν. Using the IPA:  [hóti men hyːmêːs | ɔ̂ː ándres atʰɛːnaî̯i̯oi | pepóntʰate | hypo tɔ̂ːn emɔ̂ːŋ katɛːɡórɔːn | oːk oî̯da ‖ éɡɔː dûːŋ kai̯ au̯tos | hyp au̯tɔ̂ːn olíɡoː emau̯tûː | epelatʰómɛːn | hǔːtɔː pitʰanɔ̂ːs éleɡon ‖ kaí̯toi̯ alɛːtʰéz ɡe | hɔːs épos eːpêːn | oːden eːrɛ̌ːkaːsin ‖] Transliterated into the Latin alphabet using a modern version of the Erasmian scheme:  Hóti mèn hūmeîs, ô ándres Athēnaîoi, pepónthate hupò tôn emôn katēgórōn, ouk oîda: egṑ d' oûn kaì autòs hup' autōn olígou emautoû epelathómēn, hoútō pithanôs élegon. Kaítoi alēthés ge hōs épos eipeîn oudèn eirḗkāsin. Translated into English:  How you, men of Athens, are feeling under the power of my accusers, I do not know: actually, even I myself almost forgot who I was because of them, they spoke so persuasively. And yet, loosely speaking, nothing they have said is true. Modern use See also: Classical compound In education The study of ancient Greek in European countries in addition to Latin occupied an important place in the syllabus from the Renaissance until the beginning of the 20th century. Ancient Greek is still taught as a compulsory or optional subject especially at traditional or elite schools throughout Europe, such as public schools and grammar schools in the United Kingdom. It is compulsory in the liceo classico in Italy, in the gymnasium in the Netherlands, in some classes in Austria, in klasična gimnazija (grammar school – orientation: classical languages) in Croatia, in classical studies in ASO in Belgium and it is optional in the humanities-oriented gymnasium in Germany (usually as a third language after Latin and English, from the age of 14 to 18). In 2006/07, 15,000 pupils studied ancient Greek in Germany according to the Federal Statistical Office of Germany, and 280,000 pupils studied it in Italy.[16] It is a compulsory subject alongside Latin in the humanities branch of the Spanish bachillerato. Ancient Greek is also taught at most major universities worldwide, often combined with Latin as part of the study of classics. In 2010 it was offered in three primary schools in the UK, to boost children's language skills,[17][18] and was one of seven foreign languages which primary schools could teach 2014 as part of a major drive to boost education standards.[19][needs update]  Ancient Greek is also taught as a compulsory subject in all gymnasiums and lyceums in Greece.[20][21] Starting in 2001, an annual international competition "Exploring the Ancient Greek Language and Culture" (Greek: Διαγωνισμός στην Αρχαία Ελληνική Γλώσσα και Γραμματεία) was run for upper secondary students through the Greek Ministry of National Education and Religious Affairs, with Greek language and cultural organisations as co-organisers.[22] It appears to have ceased in 2010, having failed to gain the recognition and acceptance of teachers.[23]  Modern real-world usage Modern authors rarely write in ancient Greek, though Jan Křesadlo wrote some poetry and prose in the language, and Harry Potter and the Philosopher's Stone,[24] some volumes of Asterix,[25] and The Adventures of Alix have been translated into ancient Greek. Ὀνόματα Kεχιασμένα (Onomata Kechiasmena) is the first magazine of crosswords and puzzles in ancient Greek.[26] Its first issue appeared in April 2015 as an annex to Hebdomada Aenigmatum. Alfred Rahlfs included a preface, a short history of the Septuagint text, and other front matter translated into ancient Greek in his 1935 edition of the Septuagint; Robert Hanhart also included the introductory remarks to the 2006 revised Rahlfs–Hanhart edition in the language as well.[27] Akropolis World News reports weekly a summary of the most important news in ancient Greek.[28]  Ancient Greek is also used by organizations and individuals, mainly Greek, who wish to denote their respect, admiration or preference for the use of this language. This use is sometimes considered graphical, nationalistic or humorous. In any case, the fact that modern Greeks can still wholly or partly understand texts written in non-archaic forms of ancient Greek shows the affinity of the modern Greek language to its ancestral predecessor.[28]  Ancient Greek is often used in the coinage of modern technical terms in the European languages: see English words of Greek origin. Latinized forms of ancient Greek roots are used in many of the scientific names of species and in scientific terminology.  See also Ancient Greek dialects Ancient Greek grammar Ancient Greek accent Greek alphabet Greek diacritics Greek language Hellenic languages Katharevousa Koine Greek List of Greek and Latin roots in English List of Greek phrases (mostly ancient Greek) Medieval Greek Modern Greek Mycenaean Greek Proto-Greek language Varieties of Modern Greek Notes  Mycenaean Greek is imprecisely attested and somewhat reconstructive due to its being written in an ill-fitting syllabary (Linear B). References  Ralli, Angela (2012). "Greek". Revue belge de Philologie et d'Histoire. 90 (3): 964. doi:10.3406/rbph.2012.8269.  Newton, Brian E.; Ruijgh, Cornelis Judd (13 April 2018). "Greek Language". Encyclopædia Britannica.  Roger D. Woodard (2008), "Greek dialects", in: The Ancient Languages of Europe, ed. R. D. Woodard, Cambridge: Cambridge University Press, p. 51.  Hornblower, Simon (2002). "Macedon, Thessaly and Boiotia". The Greek World, 479-323 BC (Third ed.). Routledge. p. 90. ISBN 0-415-16326-9.  Hatzopoulos, Miltiades B. (2018). "Recent Research in the Ancient Macedonian Dialect: Consolidation and New Perspectives". In Giannakis, Georgios K.; Crespo, Emilio; Filos, Panagiotis (eds.). Studies in Ancient Greek Dialects: From Central Greece to the Black Sea. Walter de Gruyter. pp. 299–324. ISBN 978-3-11-053081-0.  Crespo, Emilio (2018). "The Softening of Obstruent Consonants in the Macedonian Dialect". In Giannakis, Georgios K.; Crespo, Emilio; Filos, Panagiotis (eds.). Studies in Ancient Greek Dialects: From Central Greece to the Black Sea. Walter de Gruyter. p. 329. ISBN 978-3-11-053081-0.  Dosuna, J. Méndez (2012). "Ancient Macedonian as a Greek dialect: A critical survey on recent work (Greek, English, French, German text)". In Giannakis, Georgios K. (ed.). Ancient Macedonia: Language, History, Culture. Centre for Greek Language. p. 145. ISBN 978-960-7779-52-6.  Brixhe, Cl. "Le Phrygien". In Fr. Bader (ed.), Langues indo-européennes, pp. 165-178, Paris: CNRS Editions.  Brixhe, Claude (2008). "Phrygian". In Woodard, Roger D (ed.). The Ancient Languages of Asia Minor. Cambridge University Press. pp. 69–80. ISBN 978-0-521-68496-5. "Unquestionably, however, Phrygian is most closely linked with Greek." (p. 72).  Obrador-Cursach, Bartomeu (1 December 2019). "On the place of Phrygian among the Indo-European languages". Journal of Language Relationship (in Russian). 17 (3–4): 243. doi:10.31826/jlr-2019-173-407. S2CID 215769896. "With the current state of our knowledge, we can affirm that Phrygian is closely related to Greek."  James Clackson. Indo-European Linguistics: An Introduction. Cambridge University Press, 2007, pp. 11-12.  Benjamin W. Fortson. Indo-European Language and Culture. Blackwell, 2004, p. 181.  Henry M. Hoenigswald, "Greek," The Indo-European Languages, ed. Anna Giacalone Ramat and Paolo Ramat (Routledge, 1998 pp. 228-260), p. 228. BBC: Languages across Europe: Greek  Fortson, Benjamin W. (2004). Indo-European language and culture: an introduction. Malden, Mass: Blackwell. pp. 226–231. ISBN 978-1405103152. OCLC 54529041.  Palmer, Leonard (1996). The Greek Language. Norman, OK: University of Oklahoma Press. p. 262. ISBN 978-0-8061-2844-3.  "Ministry publication" (PDF). www.edscuola.it.  "Ancient Greek 'to be taught in state schools'". The Daily Telegraph. 30 July 2010. Retrieved 3 May 2015.  "Now look, Latin's fine, but Greek might be even Beta" Archived 3 August 2010 at the Wayback Machine, TES Editorial, 2010 - TSL Education Ltd.  More primary schools to offer Latin and ancient Greek, The Telegraph, 26 November 2012  "Ωρολόγιο Πρόγραμμα των μαθημάτων των Α, Β, Γ τάξεων του Hμερησίου Γυμνασίου". Retrieved 3 May 2015.  "ΩΡΟΛΟΓΙΟ ΠΡΟΓΡΑΜΜΑ ΓΕΝΙΚΟΥ ΛΥΚΕΙΟΥ". Retrieved 3 May 2015.  "Annex to 2012 Greek statistics" (PDF). UNESCO. 2012. p. 26. Retrieved 14 December 2018.  "Proceedings of the 2nd Pan-hellenic Congress for the Promotion of Innovation in Education". II. 2016: 548.  Areios Potēr kai ē tu philosophu lithos, Bloomsbury 2004, ISBN 1-58234-826-X  "Asterix speaks Attic (classical Greek) - Greece (ancient)". Asterix around the World - the many Languages of Asterix. 22 May 2011.  "Enigmistica: nasce prima rivista in greco antico 2015". 4 May 2015. Retrieved 10 September 2018.  Rahlfs, Alfred, and Hanhart, Robert (eds.), Septuaginta, editio altera (Deutsche Bibelgesellschaft, 2006).  "Akropolis World News". www.akwn.net. Archived from the original on 22 September 2016. Further reading Adams, Matthew. "The Introduction of Greek into English Schools." Greece and Rome 61.1: 102–13, 2014. Allan, Rutger J. "Changing the Topic: Topic Position in Ancient Greek Word Order." Mnemosyne: Bibliotheca Classica Batava 67.2: 181–213, 2014. Athenaze: An Introduction to Ancient Greek (Oxford University Press). [A series of textbooks on Ancient Greek published for school use.] Bakker, Egbert J., ed. A Companion to the Ancient Greek Language. Oxford: Wiley-Blackwell, 2010. Beekes, Robert S. P. Etymological Dictionary of Greek. Leiden, The Netherlands: Brill, 2010. Chantraine, Pierre. Dictionnaire étymologique de la langue grecque, new and updated edn., edited by Jean Taillardat, Olivier Masson, & Jean-Louis Perpillou. 3 vols. Paris: Klincksieck, 2009 (1st edn. 1968–1980). Christidis, Anastasios-Phoibos, ed. A History of Ancient Greek: from the Beginnings to Late Antiquity. Cambridge: Cambridge University Press, 2007. Easterling, P and Handley, C. Greek Scripts: An Illustrated Introduction. London: Society for the Promotion of Hellenic Studies, 2001. ISBN 0-902984-17-9 Fortson, Benjamin W. Indo-European Language and Culture: An Introduction. 2d ed. Oxford: Wiley-Blackwell, 2010. Hansen, Hardy and Quinn, Gerald M. (1992) Greek: An Intensive Course, Fordham University Press Horrocks, Geoffrey. Greek: A History of the Language and its Speakers. 2d ed. Oxford: Wiley-Blackwell, 2010. Janko, Richard. "The Origins and Evolution of the Epic Diction." In The Iliad: A Commentary. Vol. 4, Books 13–16. Edited by Richard Janko, 8–19. Cambridge, UK: Cambridge Univ. Press, 1992. Jeffery, Lilian Hamilton. The Local Scripts of Archaic Greece: Revised Edition with a Supplement by A. W. Johnston. Oxford: Oxford Univ. Press, 1990. Morpurgo Davies, Anna, and Yves Duhoux, eds. A Companion to Linear B: Mycenaean Greek Texts and their World. Vol. 1. Louvain, Belgium: Peeters, 2008. Swiggers, Pierre and Alfons Wouters. "Description of the Constituent Elements of the (Greek) Language." In Brill’s Companion to Ancient Greek Scholarship. Edited by Franco Montanari and Stephanos Matthaios, 757–797. Leiden : Brill, 2015. External links 	Wikibooks has a book on the topic of: Ancient Greek 	Ancient Greek test of Wikipedia at Wikimedia Incubator 	Ancient Greek repository of Wikisource, the free library 	For a list of words relating to Ancient Greek, see the Ancient Greek language category of words in Wiktionary, the free dictionary. 	Greek Wikisource has original text related to this article: Texts in Ancient Greek Library resources about Ancient Greek Online books Resources in your library Resources in other libraries Classical Greek Online by Winfred P. Lehmann and Jonathan Slocum, free online lessons at the Linguistics Research Center at the University of Texas at Austin Online Greek resources – Dictionaries, grammar, virtual libraries, fonts, etc. Alpheios – Combines LSJ, Autenrieth, Smyth's grammar and inflection tables in a browser add-on for use on any web site Ancient Greek basic lexicon at the Global Lexicostatistical Database Ancient Greek Swadesh list of basic vocabulary words (from Wiktionary's Swadesh list appendix) "Greek Language" . Encyclopædia Britannica (11th ed.). 1911. Slavonic – online editor for Ancient Greek glottothèque - Ancient Indo-European Grammars online, an online collection of videos on various Ancient Indo-European languages, including Ancient Greek Grammar learning A more extensive grammar of the Ancient Greek language written by J. Rietveld Recitation of classics books Perseus Greek dictionaries Greek-Language.com – Information on the history of the Greek language, application of modern Linguistics to the study of Greek, and tools for learning Greek Free Lessons in Ancient Greek, Bilingual Libraries, Forum A critical survey of websites devoted to Ancient Greek Ancient Greek Tutorials – Berkeley Language Center of the University of California A Digital Tutorial For Ancient Greek Based on White's First Greek Book New Testament Greek Acropolis World News – A summary of the latest world news in Ancient Greek, Juan Coderch, University of St Andrews Classical texts Perseus – Greek and Roman Materials Ancient Greek Texts vte Ancient Greece vte Greek language vte Ages of Greek c. 3rd millennium BC	c. 1600–1100 BC	c. 800–300 BC	c. 300 BC – AD 330	c. 330–1453	Since 1453 Proto-Greek  Mycenaean  Ancient  Koine  Medieval  Modern  Authority control Edit this at Wikidata Categories: Ancient Greek languageAncient GreeceLanguages attested from the 9th century BC9th-century BC establishments in GreeceLanguages of Sicily Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadView sourceView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version In other projects Wikimedia Commons Wikibooks  Languages Български Deutsch Ελληνικά Français Latina Македонски Nederlands Shqip Türkçe 98 more Edit links This page was last edited on 3 August 2021, at 10:59 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki   Wiki Loves Monuments: Photograph a monument, help Wikipedia and win! Learn more Homeric Greek From Wikipedia, the free encyclopedia Jump to navigationJump to search Homeric Greek Language family	 Indo-European Proto-Greek language Southern Greek Attic–Ionic Greek Ionic Greek Homeric Greek Writing system	Greek alphabet Language codes ISO 639-3	– Linguist List	grc-hom Homeric Greek is the form of the Greek language that was used by Homer in the Iliad and Odyssey and in the Homeric Hymns. It is a literary dialect of Ancient Greek consisting mainly of Ionic and Aeolic, with a few forms from Arcadocypriot, and a written form influenced by Attic.[1] It was later named Epic Greek because it was used as the language of epic poetry, typically in dactylic hexameter, by poets such as Hesiod and Theognis of Megara. Compositions in Epic Greek may date from as late as the 3rd century BC, but it disappeared with the rise of Koine Greek.   Contents 1	Main features 1.1	Phonology 1.2	Nouns 1.3	Pronouns 1.4	Verbs 1.5	Adverbs 1.6	Particles 1.7	Other features 2	Vocabulary 3	Sample 4	See also 5	Notes 6	References 7	Bibliography 8	Further reading Main features In the following description, only forms that differ from those of later Greek are discussed. Omitted forms can usually be predicted from patterns seen in Ionic Greek.  Phonology Homeric Greek is like Ionic Greek, and unlike Classical Attic, in shifting almost all cases of long ᾱ to η: thus, Homeric Τροίη, ὥρη, πύλῃσι for Attic Τροίᾱ, ὥρᾱ, πύλαις/πύλαισι "Troy", "hour", "gates (dat.)".[2] Exceptions include nouns like θεᾱ́ "goddess", and the genitive plural of first-declension nouns and the genitive singular of masculine first-declension nouns: θεᾱ́ων, Ἀτρεΐδᾱο "of goddesses, of the son of Atreus".  Nouns First declension[3] The nominative singular of most feminine nouns ends in -η, rather than long -ᾱ, even after ρ, ε, and ι (an Ionic feature): χώρη for χώρᾱ. However, θεᾱ́ and some names end in long -ᾱ. Some masculine nouns have a nominative singular in short -ᾰ rather than -ης (ναύτης, Ἀτρεΐδης): ἱππότᾰ for Attic ἱππότης. The genitive singular of masculine nouns ends in -ᾱο or -εω, rather than -ου: Ἀτρεΐδᾱο for Attic Ἀτρείδου.[note 1] The genitive plural usually ends in -ᾱων or -εων: νυμφᾱ́ων for Attic νυμφῶν.[note 2] The dative plural almost always end in -ῃσι(ν) or -ῃς: πύλῃσιν for Attic πύλαις. Second declension Genitive singular: ends in -οιο, as well as -ου. For example, πεδίοιο, as well as πεδίου. Genitive and dative dual: ends in -οιϊν. Thus, ἵπποιϊν appears, rather than ἵπποιν. Dative plural: ends in -οισι(ν) and -οις. For example, φύλλοισι, as well as φύλλοις. Third declension Accusative singular: ends in -ιν, as well as -ιδα. For example, γλαυκῶπιν, as well as γλαυκώπιδα. Dative plural: ends in -εσσι and -σι. For example, πόδεσσι or ἔπεσσι. Homeric Greek lacks the quantitative metathesis present in later Greek (except in certain masculine α-stem genitive singulars): Homeric βασιλῆος instead of βασιλέως, πόληος instead of πόλεως βασιλῆα instead of βασιλέᾱ βασιλῆας instead of βασιλέᾱς βασιλήων instead of βασιλέων Homeric Greek sometimes uses different endings: πόληος alternates with πόλιος A note on nouns:  After short vowels, the reflex of Proto-Greek *ts can alternate between -σ- and -σσ- in Homeric Greek. This can be of metrical use. For example, τόσος and τόσσος are equivalent; μέσος and μέσσος; ποσί and ποσσί. A relic of the Proto-Greek instrumental case, the ending -φι(ν) (-οφι(ν)) can be used for the dative singular and plural of nouns and adjectives (occasionally for the genitive singular and plural, as well). For example, βίηφι (...by force), δακρυόφιν (...with tears), and ὄρεσφιν (...in the mountains). Pronouns First-person pronoun (singular "I", dual "we both", plural "we") Singular	Dual	Plural Nominative	ἐγώ, ἐγών	νῶι, νώ	ἡμεῖς, ἄμμες Genitive	ἐμεῖο, ἐμέο, ἐμεῦ, μεῦ, ἐμέθεν	νῶιν	ἡμείων, ἡμέων, ἀμμέων Dative	ἐμοί, μοι	ἡμῖν, ἄμμι(ν) Accusative	ἐμέ, με	νῶι, νώ	ἡμέας, ἧμας, ἄμμε Second-person pronoun (singular "you", dual "you both", plural "you") Singular	Dual	Plural Nominative	σύ, τύνη	σφῶϊ, σφώ	ὑμεῖς, ὔμμες Genitive	σεῖο, σέο, σεῦ, σευ, σέθεν, τεοῖο	σφῶϊν, σφῷν	ὑμέων, ὑμείων, ὔμμέων Dative	σοί, τοι, τεΐν	ὑμῖν, ὔμμι(ν) Accusative	σέ	σφῶϊ, σφώ	ὑμέας, ὔμμε Third-person pronoun (singular "he, she, it", dual "they both", plural "they") Singular	Dual	Plural Nominative	—	σφωέ	σφεῖς Genitive	οὗ, εἷο, ἕο, εὗ, ἕθεν	σφωΐν	σφείων, σφέων Dative	ἑοῖ, οἱ	σφι(ν), σφίσι(ν) Accusative	ἕ, ἑέ, μιν	σφωέ	σφε, σφέας, σφας Third-person singular pronoun ("he, she, it") (the relative) or rarely singular article ("the"): ὁ, ἡ, τό Third-person plural pronoun ("they") (the relative) or rarely plural article ("the"): nominative οἰ, αἰ, τοί, ταί, dative τοῖς, τοῖσι, τῇς, τῇσι, ταῖς. Interrogative pronoun, singular and plural ("who, what, which") Nominative	τίς Accusative	τίνα Genitive	τέο, τεῦ Dative	τέῳ Genitive	τέων Verbs Person endings -ν appears rather than -σαν. For example, ἔσταν for ἔστησαν in the third-person plural active. The third plural middle/passive often ends in -αται or -ατο; for example, ἥατο is equivalent to ἧντο. Tenses Future: Generally remains uncontracted. For example, ἐρέω appears instead of ἐρῶ or τελέω instead of τελῶ. Present or imperfect: These tenses sometimes take iterative form with the letters -σκ- penultimate with the ending. For example, φύγεσκον: 'they kept on running away' Aorist or imperfect: Both tenses can occasionally drop their augments. For example, βάλον may appear instead of ἔβαλον, and ἔμβαλε may appear instead of ἐνέβαλε. Homeric Greek does not have a historical present tense, but rather uses injunctives. Injunctives are replaced by the historical present in the post-Homeric writings of Thucydides and Herodotus.[4] Subjunctive The subjunctive appears with a short vowel. Thus, the form ἴομεν, rather than ἴωμεν. The second singular middle subjunctive ending appears as both -ηαι and -εαι. The third singular active subjunctive ends in -σι(ν). Thus, we see the form φορεῇσι, instead of φορῇ. Occasionally, the subjunctive is used in place of the future and in general remarks. Infinitive The infinitive appears with the endings -μεν, -μεναι, and -ναι, in place of -ειν and -ναι. For example, δόμεναι for δοῦναι; ἴμεν instead of ἰέναι; ἔμεν, ἔμμεν, or ἔμμεναι for εἶναι; and ἀκουέμεν(αι) in place of ἀκούειν. Contracted verbs In contracted verbs, where Attic employs an -ω-, Homeric Greek will use -οω- or -ωω- in place of -αο-. For example, Attic ὁρῶντες becomes ὁρόωντες. Similarly, in places where -αε- contracts to -α- or -αει- contracts to -ᾳ-, Homeric Greek will show either αα or αᾳ. Adverbs Adverbial suffixes -δε conveys a sense of 'to where'; πόλεμόνδε 'to the war' -δον conveys a sense of 'how'; κλαγγηδόν 'with cries' -θεν conveys a sense of 'from where'; ὑψόθεν 'from above' -θι conveys a sense of 'where'; ὑψόθι 'on high' Particles ἄρα, ἄρ, ῥα 'so' or 'next' (transition) τε 'and' (a general remark or a connective) Emphatics δή 'indeed' ἦ 'surely' περ 'just' or 'even' τοι 'I tell you ...' (assertion) Other features In most circumstances, Homeric Greek did not have available a true definite article. Ὁ, ἡ, τό and their inflected forms do occur, but they are in origin demonstrative pronouns.[5]  Vocabulary Homer (in the Iliad and the Odyssey) uses about 9,000 words, of which 1,382 are proper names. Of the 7,618 remaining words 2,307 are hapax legomena.[6][7]  Sample The Iliad, lines 1–7  Μῆνιν ἄειδε, θεά, Πηληϊάδεω Ἀχιλῆος οὐλομένην, ἣ μυρί’ Ἀχαιοῖς ἄλγε’ ἔθηκε, πολλὰς δ’ ἰφθίμους ψυχὰς Ἄϊδι προΐαψεν ἡρώων, αὐτοὺς δὲ ἑλώρια τεῦχε κύνεσσιν οἰωνοῖσί τε δαῖτα· Διὸς δ’ ἐτελείετο βουλή· ἐξ οὗ δὴ τὰ πρῶτα διαστήτην ἐρίσαντε Ἀτρεΐδης τε ἄναξ ἀνδρῶν καὶ δῖος Ἀχιλλεύς.  Robert Fitzgerald (1974):  Anger be now your song, immortal one, Akhilleus' anger, doomed and ruinous, that caused the Akhaians loss on bitter loss and crowded brave souls into the undergloom, leaving so many dead men—carrion for dogs and birds; and the will of Zeus was done. Begin it when the two men first contending broke with one another—                     the Lord Marshal Agamemnon, Atreus' son, and Prince Akhilleus.  See also 	Wiktionary has a category on Epic Ancient Greek Ancient Greek dialects Homeric texts Notes  Some suggest that -ᾱο may have originally been the more expected -ηο, with -ηο later being transcribed -ᾱο under the influence of other (literary) dialects, whilst others suggest that -ᾱο may have been an Aeolic form. (See λᾱός and Ποσειδᾱ́ων for expected ληός and Ποσειδήων.)  -ᾱων for expected -ηων would occur for the reasons given in Note 1. References  Stanford 1959, pp. lii, liii, the Homeric dialect  Stanford 1959, p. liii, vowels  Stanford 1959, pp. lvii–lviii, first declension  Carroll D. Osburn (1983). "The Historical Present in Mark as a Text-Critical Criterion". Biblica. 64 (4): 486–500. JSTOR 42707093.  Goodwin, William W. (1879). A Greek Grammar (pp 204). St Martin's Press.  The Iliad: A Commentary: Volume 5, Books 17-20, Geoffrey Stephen Kirk, Mark W. Edwards, Cambridge University Press, 1991, ISBN 978-0-521-31208-0 p53, footnote 72  Google preview Bibliography Pharr, Clyde. Homeric Greek: A Book for Beginners. University of Oklahoma Press, Norman, new edition, 1959. Revised edition: John Wright, 1985. ISBN 0-8061-1937-3. First edition of 1920 in public domain. Stanford, William Bedell (1959) [1947]. "Introduction, Grammatical Introduction". Homer: Odyssey I-XII. 1 (2nd ed.). Macmillan Education Ltd. pp. ix–lxxxvi. ISBN 1-85399-502-9. Further reading Library resources about Homeric Greek Online books Resources in your library Resources in other libraries Bakker, Egbert J., ed. 2010. A companion to the Ancient Greek language. Oxford: Wiley-Blackwell. Christidis, Anastasios-Phoivos, ed. 2007. A history of Ancient Greek: From the beginnings to Late Antiquity. Cambridge, UK: Cambridge University Press. Colvin, Stephen C. 2007. A historical Greek reader: Mycenaean to the koiné. Oxford: Oxford University Press. Edwards, G. Patrick. 1971. The language of Hesiod in its traditional context. Oxford: Blackwell. Hackstein, Olav. 2010. "The Greek of epic." In A companion to the Ancient Greek language. Edited by Egbert J. Bakker, 401–23. Oxford: Wiley-Blackwell. Horrocks, Geoffrey C. 1987. "The Ionian epic tradition: Was there an Aeolic phase in its development?" Minos 20–22: 269–94. ––––. 2010. Greek: A history of the language and its speakers. 2nd ed. Oxford: Wiley-Blackwell. Janko, Richard. 1982. Homer, Hesiod, and the Hymns: Diachronic development in epic diction. Cambridge, UK: Cambridge University Press. ––––. 1992. "The origins and evolution of the Epic diction." In The Iliad: A commentary. Vol. 4, Books 13–16. Edited by Richard Janko, 8–19. Cambridge, UK: Cambridge University Press. Lord, Albert B. 1960. The singer of tales. Cambridge, MA: Harvard University Press. Nagy, Gregory. 1995. "An evolutionary model for the making of Homeric poetry: Comparative perspectives." In The ages of Homer. Edited by Jane Burr Carter and Sarah Morris, 163–79. Austin: University of Texas Press. Palmer, Leonard R. 1980. The Greek language. London: Faber & Faber. Parry, Milman. 1971. The making of Homeric verse: The collected papers of Milman Parry. Edited by Adam Parry. Oxford: Clarendon. Reece, Steve. 2009. Homer's Winged Words: the Evolution of Early Greek Epic Diction in the Light of Oral Theory. Amsterdam: Brill. West, Martin L. 1988. "The rise of the Greek epic." Journal of Hellenic Studies 108: 151–72. vte Ancient Greece vte Greek language vte Ages of Greek c. 3rd millennium BC	c. 1600–1100 BC	c. 800–300 BC	c. 300 BC – AD 330	c. 330–1453	Since 1453 Proto-Greek  Mycenaean  Ancient  Koine  Medieval  Modern  Authority control: National libraries Edit this at Wikidata	 France (data) Categories: Languages with Linglist codeHomeric GreekVarieties of Ancient Greek Navigation menu Not logged in Talk Contributions Create account Log in ArticleTalk ReadEditView history Search Search Wikipedia Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version  Languages Asturianu Català Ελληνικά Español Français Bahasa Indonesia Italiano Polski Português 7 more Edit links This page was last edited on 4 July 2021, at 18:13 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License; additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policyAbout WikipediaDisclaimersContact WikipediaMobile viewDevelopersStatisticsCookie statementWikimedia FoundationPowered by MediaWiki